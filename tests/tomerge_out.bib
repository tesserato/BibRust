@article{year_zanon1,
author = {Fabio Zanon},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {O viol/~ao no Brasil depois de},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@article{year_zanon,
author = {Fábio Zanon},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {portuguese},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {8},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {O violão no Brasil depois de Villa-Lobos},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {tesse},
}

@book{year_ye_etal1,
author = {Ronald E Walpole and Raymond H Myers and Sharon L Myers and Keying Ye},
editor = { },
translator = { },
__markedentry = {},
abstract = {Ninth edition.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {OCLC: 1014366070},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {134115856},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {791},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Probability /////////& statistics for engineers //},
subtitle = {},
timestamp = {},
title = {Probability & statistics for engineers & scientists : MyStatLab update},
titleaddon = {},
unidentified = {},
url = {https://books.google.com/books?id=aOKHrgEACAAJ},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_ye_etal,
author = {Ronald E. Walpole and Raymond H. Myers and Sharon L. Myers and Keying Ye},
editor = { },
translator = { },
__markedentry = {},
abstract = {Ninth edition.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {OCLC: 1014366070},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {134115856},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {791},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Probability /////////& statistics for engineers /////////& scientists},
subtitle = {},
timestamp = {},
title = {Probability & statistics for engineers & scientists : MyStatLab update},
titleaddon = {},
unidentified = {},
url = {https://books.google.com/books?id=aOKHrgEACAAJ},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@article{year_wellman_etal2,
author = {Junling Hu and Michael P Wellman},
editor = { },
translator = { },
__markedentry = {},
abstract = {We extend Q-learning to a noncooperative multiagent context, using the framework of generalsum stochastic games. A learning agent maintains Q-functions over joint actions, and performs updates based on assuming Nash equilibrium behavior over the current Q-values. This learning protocol provably converges given certain restrictions on the stage games (deﬁned by Q-values) that arise during learning. Experiments with a pair of two-player grid games suggest that such restrictions on the game structure are not necessarily required. Stage games encountered during learning in both grid environments violate the conditions. However, learning consistently converges in the ﬁrst grid game, which has a unique equilibrium Q-function, but sometimes fails to converge in the second, which has three different equilibrium Q-functions. In a comparison of ofﬂine learning performance in both games, we ﬁnd agents are more likely to reach a joint optimal path with Nash Q-learning than with a single-agent Q-learning method. When at least one agent adopts Nash Q-learning, the performance of both agents is better than using single-agent Q-learning. We have also implemented an online version of Nash Q-learning that balances exploration with exploitation, yielding improved performance.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {31},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Nash Q-Learning for General-Sum Stochastic Games},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Game Theory/Nash Q-Learning for General-Sum Stochastic Games - Hu and Wellman.pdf},
mendeley-tags = {game theory,#merged,tesse},
}

@article{year_wellman_etal,
author = {Junling Hu and Michael P Wellman},
editor = { },
translator = { },
__markedentry = {},
abstract = {In this paper, we adopt general-sum stochastic games as a framework for multiagent reinforcement learning. Our work extends previous work by Littman on zero-sum stochastic games to a broader framework. We design a multiagent Q-learning method under this framework, and prove that it converges to a Nash equilibrium under speci ed conditions. This algorithm is useful for nding the optimal strategy when there exists a unique Nash equilibrium in the game. When there exist multiple Nash equilibria in the game, this algorithm should be combined with other learning techniques to nd optimal strategies.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {9},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Multiagent Reinforcement LeAarlgnoinrigt:hmTheoretical Framework and an},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@article{year_vitelli_etal1,
author = {Aran Nayebi and Matt Vitelli},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {1--6},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {GRUV : Algorithmic Music Generation using Recurrent Neural Networks},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@article{year_vitelli_etal,
author = {Aran Nayebi and Matt Vitelli},
editor = { },
translator = { },
__markedentry = {},
abstract = {We compare the performance of two different types of recurrent neural networks (RNNs) for the task of algorithmic music generation, with audio waveforms as input. In particular, we focus on RNNs that have a sophisticated gating mechanism, namely, the Long Short-Term Memory (LSTM) network and the recently introduced Gated Recurrent Unit (GRU). Our results indicate that the generated outputs of the LSTM network were signiﬁcantly more musically plausible than those of the GRU.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {6},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {GRUV: Algorithmic Music Generation using Recurrent Neural Networks},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {tesse},
}

@book{year_the3,
author = {Keras: The},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {Keras Documentation, [s.d.]. Dispon�vel em},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {<},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Python Deep Learning library},
titleaddon = {},
unidentified = {},
url = {https://keras.io/%3E},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {#merged,#corrupted author},
}

@book{year_the2,
author = {Keras: The},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {Keras Documentation, [s.d.]. Disponvel em},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {<},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Python Deep Learning library},
titleaddon = {},
unidentified = {},
url = {https://keras.io/},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@article{year_shene_etal1,
author = {John Lowther and Ching-Kuang Shene},
editor = { },
translator = { },
__markedentry = {},
abstract = {This paper describes the authors' approach of introducing important concepts and algorithms of B-splines to junior computer science students with the help of a pedagogical tool DesignMentor. This approach is non-mathematical and intuitive, and has been used and reﬁned in the past six years.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {computer graphics},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {5},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Teaching B-splines Is Not Difficult!},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Computer Graphics/2003 Teaching B Splines Is Not Difficult!_LowtherTeaching.pdf},
mendeley-tags = {computer graphics,#merged,#corrupted author},
}

@article{year_salih1,
author = {A Salih},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {24},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Second-Order Wave Equation},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {#merged,acoustics},
}

@article{year_ramshaw1,
author = {Lyle Ramshaw},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {173},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {On Multiplying Points : The Paired Algebras of Forms and Sites},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/On multiplying points the paired algebras of forms and sites - Ramshaw.pdf},
mendeley-tags = {tesse,#merged},
}

@book{year_pinedo1,
author = {Michael Pinedo},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {OCLC: 945375528},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {Fifth Edit},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97833225},
issn = {},
journal = {},
journaltitle = {},
keywords = {Production scheduling},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Springer},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Scheduling},
subtitle = {},
timestamp = {},
title = {Scheduling: theory, algorithms, and systems},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_pinedo,
author = {Michael L Pinedo},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97833212},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Michael L. Pinedo},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Non-Fiction/Optimization/2016 Scheduling - Pinedo.pdf},
}

@book{year_pastine_etal1,
author = {Ivan Pastine and Tuvana Pastine},
editor = { },
translator = { },
__markedentry = {},
abstract = {When should you adopt an aggressive business strategy? How do we make decisions when we don't have all the information? What makes international environmental cooperation possible?Game theory is the study of how we make a decision when the outcome of our moves depends on the decisions of someone else. Economists Ivan and Tuvana Pastine explain why, in these situations, we sometimes cooperate, sometimes clash, and sometimes act in a way that seems completely random.Stylishly brought to life by award-winning cartoonist Tom Humberstone, Game Theory will help readers understand behaviour in everything from our social lives to business, global politics to evolutionary biology. It provides a thrilling new perspective on the world we live in.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97817912},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Icon Books Ltd},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Introducing Game Theory},
subtitle = {},
timestamp = {},
title = {Introducing Game Theory: A Graphic Guide},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_pastine_etal,
author = {Ivan Pastine and Tuvana Pastine},
editor = { },
translator = { },
__markedentry = {},
abstract = {When should you adopt an aggressive business strategy? How do we make decisions when we don't have all the information? What makes international environmental cooperation possible?Game theory is the study of how we make a decision when the outcome of our moves depends on the decisions of someone else. Economists Ivan and Tuvana Pastine explain why, in these situations, we sometimes cooperate, sometimes clash, and sometimes act in a way that seems completely random.Stylishly brought to life by award-winning cartoonist Tom Humberstone, Game Theory will help readers understand behaviour in everything from our social lives to business, global politics to evolutionary biology. It provides a thrilling new perspective on the world we live in.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Icon Books Ltd},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Introducing Game Theory},
subtitle = {},
timestamp = {},
title = {<Introducing Game Theory_ A Graphic Guide - Ivan Pastine & Tuvana Pastine.pdf>},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_papert1,
author = {Seymour A Papert},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97802612},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Perceptrons},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_papert,
author = {Seymour A Papert},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {262631113},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Perceptrons},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@book{year_martins1,
author = {Andr'ea Martins},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Central de Concursos / Degrau Cultural},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {L/'INGUA PORTUGUESA 1.000 Exerc/'icios Quest/~oes simuladas e quest/~oes de concursos anteriores com os gabaritos},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {#corrupted author,#merged},
}

@book{year_martins,
author = {Andréa Martins},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {portuguese},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Central de Concursos / Degrau Cultural},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {LÍNGUA PORTUGUESA 1.000 Exercícios Questões simuladas e questões de concursos anteriores com os gabaritos},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@unpublished{year_korner1,
author = {T W Korner},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {harmonic analysis},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {60},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {A First Look at Fourier Analysis},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {harmonic analysis},
}

@article{year_korner,
author = {T W K"orner},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {458},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Vectors, Pure and Applied},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {#merged,#corrupted author},
}

@article{year_jolley_etal,
author = {L B W Jolley and L B W Jolley},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {New York},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Summation series},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New BOOKS/JolleySummation Summation of Series.pdf},
}

@book{year_jolley,
author = {L. B. W. Jolley},
editor = { },
translator = { },
__markedentry = {},
abstract = {Over 1,100 common series, all grouped for easy reference. Arranged by category, these series include arithmetical and geometrical progressions, powers and products of natural numbers, figurate and polygonal numbers, inverse natural numbers, exponential and logarithmic series, binomials, simple inverse products, factorials, trigonometrical and hyperbolic expansions, and additional series. 1961 edition.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {Second Revised Edition edition},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97804912},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {New York},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {251},
place = {},
pmid = {},
primaryclass = {},
publisher = {Dover Publications Inc.},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Summation of Series},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {mathematics,tesse},
}

@book{year_johnston_etal1,
author = {Prof Nigel Slack and  Br and Prof Alistair On-Jones and Prof Robert Johnston},
editor = { },
translator = { },
__markedentry = {},
abstract = {Were you looking for the book with access to MyOMLab? This product is the book alone and does NOT come with access to MyOMLab. Buy Operations Management, 8th edition with MyOMLab access card (ISBN 9781292098777) if you need access to MyOMLab as well, and save money on this resource. You will also need a course ID from your instructor to access MyOMLab. Operations management is important, exciting, challenging /ldotsand everywhere you look! Important, because it enables organizations to provide services and products that we all need Exciting, because it is central to constant changes in customer preference, networks of supply and demand, and developments in technology Challenging, because solutions must be must be financially sound, resource-efficient, as well as environmentally and socially responsible And everywhere, because in our daily lives, whether at work or at home, we all experience and manage processes and operations. New features: There are now more than 110 of the popular ‘Operations in Practice' examples throughout the book, over 40 ///% of which are new. The importance of sustainability and Corporate Social Responsibility (CSR) has been emphasized further, and included throughout the book. We have even further strengthened the emphasis on the idea that ‘operations management' is relevant to every type of business and all functional areas of the organization. Many new ideas in operations management have been incorporated, including the ‘three level' approach to performance, the relationship between innovation, creativity and design, crowdsourcing, ideas management, business ecosystems, triadic relationships, office layout, telecommuting and organisational ‘ambidexterity'. However, we have retained the emphasis on the foundations of the subject. Six of the 19 cases at the end of the chapter are new (but the old ones are still available on the web site), and provide an up-to-date selection of operations issues. Operations Management focuses on the sustainable and socially responsible imperatives of operations management, using over 120 cases and illustrations of real-life operations around the world, including Apple, M/'edecins Sans Fronti/eres, Amazon, Ecover, Dyson, Disneyland Paris, Google, The North Face, and many more. This is 24-carat excellence'Par /AAhlstr/"om, Torsten and Ragnar S/"oderberg Chair of Business Administration, Stockholm School of Economics 'Operations Management is engaging and accessible, but it never dumbs-down. The book is comprehensive, but not overwhelming. Students hold on to this one; it's a ‘keeper'.'Michael Shulver, Birmingham Business School 'This continues to be the definitive operations Management text /ldotswritten by the masters of the field!'Dr Ross Ritchie, Lecturer in Operations Management, Loughborough University 'An essential text packed full of up-to-date examples that really bring the subject to life'Claire Moxham, University of Liverpool Management School 'An excellent book for those studying operations management. This book provides great illustrations to seamlessly link theory with practice' Frank Wiengarten, ESADE Business School Operations Management by Nigel Slack and Alistair Brandon-Jones is quite simply the best text on operations management. Comprehensive, engaging and insightful, I cannot recommend this book highly enough'Professor Andy Neely, Head, Institute for Manufacturing, Cambridge University Carrie Queenan, University of South Carolina Peter Race, Henley Business School, University of Reading},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {8},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97812912},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Pearson},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Operations Management},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {#corrupted author},
}

@book{year_johnston_etal,
author = {Prof Nigel Slack and  Br and Prof Alistair on-Jones and Prof Robert Johnston},
editor = { },
translator = { },
__markedentry = {},
abstract = {Were you looking for the book with access to MyOMLab? This product is the book alone and does NOT come with access to MyOMLab. Buy Operations Management, 8th edition with MyOMLab access card (ISBN 9781292098777) if you need access to MyOMLab as well, and save money on this resource. You will also need a course ID from your instructor to access MyOMLab. Operations management is important, exciting, challenging /ldots and everywhere you look! Important, because it enables organizations to provide services and products that we all need Exciting, because it is central to constant changes in customer preference, networks of supply and demand, and developments in technology Challenging, because solutions must be must be financially sound, resource-efficient, as well as environmentally and socially responsible And everywhere, because in our daily lives, whether at work or at home, we all experience and manage processes and operations. New features: There are now more than 110 of the popular ‘Operations in Practice' examples throughout the book, over 40 ///% of which are new. The importance of sustainability and Corporate Social Responsibility (CSR) has been emphasized further, and included throughout the book. We have even further strengthened the emphasis on the idea that ‘operations management' is relevant to every type of business and all functional areas of the organization. Many new ideas in operations management have been incorporated, including the ‘three level' approach to performance, the relationship between innovation, creativity and design, crowdsourcing, ideas management, business ecosystems, triadic relationships, office layout, telecommuting and organisational ‘ambidexterity'. However, we have retained the emphasis on the foundations of the subject. Six of the 19 cases at the end of the chapter are new (but the old ones are still available on the web site), and provide an up-to-date selection of operations issues. Operations Management focuses on the sustainable and socially responsible imperatives of operations management, using over 120 cases and illustrations of real-life operations around the world, including Apple, M/'edecins Sans Fronti/eres, Amazon, Ecover, Dyson, Disneyland Paris, Google, The North Face, and many more. This is 24-carat excellence'Par /AAhlstr/"om, Torsten and Ragnar S/"oderberg Chair of Business Administration, Stockholm School of Economics 'Operations Management is engaging and accessible, but it never dumbs-down. The book is comprehensive, but not overwhelming. Students hold on to this one; it's a ‘keeper'.'Michael Shulver, Birmingham Business School 'This continues to be the definitive operations Management text /ldots written by the masters of the field!'Dr Ross Ritchie, Lecturer in Operations Management, Loughborough University 'An essential text packed full of up-to-date examples that really bring the subject to life'Claire Moxham, University of Liverpool Management School 'An excellent book for those studying operations management. This book provides great illustrations to seamlessly link theory with practice' Frank Wiengarten, ESADE Business School Operations Management by Nigel Slack and Alistair Brandon-Jones is quite simply the best text on operations management. Comprehensive, engaging and insightful, I cannot recommend this book highly enough'Professor Andy Neely, Head, Institute for Manufacturing, Cambridge University Carrie Queenan, University of South Carolina Peter Race, Henley Business School, University of Reading},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {8},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97812912},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {Pearson},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Operations Management},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
}

@misc{year_farnum2,
author = {Larissa Farnum},
editor = { },
translator = { },
__markedentry = {},
abstract = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2--3},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301 General Notation:},
titleaddon = {},
unidentified = {},
url = {https://www.academia.edu/8924647/Review///////%5C%5C_of///////%5C%5C_differentiation///////%5C%5C_and///////%5C%5C_integration///////%5C%5C_rules///////%5C%5C_from///////%5C%5C_Calculus///////%5C%5C_I///////%5C%5C_and///////%5C%5C_II///////%5C%5C_for/////},
urldate = {},
volume = {2},
volumes = {},
year = {},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/review of differentiation and integration rules from calculus i and ii for - farnum.pdf},
}

@misc{year_farnum1,
author = {Larissa Farnum},
editor = { },
translator = { },
__markedentry = {},
abstract = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2--3},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301 General Notation:},
titleaddon = {},
unidentified = {},
url = {https://www.academia.edu/8924647/Review///////%5C%5C_of///////%5C%5C_differentiation///////%5C%5C_and///////%5C%5C_integration///////%5C%5C_rules///////%5C%5C_from///////%5C%5C_Calculus///////%5C%5C_I///////%5C%5C_and///////%5C%5C_II///////%5C%5C_for///////%5C%5C_Ordinary///////%5C%5C_Differential///////%5C%5C_Equations///////%5C%5C_3301},
urldate = {},
volume = {2},
volumes = {},
year = {},
}

@misc{year_farnum,
author = {Larissa Farnum},
editor = { },
translator = { },
__markedentry = {},
abstract = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations},
titleaddon = {},
unidentified = {},
url = {https://www.academia.edu/8924647/Review/////////_of/////////_differentiation/////////_and/////////_integration/////////_rules/////////_from/////////_Calculus/////////_I/////////_and/////////_II/////////_for/////////_Ordinary/////////_Differential/////////_Equations/////////_3301},
urldate = {01/04/2019},
volume = {},
volumes = {},
year = {},
}

@article{2016_kavukcuoglu_etal6,
author = {Aaron van den Oord and  S and er Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew W. Senior and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {[tesse:1]},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = {},
bibsource = {dblp computer science bibliography, https://dblp.org},
biburl = {https://dblp.org/rec/bib/journals/corr/OordDZSVGKSK16},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1609.03499},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {CoRR},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {Mon, 13 Aug 2018 16:49:15 +0200},
title = {WaveNet: A Generative Model for Raw Audio},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1609.03499},
urldate = {},
volume = {abs/1609.03499},
volumes = {},
year = {2016},
}

@unpublished{2016_kavukcuoglu_etal5,
author = {Aaron van den Oord and S Dieleman and  Er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu and Ryuichi Yamamoto and Aaron van den Oord and S Dieleman and  Er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
acmid = {},
address = {DeepMind Dispon�vel em},
adsnote = {},
adsurl = {},
annotation = {},
annote = {From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - van den Oord, Aaron; Dieleman, S; er; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray; Yamamoto, Ryuichi; van den Oord, Aaron; Dieleman, S; er; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray)From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Yamamoto, Ryuichi; Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray)From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray). arXiv preprint},
archiveprefix = {arXiv},
arxivid = { {1609.03499},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1609.03499},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {online},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {1--15},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {<},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {WaveNet: A Generative Model for Raw Audio},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1609.03499,https://deepmind.com/blog/wavenet-generative-model-raw-audio/%3E},
urldate = {},
volume = {abs/1609.0},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Artificial Intelligence/Neural Networks/GAN/2016OordWaveneta WaveNet_ a Generative Model for Raw Audio.pdf},
}

@article{2016_kavukcuoglu_etal4,
author = {Aaron van den Oord and S Dieleman and  er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1609.03499},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1609.03499},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {online},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {arXiv preprint arXiv:1609.03499},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {<},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {WaveNet: A Generative Model for Raw Audio},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1609.03499},
urldate = {},
volume = {abs/1609.03499},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Artificial Intelligence/Neural Networks/GAN/2016OordWaveneta WaveNet_ a Generative Model for Raw Audio.pdf},
mendeley-tags = {#merged},
}

@article{2016_kavukcuoglu_etal3,
author = {A"aron Van Den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1606.05328},},
bibsource = {dblp computer science bibliography, https://dblp.org},
biburl = {https://dblp.org/rec/bib/journals/corr/OordKVEGK16},
booktitle = {},
collection = {},
comment = {},
date = {2016},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1606.05328},},
eprintclass = {},
eprinttype = {arXiv},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
journaltitle = {CoRR},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {4797--4805},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {Mon, 13 Aug 2018 16:46:40 +0200},
title = {Conditional image generation with PixelCNN decoders},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1606.05328},
urldate = {},
volume = {abs/1606.05328},
volumes = {},
year = {2016},
mendeley-tags = {#merged},
}

@inproceedings{2016_kavukcuoglu_etal2,
author = {Aaron van den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = { {1601.06759},},
bibsource = {},
biburl = {},
booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
collection = {},
comment = {},
date = {2016},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1601.06759},},
eprintclass = {},
eprinttype = {arXiv},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97815112},
issn = {},
journal = {arXiv preprint arXiv:1601.06759},
journaltitle = {arXiv preprint arXiv:1601.06759},
keywords = {image synthesis},
langid = {},
language = {},
location = {New York, New York, USA},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {1747--1756},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {PMLR},
qualityassured = {},
rights = {},
school = {},
series = {Proceedings of Machine Learning Research},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Pixel Recurrent Neural Networks},
titleaddon = {},
unidentified = {},
url = {http://proceedings.mlr.press/v48/oord16.html},
urldate = {},
volume = {48},
volumes = {},
year = {2016},
mendeley-tags = {image synthesis,#merged},
}

@article{2016_kavukcuoglu_etal12,
author = {Nal Kalchbrenner and Lasse Espeholt and Karen Simonyan and Aaron van den Oord and Alex Graves and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efﬁcient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive ﬁeld. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We ﬁnd that the latent alignment structure contained in the representations reﬂects the expected alignment between the tokens.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {1610.10099v2},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {31/10/2016},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1610.10099},},
eprintclass = {},
eprinttype = {arxiv},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {},
journaltitle = {arXiv:1610.10099 [cs]},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Neural Machine Translation in Linear Time},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1610.10099},
urldate = {26/03/2019},
volume = {},
volumes = {},
year = {},
mendeley-tags = {tesse},
}

@article{2016_kavukcuoglu_etal11,
author = {A"aron Van Den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two- dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNel dataset. Samples generated from the model appear crisp, varied and globally coherent.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1601.06759},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1601.06759},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97815112},
issn = {},
journal = {33rd International Conference on Machine Learning, ICML 2016},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2611--2620},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Pixel recurrent neural networks},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {4},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Artificial Intelligence/Neural Networks/2016OordPixela Pixel Recurrent Neural Networks.pdf},
mendeley-tags = {#merged},
}

@article{2016_kavukcuoglu_etal10,
author = {A"aron Van Den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1606.05328},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1606.05328},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {4797--4805},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Conditional image generation with PixelCNN decoders},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {2016},
volumes = {},
year = {2016},
}

@article{2016_kavukcuoglu_etal,
author = {A"aron Van Den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
editor = { },
translator = { },
__markedentry = {},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1606.05328},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1606.05328},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {4797--4805},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Conditional image generation with PixelCNN decoders},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1606.05328},
urldate = {},
volume = {abs/1606.0},
volumes = {},
year = {2016},
mendeley-tags = {#corrupted author},
}

@article{2016_joly_etal1,
author = {Juliette Chabassier and Marc Duruflé and Patrick Joly},
editor = { },
translator = { },
__markedentry = {},
abstract = {This article is the second of a series of two papers devoted to the numerical simulation of the piano. It concerns the numerical aspects of the work, the implementation of a piano code and the presentation of corresponding simulations. The main diﬃculty is time discretisation and stability is achieved via energy methods. Numerical illustrations are provided for a realistic piano and compared to experimental recordings.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {2016-01},
day = {},
doi = {10.1051/m2an/2015007},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {0764-583X},
journal = {},
journaltitle = {ESAIM: Mathematical Modelling and Numerical Analysis},
keywords = {},
langid = {english},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {1},
numpages = {},
organization = {},
pages = {93--133},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {Time domain simulation of a piano. Part 2},
subtitle = {},
timestamp = {},
title = {Time domain simulation of a piano. Part 2: numerical aspects},
titleaddon = {},
unidentified = {},
url = {},
urldate = {26/03/2019},
volume = {50},
volumes = {},
year = {},
mendeley-tags = {piano},
}

@article{2016_joly_etal,
author = {Juliette Chabassier and Marc Durufl'e and Patrick Joly},
editor = { },
translator = { },
__markedentry = {},
abstract = {This article is the second of a series of two papers devoted to the numerical simulation of the piano. It concerns the numerical aspects of the work, the implementation of a piano code and the presentation of corresponding simulations. The main difficulty is time discretization and stability is achieved via energy methods. Numerical illustrations are provided for a realistic piano and compared to experimental recordings.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {10.1051/m2an/2015007},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {12903841},
journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
journaltitle = {},
keywords = {Energy preserving schemes,Numerical methods,Piano model},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {1},
numpages = {},
organization = {},
pages = {93--133},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Time domain simulation of a piano. Part 2: Numerical aspects},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {50},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Acoustics/Piano/2016 Time Domain Simulation of a Piano. Part 2_ Numerical Aspects_2016ChabassierTime.pdf},
mendeley-tags = {#merged},
}

@book{2016_johnston_etal,
author = {Prof Nigel Slack and  Br and Prof Alistair on-Jones and Prof Robert Johnston},
editor = { },
translator = { },
__markedentry = {},
abstract = {Were you looking for the book with access to MyOMLab? This product is the book alone and does NOT come with access to MyOMLab. Buy Operations Management, 8th edition with MyOMLab access card (ISBN 9781292098777) if you need access to MyOMLab as well, and save money on this resource. You will also need a course ID from your instructor to access MyOMLab. Operations management is important, exciting, challenging … and everywhere you look! Important, because it enables organizations to provide services and products that we all need Exciting, because it is central to constant changes in customer preference, networks of supply and demand, and developments in technology Challenging, because solutions must be must be financially sound, resource-efficient, as well as environmentally and socially responsible And everywhere, because in our daily lives, whether at work or at home, we all experience and manage processes and operations. New features: There are now more than 110 of the popular ‘Operations in Practice’ examples throughout the book, over 40 ///% of which are new. The importance of sustainability and Corporate Social Responsibility (CSR) has been emphasized further, and included throughout the book. We have even further strengthened the emphasis on the idea that ‘operations management’ is relevant to every type of business and all functional areas of the organization. Many new ideas in operations management have been incorporated, including the ‘three level’ approach to performance, the relationship between innovation, creativity and design, crowdsourcing, ideas management, business ecosystems, triadic relationships, office layout, telecommuting and organisational ‘ambidexterity’. However, we have retained the emphasis on the foundations of the subject. Six of the 19 cases at the end of the chapter are new (but the old ones are still available on the web site), and provide an up-to-date selection of operations issues. Operations Management focuses on the sustainable and socially responsible imperatives of operations management, using over 120 cases and illustrations of real-life operations around the world, including Apple, Médecins Sans Frontières, Amazon, Ecover, Dyson, Disneyland Paris, Google, The North Face, and many more. This is 24-carat excellence'Par Åhlström, Torsten and Ragnar Söderberg Chair of Business Administration, Stockholm School of Economics 'Operations Management is engaging and accessible, but it never dumbs-down. The book is comprehensive, but not overwhelming. Students hold on to this one; it’s a ‘keeper’.'Michael Shulver, Birmingham Business School 'This continues to be the definitive operations Management text … written by the masters of the field!'Dr Ross Ritchie, Lecturer in Operations Management, Loughborough University 'An essential text packed full of up-to-date examples that really bring the subject to life'Claire Moxham, University of Liverpool Management School 'An excellent book for those studying operations management. This book provides great illustrations to seamlessly link theory with practice' Frank Wiengarten, ESADE Business School Operations Management by Nigel Slack and Alistair Brandon-Jones is quite simply the best text on operations management. Comprehensive, engaging and insightful, I cannot recommend this book highly enough'Professor Andy Neely, Head, Institute for Manufacturing, Cambridge University Carrie Queenan, University of South Carolina Peter Race, Henley Business School, University of Reading},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {24/06/2016},
day = {},
doi = {},
ean = {},
edition = {8},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97812912},
issn = {},
journal = {},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {Harlow, England London New York},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {},
pagetotal = {752},
place = {},
pmid = {},
primaryclass = {},
publisher = {Pearson},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Operations Management},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {},
mendeley-tags = {tesse},
}

@article{2016_john_etal,
author = {Author Robert and L Mathis John},
editor = { },
translator = { },
__markedentry = {},
abstract = {After you have read this chapter, you should be able to: q Identify four major HR challenges currently facing organizations and managers. q List and define each of the seven major categories of HR activities. q Identify the three different roles of HR management. q Discuss the three dimensions associated with HR management as a strategic business contributor. q Explain why HR professionals and operating managers must view HR management as an interface. q Discuss why ethical issues and professionalism affect HR management as a career field. 3 HR TRANSITIONS},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {324289588},
issn = {},
journal = {Workforce},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {156},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Changing Nature of Human Resource Management After you have read this chapter , you should be able to : HR Management Contributes to},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New BOOKS/Gary Dessler - Human Resource Management - 9th Edition.pdf},
}

@article{2016_jinjun_etal2,
author = {Shizhou Zhang and Yihong Gong and Jinjun Wang and Zhang Shizhou and Yihong Gong and Wang Jinjun},
editor = { },
translator = { },
__markedentry = {},
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human vi-sual cortex, and propose a DCNN performance im-provement method without the need for increasing the network complexity. Inspired by the category-selective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As ex-perimental results show, when applying the pro-posed method to the " Quick " model and NIN models, image classification performances are re-markably improved on four widely used bench-mark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
journaltitle = {},
keywords = {Machine Learning,image synthesis},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2343--2349},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Improving DCNN performance with sparse category-selective objective function},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {2016-Janua},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/Improving DCNN Performance with Sparse Category-Selective Objective Function - Zhang et al.pdf},
mendeley-tags = {image synthesis,#merged},
}

@article{2016_jinjun_etal1,
author = {Zhang Shizhou and Yihong Gong and Wang Jinjun},
editor = { },
translator = { },
__markedentry = {},
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human visual cortex, and propose a DCNN performance improvement method without the need for increasing the network complexity. Inspired by the categoryselective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As experimental results show, when applying the proposed method to the "Quick" model and NIN models, image classification performances are remarkably improved on four widely used benchmark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
journaltitle = {},
keywords = {Machine Learning},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2343--2349},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Improving DCNN performance with sparse category-selective objective function},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {2016-January},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/Improving DCNN Performance with Sparse Category-Selective Objective Function - Zhang et al.pdf},
}

@article{2016_jinjun_etal,
author = {Zhang Shizhou and Yihong Gong and Wang Jinjun},
editor = { },
translator = { },
__markedentry = {},
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human visual cortex, and propose a DCNN performance improvement method without the need for increasing the network complexity. Inspired by the categoryselective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As experimental results show, when applying the proposed method to the "Quick" model and NIN models, image classification performances are remarkably improved on four widely used benchmark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
journaltitle = {},
keywords = {Machine Learning,image synthesis},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {2343--2349},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Improving DCNN performance with sparse category-selective objective function},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {2016-January},
volumes = {},
year = {2016},
mendeley-tags = {image synthesis},
}

@article{2016_jaitly_etal,
author = {Yu Zhang and William Chan and Navdeep Jaitly},
editor = { },
translator = { },
__markedentry = {},
abstract = {Sequence-to-sequence models have shown success in end-to-end speech recognition. However these models have only used shallow acoustic encoder networks. In our work, we successively train very deep convolutional networks to add more expressive power and better generalization for end-to-end ASR models. We apply network-in-network principles, batch normalization, residual connections and convolutional LSTMs to build very deep recurrent and convolutional structures. Our models exploit the spectral structure in the feature space and add computational depth without overfitting issues. We experiment with the WSJ ASR task and achieve 10.5/% word error rate without any dictionary or language using a 15 layer deep network.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {arXiv},
arxivid = { {1610.03022},},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {10.1109/ICASSP.2017.7953077},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = { {1610.03022},},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {IEEE},
interhash = {},
intrahash = {},
isbn = {97815112},
issn = {15206149},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on},
journaltitle = {},
keywords = {Automatic Speech Recognition,End-to-End Speech Recognition,Very Deep Convolutional Neural Networks,speech recognition,state of the art},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {},
numpages = {},
organization = {},
pages = {10--14},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Very Deep Convolutional Networks for End-to-End Speech Recognition},
titleaddon = {},
unidentified = {},
url = {http://arxiv.org/abs/1610.03022},
urldate = {},
volume = {},
volumes = {},
year = {2016},
mendeley-tags = {state of the art,speech recognition},
}

@article{2016_ishikawa_etal4,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
editor = { },
translator = { },
__markedentry = {},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network fea- tures a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification data-base to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Further- more, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {2016},
day = {},
doi = {10.1145/2897824.2925974},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97814512},
issn = {0730-0301},
journal = {},
journaltitle = {ACM Transactions on Graphics},
keywords = {colorization,computing methodologies,convolutional neural network concepts,image processing,image synthesis,neural net-},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {4},
numpages = {},
organization = {},
pages = {1--11},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Let there be color! :Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification},
titleaddon = {},
unidentified = {},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
urldate = {},
volume = {35},
volumes = {},
year = {},
mendeley-tags = {image synthesis,tesse},
}

@article{2016_ishikawa_etal3,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
editor = { },
translator = { },
__markedentry = {},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network fea- tures a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification data-base to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Further- more, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {10.1145/2897824.2925974},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97814512},
issn = {0730-0301},
journal = {ACM Transactions on Graphics},
journaltitle = {},
keywords = {colorization,computing methodologies,convolutional neural network concepts,image processing,neural net-},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {4},
numpages = {},
organization = {},
pages = {1--11},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Let there be color!},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {35},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/2016 Let there be color! joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification - Iizuka et al.pdf},
}

@article{2016_ishikawa_etal2,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
editor = { },
translator = { },
__markedentry = {},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {10.1145/2897824.2925974},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97814512},
issn = {15577368},
journal = {ACM Transactions on Graphics},
journaltitle = {},
keywords = {Colorization,Convolutional neural network,colorization,computing methodologies,convolutional neural network concepts,image processing,image synthesis,neural net-},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {4},
numpages = {},
organization = {},
pages = {1--11},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {ACM},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Let there be color! :Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification},
titleaddon = {},
unidentified = {},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
urldate = {},
volume = {35},
volumes = {},
year = {2016},
mendeley-tags = {image synthesis},
}

@article{2016_ishikawa_etal1,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
editor = { },
translator = { },
__markedentry = {},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {10.1145/2897824.2925974},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {97814512},
issn = {15577368},
journal = {ACM Transactions on Graphics},
journaltitle = {},
keywords = {Colorization,Convolutional neural network,image synthesis},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {4},
numpages = {},
organization = {},
pages = {1--11},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Let there be color!: Joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification},
titleaddon = {},
unidentified = {},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
urldate = {},
volume = {35},
volumes = {},
year = {2016},
file = {C:/Users/tesse/Desktop/Files/Dropbox/BIBrep/0 New PAPERS/2016 Let there be color! joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification - Iizuka et al.pdf},
mendeley-tags = {image synthesis,#merged,#corrupted author},
}

@article{2016_ishikawa_etal,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
editor = { },
translator = { },
__markedentry = {},
abstract = {},
acmid = {},
address = {},
adsnote = {},
adsurl = {},
annotation = {},
annote = {},
archiveprefix = {},
arxivid = {},
bibsource = {},
biburl = {},
booktitle = {},
collection = {},
comment = {},
date = {},
day = {},
doi = {},
ean = {},
edition = {},
editora = {},
editoratype = {},
editorb = {},
editorbtype = {},
ee = {},
eprint = {},
eprintclass = {},
eprinttype = {},
eventtitle = {},
howpublished = {},
id = {},
institution = {},
interhash = {},
intrahash = {},
isbn = {},
issn = {},
journal = {ACM Transactions on Graphics (TOG)},
journaltitle = {},
keywords = {},
langid = {},
language = {},
location = {},
month = {},
n = {},
note = {},
number = {4},
numpages = {},
organization = {},
pages = {110},
pagetotal = {},
place = {},
pmid = {},
primaryclass = {},
publisher = {ACM},
qualityassured = {},
rights = {},
school = {},
series = {},
shortjournal = {},
shorttitle = {},
subtitle = {},
timestamp = {},
title = {Let there be color!: joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification},
titleaddon = {},
unidentified = {},
url = {},
urldate = {},
volume = {35},
volumes = {},
year = {2016},
}

