@article{Klein2016,
abstract = {This article is concerned with the ways virtual instrument software simulates acoustic human performance. In particular, it examines two case studies-virtual orchestral instruments and virtual singing instruments-to consider how their design and implementation seek to express human music performance by adopting the micro and macro sonic variations of timing, pitch, dynamics, articulation, ambience, and other limitations imposed by the physical relationship between the player and the instrument. Baudrillard considers that "simulation threatens the difference between the 'true' and the 'false', the 'real' and the 'imaginary'" (1994: 3). By feigning the acoustic markers of expressive human musical performance, virtual instrument designers and composer-users encourage the listener to produce, in themselves, the experience of hearing an orchestra or singer. Users also contribute to the recontextualization of human performance by feeding back into the cultures and development cycles of virtual instrument software, where sonic gestures are recurrently refreshed. The construction of virtual instruments as devices of musical expressivity is, therefore, an evolving, mutually constructed, and performative endeavour.},
author = {Klein, Eve},
doi = {10.5429/2079-3871(2016)v6i2.3en},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 Feigning Humanity Virtual Instruments, Simulation and Performativity - Klein.pdf:pdf},
issn = {20793871},
journal = {IASPM Journal},
keywords = {Musical Expressivity,Performativity,Simulation,Synthesizers,Virtual Instruments,Virtual Orchestras,Vocaloid},
number = {2},
pages = {22--48},
title = {{Feigning humanity: Virtual instruments, simulation and performativity}},
volume = {6},
year = {2016}
}
@article{Vamvakousis2016,
abstract = {We present and evaluate the EyeHarp, a new gaze-controlled Digital Musical Instrument, which aims to enable people with severe motor disabilities to learn, perform, and compose music using only their gaze as control mechanism. It consists of (1) a step-sequencer layer, which serves for constructing chords/arpeggios, and (2) a melody layer, for playing melodies and changing the chords/arpeggios. We have conducted a pilot evaluation of the EyeHarp involving 39 participants with no disabilities from both a performer and an audience perspective. In the first case, eight people with normal vision and no motor disability participated in a music-playing session in which both quantitative and qualitative data were collected. In the second case 31 people qualitatively evaluated the EyeHarp in a concert setting consisting of two parts: a solo performance part, and an ensemble (EyeHarp, two guitars, and flute) performance part. The obtained results indicate that, similarly to traditional music instruments, the proposed digital musical instrument has a steep learning curve, and allows to produce expressive performances both from the performer and audience perspective.},
author = {Vamvakousis, Zacharias and Ramirez, Rafael},
doi = {10.3389/fpsyg.2016.00906},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 The EyeHarp A Gaze-Controlled Digital Musical Instrument - Vamvakousis and Ramirez.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Accessible interfaces,Digital musical instrument,Disabilities,Gaze interaction,Music performance},
number = {JUN},
pages = {1--14},
title = {{The EyeHarp: A gaze-controlled digital musical instrument}},
volume = {7},
year = {2016}
}
@article{Tasaki2013,
author = {Tasaki, Tsuyoshi and Ogata, Tetsuya and Okuno, Hiroshi G and Iteraction, The and People, Multiple},
doi = {10.1162/COMJ},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 The Hands The Making of a Digital Musical Instrument - Torre et al..pdf:pdf},
number = {12},
pages = {1--8},
title = {{( B ) 有査読学術雑誌論文}},
volume = {52},
year = {2013}
}
@article{Staudt,
author = {Staudt, Pascal},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016StaudtDevelopment Development of a Digital Musical Instrument with Embedded Sound Synthesis.pdf:pdf},
title = {{Development of a Digital Musical Instrument with Embedded Sound Synthesis}},
year = {2016}
}
@article{Calegario2017,
abstract = {Digital musical instruments (DMIs) make up a class of devices in which gestural control and sound production are physically decoupled, but digitally mapped. This work discusses aspects of DMI design by focusing on the complexity of the design space and the importance of prototyping cycles. The authors' research questions cover how to provide an initial path for generating DMI ideas and how to reduce the time and effort required to build functional DMI prototypes. To address these questions, they propose a new methodology and an associated physical prototyping toolkit, which has building blocks inspired by of existing instruments. Preliminary tests with musicians and DMI designers revealed a strong potential for its use in the development of DMIs, and also uncovered limitations of the current toolkit. This article is part of a special issue on multimedia technologies for enriched music.},
author = {Calegario, Filipe and Wanderley, Marcelo M. and Huot, Stephane and Cabral, Giordano and Ramalho, Geber},
doi = {10.1109/MMUL.2017.18},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2017 A Method and Toolkit for Digital Musical Instruments Generating Ideas and Prototypes - Calegario et al..pdf:pdf},
issn = {1070986X},
journal = {IEEE Multimedia},
keywords = {DMI,NIME,design ideation toolkit,design of digital musical instruments,digital musical instrument,hackers,hardware,idea generation,morphological chart,multimedia,new interface for musical expression,prototype,prototyping toolkit,visualization},
number = {1},
pages = {63--71},
title = {{A Method and Toolkit for Digital Musical Instruments: Generating Ideas and Prototypes}},
volume = {24},
year = {2017}
}
@book{2017SchmidEvaluating,
author = {Schmid, Gian-Marco},
booktitle = {Evaluating the Experiential Quality of Musical Instruments},
doi = {10.1007/978-3-658-18420-9},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2017 Evaluating the Experiential Quality of Musical Instruments - Schmid.pdf:pdf},
isbn = {978-3-658-18419-3 978-3-658-18420-9},
publisher = {Springer Fachmedien Wiesbaden},
title = {{Evaluating the Experiential Quality of Musical Instruments}},
year = {2017}
}
@article{Tahlroglu2020,
abstract = {This article explores how computation opens up possibilities for new musical practices to emerge through technology design. Using the notion of the cultural probe as a lens, we consider the digital musical instrument as an experimental device that yields findings across the fields of music, sociology and acoustics. As part of an artistic-research methodology, the instrumental object as a probe is offered as a means for artists to answer questions that are often formulated outside semantic language. This article considers how computation plays an important role in the authors' personal performance practices in different ways, which reflect the changed mode-of-being of new musical instruments and our individual and collective relations with them.},
author = {Tahlroǧlu, Koray and Magnusson, Thor and Parkinson, Adam and Garrelfs, Iris and Tanaka, Atau},
doi = {10.1017/S1355771819000475},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2020 Digital Musical Instruments as Probes How computation changes the mode-of-being of musical instruments - Tahıroğlu et al..pdf:pdf},
issn = {14698153},
journal = {Organised Sound},
number = {1},
pages = {64--74},
title = {{Digital Musical Instruments as Probes: How computation changes the mode-of-being of musical instruments}},
volume = {25},
year = {2020}
}
@book{Emerson2020,
abstract = {Over the past four decades, the number, diversity and complexity of digital musical instruments (DMIs) has increased rapidly. There are very few constraints on DMI design as such systems can be easily reconfigured, offering near limitless flexibility for music-making. Given that new acoustic musical instruments have in many cases been created in response to the limitations of available technologies, what motivates the development of new DMIs? We conducted an interview study with ten designers of new DMIs, in order to explore (a) the motivations electronic musicians may have for wanting to build their own instruments; and (b) the extent to which these motivations relate to the context in which the artist works and performs (academic vs club settings). We found that four categories of motivation were mentioned most often: M1 – wanting to bring greater embodiment to the activity of performing and producing electronic music; M2 – wanting to improve audience experiences of DMI performances; M3 – wanting to develop new sounds, and M4 – wanting to build responsive systems for improvisation. There were also some detectable trends in motivation according to the context in which the artists work and perform. Our results offer the first systematically gathered insights into the motivations for new DMI design. It appears that the challenges of controlling digital sound synthesis drive the development of new DMIs, rather than the shortcomings of any one particular design or existing technology.},
author = {Emerson, Gina and Egermann, Hauke},
booktitle = {Musicae Scientiae},
doi = {10.1177/1029864918802983},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2020 Exploring the motivations for building new digital musical instruments - Emerson and Egermann.pdf:pdf},
isbn = {0000000170147},
issn = {10298649},
keywords = {Digital musical instruments,embodiment,expressivity,motivation},
number = {3},
pages = {313--329},
title = {{Exploring the motivations for building new digital musical instruments}},
volume = {24},
year = {2020}
}
@article{2015YoungHci,
abstract = {Here we present an analysis of literature relating to the evaluation methodologies of Digital Musical Instruments (DMIs) derived from the field of Human Computer Interaction (HCI). We then apply choice aspects from these existing evaluation models and apply them to an optimized evaluation for assessing new DMIs.},
author = {Young, Gareth W. and Murphy, Dave},
doi = {10.13140/rg.2.1.3949.9364},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/HCI Models for Digital Musical Instruments Methodologies for Rigorous Testing of Digital Musical Instruments - Young and Murphy.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Digital Musical Instrument,Evaluation Techniques,Human Computer Interaction},
shorttitle = {HCI Models for Digital Musical Instruments},
title = {{HCI models for digital musical instruments: Methodologies for rigorous testing of digital musical instruments}},
year = {2020}
}
@article{Zappi2017,
abstract = {Physical modelling is a sophisticated synthesis technique, often used in the design of Digital Musical Instruments (DMIs). Some of the most precise physical simulations of sound propagation are based on Finite-Difference Time-Domain (FDTD) methods, which are stable, highly parameterizable but characterized by an extremely heavy computational load. This drawback hinders the spread of FDTD from the domain of off-line simulations to the one of DMIs. With this paper, we present a novel approach to real-time physical modelling synthesis, which implements a 2D FDTD solver as a shader program running on the GPU directly within the graphics pipeline. The result is a system capable of running fully interactive, massively sized simulation domains, suitable for novel DMI design. With the help of diagrams and code snippets, we provide the implementation details of a first interactive application, a drum head simulator whose source code is available online. Finally, we evaluate the proposed system, showing how this new approach can work as a valuable alternative to classic GPGPU modelling.},
author = {Zappi, Victor and Allen, Andrew and Fels, Sidney},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/Shader-based Physical Modelling for the Design of Massive Digital Musical Instruments - Zappi et al..pdf:pdf},
journal = {NIME 2017 Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {145--150},
title = {{Shader-based Physical Modelling for the Design of Massive Digital Musical Instruments}},
url = {http://www.nime.org/proceedings/2017/nime2017_paper0028.pdf},
year = {2017}
}
@article{Mehes2017,
abstract = {Exploration is an intrinsic element of designing and engaging with acoustic as well as digital musical instruments. This paper reports on the ongoing development of a virtual-acoustic instrument based on a physical model of a string coupled nonlinearly to a plate. The performer drives the model by tactile interaction with a string-board controller fitted with piezo-electric sensors. The string-plate model is formulated in a way that prioritises its parametric explorability. Where the roles of creating performance gestures and designing instruments are traditionally separated, such a design provides a continuum across these domains. The string-plate model, its real-time implementation, and the control interface are described, and the system is preliminarily evaluated through informal observations of how musicians engage with the system.},
author = {Mehes, Sandor and van Walstijn, Maarten and Stapleton, Paul},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/Virtual-Acoustic Instrument Design Exploring the Parameter Space of a String-Plate Model - Mehes et al..pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {399--403},
title = {{Virtual-Acoustic Instrument Design: Exploring the Parameter Space of a String-Plate Model}},
url = {http://www.nime.org/proceedings/2017/nime2017_paper0075.pdf},
year = {2017}
}
@article{Valimaki1996,
abstract = {Physical modelling of musical instruments is an exciting new paradigm in digital sound synthesis. The basic idea is to imitate the sound production mechanism of an acoustic musical instrument using a computer program. The sound produced by such a model will automatically resemble that of the real instrument, if the model has been devised in a proper way. In this article we review the history and present techniques of physical modelling. It appears that the many seemingly very different modelling methods try to achieve the same result: to simulate the solutions of the wave equation in a simplified manner. We concentrate on the digital waveguide modelling technique which has gained much popularity among both researchers and engineers in the music technology industry. The benefits and drawbacks of the new technology are considered, and concurrent research topics are discussed. The physical modelling approach offers many new applications, especially in the fields of multimedia and virtual reality. {\textcopyright} 1996, Cambridge University Press. All rights reserved.},
author = {Valimaki, Vesa and Takala, Tapio},
doi = {10.1017/S1355771896000039},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/1996 Virtual musical instruments — natural sound using physical models - V{\"{a}}lim{\"{a}}ki and Takala.pdf:pdf},
isbn = {1355771896000},
issn = {14698153},
journal = {Organised Sound},
number = {2},
pages = {75},
title = {{Virtual musical instruments - natural sound using physical models}},
volume = {1},
year = {1996}
}
@article{Smith2008,
abstract = {This chapter summarizes some ecient signal processing structures used for virtual musical instruments based on physical models. Instruments in the string and wind families are considered.},
author = {Smith, Julius O.},
doi = {10.1007/978-0-387-30441-0_25},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2008 Digital Waveguide Architectures for Virtual Musical Instruments - Smith.pdf:pdf},
journal = {Handbook of Signal Processing in Acoustics},
pages = {399--417},
title = {{Digital Waveguide Architectures for Virtual Musical Instruments}},
year = {2008}
}
@article{OModhrain2011,
author = {O'Modhrain, Sile},
doi = {10.1162/COMJ_a_00038},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2011 A Framework for the Evaluation of Digital Musical Instruments - O'Modhrain.pdf:pdf},
issn = {01489267},
journal = {Computer Music Journal},
number = {1},
pages = {28--42},
title = {{A framework for the evaluation of digital musical instruments}},
volume = {35},
year = {2011}
}
@article{Zoran2011,
abstract = {This paper considers the controversy of modern acoustic instruments, which may have come to an evolutionary impasse, due to its high standardization that makes it difficult to explore design modifications. A new approach for the design and fabrication of an acoustic instrument is presented, using digital fabrication technologies, and specifically 3D printing, which has the potential to influence new designs, and to lead to new acoustics and ergonomic innovations. This paper describes the key concepts of this approach, presenting the development process of such a 3D printed instrument-a prototype ofa 3D printed concert flute, some other 3D printed elements, and a conceptual example of an innovative trumpet-discussing the potential of the new technology in fabricating and designing of musical instruments. {\textcopyright} 2011 Copyright Taylor and Francis Group, LLC.},
author = {Zoran, Amit},
doi = {10.1080/09298215.2011.621541},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2011 The 3D Printed Flute Digital Fabrication and Design of Musical Instruments - Zoran.pdf:pdf},
issn = {09298215},
journal = {Journal of New Music Research},
number = {4},
pages = {379--387},
title = {{The 3D Printed Flute: Digital Fabrication and Design of Musical Instruments}},
volume = {40},
year = {2011}
}
@article{Hewitt2006,
author = {Hewitt, Kevin C and Paesler, Michael},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2014 BLURRING THE LINES AN INTEGRATED COMPOSITIONAL MODEL FOR DIGITAL MUSIC INSTRUMENT DESIGN - Dalgleish et al..pdf:pdf},
journal = {Physics},
pages = {1--6},
title = {{I Nstrument D Esign and T Echniques}},
year = {2006}
}
@article{Medeiros2014,
abstract = {The new interfaces are changing the way we interact with computers. In the musical context, those new technologies open a wide range of possibilities in the creation of New Interfaces for Musical Expression (NIME). Despite 10 years of research in NIME, it is hard to find artifacts that have been widely or convincingly adopted by musicians. In this paper, we discuss some NIME design challenges, highlighting particularities related to the digital and musical nature of these artifacts, such as virtuosity, cultural elements, context of use, creation catalysis, success criteria, adoption strategy, etc. With these challenges, we aim to call attention for the intersection of music, computing and design, which can be an interesting area for people working on product design and interaction design.},
author = {Medeiros, Rodrigo and Calegario, Filipe and Cabral, Giordano and Ramalho, Geber},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2014 Challenges in Designing New Interfaces for Musical Expression - Medeiros et al..pdf:pdf},
journal = {International Conference of Design, User Experience, and Usability},
keywords = {design challenges,digital musical instrument,interaction design,musical expression,new interfaces for,user experience},
pages = {643--652},
title = {{Challenges in Designing New Interfaces}},
year = {2014}
}
@inproceedings{2016JackEffect,
abstract = {When designing digital musical instruments the importance of low and consistent action-to-sound latency is widely accepted. This paper investigates the effects of latency (0-20ms) on instrument quality evaluation and performer interaction. We present findings from an experiment conducted with musicians who performed on an percussive digital musical instrument with variable amounts of latency. Three latency conditions were tested against a zero latency condition, 10ms, 20ms and 10ms ± 3ms jitter. The zero latency condition was significantly rated more positively than the 10ms with jitter and 20ms latency conditions in six quality measures, emphasising the importance of not only low, but stable latency in digital musical instruments. There was no significant difference in rating between the zero latency condition and 10ms condition. A quantitative analysis of timing accuracy in a metronome task under latency conditions showed no significant difference in mean synchronisation error. This suggests that the 20ms and 10ms with jitter latency conditions degrade subjective impressions of an instrument, but without significantly affecting the timing performance of our participants. These findings are discussed in terms of control intimacy and instrument transparency.},
author = {Jack, Robert H. and Stockman, Tony and McPherson, Andrew},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2986416.2986428},
file = {:C\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument - Jack et al..pdf:pdf},
isbn = {9781450348225},
keywords = {Control intimacy,Digital musical instruments,Effort,Interaction,Latency,Multisensory feedback,Perceived quality},
pages = {116--123},
publisher = {ACM Press},
title = {{Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument}},
url = {http://dl.acm.org/citation.cfm?doid=2986416.2986428},
volume = {04-06-October-2016},
year = {2016}
}
