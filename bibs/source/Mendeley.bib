@unpublished{w18,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
address = {DeepMind Dispon�vel em},
annote = {From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Yamamoto, Ryuichi; Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray)

From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray)

. arXiv preprint},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray and Yamamoto, Ryuichi and van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
eprint = {1609.03499},
pages = {1--15},
publisher = {<},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {http://arxiv.org/abs/1609.03499 https://deepmind.com/blog/wavenet-generative-model-raw-audio/%3E},
year = {2018}
}
@unpublished{gs16,
abstract = {We study the wave equation for a string with stiffness. We solve the equation and provide a uniqueness theorem with suitable boundary conditions. For a pinned string we compute the spectrum, which is slightly inharmonic. Therefore, the widespread scale of 12 equal divisions of the just octave is not the best choice to tune instruments like the piano. Basing on the theory of dissonance, we provide a way to tune the piano in order to improve its consonance. A good solution is obtained by tuning a note and its fifth by minimizing their beats.},
annote = {From Duplicate 2 (The wave equation for stiff strings and piano tuning - Gr{\`{a}}cia, Xavier; Sanz-perela, Tom{\'{a}}s; Gr, Xavier; Gracia, X; Sanz-perela, Tom{\'{a}}s)

From Duplicate 1 (The wave equation for stiff strings and piano tuning. - Gracia, X; Sanz-perela, T)
And Duplicate 3 (The wave equation for stiff strings and piano tuning - Gr{\`{a}}cia, Xavier; Sanz-Perela, Tom{\'{a}}s)

preprint},
archivePrefix = {arXiv},
arxivId = {1603.05516},
author = {Gr{\`{a}}cia, Xavier and Sanz-perela, Tom{\'{a}}s and Gr, Xavier and Gracia, X and Sanz-perela, Tom{\'{a}}s},
doi = {10.2436/20.2002.02.11},
eprint = {1603.05516},
keywords = {,00a65,2010,35g16,35l05,dissonance,inharmonic spectrum,msc,musical,musical scale,stiffness,string,vibrating,vibrating string,wave equation},
pages = {1--16},
title = {{The wave equation for stiff strings and piano tuning}},
url = {http://arxiv.org/abs/1603.05516%0Ahttp://dx.doi.org/10.2436/20.2002.02.11},
volume = {3},
year = {2016}
}
@article{Patterson,
abstract = {"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors"--Page 4 of cover. Introduction -- Applied math and machine learning basics. Linear algebra -- Probability and information theory -- Numerical computation -- Machine learning basics -- Deep networks: modern practices. Deep feedforward networks -- Regularization for deep learning -- Optimization for training deep models -- Convolutional networks -- Sequence modeling: recurrent and recursive nets -- Practical methodology -- Applications -- Deep learning research. Linear factor models -- Autoencoders -- Representation learning -- Structured probabilistic models for deep learning -- Monte Carlo methods -- Confronting the partition function -- Approximate inference -- Deep generative models.},
author = {{Mirza Rahim Baig, Thomas V. Joseph, Nipun Sadvilkar, Mohan Kumar Silaparasetty}, Anthony So and Courville, Ian Goodfellow and Yoshua Bengio and Aaron},
isbn = {3463353563306},
journal = {Nature},
keywords = {,cnn,convolutional neural networks,deep learning,plant disease},
number = {7553},
pages = {1--73},
title = {{Deep learning 简介 一 、 什么是 Deep Learning ？}},
volume = {29},
year = {2016}
}
@article{He2015,
abstract = {This paper presents our system design for the Audio-Visual Emotion Challenge (AV +EC 2015). Besides the baseline features, we extract from audio the functionals on low-level descriptors (LLDs) obtained via the YAAFE toolbox, and from video the Local Phase Quantization from Three Orthogonal Planes (LPQ-TOP) features. From the physiological signals, we extract 52 electro-cardiogram (ECG) features and 22 electro-dermal activity (EDA) features from various analysis domains. The extracted features along with the AV +EC 2015 baseline features of audio, ECG or EDA are concatenated for a further feature selection step, in which the concordance correlation coefficient (CCC), instead of the usual Pearson correlation coefficient (CC), has been used as objective function. In addition, offsets between the features and the arousal/valence labels are considered in both feature selection and modeling of the affective dimensions. For the fusion of multimodal features, we propose a Deep Bidirectional Long Short-Term Memory Recurrent Neural Network (DBLSTM-RNN) based multimodal affect prediction framework, in which the initial predictions from the single modalities via the DBLSTM-RNNs are firstly smoothed with Gaussian smoothing, then input into a second layer of DBLSTMRNN for the final prediction of affective state. Experimental results show that our proposed features and the DBLSTMRNN based fusion framework obtain very promising results. On the development set, the obtained CCC is up to 0.824 for arousal and 0.688 for valence, and on the test set, the CCC is 0.747 for arousal and 0.609 for valence.},
author = {He, Lang and Jiang, Dongmei and Yang, Le and Pei, Ercheng and Wu, Peng and Sahli, Hichem and Others and Jiang, Dongmei and Yang, Le and Pei, Ercheng and Wu, Peng and Sahli, Hichem},
doi = {10.1145/2808196.2811641},
edition = {Proceeding},
institution = {ACM},
isbn = {9781450337434},
journal = {AVEC 2015 - Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015},
keywords = {Audio and video features,DBLSTM-RNN,Multimodal fusion,Offset,Physiological feature,state of the art,video classification},
mendeley-tags = {state of the art,video classification},
number = {October 2015},
pages = {73--80},
publisher = {Anais�ACM},
title = {{Multimodal affective dimension prediction using deep bidirectional long short-term memory recurrent neural networks}},
url = {http://dl.acm.org/citation.cfm?doid=2808196.2811641},
year = {2015}
}
@unpublished{e17,
abstract = {Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autocncodcr model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.},
annote = {From Duplicate 2 (Neural audio synthesis of musical notes with wavenet autoencoders. - Engel, J; others)
And Duplicate 3 (Neural audio synthesis of musical notes with WaveNet autoencoders - Engel, Jesse; Resnick, Cinjon; Roberts, Adam; Dieleman, Sander; Norouzi, Mohammad; Eck, Douglas; Simonyan, Karen)

preprint},
archivePrefix = {arXiv},
arxivId = {1704.01279},
author = {Engel, Jesse and Resnick, Cinjon and Roberts, Adam and Dieleman, Sander and Norouzi, Mohammad and Eck, Douglas and Simonyan, Karen and Others and Resnick, Cinjon and Roberts, Adam and Dieleman, Sander and Eck, Douglas},
booktitle = {34th International Conference on Machine Learning, ICML 2017},
eprint = {1704.01279},
isbn = {9781510855144},
pages = {1771--1780},
title = {{Neural audio synthesis of musical notes with wavenet autoencoders.}},
volume = {3},
year = {2017}
}
@article{Thesis,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Savira, Fitria and Suharsono, Yudi and {American Journal of Sociology} and 中島 and Savira, Fitria and Suharsono, Yudi},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {,icle},
number = {01},
pages = {1689--1699},
pmid = {25246403},
title = {{済無No Title No Title}},
url = {https://github.com/tesserato/tesserato.github.io%3E},
volume = {01},
year = {2013}
}
@article{Johnston2017a,
abstract = {We propose a method for lossy image compression based on recurrent, convolutional neural networks that outperforms BPG (4:2:0), WebP, JPEG2000, and JPEG as measured by MS-SSIM. We introduce three improvements over previous research that lead to this state-of-the-art result using a single model. First, we modify the recurrent architecture to improve spatial diffusion, which allows the network to more effectively capture and propagate image information through the network's hidden state. Second, in addition to lossless entropy coding, we use a spatially adaptive bit allocation algorithm to more efficiently use the limited number of bits to encode visually complex image regions. Finally, we show that training with a pixel-wise loss weighted by SSIM increases reconstruction quality according to multiple metrics. We evaluate our method on the Kodak and Tecnick image sets and compare against standard codecs as well as recently published methods based on deep neural networks.},
archivePrefix = {arXiv},
arxivId = {1703.10114},
author = {Johnston, Nick and Vincent, Damien and Minnen, David and Covell, Michele and Singh, Saurabh and Chinen, Troy and Hwang, Sung Jin and Shor, Joel and Toderici, George and {Jin Hwang}, Sung and Shor, Joel and Toderici, George and Hwang, Sung Jin and Shor, Joel and Toderici, George},
doi = {10.1109/CVPR.2018.00461},
eprint = {1703.10114},
isbn = {9781538664209},
issn = {10636919},
journal = {arXiv preprint arXiv:1703.10114},
keywords = {,image compression- lossy},
mendeley-tags = {image compression- lossy},
pages = {4385--4393},
title = {{Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks}},
url = {http://arxiv.org/abs/1703.10114},
year = {2017}
}
@incollection{08,
abstract = {This chapter summarizes some ecient signal processing structures used for virtual musical instruments based on physical models. Instruments in the string and wind families are considered.},
address = {Traducao. [s.l.] p. 399�417},
author = {Smith, Julius O. and Iii, Julius O Smith},
booktitle = {Handbook of Signal Processing in Acoustics},
doi = {10.1007/978-0-387-30441-0_25},
pages = {399--417},
publisher = {Springer},
title = {{Digital Waveguide Architectures for Virtual Musical Instruments}},
year = {2008}
}
@article{Pang2017,
abstract = {Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and $ 1\times 1 $ convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.},
archivePrefix = {arXiv},
arxivId = {1603.06759},
author = {Pang, Yanwei and Sun, Manli and Jiang, Xiaoheng and Li, Xuelong and Others and Sun, Manli and Jiang, Xiaoheng and Li, Xuelong},
doi = {10.1109/TNNLS.2017.2676130},
eprint = {1603.06759},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Convolution in convolution (CiC),Convolutional neural networks (CNNs),Image recognition,Network in network (NiN),image classification},
mendeley-tags = {image classification},
number = {5},
pages = {1587--1597},
pmid = {28328517},
publisher = {IEEE},
title = {{Convolution in convolution for network in network}},
volume = {29},
year = {2017}
}
@article{Oord2016,
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
annote = {From Duplicate 2 (Pixel recurrent neural networks. - Oord, A Van Den; Kalchbrenner, N; Kavukcuoglu, K)

preprint},
archivePrefix = {arXiv},
arxivId = {1601.06759},
author = {Oord, Aaron Van Den and Kalchbrenner, Nal and Kavukcuoglu, Koray and {Van Den Oord}, A{\"{a}}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
eprint = {1601.06759},
isbn = {9781510829008},
journal = {arXiv preprint arXiv:1601.06759},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {2611--2620},
title = {{Pixel Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1601.06759},
volume = {48},
year = {2016}
}
@article{Toderici2015,
abstract = {A large fraction of Internet traffic is now driven by requests from mobile devices with relatively small screens and often stringent bandwidth requirements. Due to these factors, it has become the norm for modern graphics-heavy websites to transmit low-resolution, low-bytecount image previews (thumbnails) as part of the initial page load process to improve apparent page responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore a current research focus, as any byte savings will significantly enhance the experience of mobile device users. Toward this end, we propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional LSTM recurrent networks. Our models address the main issues that have prevented autoencoder neural networks from competing with existing image compression algorithms: (1) our networks only need to be trained once (not per-image), regardless of input image dimensions and the desired compression rate; (2) our networks are progressive, meaning that the more bits are sent, the more accurate the image reconstruction; and (3) the proposed architecture is at least as efficient as a standard purpose-trained autoencoder for a given number of bits. On a large-scale benchmark of 32$\times$32 thumbnails, our LSTM-based approaches provide better visual quality than (headerless) JPEG, JPEG2000 and WebP, with a storage size that is reduced by 10% or more.},
archivePrefix = {arXiv},
arxivId = {1511.06085},
author = {Toderici, George and O'Malley, Sean M. and Hwang, Sung Jin and Vincent, Damien and Minnen, David and Baluja, Shumeet and Covell, Michele and Sukthankar, Rahul and O'Malley, Sean M. and Hwang, Sung Jin and Vincent, Damien and Minnen, David and Baluja, Shumeet and Covell, Michele and Sukthankar, Rahul},
eprint = {1511.06085},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
keywords = {,image compression- lossy},
mendeley-tags = {image compression- lossy},
pages = {1--12},
title = {{Variable Rate Image Compression with Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1511.06085},
year = {2015}
}
@article{Kecerdasan,
author = {Kecerdasan, Inventori and Ikep, Pelbagai},
isbn = {080581258X},
pages = {6},
title = {{No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title}}
}
@article{DIppolito2014a,
abstract = {Scholars dedicated increasing attention towards appreciating how design has changed individualsperception of new products, firmsunderstanding and formulation of strategy, or other relevant actorsapproach to innovation and technology management. By emphasising the importance of design for the definition of consumersneeds, the restructuring of firmsorganisational structures and strategies, and the evolution of firmsvalue creation processes, this review paper identifies relevant research gaps and questions that would benefit from future scholarly attention. In particular, it is suggested that such effort should address the analysis of how design consumption can help better comprehend consumersneeds; what are the implications of design thinking on the skill sets of design professionals; the organisational structure of firms, including the reconfiguration of other business functions, and their strategy; and whether and how design thinking can shape firmsvalue creation processes and contribute to the formalisation of design tasks.},
author = {D'Ippolito, Beatrice},
doi = {10.1016/j.technovation.2014.01.007},
isbn = {0166-4972},
issn = {01664972},
journal = {Technovation},
keywords = {Consumers' needs,Design,Firm competitiveness,Literature review,Research gaps,Strategy making,Value creation},
month = {feb},
number = {11},
pages = {716--730},
pmid = {1629546633},
publisher = {Elsevier},
title = {{The importance of design for firms competitiveness: A review of the literature}},
url = {http://www.sciencedirect.com/science/article/pii/S016649721400008X},
volume = {34},
year = {2014}
}
@article{s06,
address = {Stanford University. stanford. edu/ jos/swgt},
author = {Iii, Jo Smith},
journal = {Center for Computer Research in Music and {\ldots}},
pages = {1--5},
publisher = {Center for Computer Research in Music and Acoustics (CCRMA)},
title = {{A basic introduction to digital waveguide synthesis (for the technically inclined)}},
url = {http://virtualmusic.mysteria.cz/docs/orion1.pdf},
year = {2006}
}
@article{Agerfalk2008a,
abstract = {This paper presents a psychological contract perspective on the use of the open source development model as a global sourcing strategy-opensourcing, as we term it here-whereby commerical companies and open source communities collaborate on development of software of commercial interest to the company. Building on previous research on information systems outsourcing, a theoretical framework for exploring the opensourcing phenomenon is derived. The first phase of the research concerned qualitative case studies involving three commercial organizations (IONA Technologies, Philips Medical Systems, and Telefonica) that had "liberated" what had hitherto been proprietary software and sought to grow a global open source community around their product. We followed this with a large-scale survey involving additional exemplars of the phenomenon. The study identifies a number of symmetrical and complementary customer and community obligations that are associated with opensourcing success. We also identify a number of tension points on which customer and community perceptions tend to vary. Overall the key watchwords for opensourcing are openness, trust, tact, professionalism, transparency, and complementariness: The customer and community need to establish a trusted partnership of shared responsibility in building an overall opensourcing ecosystem. The study reveals an ongoing shift from OSS as a community of individual developers to OSS as a community of commercial organizations, primarily small to medium-sized enterprises. It also reveals that opensourcing provides ample opportunity for companies to headhunt top developers, hence moving from outsourcing to a largely unknown OSS workforce toward recruitment of developers from a global open source community whose talents have become known as a result of the opensourcing experience.},
author = {{\AA}gerfalk, P{\"{a}}r J. and Fitzgerald, Brian and Agerfalk, Par J and Fitzgerald, Brian},
doi = {Article},
isbn = {02767783},
issn = {02767783},
journal = {MIS Quarterly: Management Information Systems},
keywords = {,Crowdsourcing,Global software development,Multimethod research,Offshoring,Open source,Opensourcing,Outsourcing,crowdsourcing,global software development,multi-method research,offshoreing,open source,opensourcing,outsourcing},
number = {2},
pages = {385--409},
pmid = {31831011},
shorttitle = {OUTSOURCING TO AN UNKNOWN WORKFORCE},
title = {{Outsourcing to an unknown workforce: exploring opensourcing as a global sourcing strategy}},
volume = {32},
year = {2008}
}
@article{Hinton2018,
abstract = {A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagat-ing through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.},
author = {Hinton, Geoffrey and Sabour, Sara and Frosst, Nicholas},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
pages = {1--15},
title = {{Matrix capsules with EM routing}},
year = {2018}
}
@article{Wang2016a,
abstract = {Convolutional neural networks play an increasingly important role in computer vision tasks, especially in the field of visual object recognition. Many prominent models, such as Inception, Maxout, ResNet, and NIN, have been proposed to significantly improve recognition performance. Inspired from those models, we propose a novel module called self-adaptive module (SAM). SAM consists of four passes and one selector. Specifically, the four passes include two direct passes with different receptive fields and depths, one residual pass, and one Maxout pass. Actually, the residual pass is used to speed up convergence, while we take advantage of the Maxout pass to enhance approximate capabilities of SAM. The selector is further designed to help choose reasonable output. Basically, SAM is intended to simplify design of any new deep learning architecture, since it no longer requires consideration of how to select receptive fields and depths. Our SAM is tested on the visual object recognition datasets including CIFAR-10, CIFAR-100, MNIST, and SVHN. The experimental results demonstrate that the SAM-Net has superior recognition performances on the four benchmarks, which achieve test errors of 5.76%, 28.56%, 0.31%, and 1.98%, respectively.},
author = {Wang, Zhenyang and Deng, Zhidong and Wang, Shiyao},
doi = {10.1109/IJCNN.2016.7727308},
institution = {IEEE},
isbn = {9781509006205},
journal = {Neural Networks (IJCNN), 2016 International Joint Conference on},
keywords = {,image classification},
mendeley-tags = {image classification},
number = {July},
pages = {1008--1014},
title = {{SAM : A Rethinking of Prominent Convolutional Neural Network Architectures for Visual Object Recognition}},
volume = {2016-Octob},
year = {2016}
}
@article{Mizutani,
abstract = {The well-known backpropagation (BP) derivative computation process for multilayer perceptrons (MLP) learning can be viewed as a simplified version of the Kelley-Bryson gradient formula in the classical discrete-time optimal control theory. We detail the derivation in the spirit of dynamic programming, showing how they can serve to implement more elaborate learning whereby teacher signals can be presented to any nodes at any hidden layers, as well as at the terminal output layer. We illustrate such an elaborate training scheme using a small-scale industrial problem as a concrete example, in which some hidden nodes are taught to produce specified target values. In this context, part of the hidden layer is no longer `hidden.'},
author = {Mizutani, Eiji and Dreyfus, Stuart E. and Nishio, Kenichi},
doi = {10.1109/ijcnn.2000.857892},
journal = {Proceedings of the International Joint Conference on Neural Networks},
pages = {167--172},
title = {{On derivation of MLP backpropagation from the Kelley-Bryson optimal-control gradient formula and its application}},
volume = {2},
year = {2000}
}
@article{s92,
abstract = {Music synthesis based on a physical model promises the highest quality when it comes to imitating natural instruments. Because the artificial instrument can have the same control parameters as the real instrument, expressivity of control is unbounded. Historically, physical models have led to prohibitively expensive synthesis algorithms, and commercially available synthesizers do not yet appear to make use of them. These days, most synthesizers use either processed digital recordings ("sampling synthesis") or an abstract algorithm such as frequency modulation (FM). However, as computers become faster and cheaper, and as algorithms based on physical models become more efficient, we may expect to hear more from them. Most attempts to synthesize sounds based on a physical model have been based on numerical integration of the wave equation (covered in any textbook on acoustics). These methods generally require at least one operation (multiplication and/or addition) for each point on a grid that permeates the instrument. In principle, the grid spacing must be less than half a wavelength at the highest audio frequency. This is essentially why the computational costs are so high in "brute force" numerical solutions of the wave equation. More recently developed "digital waveguide" methods follow a different path to the physical model; the wave equation is first solved in a general way to obtain traveling waves in the medium interior. The traveling waves are explicitly simulated in the waveguide model, in contrast to computing a physical variable. (The traveling waves must be summed together to produce a physical output.) In the lossless case, a traveling wave between two points in the medium can be simulated using nothing but a digital delay line. In the general linear case, in which there are frequency-dependent losses and dispersion, the commutativity of linear time-invariant systems allows the losses and dispersion to be lumped at discrete points such that most of the simulation still consists of multiply-free delay lines. This is essentially why computational costs are so low in "waveguide synthesis" algorithms. Computer-music programmers know very well that a delay line can be implemented by a single fetch, store, and pointer update for each sample of output. If the delay line is, say, 500 samples long (corresponding to a pitch of 44,100/500=88 Hz in a string or bore model of compact disk quality), computational requirements relative to "brute force" numerical integration on the grid are reduced by three orders of magnitude. As a result, for very simple physical models, several CD-quality voices can be sustained in real time on a single digital signal processing (DSP) chip costing only a few dollars. This article develops waveguide synthesis beginning with the wave equation for vibrating strings. Transverse waves on a string are taken as the primary example due to the relative clarity of the underlying physics, but the formulation for string simulation is unified with that of the acoustic tube. The technique of lumping losses at discrete points in the waveguide, replacing more expensive distributed losses, is described.},
author = {Smith, Julius O.},
doi = {10.2307/3680470},
issn = {01489267},
journal = {Computer Music Journal},
number = {4},
pages = {74},
title = {{Physical Modeling Using Digital Waveguides}},
volume = {16},
year = {1992}
}
@unpublished{m17,
abstract = {A recently published method for audio style transfer has shown how to extend the process of image style transfer to audio. This method synthesizes audio "content" and "style" independently using the magnitudes of a short time Fourier transform, shallow convolutional networks with randomly initialized filters, and iterative phase reconstruction with Griffin-Lim. In this work, we explore whether it is possible to directly optimize a time domain audio signal, removing the process of phase reconstruction and opening up possibilities for real-time applications and higher quality syntheses. We explore a variety of style transfer processes on neural networks that operate directly on time domain audio signals and demonstrate one such network capable of audio stylization.},
annote = {From Duplicate 2 (Time Domain Neural Audio Style Transfer. - Mital, P K)

preprint},
archivePrefix = {arXiv},
arxivId = {1711.11160},
author = {Mital, Parag K.},
booktitle = {arXiv},
eprint = {1711.11160},
issn = {23318422},
number = {Nips},
title = {{Time Domain Neural Audio Style Transfer.}},
year = {2017}
}
@article{Frans2017,
abstract = {When creating digital art, coloring and shading are often time consuming tasks that follow the same general patterns. A solution to automatically colorize raw line art would have many practical applications. We propose a setup utilizing two networks in tandem: a color prediction network based only on outlines, and a shading network conditioned on both outlines and a color scheme. We present processing methods to limit information passed in the color scheme, improving generalization. Finally, we demonstrate natural-looking results when colorizing outlines from scratch, as well as from a messy, user-defined color scheme.},
annote = {From Duplicate 2 (Outline Colorization through Tandem Adversarial Networks. - Frans, K)

preprint},
archivePrefix = {arXiv},
arxivId = {1704.08834},
author = {Frans, Kevin},
eprint = {1704.08834},
journal = {arXiv preprint arXiv:1704.08834},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
title = {{Outline Colorization through Tandem Adversarial Networks}},
url = {http://arxiv.org/abs/1704.08834},
year = {2017}
}
@article{sfh,
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-The-Art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-Agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
archivePrefix = {arXiv},
arxivId = {arXiv:1710.09829v1},
author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E. and Oct, C V and Hinton, Geoffrey E.},
eprint = {arXiv:1710.09829v1},
issn = {23318422},
journal = {arXiv},
number = {Nips},
title = {{Dynamic routing between capsules}},
volume = {2017},
year = {2017}
}
@article{Serafin,
abstract = {In this paper we propose a new technique to model complex resonators, which uses a combination of digital waveguides and waveguide meshes banded in frequency. An application for simulating a bowed cymbal is discussed.},
author = {Serafin, Stefania and Huang, Patty and Smith, Jo},
journal = {Mosart meeting},
pages = {2--5},
title = {{The banded digital waveguide mesh}},
url = {http://www.media.aau.dk/people/sts/publications/mosart.pdf},
volume = {1},
year = {2001}
}
@article{Kulkarni2015,
abstract = {This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a model that learns an interpretable representation of images. This representation is disentangled with respect to transformations such as out-of-plane rotations and lighting variations. The DC-IGN model is composed of multiple layers of convolution and de-convolution operators and is trained using the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a training procedure to encourage neurons in the graphics code layer to represent a specific transformation (e.g. pose or light). Given a single input image, our model can generate new images of the same object with variations in pose and lighting. We present qualitative and quantitative results of the model's efficacy at learning a 3D rendering engine.},
archivePrefix = {arXiv},
arxivId = {1503.03167},
author = {Kulkarni, Tejas D. and Others and Whitney, William F and Kohli, Pushmeet and Tenenbaum, Joshua B.},
doi = {10.1063/1.4914407},
eprint = {1503.03167},
issn = {10897550},
journal = {Advances in Neural Information Processing Systems},
keywords = {,image synthesis,tesis},
mendeley-tags = {image synthesis,tesis},
pages = {1--10},
title = {{Deep Convolutional Inverse Graphics Network}},
url = {http://arxiv.org/abs/1503.03167},
volume = {2015},
year = {2015}
}
@article{Guang-BinHuang2014,
author = {{Guang-Bin Huang} and {Qin-Yu Zhu} and {Chee-Kheong Siew} and Huang, Guang-Bin and Zhu, Qin-Yu and Siew, Chee-Kheong and {Guang-Bin Huang} and {Qin-Yu Zhu} and {Chee-Kheong Siew}},
doi = {10.1109/IJCNN.2004.1380068},
institution = {IEEE},
isbn = {0-7803-8359-1},
journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
keywords = {,seminal},
mendeley-tags = {seminal},
number = {August 2004},
pages = {985--990},
title = {{Extreme learning machine: a new learning scheme of feedforward neural networks}},
url = {http://ieeexplore.ieee.org/document/1380068/},
volume = {2},
year = {2014}
}
@article{Khorrami2016a,
abstract = {We consider the task of dimensional emotion recognition on video data using deep learning. While several previous methods have shown the benefits of training temporal neural network models such as recurrent neural networks (RNNs) on hand-crafted features, few works have considered combining convolutional neural networks (CNNs) with RNNs. In this work, we present a system that performs emotion recognition on video data using both CNNs and RNNs, and we also analyze how much each neural network component contributes to the system's overall performance. We present our findings on videos from the Audio/Visual+Emotion Challenge (AV+EC2015). In our experiments, we analyze the effects of several hyperparameters on overall performance while also achieving superior performance to the baseline and other competing methods.},
archivePrefix = {arXiv},
arxivId = {1602.07377},
author = {Khorrami, Pooya and {Le Paine}, Tom and Brady, Kevin and Dagli, Charlie and Huang, Thomas S. and Paine, Tom Le and Brady, Kevin and Dagli, Charlie and Huang, Thomas S. and {Le Paine}, Tom and Brady, Kevin and Dagli, Charlie and Huang, Thomas S. and Paine, Tom Le and Brady, Kevin and Dagli, Charlie and Huang, Thomas S. and {Le Paine}, Tom and Brady, Kevin and Dagli, Charlie and Huang, Thomas S.},
doi = {10.1017/pasa.2016.3},
edition = {(ICIP), 20},
eprint = {1602.07377},
institution = {IEEE},
isbn = {9781467399616},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Convolutional Neural Networks,Deep Learning,Emotion Recognition,Recurrent Neural Networks,Video Processing,sentiment analysis,video classification},
mendeley-tags = {sentiment analysis,video classification},
pages = {619--623},
publisher = {Anais�IEEE},
title = {{How Deep Neural Networks Can Improve Emotion Recognition on Video Data}},
url = {http://arxiv.org/abs/1602.07377},
volume = {2016-Augus},
year = {2016}
}
@article{Isola2016,
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
annote = {From Duplicate 1 (Image-to-image translation with conditional adversarial networks. - Isola, P; others)

preprint},
archivePrefix = {arXiv},
arxivId = {1611.07004},
author = {Isola, Phillip and Zhu, Jun-Yan Yan and Zhou, Tinghui and Efros, Alexei A. and Others},
doi = {10.1109/CVPR.2017.632},
eprint = {1611.07004},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {5967--5976},
title = {{Image-to-image translation with conditional adversarial networks}},
url = {http://arxiv.org/abs/1611.07004},
volume = {2017-Janua},
year = {2016}
}
@article{Zhu2016,
abstract = {Realistic image manipulation is challenging because it requires modifying the image appearance in a user-controlled way, while preserving the realism of the result. Unless the user has considerable artistic skill, it is easy to "fall off" the manifold of natural images while editing. In this paper, we propose to learn the natural image manifold directly from data using a generative adversarial neural network. We then define a class of image editing operations, and constrain their output to lie on that learned manifold at all times. The model automatically adjusts the output keeping all edits as realistic as possible. All our manipulations are expressed in terms of constrained optimization and are applied in near-real time. We evaluate our algorithm on the task of realistic photo manipulation of shape and color. The presented method can further be used for changing one image to look like the other, as well as generating novel imagery from scratch based on user's scribbles.},
address = {Anais�},
archivePrefix = {arXiv},
arxivId = {1609.03552},
author = {Zhu, Jun-Yan Yan J.-y. and Kr??henb??hl, Philipp and Shechtman, Eli and Efros, Alexei A. and Kr{\"{a}}henb{\"{u}}hl, Philipp and Shechtman, Eli and Efros, Alexei A. and Others and Kr{\"{a}}henb{\"{u}}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},
doi = {10.1007/978-3-319-46454-1_36},
edition = {European C},
eprint = {1609.03552},
institution = {Springer},
isbn = {9783319464534},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {597--613},
pmid = {4520227},
publisher = {Springer},
title = {{Generative visual manipulation on the natural image manifold}},
volume = {9909 LNCS},
year = {2016}
}
@article{L.Elman1990,
abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction. {\textcopyright} 1990.},
author = {Elman, Jeffrey L. and L.Elman, Jeffrey and Elman, Jeffrey L.},
doi = {10.1207/s15516709cog1402_1},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive science},
keywords = {,seminal},
mendeley-tags = {seminal},
number = {2},
pages = {179--211},
pmid = {19563812},
publisher = {Wiley Online Library},
title = {{Finding structure in time}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed&cmd=Retrieve&dopt=AbstractPlus&list_uids=17969258453606390073related:OdlkvFuhX_kJ%5Cnpapers2://publication/uuid/3DEB06EE-B169-47A0-BD84-BFEE3386098E http://linkinghub.elsevier.com/retrieve/pii/036402},
volume = {14},
year = {1990}
}
@article{Wu2012,
abstract = {The Hop field model is a well-known dynamic associative-memory model. In this paper, we investigate various aspects of the Hop field model for associative memory. We conduct a systematic simulation investigation of several storage algorithms for Hop field networks, and conclude that the perceptron learning based storage algorithms can achieve much better storage capacity than the Hebbian learning based algorithms.},
author = {Paper, Conference and Wu, Yue and Hu, Jianqing and Wu, Wei and Zhou, Yong and Du, K. L.},
doi = {10.1109/ICICTA.2012.89},
institution = {IEEE},
isbn = {9780769546377},
journal = {Proceedings - 2012 5th International Conference on Intelligent Computation Technology and Automation, ICICTA 2012},
keywords = {Associative memory,Hebbian learning,Hopfield model,Perceptron learning,associative memory,hebbian,hopfield model,learning,perceptron learning,theory},
mendeley-tags = {theory},
number = {January},
pages = {330--336},
title = {{Storage capacity of the hopfield network associative memory}},
year = {2012}
}
@article{Rosenblatt1958,
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
author = {Rosenblatt, F. and Nonr-, Contract},
doi = {10.1037/h0042519},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {AS INFORMATION STORAGE MODEL INFORMATION,IN BRAIN BRAIN,INFORMATION STORAGE IN,MODEL FOR,MODEL FOR LEARNING & MEMORY,PERCEPTION,STORAGE,seminal},
mendeley-tags = {seminal},
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
url = {http://content.apa.org/journals/rev/65/6/386},
volume = {65},
year = {1958}
}
@article{Shizhou2016,
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human vi-sual cortex, and propose a DCNN performance im-provement method without the need for increasing the network complexity. Inspired by the category-selective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As ex-perimental results show, when applying the pro-posed method to the " Quick " model and NIN models, image classification performances are re-markably improved on four widely used bench-mark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
author = {Zhang, Shizhou and Gong, Yihong and Wang, Jinjun and Shizhou, Zhang and Gong, Yihong and Jinjun, Wang},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning,image synthesis},
mendeley-tags = {image synthesis},
pages = {2343--2349},
title = {{Improving DCNN performance with sparse category-selective objective function}},
volume = {2016-Janua},
year = {2016}
}
@article{Sainath2015,
abstract = {Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, we hypothesize that CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs). In this paper, we explore applying CNNs to large vocabulary continuous speech recognition (LVCSR) tasks. First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks. Specifically, we focus on how many convolutional layers are needed, what is an appropriate number of hidden units, what is the best pooling strategy. Second, investigate how to incorporate speaker-adapted features, which cannot directly be modeled by CNNs as they do not obey locality in frequency, into the CNN framework. Third, given the importance of sequence training for speech tasks, we introduce a strategy to use ReLU+dropout during Hessian-free sequence training of CNNs. Experiments on 3 LVCSR tasks indicate that a CNN with the proposed speaker-adapted and ReLU+dropout ideas allow for a 12%-14% relative improvement in WER over a strong DNN system, achieving state-of-the art results in these 3 tasks.},
archivePrefix = {arXiv},
arxivId = {1309.1501},
author = {Sainath, Tara N. and Kingsbury, Brian and Saon, George and Soltau, Hagen and rahman Mohamed, Abdel-rahman and Dahl, George and Ramabhadran, Bhuvana and Others and Kingsbury, Brian and Saon, George and Soltau, Hagen and rahman Mohamed, Abdel-rahman and Dahl, George and Ramabhadran, Bhuvana},
doi = {10.1016/j.neunet.2014.08.005},
eprint = {1309.1501},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep learning,Neural networks,Speech recognition,speech recognition},
mendeley-tags = {speech recognition},
pages = {39--48},
pmid = {25439765},
publisher = {Elsevier Ltd},
title = {{Deep Convolutional Neural Networks for Large-scale Speech Tasks}},
url = {http://dx.doi.org/10.1016/j.neunet.2014.08.005},
volume = {64},
year = {2015}
}
@article{Gatys2016,
abstract = {Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic in-formation and, thus, allow to separate image content from style. Here we use image representations derived from Con-volutional Neural Networks optimised for object recogni-tion, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can sep-arate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an ar-bitrary photograph with the appearance of numerous well-known artworks. Our results provide new insights into the deep image representations learned by Convolutional Neu-ral Networks and demonstrate their potential for high level image synthesis and manipulation.},
archivePrefix = {arXiv},
arxivId = {1505.07376},
author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
doi = {10.1109/CVPR.2016.265},
eprint = {1505.07376},
isbn = {9781467388511},
issn = {10636919},
journal = {The IEEE conference on computer vision and pattern recognition},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {2414--2423},
pmid = {15430064963552939126},
title = {{Image style transfer using convolutional neural networks}},
volume = {2016-Decem},
year = {2016}
}
@article{Tuohy2006,
abstract = {In this paper we describe a technique for creating guitar tablature using a neural network. Training data was parsed from an online repository of human-created tablatures. The contents of both the input layer and the set of training data have been optimized through genetic search in order to maximize the accuracy of the network. The output of the network is im- proved upon with a local heuristic hill-climber (HC). We implement this model in an existing system for generating guitar arrangements via genetic algorithm (GA). When compared to the original system for generating tablature, we note modest improvement in tablature quality and drastic improvements in execution time.},
author = {Tuohy, Daniel R. and Potter, Walter D. and Center, Artificial Intelligence},
isbn = {%(},
journal = {Procs. of the International Computer Music Conference (ICMC06)},
keywords = {GA,fingering_prediction,guitar,music transcription},
mendeley-tags = {GA,music transcription},
number = {January 2006},
pages = {576--579},
title = {{An Evolved Neural Network/HC Hybrid for Tablature Creation in GA- based Guitar Arranging}},
url = {http://quod.lib.umich.edu/cgi/p/pod/dod-idx?c=icmc;idno=bbp2372.2006.119},
volume = {2006},
year = {2006}
}
@article{Choi2016a,
abstract = {We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.},
annote = {From Duplicate 4 (Automatic tagging using deep convolutional neural networks. - Choi, K; Fazekas, G; Sandler, M)

preprint},
archivePrefix = {arXiv},
arxivId = {1606.00298},
author = {Choi, Keunwoo and Fazekas, George Gy{\"{o}}rgy and Sandler, Mark},
doi = {10.5281/zenodo.1416253},
eprint = {1606.00298},
isbn = {9780692755068},
journal = {arXiv preprint arXiv:1606.00298},
keywords = {,music classification},
mendeley-tags = {music classification},
pages = {805--811},
title = {{Automatic tagging using deep convolutional neural networks}},
url = {http://arxiv.org/abs/1606.00298},
year = {2016}
}
@article{Bell2015a,
abstract = {It is well known that contextual and multi-scale representations are important for accurate visual recognition. In this paper we present the Inside-Outside Net (ION), an object detector that exploits information both inside and outside the region of interest. Contextual information outside the region of interest is integrated using spatial recurrent neural networks. Inside, we use skip pooling to extract information at multiple scales and levels of abstraction. Through extensive experiments we evaluate the design space and provide readers with an overview of what tricks of the trade are important. ION improves state-of-the-art on PASCAL VOC 2012 object detection from 73.9% to 77.9% mAP. On the new and more challenging MS COCO dataset, we improve state-of-the-art from 19.7% to 33.1% mAP. In the 2015 MS COCO Detection Challenge, our ION model won 'Best Student Entry' and finished 3rd place overall. As intuition suggests, our detection results provide strong evidence that context and multi-scale representations improve small object detection.},
archivePrefix = {arXiv},
arxivId = {1512.04143},
author = {Bell, Sean and {Lawrence Zitnick}, C and Bala, Kavita and Girshick, Ross and Zitnick, C. Lawrence and Bala, Kavita and Girshick, Ross and {Lawrence Zitnick}, C and Bala, Kavita and Girshick, Ross and Zitnick, C. Lawrence and Bala, Kavita and Girshick, Ross},
doi = {10.1109/CVPR.2016.314},
eprint = {1512.04143},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {,object detection},
mendeley-tags = {object detection},
pages = {2874--2883},
pmid = {21803542},
title = {{Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1512.04143},
volume = {2016-Decem},
year = {2016}
}
@article{Huang2016,
abstract = {A sparse representation classifier (SRC) and a kernel discriminant analysis (KDA) are two successful methods for face recognition. An SRC is good at dealing with occlusion, while a KDA does well in suppressing intraclass variations. In this paper, we propose kernel extended dictionary (KED) for face recognition, which provides an efficient way for combining KDA and SRC. We first learn several kernel principal components of occlusion variations as an occlusion model, which can represent the possible occlusion variations efficiently. Then, the occlusion model is projected by KDA to get the KED, which can be computed via the same kernel trick as new testing samples. Finally, we use structured SRC for classification, which is fast as only a small number of atoms are appended to the basic dictionary, and the feature dimension is low. We also extend KED to multikernel space to fuse different types of features at kernel level. Experiments are done on several large-scale data sets, demonstrating that not only does KED get impressive results for nonoccluded samples, but it also handles the occlusion well without overfitting, even with a single gallery sample per subject.},
author = {Huang, Ke-Kun Kun and Dai, Dao-Qing Qing and Ren, Chuan-Xian Xian and Lai, Zhao-Rong Rong},
doi = {10.1109/TNNLS.2016.2522431},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Face occlusion,face recognition,image classification,kernel discriminant analysis (KDA),sparse representation classifier (SRC)},
mendeley-tags = {image classification},
number = {5},
pages = {1082--1094},
pmid = {26890929},
publisher = {IEEE},
title = {{Learning Kernel Extended Dictionary for Face Recognition}},
volume = {28},
year = {2017}
}
@article{Zhang2017,
abstract = {Convolutional Neural Networks (CNNs) are effective models for reducing spectral variations and modeling spectral correlations in acoustic features for automatic speech recognition (ASR). Hybrid speech recognition systems incorporating CNNs with Hidden Markov Models/Gaussian Mixture Models (HMMs/GMMs) have achieved the state-of-the-art in various benchmarks. Meanwhile, Connectionist Temporal Classification (CTC) with Recurrent Neural Networks (RNNs), which is proposed for labeling unsegmented sequences, makes it feasible to train an end-to-end speech recognition system instead of hybrid settings. However, RNNs are computationally expensive and sometimes difficult to train. In this paper, inspired by the advantages of both CNNs and the CTC approach, we propose an end-to-end speech framework for sequence labeling, by combining hierarchical CNNs with CTC directly without recurrent connections. By evaluating the approach on the TIMIT phoneme recognition task, we show that the proposed model is not only computationally efficient, but also competitive with the existing baseline systems. Moreover, we argue that CNNs have the capability to model temporal correlations with appropriate context information.},
annote = {From Duplicate 1 (Towards end-to-end speech recognition with deep convolutional neural networks - Zhang, Ying; Pezeshki, Mohammad; Brakel, Phil{\'{e}}mon; Zhang, Saizheng; Laurent, C{\'{e}}sar; Bengio, Yoshua; Courville, Aaron)

preprint},
archivePrefix = {arXiv},
arxivId = {1701.02720},
author = {Zhang, Ying and Pezeshki, Mohammad and Brakel, Philemon Phil{\'{e}}mon Philemon and Zhang, Saizheng and Bengio, Cesar Laurent Yoshua and Courville, Aaron and Laurent, C{\'{e}}sar and Bengio, Yoshua and Courville, Aaron},
doi = {10.21437/Interspeech.2016-1446},
eprint = {1701.02720},
issn = {19909772},
journal = {arXiv preprint arXiv:1701.02720},
keywords = {Connectionist temporal classification,Convolutional neural networks,Speech recognition,speech recognition},
mendeley-tags = {speech recognition},
pages = {410--414},
title = {{Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1701.02720},
volume = {08-12-Sept},
year = {2017}
}
@article{Graves2013,
abstract = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates \emph{deep recurrent neural networks}, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.},
archivePrefix = {arXiv},
arxivId = {1303.5778},
author = {Graves, Alex and Mohamed, A.-r. Abdel-rahman Rahman and Hinton, Geoffrey},
doi = {10.1109/ICASSP.2013.6638947},
edition = {Acoustics,},
eprint = {1303.5778},
institution = {IEEE},
isbn = {978-1-4799-0356-6},
issn = {1520-6149},
journal = {Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},
keywords = {deep neural networks,recurrent neural networks,speech recognition},
mendeley-tags = {speech recognition},
number = {3},
pages = {6645--6649},
pmid = {27295638},
publisher = {Anais�IEEE},
title = {{Speech Recognition with Deep Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1303.5778},
year = {2013}
}
@article{Mollahosseini2015a,
abstract = {Automated Facial Expression Recognition (FER) has remained a challenging and interesting problem. Despite efforts made in developing various methods for FER, existing approaches traditionally lack generalizability when applied to unseen images or those that are captured in wild setting. Most of the existing approaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where the classifier's hyperparameters are tuned to give best recognition accuracies across a single database, or a small collection of similar databases. Nevertheless, the results are not significant when they are applied to novel data. This paper proposes a deep neural network architecture to address the FER problem across multiple well-known standard face datasets. Specifically, our network consists of two convolutional layers each followed by max pooling and then four Inception layers. The network is a single component architecture that takes registered facial images as the input and classifies them into either of the six basic or the neutral expressions. We conducted comprehensive experiments on seven publically available facial expression databases, viz. MultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of proposed architecture are comparable to or better than the state-of-the-art methods and better than traditional convolutional neural networks and in both accuracy and training time.},
archivePrefix = {arXiv},
arxivId = {1511.04110},
author = {Mollahosseini, Ali and Chan, David and Mahoor, Mohammad H.},
doi = {10.1109/WACV.2016.7477450},
eprint = {1511.04110},
institution = {IEEE},
isbn = {9781509006410},
journal = {Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on},
keywords = {,facial expression},
mendeley-tags = {facial expression},
pages = {1--10},
title = {{Going deeper in facial expression recognition using deep neural networks}},
url = {http://arxiv.org/abs/1511.04110%0Ahttp://dx.doi.org/10.1109/WACV.2016.7477450},
year = {2016}
}
@article{McCulloch1943,
abstract = {Because of the "all-or-none" character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {McCulloch, Warren S. and Pitts, Walter A},
doi = {10.1007/BF02478259},
eprint = {arXiv:1011.1669v3},
isbn = {0007-4985},
issn = {00074985},
journal = {The Bulletin of Mathematical Biophysics},
keywords = {,seminal},
mendeley-tags = {seminal},
number = {4},
pages = {115--133},
pmid = {2185863},
title = {{A logical calculus of the ideas immanent in nervous activity}},
volume = {5},
year = {1943}
}
@article{hwangimage,
author = {Hwang, Jeff and Zhou, You},
title = {{Image Colorization with Deep Convolutional Neural Networks}},
year = {2016}
}
@article{ke04,
abstract = {Digital waveguides and finite difference time domain schemes have been used in physical modeling of spatially distributed systems. Both of them are known to provide exact modeling of ideal one-dimensional (ID) band-limited wave propagation, and both of them can be composed to approximate two-dimensional (2D) and three-dimensional (3D) mesh structures. Their equal capabilities in physical modeling have been shown for special cases and have been assumed to cover generalized cases as well. The ability to form mixed models by joining substructures of both classes through converter elements has been proposed recently. In this paper, we formulate a general digital signal processing (DSP)-oriented framework where the functional equivalence of these two approaches is systematically elaborated and the conditions of building mixed models are studied. An example of mixed modeling of a 2D waveguide is presented.},
author = {Karjalainen, Matti and Erkut, Cumhur},
doi = {10.1155/S1110865704401176},
issn = {11108657},
journal = {Eurasip Journal on Applied Signal Processing},
keywords = {,Acoustic signal processing,Digital waveguides,Fdtd model structures,Hybrid models,Scattering,acoustic signal processing,and phrases,digital waveguides,fdtd model structures,hybrid models,scattering},
number = {7},
pages = {978--989},
title = {{Digital waveguides versus finite difference structures: Equivalence and mixed modeling}},
volume = {2004},
year = {2004}
}
@article{e17,
abstract = {Deep learning is an important new area of machine learning which encompasses a wide range of neural network architectures designed to complete various tasks. In the medical imaging domain, example tasks include organ segmentation, lesion detection, and tumor classification. The most popular network architecture for deep learning for images is the convolutional neural network (CNN). Whereas traditional machine learning requires determination and calculation of features from which the algorithm learns, deep learning approaches learn the important features as well as the proper weighting of those features to make predictions for new data. In this paper, we will describe some of the libraries and tools that are available to aid in the construction and efficient execution of deep learning as applied to medical images.},
author = {Erickson, Bradley J. and Korfiatis, Panagiotis and Akkus, Zeynettin and Kline, Timothy and Philbrick, Kenneth and Others},
doi = {10.1007/s10278-017-9965-6},
issn = {1618727X},
journal = {Journal of digital imaging, v.},
keywords = {,Artificial intelligence,Convolutional neural network,Deep learning,Machine learning},
number = {4},
pages = {400--405},
pmid = {28315069},
publisher = {Journal of Digital Imaging},
title = {{Toolkits and Libraries for Deep Learning}},
volume = {30},
year = {2017}
}
@article{Santurkar2017,
abstract = {Traditional image and video compression algorithms rely on hand-crafted encoder/decoder pairs (codecs) that lack adaptability and are agnostic to the data being compressed. Here we describe the concept of generative compression, the compression of data using generative models, and show its potential to produce more accurate and visually pleasing reconstructions at much deeper compression levels for both image and video data. We also demonstrate that generative compression is orders-of-magnitude more resilient to bit error rates (e.g. from noisy wireless channels) than traditional variable-length entropy coding schemes.},
archivePrefix = {arXiv},
arxivId = {1703.01467},
author = {Santurkar, Shibani and Budden, David and Shavit, Nir},
doi = {10.1109/PCS.2018.8456298},
eprint = {1703.01467},
isbn = {9781538641606},
journal = {arXiv preprint arXiv:1703.01467},
keywords = {,image compression- lossy},
mendeley-tags = {image compression- lossy},
pages = {258--262},
title = {{Generative Compression}},
url = {http://arxiv.org/abs/1703.01467},
year = {2017}
}
@article{Leung2003,
abstract = {This paper presents the tuning of the structure and parameters of a neural network using an improved genetic algorithm (GA). It is also shown that the improved GA performs better than the standard GA based on some benchmark test functions. A neural network with switches introduced to its links is proposed. By doing this, the proposed neural network can learn both the input-output relationships of an application and the network structure using the improved GA. The number of hidden nodes is chosen manually by increasing it from a small number until the learning performance in terms of fitness value is good enough. Application examples on sunspot forecasting and associative memory are given to show the merits of the improved GA and the proposed neural network.},
archivePrefix = {arXiv},
arxivId = {arXiv:1403.7012v1},
author = {Leung, F.H.F. Frank Hung-Fat F and Lam, Hak-Keung K and Ling, S.H. Sai-Ho H and Tam, Peter Kwong-Shun S P.K.S.},
doi = {10.1109/TNN.2002.804317},
eprint = {arXiv:1403.7012v1},
isbn = {1045-9227 (Print)\r1045-9227 (Linking)},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {,evolutive},
mendeley-tags = {evolutive},
number = {1},
pages = {79--88},
pmid = {18237992},
publisher = {IEEE},
title = {{Tuning of the structure and parameters of a neural network using an improved genetic algorithm.}},
url = {http://ieeexplore.ieee.org/document/1176129/},
volume = {14},
year = {2003}
}
@article{Floreano2008a,
abstract = {Artificial neural networks are applied to many\nreal-world problems, ranging from pattern classification\nto robot control. In order to design a neural network for\na particular task, the choice of an architecture\n(including the choice of a neuron model), and the choice\nof a learning algorithm have to be addressed.\nEvolutionary search methods can provide an automatic\nsolution to these problems. New insights in both\nneuroscience and evolutionary biology have led to the\ndevelopment of increasingly powerful neuroevolution\ntechniques over the last decade. This paper gives an\noverview of the most prominent methods for evolving\nartificial neural networks with a special focus on recent\nadvances in the synthesis of learning architectures.},
author = {Floreano, Dario and D{\"{u}}rr, Peter and Mattiussi, Claudio and D??rr, Peter and Mattiussi, Claudio and D{\"{u}}rr, Peter and Mattiussi, Claudio},
doi = {10.1007/s12065-007-0002-4},
isbn = {1206500700},
issn = {18645909},
journal = {Evolutionary Intelligence},
keywords = {Evolution,Learning,Neural networks,evolutive,review},
mendeley-tags = {evolutive,review},
number = {1},
pages = {47--62},
publisher = {Springer},
title = {{Neuroevolution: From architectures to learning}},
volume = {1},
year = {2008}
}
@article{Sak2015,
abstract = {We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition. More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC). In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition. We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding. CD phone modeling leads to further improvements. We also present initial results for LSTM RNN models outputting words directly.},
annote = {From Duplicate 4 (Fast and accurate recurrent neural network acoustic models for speech recognition. - Sak, H; others)

preprint},
archivePrefix = {arXiv},
arxivId = {1507.06947},
author = {Sak, Haşim Ha\csim Haşim and Others and Senior, Andrew and Rao, Kanishka and Beaufays, Fran{\c{c}}oise Francoise},
eprint = {1507.06947},
issn = {19909772},
journal = {arXiv preprint arXiv:1507.06947},
keywords = {Acoustic modeling,CTC,Connectionist temporal classification,LSTM RNN,Long short-term memory recurrent neural networks,Speech recognition,speech recognition},
mendeley-tags = {speech recognition},
pages = {1468--1472},
pmid = {1000285842},
title = {{Fast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition}},
url = {http://arxiv.org/abs/1507.06947},
volume = {2015-Janua},
year = {2015}
}
@article{Esteva2017,
abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images - two orders of magnitude larger than previous datasets - consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
author = {Esteva, Andre and Others and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
doi = {10.1038/nature21056},
isbn = {0028-0836},
issn = {14764687},
journal = {Nature},
keywords = {,health,image classification,state of the art},
mendeley-tags = {health,image classification,state of the art},
number = {7639},
pages = {115--118},
pmid = {28117445},
publisher = {Nature Publishing Group},
title = {{Dermatologist-level classification of skin cancer with deep neural networks}},
url = {http://dx.doi.org/10.1038/nature21056 http://www.nature.com/doifinder/10.1038/nature21056},
volume = {542},
year = {2017}
}
@article{Costa2017,
abstract = {Music genre recognition based on visual representation has been successfully explored over the last years. Classifiers trained with textural descriptors (e.g., Local Binary Patterns, Local Phase Quantization, and Gabor filters) extracted from the spectrograms have achieved state-of-the-art results on several music datasets. In this work, though, we argue that we can go further with the time-frequency analysis through the use of representation learning. To show that, we compare the results obtained with a Convolutional Neural Network (CNN) with the results obtained by using handcrafted features and SVM classifiers. In addition, we have performed experiments fusing the results obtained with learned features and handcrafted features to assess the complementarity between these representations for the music classification task. Experiments were conducted on three music databases with distinct characteristics, specifically a western music collection largely used in research benchmarks (ISMIR 2004 Database), a collection of Latin American music (LMD database), and a collection of field recordings of ethnic African music. Our experiments show that the CNN compares favorably to other classifiers in several scenarios, hence, it is a very interesting alternative for music genre recognition. Considering the African database, the CNN surpassed the handcrafted representations and also the state-of-the-art by a margin. In the case of the LMD database, the combination of CNN and Robust Local Binary Pattern achieved a recognition rate of 92%, which to the best of our knowledge, is the best result (using an artist filter) on this dataset so far. On the ISMIR 2004 dataset, although the CNN did not improve the state of the art, it performed better than the classifiers based individually on other kind of features.},
author = {Costa, Yandre M.G. G and Oliveira, Luiz S. and Silla, Carlos N.},
doi = {10.1016/j.asoc.2016.12.024},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {Music genre recognition,Neural network applications,Pattern recognition,music classification,music genre recognition,state of the art},
mendeley-tags = {music classification,state of the art},
pages = {28--38},
publisher = {Elsevier B.V.},
title = {{An evaluation of Convolutional Neural Networks for music classification using spectrograms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616306421},
volume = {52},
year = {2017}
}
@article{LeCun1998,
abstract = {Multilayer neural networks trained with the back-propagation\nalgorithm constitute the best example of a successful gradient based\nlearning technique. Given an appropriate network architecture,\ngradient-based learning algorithms can be used to synthesize a complex\ndecision surface that can classify high-dimensional patterns, such as\nhandwritten characters, with minimal preprocessing. This paper reviews\nvarious methods applied to handwritten character recognition and\ncompares them on a standard handwritten digit recognition task.\nConvolutional neural networks, which are specifically designed to deal\nwith the variability of 2D shapes, are shown to outperform all other\ntechniques. Real-life document recognition systems are composed of\nmultiple modules including field extraction, segmentation recognition,\nand language modeling. A new learning paradigm, called graph transformer\nnetworks (GTN), allows such multimodule systems to be trained globally\nusing gradient-based methods so as to minimize an overall performance\nmeasure. Two systems for online handwriting recognition are described.\nExperiments demonstrate the advantage of global training, and the\nflexibility of graph transformer networks. A graph transformer network\nfor reading a bank cheque is also described. It uses convolutional\nneural network character recognizers combined with global training\ntechniques to provide record accuracy on business and personal cheques.\nIt is deployed commercially and reads several million cheques per day\n},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {LeCun, Yann and Bottou, L{\'{e}}on L??on L{\'{e}}on L??on L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
doi = {10.1109/5.726791},
eprint = {1102.0183},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR),seminal},
mendeley-tags = {seminal},
number = {11},
pages = {2278--2323},
pmid = {15823584},
publisher = {IEEE},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@article{Veit2016,
abstract = {In this work we propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training. To support this observation, we rewrite residual networks as an explicit collection of paths. Unlike traditional models, paths through residual networks vary in length. Further, a lesion study reveals that these paths show ensemble-like behavior in the sense that they do not strongly depend on each other. Finally, and most surprising, most paths are shorter than one might expect, and only the short paths are needed during training, as longer paths do not contribute any gradient. For example, most of the gradient in a residual network with 110 layers comes from paths that are only 10-34 layers deep. Our results reveal one of the key characteristics that seem to enable the training of very deep networks: Residual networks avoid the vanishing gradient problem by introducing short paths which can carry gradient throughout the extent of very deep networks.},
archivePrefix = {arXiv},
arxivId = {1605.06431},
author = {Veit, Andreas and Wilber, Michael J and Belongie, Serge},
eprint = {1605.06431},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {,theory},
mendeley-tags = {theory},
pages = {550--558},
title = {{Residual networks behave like ensembles of relatively shallow networks}},
url = {http://arxiv.org/abs/1605.06431},
volume = {2016},
year = {2016}
}
@article{Hornik1991,
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp($\mu$) performance criteria, for arbitrary finite input environment measures $\mu$, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. {\textcopyright} 1991.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hornik, Kurt},
doi = {10.1016/0893-6080(91)90009-T},
eprint = {arXiv:1011.1669v3},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {Activation function,Input environment measure,Lp(??) approximation,Lp($\mu$) approximation,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities,theory},
mendeley-tags = {theory},
number = {2},
pages = {251--257},
pmid = {25246403},
publisher = {Elsevier},
title = {{Approximation capabilities of multilayer feedforward networks}},
volume = {4},
year = {1991}
}
@article{Zen2015,
abstract = {Long short-term memory recurrent neural networks (LSTM-RNNs) have been applied to various speech applications including acoustic modeling for statistical parametric speech synthesis. One of the con- cerns for applying them to text-to-speech applications is its effect on latency. To address this concern, this paper proposes a low-latency, streaming speech synthesis architecture using unidirectional LSTM- RNNs with a recurrent output layer. The use of unidirectional RNN architecture allows frame-synchronous streaming inference of out- put acoustic features given input linguistic features. The recurrent output layer further encourages smooth transition between acoustic features at consecutive frames. Experimental results in subjective listening tests show that the proposed architecture can synthesize natural sounding speech without requiring utterance-level batch pro- cessing.},
author = {Zen, Heiga and Sak, Hasim Ha\csim Ha\csim},
doi = {10.1109/ICASSP.2015.7178816},
institution = {IEEE},
isbn = {9781467369978},
issn = {9781467369978},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
keywords = {Statistical parametric speech synthesis,long short-term memory,low-latency,recurrent neural networks,speech synthesis},
mendeley-tags = {speech synthesis},
pages = {4470--4474},
pmid = {18557655},
title = {{Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis}},
volume = {2015-Augus},
year = {2015}
}
@article{03,
abstract = {A model of transverse piano string vibration, second order in time, which models frequency-dependent loss and dispersion effects is presented here. This model has many desirable properties, in particular that it can be written as a well-posed initial-boundary value problem (permitting stable finite difference schemes) and that it may be directly related to a digital waveguide model, a digital filter-based algorithm which can be used for musical sound synthesis. Techniques for the extraction of model parameters from experimental data over the full range of the grand piano are discussed, as is the link between the model parameters and the filter responses in a digital waveguide. Simulations are performed. Finally, the waveguide model is extended to the case of several coupled strings.},
author = {Bensa, Julien and Bilbao, Stefan and Kronland-Martinet, Richard and Smith, Julius O. and Iii, Julius O Smith},
doi = {10.1121/1.1587146},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {2},
pages = {1095--1107},
pmid = {12942987},
title = {{The simulation of piano string vibration: From physical models to finite difference schemes and digital waveguides}},
volume = {114},
year = {2003}
}
@article{Widrob1990,
abstract = {Fundamental developments in feedforward artificial neural networks from the past thirty years are reviewed. The central theme of this paper is a description of the history, origination, operating characteristics, and basic theory of several supervised neural network training algorithms including the Perceptron rule, the LMS algorithm, three Madaline rules, and the backpropagation technique. These methods were developed independently, but with the perspective of history they can all be related to each other. The concept underlying these algorithms is the “minimal disturbance principle,” which suggests that during training it is advisable to inject new information into a network in a manner that disturbs stored information to the smallest extent possible. {\textcopyright} 1990 IEEE},
address = {n. 9, p. 1415�1442},
author = {Widrow, Bernard and Lehr, Michael A.},
doi = {10.1109/5.58323},
isbn = {0018-9219},
issn = {15582256},
journal = {Proceedings of the IEEE},
keywords = {,review},
mendeley-tags = {review},
number = {9},
pages = {1415--1442},
publisher = {v. 78},
title = {{30 Years of Adaptive Neural Networks: Perceptron, Madaline, and Backpropagation}},
volume = {78},
year = {1990}
}
@article{Wang2016,
abstract = {In recent years, financialmarket dynamics forecasting has been a focus of economic research. To predict the price indices of stock markets,we developed an architecturewhich combinedElman recurrent neural networkswith stochastic time effective function.By analyzing the proposedmodelwith the linear regression, complexity invariant distance (CID), andmultiscaleCID(MCID) analysis methods and taking themodel compared with differentmodels such as the backpropagation neural network (BPNN), the stochastic time effective neural network (STNN), and the Elman recurrent neural network (ERNN), the empirical results show that the proposed neural network displays the best performance among these neural networks in financial time series forecasting. Further, the empirical research is performed in testing the predictive effects of SSE, TWSE, KOSPI, and Nikkei225 with the established model, and the corresponding statistical comparisons of the above market indices are also exhibited. The experimental results show that this approach gives good performance in predicting the values fromthe stockmarket indices. 1.},
author = {Wang, Jun Jie Jun Jie and Wang, Jun Jie Jun Jie and Fang, Wen and Niu, Hongli},
doi = {10.1155/2016/4742515},
isbn = {1687-5265},
issn = {16875273},
journal = {Computational Intelligence and Neuroscience},
keywords = {,forecasting},
mendeley-tags = {forecasting},
publisher = {Hindawi Publishing Corporation},
title = {{Financial Time Series Prediction Using Elman Recurrent Random Neural Networks}},
volume = {2016},
year = {2016}
}
@article{Theis2015,
abstract = {Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multidimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.},
archivePrefix = {arXiv},
arxivId = {1506.03478},
author = {Theis, Lucas and Bethge, Matthias},
eprint = {1506.03478},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {1927--1935},
title = {{Generative image modeling using spatial LSTMs}},
url = {http://arxiv.org/abs/1506.03478},
volume = {2015-Janua},
year = {2015}
}
@article{Bagozzi2006,
abstract = {We conceptualize participation in Linux user groups (LUGs) in terms of group-referent intentional actions and investigate cognitive (attitudes, perceived behavioral control, identification with the open source movement), affective (positive and negative anticipated emotions), and social (social identity) determinants of participation and its consequences on Linux-related behaviors of users. This survey-based study, conducted with 402 active LUG members representing 191 different LUGs from 23 countries and employing structural equation modeling methodology, supports the proposed model. Furthermore, we find that the Linux user's experience level moderates the extent of the LUG's social influence and its impact on the user's participation. We conclude with a consideration of the managerial and research implications of the study's findings.},
author = {Bagozzi, Richard P. and Dholakia, Utpal M.},
doi = {10.1287/mnsc.1060.0545},
isbn = {0025-1909},
issn = {0025-1909},
journal = {Management Science},
keywords = {,2004,accepted by eric von,anticipated emotions,for 3 revisions,hippel and georg von,history,krogh,linux,model of goal-directed behavior,novice versus experienced users,open source software,received september 1,social identity,special issue editors,the authors 4 months,this paper was with,virtual communities,we-intentions},
month = {jul},
number = {7},
pages = {1099--1115},
pmid = {21517591},
title = {{Open Source Software User Communities: A Study of Participation in Linux User Groups}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0545},
volume = {52},
year = {2006}
}
@article{Iizuka2016a,
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
author = {Iizuka, Satoshi and Simo-Serra, Edgar and Ishikawa, Hiroshi},
doi = {10.1145/2897824.2925974},
isbn = {9781450342797},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Colorization,Convolutional neural network,colorization,computing methodologies,convolutional neural network concepts,image processing,image synthesis,neural net-},
mendeley-tags = {image synthesis},
number = {4},
pages = {1--11},
publisher = {ACM},
title = {{Let there be color! :Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification}},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
volume = {35},
year = {2016}
}
@article{Gregor2016a,
abstract = {We introduce convolutional DRAW, a homogeneous deep generative model achieving state-of-the-art performance in latent variable image modeling. The algorithm naturally stratifies information into higher and lower level details, creating abstract features and as such addressing one of the fundamentally desired properties of representation learning. Furthermore, the hierarchical ordering of its latents creates the opportunity to selectively store global information about an image, yielding a high quality 'conceptual compression' framework.},
archivePrefix = {arXiv},
arxivId = {1604.08772},
author = {Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
eprint = {1604.08772},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
keywords = {,image compression - conceptual,state of the art},
mendeley-tags = {image compression - conceptual,state of the art},
number = {Nips},
pages = {3549--3557},
title = {{Towards conceptual compression}},
url = {http://arxiv.org/abs/1604.08772},
year = {2016}
}
@article{Risi2017,
abstract = {This paper surveys research on applying neuroevolution (NE) to games. In neuroevolution, artificial neural networks are trained through evolutionary algorithms, taking inspiration from the way biological brains evolved. We analyse the application of NE in games along five different axes, which are the role NE is chosen to play in a game, the different types of neural networks used, the way these networks are evolved, how the fitness is determined and what type of input the network receives. The article also highlights important open research challenges in the field.},
archivePrefix = {arXiv},
arxivId = {1410.7326},
author = {Risi, Sebastian and Togelius, Julian},
doi = {10.1109/TCIAIG.2015.2494596},
eprint = {1410.7326},
isbn = {1943-068X VO  - PP},
issn = {1943068X},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
keywords = {Evolutionary algorithms,evolutive,games,neural networks,neuroevolution,review},
mendeley-tags = {evolutive,games,review},
number = {1},
pages = {25--41},
publisher = {IEEE},
title = {{Neuroevolution in Games: State of the Art and Open Challenges}},
volume = {9},
year = {2017}
}
@article{Yang2017,
abstract = {The Recurrent Neural Networks and their variants have shown promising performances in sequence modeling tasks such as Natural Language Processing. These models, however, turn out to be impractical and difficult to train when exposed to very high-dimensional inputs due to the large input-to-hidden weight matrix. This may have prevented RNNs' large-scale application in tasks that involve very high input dimensions such as video modeling; current approaches reduce the input dimensions using various feature extractors. To address this challenge, we propose a new, more general and efficient approach by factorizing the input-to-hidden weight matrix using Tensor-Train decomposition which is trained simultaneously with the weights themselves. We test our model on classification tasks using multiple real-world video datasets and achieve competitive performances with state-of-the-art models, even though our model architecture is orders of magnitude less complex. We believe that the proposed approach provides a novel and fundamental building block for modeling high-dimensional sequential data with RNN architectures and opens up many possibilities to transfer the expressive and advanced architectures from other domains such as NLP to modeling high-dimensional sequential data.},
archivePrefix = {arXiv},
arxivId = {1707.01786},
author = {Yang, Yinchong and Krompass, Denis and Tresp, Volker},
eprint = {1707.01786},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
keywords = {,video classification},
mendeley-tags = {video classification},
pages = {5929--5938},
title = {{Tensor-Train Recurrent Neural Networks for Video Classification}},
url = {https://arxiv.org/pdf/1707.01786.pdf},
volume = {8},
year = {2017}
}
@article{Schmidhuber2015,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, J??rgen J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning,review},
mendeley-tags = {review},
pages = {85--117},
pmid = {25462637},
title = {{Deep Learning in neural networks: An overview}},
volume = {61},
year = {2015}
}
@article{Hornik1989,
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators. ?? 1989.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
doi = {10.1016/0893-6080(89)90020-8},
eprint = {arXiv:1011.1669v3},
isbn = {08936080 (ISSN)},
issn = {08936080},
journal = {Neural Networks},
keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation,seminal,theory},
mendeley-tags = {seminal,theory},
number = {5},
pages = {359--366},
pmid = {74},
publisher = {Elsevier},
title = {{Multilayer feedforward networks are universal approximators}},
volume = {2},
year = {1989}
}
@article{Deng2016,
abstract = {With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user's trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users' interests and their trusted friends' interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.},
author = {Deng, Shuiguang and Huang, Longtao and Xu, Guandong and Wu, Xindong and Wu, Zhaohui},
doi = {10.1109/TNNLS.2016.2514368},
isbn = {2162-2388 (Electronic)\r2162-237X (Linking)},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Deep learning,Recommender systems (RSs),Social network,Trust,social recommendations},
mendeley-tags = {social recommendations},
number = {February},
pages = {1164--1177},
pmid = {26915135},
title = {{On Deep Learning for Trust-Aware Recommendations in Social Networks}},
volume = {28},
year = {2016}
}
@article{Lee2015,
abstract = {We seek to improve deep neural networks by generalizing the pooling operations that play a central role in current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures. These benefits come with only a light increase in computational overhead during training and a very modest increase in the number of model parameters.},
archivePrefix = {arXiv},
arxivId = {1509.08985},
author = {Lee, Chen-Yu and Gallagher, Patrick W. and Tu, Zhuowen},
doi = {10.1109/TPAMI.2017.2703082},
eprint = {1509.08985},
issn = {0162-8828},
journal = {Artificial Intelligence and Statistics},
keywords = {,optimization},
mendeley-tags = {optimization},
pages = {464--472},
pmid = {67101},
title = {{Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree}},
url = {http://arxiv.org/abs/1509.08985},
volume = {51},
year = {2015}
}
@article{Sarroff,
abstract = {With an optimal network topology and tuning of hyperpa-rameters, artificial neural networks (ANNs) may be trained to learn a mapping from low level audio features to one or more higher-level representations. Such artificial neural networks are commonly used in classification and regression settings to perform arbitrary tasks. In this work we suggest repurposing autoencoding neural networks as musical audio synthesizers. We offer an interactive musical audio synthesis system that uses feedforward artificial neural networks for musical audio synthesis, rather than discriminative or regression tasks. In our system an ANN is trained on frames of low-level features. A high level representation of the musical audio is learned though an autoencoding neural net. Our real-time synthesis system allows one to interact directly with the parameters of the model and generate musical audio in real time. This work therefore proposes the exploitation of neural networks for creative musical applications. Copyright:},
author = {Sarroff, Andy M. and Casey, Michael},
isbn = {9789604661374},
journal = {Proceedings - 40th International Computer Music Conference, ICMC 2014 and 11th Sound and Music Computing Conference, SMC 2014 - Music Technology Meets Philosophy: From Digital Echos to Virtual Ethos},
number = {September},
pages = {14--20},
title = {{Musical audio synthesis using autoencoding neural nets}},
volume = {1},
year = {2014}
}
@article{wang2017tacotron,
abstract = {A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods.},
archivePrefix = {arXiv},
arxivId = {1703.10135},
author = {Wang, Yuxuan and Skerry-Ryan, RJ J. and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J. and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and Le, Quoc and Agiomyrgiannakis, Yannis and Clark, Rob and Saurous, Rif A.},
doi = {10.21437/Interspeech.2017-1452},
eprint = {1703.10135},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Sequence-To-sequence,Text-To-speech synthesis,end-To-end model.,speech synthesis,state of the art},
mendeley-tags = {speech synthesis,state of the art},
pages = {4006--4010},
title = {{Tacotron: Towards end-To-end speech synthesis}},
url = {http://arxiv.org/abs/1703.10135},
volume = {2017-Augus},
year = {2017}
}
@article{Arik2017,
abstract = {We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For the segmentation model, we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component, our system is simpler and more flexible than traditional text-to-speech systems, where each component requires laborious feature engineering and extensive domain expertise. Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.},
archivePrefix = {arXiv},
arxivId = {1702.07825},
author = {Arik, Sercan O. and Chrzanowski, Mike and Coates, Adam and Diamos, Gregory and Gibiansky, Andrew and Kang, Yongguo and Li, Xian and Miller, John and Ng, Andrew and Raiman, Jonathan and Sengupta, Shubho and Shoeybi, Mohammad and Others and Ng, Andrew and Raiman, Jonathan and Sengupta, Shubho and Shoeybi, Mohammad and Others},
eprint = {1702.07825},
issn = {1938-7228},
journal = {arXiv preprint arXiv:1702.07825},
keywords = {,speech synthesis,state of the art},
mendeley-tags = {speech synthesis,state of the art},
number = {Icml},
title = {{Deep Voice: Real-time Neural Text-to-Speech}},
url = {http://arxiv.org/abs/1702.07825},
year = {2017}
}
@article{Toderici2016a,
abstract = {This paper presents a set of full-resolution lossy image compression methods based on neural networks. Each of the architectures we describe can provide variable compression rates during deployment without requiring retraining of the network: each network need only be trained once. All of our architectures consist of a recurrent neural network (RNN)-based encoder and decoder, a binarizer, and a neural network for entropy coding. We compare RNN types (LSTM, associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study "one-shot" versus additive reconstruction architectures and introduce a new scaled-additive framework. We compare to previous work, showing improvements of 4.3%-8.8% AUC (area under the rate-distortion curve), depending on the perceptual metric used. As far as we know, this is the first neural network architecture that is able to outperform JPEG at image compression across most bitrates on the rate-distortion curve on the Kodak dataset images, with and without the aid of entropy coding.},
archivePrefix = {arXiv},
arxivId = {1608.05148},
author = {Toderici, George and Vincent, Damien and Johnston, Nick and Hwang, Sung Jin and Minnen, David and Shor, Joel and Covell, Michele},
doi = {10.4135/9781412985277},
eprint = {1608.05148},
isbn = {9780761914402},
issn = {08936080},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
keywords = {,image compression- lossy},
mendeley-tags = {image compression- lossy},
pages = {5435--5443},
pmid = {21655600},
title = {{Full Resolution Image Compression with Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1608.05148},
volume = {2017-Janua},
year = {2016}
}
@article{Ding2016,
abstract = {Relatively small data sets available for expression recognition research make the training of deep networks for expression recognition very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redun- dant information from the pre-trained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully- connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization shows that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu-CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1609.06591},
author = {Ding, Hui and Zhou, Shaohua Kevin and Chellappa, Rama},
doi = {10.1109/FG.2017.23},
eprint = {1609.06591},
institution = {IEEE},
isbn = {9781509040230},
issn = {2160-7508},
journal = {Automatic Face & Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
keywords = {,facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
pages = {118--126},
title = {{FaceNet2ExpNet: Regularizing a Deep Face Recognition Net for Expression Recognition}},
url = {http://arxiv.org/abs/1609.06591},
year = {2016}
}
@article{Park2017a,
author = {Park, Sungheon and Kwak, Nojun},
doi = {10.1007/978-3-319-54184-6_12},
institution = {Springer},
isbn = {9783319541839},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {,optimization},
mendeley-tags = {optimization},
pages = {189--204},
title = {{Analysis on the dropout effect in convolutional neural networks}},
volume = {10112 LNCS},
year = {2017}
}
@article{stanley2007compositional,
abstract = {Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed.},
author = {Stanley, Kenneth O.},
doi = {10.1007/s10710-007-9028-8},
isbn = {1389-2576},
issn = {13892576},
journal = {Genetic programming and evolvable machines},
keywords = {,Artificial embryogeny,Complexity,Developmental encoding,Evolutionary computation,Generative systems,Indirect encoding,Representation},
number = {2},
pages = {131--162},
publisher = {Springer},
title = {{Compositional pattern producing networks: A novel abstraction of development}},
volume = {8},
year = {2007}
}
@article{Larsson2016,
abstract = {We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.},
address = {Anais�},
archivePrefix = {arXiv},
arxivId = {1603.06668},
author = {Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
doi = {10.1007/978-3-319-46493-0_35},
edition = {European C},
eprint = {1603.06668},
institution = {Springer},
isbn = {9783319464923},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {,image synthesis},
mendeley-tags = {image synthesis},
pages = {577--593},
publisher = {Springer},
title = {{Learning representations for automatic colorization}},
volume = {9908 LNCS},
year = {2016}
}
@article{Tsai2006,
abstract = {In this paper, a hybrid Taguchi-genetic algorithm (HTGA) is applied to solve the problem of tuning both network structure and parameters of a feedforward neural network. The HTGA approach is a method of combining the traditional genetic algorithm (TGA), which has a powerful global exploration capability, with the Taguchi method, which can exploit the optimum offspring. The Taguchi method is inserted between crossover and mutation operations of a TGA. Then, the systematic reasoning ability of the Taguchi method is incorporated in the crossover operations to select the better genes to achieve crossover, and consequently enhance the genetic algorithms. Therefore, the HTGA approach can be more robust, statistically sound, and quickly convergent. First, the authors evaluate the performance of the presented HTGA approach by studying some global numerical optimization problems. Then, the presented HTGA approach is effectively applied to solve three examples on forecasting the sunspot numbers, tuning the associative memory, and solving the XOR problem. The numbers of hidden nodes and the links of the feedforward neural network are chosen by increasing them from small numbers until the learning performance is good enough. As a result, a partially connected feedforward neural network can be obtained after tuning. This implies that the cost of implementation of the neural network can be reduced. In these studied problems of tuning both network structure and parameters of a feedforward neural network, there are many parameters and numerous local optima so that these studied problems are challenging enough for evaluating the performances of any proposed GA-based approaches. The computational experiments show that the presented HTGA approach can obtain better results than the existing method reported recently in the literature.},
author = {Tsai, Jinn-Tsong Tsong and Chou, Jyh-Horng Horng and Liu, Tung-Kuan Kuan},
doi = {10.1109/TNN.2005.860885},
isbn = {1045-9227 (Print)\r1045-9227 (Linking)},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Genetic algorithm (GA),Neural networks (NN),Taguchi method,evolutive},
mendeley-tags = {evolutive},
number = {1},
pages = {69--80},
pmid = {16526477},
publisher = {IEEE},
title = {{Tuning the structure and parameters of a neural network by using hybrid Taguchi-genetic algorithm}},
volume = {17},
year = {2006}
}
@article{Hou2015,
author = {Hou, Weilong and Gao, Xinbo and Tao, Dacheng and Li, Xuelong and Member, Senior and Tao, Dacheng and Member, Senior},
journal = {IEEE transactions on neural networks and learning systems},
keywords = {,image classification,sentiment analysis},
mendeley-tags = {image classification,sentiment analysis},
number = {6},
pages = {1275--1286},
publisher = {IEEE},
title = {{Blind Image Quality Assessment via Deep Learning}},
volume = {26},
year = {2015}
}
@article{Hopfield1982,
abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.3159v1},
author = {Hopfield, John J.},
doi = {10.1073/pnas.79.8.2554},
eprint = {arXiv:1411.3159v1},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {,seminal},
mendeley-tags = {seminal},
number = {8},
pages = {2554--2558},
pmid = {6953413},
publisher = {National Acad Sciences},
title = {{Neural networks and physical systems with emergent collective computational abilities.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
volume = {79},
year = {1982}
}
@article{Yadav2007,
abstract = {Single neuron models are typical functional replica of the biological neuron that are derived using their individual and group responses in networks. In recent past, a lot of work in this area has produced advanced neuron models for both analog and binary data patterns. Popular among these are the higher-order neurons, fuzzy neurons and other polynomial neurons. In this paper, we propose a new neuron model based on a polynomial architecture. Instead of considering all the higher-order terms, a simple aggregation function is used. The aggregation function is considered as a product of linear functions in different dimensions of the space. The functional mapping capability of the proposed neuron model is demonstrated through some well known time series prediction problems and is compared with the standard multilayer neural network. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Yadav, Ram N. and Kalra, Prem Kumar and John, Joseph},
doi = {10.1016/j.asoc.2006.01.003},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Capacity of single neuron,Financial time series prediction,Mackey-Glass time series,Multiplicative neuron model,Time series prediction,forecasting},
mendeley-tags = {forecasting},
number = {4},
pages = {1157--1163},
publisher = {Elsevier},
title = {{Time series prediction with single multiplicative neuron model}},
volume = {7},
year = {2007}
}
@article{Sigtia2016b,
abstract = {We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yields the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.},
archivePrefix = {arXiv},
arxivId = {1508.01774},
author = {Sigtia, Siddharth and Benetos, Emmanouil and DIxon, Simon},
doi = {10.1109/TASLP.2016.2533858},
eprint = {1508.01774},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Automatic music transcription,Deep learning,Music language models,Recurrent neural networks,music transcription,state of the art},
mendeley-tags = {music transcription,state of the art},
number = {5},
pages = {927--939},
publisher = {IEEE Press},
title = {{An end-to-end neural network for polyphonic piano music transcription}},
url = {https://arxiv.org/abs/1508.01774},
volume = {24},
year = {2016}
}
@article{Hutchings2017,
abstract = {Presented is a method of generating a full drum kit part for a provided kick-drum sequence. A sequence to sequence neural network model used in natural language translation was adopted to encode multiple musical styles and an online survey was developed to test different techniques for sampling the output of the softmax function. The strongest results were found using a sampling technique that drew from the three most probable outputs at each subdivision of the drum pattern but the consistency of output was found to be heavily dependent on style.},
annote = {From Duplicate 2 (Talking Drums: Generating drum grooves with neural networks. - Hutchings, P)

preprint},
archivePrefix = {arXiv},
arxivId = {1706.09558},
author = {Hutchings, P.},
eprint = {1706.09558},
issn = {23318422},
journal = {arXiv},
keywords = {Generative music,Percussion,RNN,Translation,music generation,state of the art},
mendeley-tags = {music generation,state of the art},
number = {1},
pages = {43--47},
title = {{Talking Drums: Generating drum grooves with neural networks}},
url = {http://arxiv.org/abs/1706.09558},
volume = {1},
year = {2017}
}
@article{Omar2017,
abstract = {This study explores the effectiveness of an Artificial Neural Network (ANN) in predicting fraudulent financial reporting in small market capitalization companies in Malaysia. Design/methodology/approach Based on the concepts of ANN, a mathematical model is developed to compare non-fraud and fraud companies selected from among small market capitalization companies in Malaysia; the fraud companies had already been charged by the Securities Commission for the falsification of financial statements. Ten financial ratios are used as fraud risk indicators to predict fraudulent financial reporting using ANN. Findings Indicate that the proposed ANN methodology outperforms other statistical techniques widely used for predicting fraudulent financial reporting. Originality/value The study is one of few to adopt the ANN approach to the prediction of financial reporting fraud.},
author = {Omar, Normah and Johari, Zulaikha 'Amirah Amirah and Smith, Malcolm},
doi = {10.1108/13590791011082797},
isbn = {1359079051062},
issn = {1359-0790},
journal = {Journal of Financial Crime Iss},
keywords = {ANN,Fraud prediction models,Small market capitalization companies,security},
mendeley-tags = {security},
number = {2},
pages = {362--387},
title = {{Predicting fraudulent financial reporting using artificial neural network}},
url = {http://dx.doi.org/10.1108/eb025814%5Cnhttp://},
volume = {24},
year = {2017}
}
@article{rdd13,
abstract = {Inharmonicity of piano tones is an essential property of their timbre that strongly influences the tuning, leading to the so-called octave stretching. It is proposed in this paper to jointly model the inharmonicity and tuning of pianos on the whole compass. While using a small number of parameters, these models are able to reflect both the specificities of instrument design and tuner's practice. An estimation algorithm is derived that can run either on a set of isolated note recordings, but also on chord recordings, assuming that the played notes are known. It is applied to extract parameters highlighting some tuner's choices on different piano types and to propose tuning curves for out-of-tune pianos or piano synthesizers.},
author = {Rigaud, Fran{\c{c}}ois and David, Bertrand and Daudet, Laurent},
doi = {10.1121/1.4799806},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {5},
pages = {3107--3118},
pmid = {23654413},
title = {{A parametric model and estimation techniques for the inharmonicity and tuning of the piano}},
volume = {133},
year = {2013}
}
@article{Goldberg2015,
abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
archivePrefix = {arXiv},
arxivId = {1510.00726},
author = {Goldberg, Yoav},
doi = {10.1613/jair.4992},
eprint = {1510.00726},
issn = {1076-9757},
journal = {J. Artif. Intell. Res.(JAIR)},
keywords = {,review,speech recognition,speech synthesis},
mendeley-tags = {review,speech recognition,speech synthesis},
pages = {1--76},
title = {{A Primer on Neural Network Models for Natural Language Processing}},
url = {http://arxiv.org/abs/1510.00726},
volume = {57},
year = {2015}
}
@article{Boulanger-lewandowski2014,
abstract = {In this paper, we investigate phone sequence modeling with recurrent neural networks in the context of speech recognition. We introduce a hybrid architecture that combines a phonetic model with an arbitrary frame-level acoustic model and we propose efficient algorithms for training, decoding and sequence alignment. We evaluate the advantage of our phonetic model on the TIMIT and Switchboard-mini datasets in complementarity to a powerful context-dependent deep neural network (DNN) acoustic classifier and a higher-level 3-gram language model. Consistent improvements of 2-10% in phone accuracy and 3% in word error rate suggest that our approach can readily replace HMMs in current state-of-the-art systems. {\textcopyright} 2014 IEEE.},
author = {Boulanger-Lewandowski, Nicolas and Droppo, Jasha and Seltzer, Mike and Yu, Dong},
doi = {10.1109/ICASSP.2014.6854638},
institution = {IEEE},
isbn = {9781479928927},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Recurrent neural network,phonetic model,speech recognition},
mendeley-tags = {speech recognition},
number = {2},
pages = {5454--5458},
title = {{Phone sequence modeling with recurrent neural networks}},
year = {2014}
}
@article{Zhao2016,
abstract = {Objective functions for training of deep networks for face-related recognition tasks, such as facial expression recognition (FER), usually consider each sample independently. In this work, we present a novel peak-piloted deep network (PPDN) that uses a sample with peak expression (easy sample) to supervise the intermediate feature responses for a sample of non-peak expression (hard sample) of the same type and from the same subject. The expression evolving process from non-peak expression to peak expression can thus be implicitly embedded in the network to achieve the invariance to expression intensities. A special purpose back-propagation procedure, peak gradient suppression (PGS), is proposed for network training. It drives the intermediate-layer feature responses of non-peak expression samples towards those of the corresponding peak expression samples, while avoiding the inverse. This avoids degrading the recognition capability for samples of peak expression due to interference from their non-peak expression counterparts. Extensive comparisons on two popular FER datasets, Oulu-CASIA and CK+, demonstrate the superiority of the PPDN over state-ofthe-art FER methods, as well as the advantages of both the network structure and the optimization strategy. Moreover, it is shown that PPDN is a general architecture, extensible to other tasks by proper definition of peak and non-peak samples. This is validated by experiments that show state-of-the-art performance on pose-invariant face recognition, using the Multi-PIE dataset.},
archivePrefix = {arXiv},
arxivId = {1607.06997},
author = {Zhao, Xiangyun and Liang, Xiaodan and Liu, Luoqi and Li, Teng and Han, Yugang and Vasconcelos, Nuno and Yan, Shuicheng},
doi = {10.1007/978-3-319-46475-6_27},
eprint = {1607.06997},
institution = {Springer},
isbn = {9783319464749},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Deep network,Facial expression recognition,Peak gradient suppression,Peak-piloted,facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
pages = {425--442},
pmid = {4520227},
title = {{Peak-piloted deep network for facial expression recognition}},
url = {http://arxiv.org/abs/1607.06997},
volume = {9906 LNCS},
year = {2016}
}
@article{Boulanger-Lewandowski2013,
abstract = {We investigate the problem of transforming an input sequence into a high-dimensional output sequence in order to transcribe polyphonic audio music into symbolic notation. We introduce a probabilistic model based on a recurrent neural network that is able to learn realistic output distributions given the input and we devise an efficient algorithm to search for the global mode of that distribution. The resulting method produces musically plausible transcriptions even under high levels of noise and drastically outperforms previous state-of-the-art approaches on five datasets of synthesized sounds and real recordings, approximately halving the test error rate.},
archivePrefix = {arXiv},
arxivId = {1212.1936},
author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
doi = {10.1109/ICASSP.2013.6638244},
eprint = {1212.1936},
institution = {IEEE},
isbn = {9781479903566},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Sequence transduction,music transcription,polyphonic transcription,recurrent neural network,restricted Boltzmann machine},
mendeley-tags = {music transcription},
number = {5},
pages = {3178--3182},
publisher = {Anais�IEEE},
title = {{High-dimensional sequence transduction}},
year = {2013}
}
@article{Xu2015,
abstract = {Recent work on supertagging using a feed-forward neural network achieved signifi-cant improvements for CCG supertagging and parsing (Lewis and Steedman, 2014). However, their architecture is limited to considering local contexts and does not naturally model sequences of arbitrary length. In this paper, we show how di-rectly capturing sequence information us-ing a recurrent neural network leads to fur-ther accuracy improvements for both su-pertagging (up to 1.9%) and parsing (up to 1% FI), on CCGBank, Wikipedia and biomedical text.},
author = {Xu, Wenduan and Auli, Michael and Clark, Stephen},
doi = {10.3115/v1/p15-2041},
isbn = {9781941643730},
journal = {Acl-2015},
keywords = {sentence classification},
mendeley-tags = {sentence classification},
number = {2014},
pages = {250--255},
publisher = {Association for Computational Linguistics},
title = {{CCG Supertagging with a Recurrent Neural Network}},
url = {https://doi.org/10.3115/v1/p15-2041},
volume = {2},
year = {2015}
}
@article{Shin2016,
abstract = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and the revival of deep CNN. CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
archivePrefix = {arXiv},
arxivId = {1602.03409},
author = {Shin, Hoo-Chang Chang and Roth, Holger R. and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M.},
doi = {10.1109/TMI.2016.2528162},
eprint = {1602.03409},
isbn = {0278-0062 VO - 35},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Biomedical imaging,computer aided diagnosis,image analysis,image classification,machine learning,neural networks,optimization},
mendeley-tags = {image classification,optimization},
number = {5},
pages = {1285--1298},
pmid = {26886976},
publisher = {IEEE},
title = {{Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning}},
volume = {35},
year = {2016}
}
@article{Collobert2004,
abstract = {We propose to study links between three important classification algorithms: Perceptrons, Multi-Layer Perceptrons (MLPs) and Support Vector Machines (SVMs). We first study ways to control the capacity of Perceptrons (mainly regularization parameters and early stopping), using the margin idea introduced with SVMs. After showing that under simple conditions a Perceptron is equivalent to an SVM, we show it can be computationally expensive in time to train an SVM (and thus a Perceptron) with stochastic gradient descent, mainly because of the margin maximization term in the cost function. We then show that if we remove this margin maximization term, the learning rate or the use of early stopping can still control the margin. These ideas are extended afterward to the case of MLPs. Moreover, under some assumptions it also appears that MLPs are a kind of mixture of SVMs, maximizing the margin in the hidden layer space. Finally, we present a very simple MLP based on the previous findings, which yields better performances in generalization and speed than the other models.},
author = {Collobert, Ronan and Bengio, Samy},
doi = {10.1145/1015330.1015415},
institution = {ACM},
isbn = {1581138285},
issn = {1581138385},
journal = {Twenty-first international conference on Machine learning - ICML '04},
keywords = {theory},
mendeley-tags = {theory},
pages = {23},
title = {{Links between perceptrons, MLPs and SVMs}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015415},
year = {2004}
}
@article{Araque2017a,
abstract = {Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on F1-Score.},
author = {Araque, Oscar and Corcuera-Platas, Ignacio and S{\'{a}}nchez-Rada, J. Fernando and Iglesias, Carlos A.},
doi = {10.1016/j.eswa.2017.02.002},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Deep learning,Ensemble,Machine learning,Natural language processing,Sentiment analysis,sentiment analysis},
mendeley-tags = {sentiment analysis},
pages = {236--246},
publisher = {Elsevier Ltd},
title = {{Enhancing deep learning sentiment analysis with ensemble techniques in social applications}},
volume = {77},
year = {2017}
}
@article{Zhang2016b,
abstract = {Sequence-to-sequence models have shown success in end-to-end speech recognition. However these models have only used shallow acoustic encoder networks. In our work, we successively train very deep convolutional networks to add more expressive power and better generalization for end-to-end ASR models. We apply network-in-network principles, batch normalization, residual connections and convolutional LSTMs to build very deep recurrent and convolutional structures. Our models exploit the spectral structure in the feature space and add computational depth without overfitting issues. We experiment with the WSJ ASR task and achieve 10.5\% word error rate without any dictionary or language using a 15 layer deep network.},
archivePrefix = {arXiv},
arxivId = {1610.03022},
author = {Zhang, Yu and Chan, William and Jaitly, Navdeep},
doi = {10.1109/ICASSP.2017.7953077},
eprint = {1610.03022},
institution = {IEEE},
isbn = {9781509041176},
issn = {15206149},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on},
keywords = {Automatic Speech Recognition,End-to-End Speech Recognition,Very Deep Convolutional Neural Networks,speech recognition,state of the art},
mendeley-tags = {speech recognition,state of the art},
pages = {10--14},
title = {{Very Deep Convolutional Networks for End-to-End Speech Recognition}},
url = {http://arxiv.org/abs/1610.03022},
year = {2016}
}
@article{Zhang2016a,
abstract = {Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test," asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.},
address = {Anais�},
archivePrefix = {arXiv},
arxivId = {1603.08511},
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A.},
doi = {10.1007/978-3-319-46487-9_40},
edition = {European C},
eprint = {1603.08511},
institution = {Springer},
isbn = {9783319464862},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {CNNs,Colorization,Self-supervised learning,Vision for graphics,image synthesis},
mendeley-tags = {image synthesis},
pages = {649--666},
pmid = {10463930},
publisher = {Springer},
title = {{Colorful image colorization}},
volume = {9907 LNCS},
year = {2016}
}
@article{Wu2016,
abstract = {Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feed-forward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.},
archivePrefix = {arXiv},
arxivId = {1601.02539},
author = {Wu, Zhizheng and King, Simon},
doi = {10.1109/ICASSP.2016.7472657},
eprint = {1601.02539},
institution = {IEEE},
isbn = {9781479999880},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Speech synthesis,acoustic modelling,gated recurrent network,long short-term memory,recurrent network network,speech synthesis},
mendeley-tags = {speech synthesis},
pages = {5140--5144},
title = {{Investigating gated recurrent networks for speech synthesis}},
volume = {2016-May},
year = {2016}
}
@article{Tu2016,
abstract = {This paper proposes a new method for an optimized mapping of temporal variables, describing a temporal stream data, into the recently proposed NeuCube spiking neural network architecture. This optimized mapping extends the use of the NeuCube, which was initially designed for spatiotemporal brain data, to work on arbitrary stream data and to achieve a better accuracy of temporal pattern recognition, a better and earlier event prediction and a better understanding of complex temporal stream data through visualization of the NeuCube connectivity. The effect of the new mapping is demonstrated on three bench mark problems. The first one is early prediction of patient sleep stage event from temporal physiological data. The second one is pattern recognition of dynamic temporal patterns of traffic in the Bay Area of California and the last one is the Challenge 2012 contest data set. In all cases the use of the proposed mapping leads to an improved accuracy of pattern recognition and event prediction and a better understanding of the data when compared to traditional machine learning techniques or spiking neural network reservoirs with arbitrary mapping of the variables.},
archivePrefix = {arXiv},
arxivId = {1603.05594},
author = {Tu, Enmei and Kasabov, Nikola and Yang, Jie},
doi = {10.1109/TNNLS.2016.2536742},
eprint = {1603.05594},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Early event prediction,NeuCube architecture,forecasting,spatiotemporal data,spiking neural network (SNN),state of the art},
mendeley-tags = {forecasting,state of the art},
number = {6},
pages = {1--14},
pmid = {26992179},
publisher = {IEEE},
title = {{Mapping Temporal Variables Into the NeuCube for Improved Pattern Recognition, Predictive Modeling, and Understanding of Stream Data}},
volume = {28},
year = {2016}
}
@article{s07,
abstract = {Sound synthesis and processing has been the most active research topic in the field of Sound and Music Computing for more than 40 years. Quite a number of the early research results are now standard components of many audio and music devices and new technologies are continuously being developed and integrated into new products. Through the years there have been important changes. For example, most of the abstract algorithms that were the focus of work in the 70s and 80s are considered obsolete. Then the 1990s saw the emergence of computational approaches that aimed either at capturing the characteristics of a sound source, known as physical models, or at capturing the perceptual characteristics of the sound signal, generally referred to as spectral or signal models. More recent trends include the combination of physical and spectral models and the corpus-based concatenative methods. But the field faces major challenges that might revolutionize the standard paradigms and applications of sound synthesis. In this article we will first place the sound synthesis topic within its research context, then we will highlight some of the current trends, and finally we will attempt to identify some challenges for the future. {\textcopyright} 2007 IEEE.},
author = {Serra, Xavier},
doi = {10.1109/MMSP.2007.4412805},
isbn = {1424412749},
journal = {2007 IEEE 9Th International Workshop on Multimedia Signal Processing, MMSP 2007 - Proceedings},
keywords = {Sound and music computing,Sound synthesis,and music composition,experimental psychology and neurosciences,including,most smc research is,psychoacoustics,psychology,quite applied,signal processing and electronics,sound and music computing,sound synthesis},
pages = {9--12},
title = {{State of the art and future directions in musical sound synthesis}},
volume = {2007},
year = {2007}
}
@article{Bock2012,
abstract = {In this paper a new approach for polyphonic piano note onset transcription is presented. It is based on a recurrent neural network to simultaneously detect the onsets and the pitches of the notes from spectral features. Long Short-Term Memory units are used in a bidirectional neural network to model the context of the notes. The use of a single regression output layer instead of the often used one-versus-all classification approach enables the system to significantly lower the number of erroneous note detections. Evaluation is based on common test sets and shows exceptional temporal precision combined with a significant boost in note transcription performance compared to current state-of-the-art approaches. The system is trained jointly with various synthesized piano instruments and real piano recordings and thus generalizes much better than existing systems. {\textcopyright} 2012 IEEE.},
author = {Bock, Sebastian and Schedl, Markus},
doi = {10.1109/ICASSP.2012.6287832},
institution = {IEEE},
isbn = {9781467300469},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {music information retrieval,music transcription,neural networks},
mendeley-tags = {music transcription},
pages = {121--124},
publisher = {Anais�IEEE},
title = {{Polyphonic piano note transcription with recurrent neural networks}},
year = {2012}
}
@unpublished{r16,
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
annote = {From Duplicate 1 (An overview of gradient descent optimization algorithms - Ruder, Sebastian)

preprint},
archivePrefix = {arXiv},
arxivId = {1609.04747},
author = {Ruder, Sebastian},
eprint = {1609.04747},
pages = {1--14},
title = {{An overview of gradient descent optimization algorithms}},
url = {http://arxiv.org/abs/1609.04747},
year = {2016}
}
@article{Choi2016,
abstract = {We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features. We compare CRNN with three CNN structures that have been used for music tagging while controlling the number of parameters with respect to their performance and training time per sample. Overall, we found that CRNNs show a strong performance with respect to the number of parameter and training time, indicating the effectiveness of its hybrid structure in music feature extraction and feature summarisation.},
archivePrefix = {arXiv},
arxivId = {1609.04243},
author = {Choi, Keunwoo and Fazekas, George Gy{\"{o}}rgy and Sandler, Mark and Cho, Kyunghyun},
doi = {10.1.1.302.7795},
eprint = {1609.04243},
institution = {IEEE},
isbn = {9789881701282},
issn = {15209210},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on},
keywords = {music classification},
mendeley-tags = {music classification},
pages = {1--5},
title = {{Convolutional Recurrent Neural Networks for Music Classification}},
url = {http://arxiv.org/abs/1609.04243},
year = {2016}
}
@book{l11,
abstract = {Digital Signal Processing (DSP) is the process of taking any kind of analog signal (such as voice) and converting it into digital form so that it can be sent over a telephone line, the Internet, a wireless network, or other communication vehicle. Understanding Digital Signal Processing presents both the theory and application of DSP in an approachable manner.},
address = {Traducao. [s.l.]},
author = {Lyons, Richard G.},
doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
isbn = {9780201634679},
issn = {1053-5888},
pages = {552},
pmid = {13458011},
publisher = {Springer},
title = {{Understanding digital signal processing}},
url = {http://books.google.co.uk/books?id=8osoAQAAMAAJ},
year = {2004}
}
@article{Karpathy2014a,
abstract = {Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a new...},
archivePrefix = {arXiv},
arxivId = {1412.0767},
author = {Karpathy, Andrej and Toderici, George and Shetty, Sachin Sanketh Sachin and Leung, Tommy Thomas and Sukthankar, Rahul and Fei-Fei, Li},
doi = {10.1109/CVPR.2014.223},
eprint = {1412.0767},
isbn = {978-1-4799-5118-5},
issn = {978-1-4799-5118-5},
journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
keywords = {video classification},
mendeley-tags = {video classification},
pages = {1725--1732},
title = {{Large-Scale Video Classification with Convolutional Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909619%0Apapers3://publication/doi/10.1109/CVPR.2014.223},
year = {2014}
}
@article{Deng2013,
abstract = {In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled “New Types of Deep Neural Network Learning for Speech Recognition and Related Applications,” as organized by the authors. We also describe the historical context in which acoustic models based on deep neural networks have been developed. The technical overview of the papers presented in our special session is organized into five ways of improving deep learning methods: (1) better optimization; (2) better types of neural activation function and better network architectures; (3) better ways to determine the myriad hyper-parameters of deep neural networks; (4) more appropriate ways to preprocess speech for deep neural networks; and (5) ways of leveraging multiple languages or dialects that are more easily achieved with deep neural networks than with Gaussian mixture models.},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.5778v1},
author = {Deng, Li and Hinton, Geoffrey E. and Kingsbury, Brian},
doi = {10.1109/ICASSP.2013.6639344},
eprint = {arXiv:1303.5778v1},
institution = {IEEE},
isbn = {978-1-4799-0356-6},
issn = {1520-6149},
journal = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
keywords = {Acoustics,Hidden Markov models,ICASSP- 2013,Neural networks,Optimization,Speech,Speech recognition,Training,acoustic models,acoustic signal processing,convolutional neural network,deep neural network,deep neural network learning,dialects,learning (artificial intelligence),multilingual,multiple languages,multitask,music processing,myriad hyper-parameter determination,network architectures,neural activation function,neural net architecture,optimisation,parameter estimation,recurrent neural network,review,spectrogram features,speech preprocessing,speech recognition},
mendeley-tags = {review,speech recognition},
pages = {8599--8603},
pmid = {23127789},
title = {{New types of deep neural network learning for speech recognition and related applications: An overview}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6639344},
year = {2013}
}
@article{Salama2015,
abstract = {Ant colony optimization (ACO) has been successfully applied to classification, where the aim is to build a model that captures the relationships between the input attributes and the target class in a given domain's dataset. The constructed classification model can then be used to predict the unknown class of a new pattern. While artificial neural networks are one of the most widely used models for pattern classification, their application is commonly restricted to fully connected three-layer topologies. In this paper, we present a new algorithm, ANN-Miner, which uses ACO to learn the structure of feed-forward neural networks. We report computational results on 40 benchmark datasets for several variations of the algorithm. Performance is compared to the standard three-layer structure trained with two different weight-learning algorithms (back propagation, and the ACOℝ algorithm), and also to a greedy algorithm for learning NN structures. A nonparametric Friedman test is used to determine statistical significance. In addition, we compare our proposed algorithm with NEAT, a prominent evolutionary algorithm for evolving neural networks, as well as three different well-known state-of-the-art classifiers, namely the C4.5 decision tree induction algorithm, the Ripper classification rule induction algorithm, and support vector machines.},
author = {Salama, Khalid M. and Abdelbar, Ashraf M.},
doi = {10.1007/s11721-015-0112-z},
issn = {19353820},
journal = {Swarm Intelligence},
keywords = {Ant colony optimization (ACO),Machine learning,Neural networks,Pattern classification,evolutive},
mendeley-tags = {evolutive},
number = {4},
pages = {229--265},
publisher = {Springer US},
title = {{Learning neural network structures with ant colony algorithms}},
volume = {9},
year = {2015}
}
@article{aa16,
abstract = {DDoS attacks are the perfect planned attacks with the aim to stop the legitimate users from accessing the system or the service by consuming the bandwidth or by making the system or service unavailable. The attackers do not attack to steal or access any information but they decline the performance of the network and the system. DDoS attack at application layers are difficult to detect because they imitate the legitimate traffic. We used Lyapunav coefficient to check the traffic and patter for being attack traffic or legitimate traffic and a six step technique is designed using chaos theory to secure networks from DDoS attack traffic. In this research article we have proposed a novel approach of detecting DDoS attack using artificial neural network and theory of chaos.},
author = {Aljumah, Abdullah and Ahamad, Tariq},
journal = {Ijcsns},
keywords = {security},
mendeley-tags = {security},
number = {12},
pages = {132},
title = {{A Novel Approach for Detecting DDoS using Artificial Neural Networks.}},
volume = {16},
year = {2016}
}
@article{Benardos2007,
abstract = {Despite the fact that feedforward artificial neural networks (ANNs) have been a hot topic of research for many years there still are certain issues regarding the development of an ANN model, resulting in a lack of absolute guarantee that the model will perform well for the problem at hand. The multitude of different approaches that have been adopted in order to deal with this problem have investigated all aspects of the ANN modelling procedure, from training data collection and pre/post-processing to elaborate training schemes and algorithms. Increased attention is especially directed to proposing a systematic way to establish an appropriate architecture in contrast to the current common practice that calls for a repetitive trial-and-error process, which is time-consuming and produces uncertain results. This paper proposes such a methodology for determining the best architecture and is based on the use of a genetic algorithm (GA) and the development of novel criteria that quantify an ANN's performance (both training and generalization) as well as its complexity. This approach is implemented in software and tested based on experimental data capturing workpiece elastic deflection in turning. The intention is to present simultaneously the approach's theoretical background and its practical application in real-life engineering problems. Results show that the approach performs better than a human expert, at the same time offering many advantages in comparison to similar approaches found in literature. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Benardos, P. G. and Vosniakos, G-C C.},
doi = {10.1016/j.engappai.2006.06.005},
isbn = {0952-1976},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {ANN architecture,Engineering problems,Feedforward artificial neural networks,Generalization,Genetic algorithms,evolutive},
mendeley-tags = {evolutive},
number = {3},
pages = {365--382},
publisher = {Elsevier},
title = {{Optimizing feedforward artificial neural network architecture}},
volume = {20},
year = {2007}
}
@article{Sotelo2017b,
author = {Sotelo, Jose and Mehri, Soroush and Kumar, Kundan and Kastner, Kyle},
number = {2015},
pages = {1--6},
title = {{C Har 2W Av : E Nd - To -E Nd S Peech S Ynthesis}},
year = {2017}
}
@article{Deng2015,
abstract = {Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that “random hidden neurons” capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.},
author = {Deng, ChenWei and Huang, GuangBin and Xu, Jia and Tang, JieXiong},
doi = {10.1007/s11432-014-5269-3},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {ELM,review},
mendeley-tags = {ELM,review},
number = {2},
pages = {1--16},
title = {{Extreme learning machines: new trends and applications}},
url = {http://link.springer.com/10.1007/s11432-014-5269-3},
volume = {58},
year = {2015}
}
@article{Hoover2012,
author = {Hoover, Amy K and Szerlip, Paul A and Norton, Marie E and Brindle, Trevor A and Merritt, Zachary and Stanley, Kenneth O},
isbn = {9781905254668},
journal = {International Conference on Computational Creativity},
keywords = {music generation},
mendeley-tags = {music generation},
pages = {111},
title = {{Generating a complete multipart musical composition from a single monophonic melody with functional scaffolding}},
year = {2012}
}
@book{s16,
author = {Staudt, Pascal},
title = {{Development of a Digital Musical Instrument with Embedded Sound Synthesis}},
year = {2016}
}
@article{Tang2015,
abstract = {— Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parame-ters are randomly generated and the output weights are analyti-cally computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via 1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme. Index Terms— Deep learning (DL), deep neural network (DNN), extreme learning machine (ELM), multilayer perceptron (MLP), random feature mapping.},
author = {Tang, Jiexiong and ChenweiDeng and Huang, Guang-Bin},
doi = {10.1109/TNNLS.2015.2424995},
isbn = {2162-2388 (Electronic) 2162-237X (Linking)},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {ELM},
mendeley-tags = {ELM},
pages = {1--13},
pmid = {25966483},
title = {{Extreme Learning Machine for Multilayer Perceptron}},
year = {2015}
}
@article{Fritzke1994,
abstract = {We present a new self-organizing neural network model that has two variants. The first variant performs unsupervised learning and can be used for data visualization, clustering, and vector quantization. The main advantage over existing approaches (e.g., the Kohonen feature map) is the ability of the model to automatically find a suitable network structure and size. This is achieved through a controlled growth process that also includes occasional removal of units. The second variant of the model is a supervised learning method that results from the combination of the above-mentioned self-organizing network with the radial basis function (RBF) approach. In this model it is possible—in contrast to earlier approaches—to perform the positioning of the RBF units and the supervised training of the weights in parallel. Therefore, the current classification error can be used to determine where to insert new RBF units. This leads to small networks that generalize very well. Results on the two-spirals benchmark and a vowel classification problem are presented that are better than any results previously published.},
author = {Fritzke, Bernd},
doi = {10.1016/0893-6080(94)90091-4},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {--self-organization,1,as proposed by,classification,clustering,data visualization,evolutive,feature map,i n t r,incremental learning,o d u c,pattern,radial basis function,self-organizing neural network models,seminal,t i o n,two-spiral problem},
mendeley-tags = {evolutive,seminal},
number = {9},
pages = {1441--1460},
publisher = {Elsevier},
title = {{Growing cell structures—A self-organizing network for unsupervised and supervised learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0893608094900914},
volume = {7},
year = {1994}
}
@article{Balle2016,
abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.},
archivePrefix = {arXiv},
arxivId = {1611.01704},
author = {Ball{\'{e}}, Johannes and Laparra, Valero and Simoncelli, Eero P.},
doi = {10.1016/S0197-3975(03)00059-6},
eprint = {1611.01704},
isbn = {0197-3975},
issn = {01973975},
journal = {arXiv preprint arXiv:1611.01704},
keywords = {image compression,image compression- lossy},
mendeley-tags = {image compression,image compression- lossy},
pmid = {16508805},
title = {{End-to-end Optimized Image Compression}},
url = {http://arxiv.org/abs/1611.01704},
year = {2016}
}
@article{Kulkarni2015a,
abstract = {We have studied the structural behavior of bismuth phosphate under compression. We performed x-ray powder diffraction measurements up to 31.5 GPa and ab initio calculations. Experiments were carried out on different polymorphs: trigonal (phase I) and monoclinic (phases II and III). Phases I and III, at low pressure (P < 0.2-0.8 GPa), transform into phase II, which has a monazite-type structure. At room temperature, this polymorph is stable up to 31.5 GPa. Calculations support these findings and predict the occurrence of an additional transition from the monoclinic monazite-type to a tetragonal scheelite-type structure (phase IV). This transition was experimentally found after the simultaneous application of pressure (28 GPa) and temperature (1500 K), suggesting that at room temperature the transition might by hindered by kinetic barriers. Calculations also predict an additional phase transition at 52 GPa, which exceeds the maximum pressure achieved in the experiments. This transition is from phase IV to an orthorhombic barite-type structure (phase V). We also studied the axial and bulk compressibility of BiPO4. Room-temperature pressure-volume equations of state are reported. BiPO4 was found to be more compressible than isomorphic rare-earth phosphates. The discovered phase IV was determined to be the less compressible polymorph of BiPO4. On the other hand, the theoretically predicted phase V has a bulk modulus comparable with that of monazite-type BiPO4. Finally, the isothermal compressibility tensor for the monazite-type structure is reported at 2.4 GPa showing that the direction of maximum compressibility is in the (0 1 0) plane at approximately 15° (21°) to the a axis for the case of our experimental (theoretical) study.},
archivePrefix = {arXiv},
arxivId = {1503.03167},
author = {Errandonea, D. and Gomis, O. and Santamar{\'{i}}a-Perez, D. and Garc{\'{i}}a-Domene, B. and Mu{\~{n}}oz, A. and Rodr{\'{i}}guez-Hern{\'{a}}ndez, P. and Achary, S. N. and Tyagi, A. K. and Popescu, C.},
doi = {10.1063/1.4914407},
eprint = {1503.03167},
issn = {10897550},
journal = {Journal of Applied Physics},
keywords = {image synthesis,tesis},
mendeley-tags = {image synthesis,tesis},
number = {10},
pages = {1--10},
title = {{Exploring the high-pressure behavior of the three known polymorphs of BiPO4: Discovery of a new polymorph}},
url = {http://arxiv.org/abs/1503.03167},
volume = {117},
year = {2015}
}
@article{Sato2015,
abstract = {Deep neural networks have been exhibiting splendid accuracies in many of visual pattern classification problems. Many of the state-of-the-art methods employ a technique known as data augmentation at the training stage. This paper addresses an issue of decision rule for classifiers trained with augmented data. Our method is named as APAC: the Augmented PAttern Classification, which is a way of classification using the optimal decision rule for augmented data learning. Discussion of methods of data augmentation is not our primary focus. We show clear evidences that APAC gives far better generalization performance than the traditional way of class prediction in several experiments. Our convolutional neural network model with APAC achieved a state-of-the-art accuracy on the MNIST dataset among non-ensemble classifiers. Even our multilayer perceptron model beats some of the convolutional models with recently invented stochastic regularization techniques on the CIFAR-10 dataset.},
archivePrefix = {arXiv},
arxivId = {1505.03229},
author = {Sato, Ikuro and Nishimura, Hiroki and Yokoi, Kensuke},
eprint = {1505.03229},
journal = {arXiv preprint arXiv:1505.03229},
keywords = {image classification,optimization},
mendeley-tags = {image classification,optimization},
title = {{APAC: Augmented PAttern Classification with Neural Networks}},
url = {http://arxiv.org/abs/1505.03229},
year = {2015}
}
@article{Yao1999,
abstract = {Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANNs) in recent years. This paper: 1) reviews different combinations between ANNs and evolutionary algorithms (EAs), including using EAs to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EAs; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANNs and EAs can lead to significantly better intelligent systems than relying on ANNs or EAs alone},
archivePrefix = {arXiv},
arxivId = {1108.1530},
author = {Yao, Xin},
doi = {10.1109/5.784219},
eprint = {1108.1530},
isbn = {9780470287194},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {evolutionary computation,evolutive,intelligent systems,neu-,seminal},
mendeley-tags = {evolutive,seminal},
number = {9},
pages = {1423--1447},
pmid = {9821520},
publisher = {IEEE},
title = {{Evolving artificial neural networks}},
volume = {87},
year = {1999}
}
@article{Zweig2016,
abstract = {This paper advances the design of CTC-based all-neural (or end-to-end) speech recognizers. We propose a novel symbol inventory, and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner version. We present a number of stabilization and initialization methods we have found useful in training these networks. We evaluate our system on the commonly used NIST 2000 conversational telephony test set, and significantly exceed the previously published performance of similar systems, both with and without the use of an external language model and decoding technology.},
archivePrefix = {arXiv},
arxivId = {1609.05935},
author = {Zweig, Geoffrey and Yu, Chengzhu and Droppo, Jasha and Stolcke, Andreas},
doi = {10.1109/ICASSP.2017.7953069},
edition = {Acoustics,},
eprint = {1609.05935},
institution = {IEEE},
isbn = {9781509041176},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {CTC,end-to-end training,recurrent neural network,speech recognition},
mendeley-tags = {speech recognition},
pages = {4805--4809},
publisher = {Anais�IEEE},
title = {{Advances in all-neural speech recognition}},
url = {http://arxiv.org/abs/1609.05935},
year = {2017}
}
@book{18,
address = {Intel AI Dispon�vel em},
publisher = {<},
title = {{Neon}},
url = {https://ai.intel.com/neon/%3E},
year = {2018}
}
@article{Ludermir2006,
abstract = {This paper introduces a methodology for neural network global optimization. The aim is the simultaneous optimization of multilayer perceptron (MLP) network weights and architectures, in order to generate topologies with few connections and high classification performance for any data sets. The approach combines the advantages of simulated annealing, tabu search and the backpropagation training algorithm in order to generate an automatic process for producing networks with high classification performance and low complexity. Experimental results obtained with four classification problems and one prediction problem has shown to be better than those obtained by the most commonly used optimization techniques.},
author = {Ludermir, Teresa B. and Yamazaki, Akio and Zanchettin, Cleber},
doi = {10.1109/TNN.2006.881047},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Multilayer perceptron (MLP),Optimization of weights and architectures,Simulating annealing,Tabu search,evolutive},
mendeley-tags = {evolutive},
number = {6},
pages = {1452--1459},
pmid = {17131660},
publisher = {IEEE},
title = {{An optimization methodology for neural network weights and architectures}},
volume = {17},
year = {2006}
}
@article{JeffHwang2016,
abstract = {Colorization, a task of coloring monochrome images or videos, plays an important role in the human perception of visual information, to black and white pictures or videos. Colorizing, when done manually in Photoshop, a single picture might take months to get exactly correct. Understanding the tediousness of the task and inspired by the benefits of artificial intelligence, we propose a mechanism to automate the coloring process with the help of convolutional neural networks (CNNs). Firstly, an Alpha version is developed which successfully works on trained images but fails to colorize images, and the network has never seen before. Subsequently, a Beta version is implemented which is able to overcome the limitations of Alpha version and works well for untrained images. To further enhance the network, we fused the deep CNN with a classifier called Inception ResNet V2 which is a pre-trained model. Finally, the training results are observed for all the versions followed by a comparative analysis for trained and untrained images.},
author = {Pahal, Sudesh and Sehrawat, Preeti},
doi = {10.1007/978-981-15-5341-7_4},
isbn = {9789811553400},
issn = {18761119},
journal = {Lecture Notes in Electrical Engineering},
keywords = {Colorization,Convolutional neural networks,Image classification,Keras,Resnet,image synthesis},
mendeley-tags = {image synthesis},
pages = {45--56},
title = {{Image Colorization with Deep Convolutional Neural Networks}},
volume = {668},
year = {2021}
}
@article{Wu2015a,
abstract = {In this paper, a drum transcription algorithm using partially fixed non-negative matrix factorization is presented. The proposed method allows users to identify percussive events in complex mixtures with a minimal training set. The algorithm decomposes the music signal into two parts: percussive part with pre-defined drum templates and harmonic part with undefined entries. The harmonic part is able to adapt to the music content, allowing the algorithm to work in polyphonic mixtures. Drum event times can be simply picked from the percussive activation matrix with onset detection. The system is efficient and robust even with a minimal training set. The recognition rates for the ENST dataset vary from 56.7 to 78.9% for three percussive instruments extracted from polyphonic music.},
author = {Wu, Chih Wei and Lerch, Alexander},
doi = {10.1109/EUSIPCO.2015.7362590},
isbn = {9780992862633},
journal = {2015 23rd European Signal Processing Conference, EUSIPCO 2015},
keywords = {Automatic Music Transcription,Drum Transcription,MIR,NMF,music transcription,tesis},
mendeley-tags = {music transcription,tesis},
pages = {1281--1285},
title = {{Drum transcription using partially fixed non-negative matrix factorization}},
year = {2015}
}
@article{Wang2015,
abstract = {Image compression technology is to compress the redundancy between the pixels to reduce the transmission broadband and storage space by using the correlation of the image pixels. Fuzzy neural network effectively integrates neural network technology and fuzzy technology; combines learning, self- adaptivity, imagination and identity and uses rule-based reasoning and fuzzy information processing in the nodes; thus greatly improving the transparency of fuzzy neural network. This paper mainly investigates the applications of fuzzy neural network in image compression and realizes the image compression and reconstruction of fuzzy neural network. It is demonstrated in the simulation experiment that the image compression algorithm based on fuzzy neural network has significant advantages in training speed, compression quality and robustness.},
author = {Wang, Bo and Gao, Yubin},
doi = {10.12928/telkomnika.v13i1.1270},
issn = {2302-9293},
journal = {TELKOMNIKA (Telecommunication Computing Electronics and Control)},
keywords = {fuzzy theory,image compression,image compression- lossy,neural network},
mendeley-tags = {image compression- lossy},
number = {1},
pages = {137},
title = {{An Image Compression Scheme Based on Fuzzy Neural Network}},
url = {http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/1270},
volume = {13},
year = {2015}
}
@unpublished{b15,
abstract = {Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.},
annote = {From Duplicate 2 (Comparative Study of Deep Learning Software Frameworks - Bahrampour, Soheil; Ramakrishnan, Naveen; Schott, Lukas; Shah, Mohak)

preprint},
archivePrefix = {arXiv},
arxivId = {1511.06435},
author = {Bahrampour, Soheil and Ramakrishnan, Naveen and Schott, Lukas and Shah, Mohak},
eprint = {1511.06435},
title = {{Comparative Study of Deep Learning Software Frameworks}},
url = {http://arxiv.org/abs/1511.06435},
year = {2015}
}
@unpublished{,
title = {{Torch}},
url = {http://torch.ch/%3E}
}
@article{DiPersio2016,
abstract = {? 2016, North Atlantic University Union. All rights reserved.We present an Artificial Neural Network (ANN) approach to predict stock market indices, particularly with respect to the forecast of their trend movements up or down. Exploiting different Neural Networks architectures, we provide numerical analysis of concrete financial time series. In particular, after a brief r?esum?e of the existing literature on the subject, we consider the Multi-layer Perceptron (MLP), the Convolutional Neural Networks (CNN), and the Long Short-Term Memory (LSTM) recurrent neural networks techniques. We focus on the importance of choosing the correct input features, along with their preprocessing, for the specific learning algorithm one wants to use. Eventually, we consider the S&P500 historical time series, predicting trend on the basis of data from the past days, and proposing a novel approach based on combination of wavelets and CNN, which outperforms the basic neural networks ones. We show, that neural networks are able to predict financial time series movements even trained only on plain time series data and propose more ways to improve results.},
author = {{Di Persio}, Luca and Honchar, Oleksandr},
issn = {19984464},
journal = {International Journal of Circuits, Systems and Signal Processing},
keywords = {Artificial neural networks,Convolutional neural network,Deep Learning,Financial forecasting,Long shortterm memory,Multi-layer neural network,Recurrent neural network,Stock markets analysis,Time series analysis,forecasting},
mendeley-tags = {forecasting},
pages = {403--413},
title = {{Artificial neural networks architectures for stock price prediction: Comparisons and applications}},
volume = {10},
year = {2016}
}
@article{Saxena2016,
abstract = {Despite the success of CNNs, selecting the optimal architecture for a given task remains an open problem. Instead of aiming to select a single optimal architecture, we propose a "fabric" that embeds an exponentially large number of architectures. The fabric consists of a 3D trellis that connects response maps at different layers, scales, and channels with a sparse homogeneous local connectivity pattern. The only hyper-parameters of a fabric are the number of channels and layers. While individual architectures can be recovered as paths, the fabric can in addition ensemble all embedded architectures together, sharing their weights where their paths overlap. Parameters can be learned using standard methods based on back-propagation, at a cost that scales linearly in the fabric size. We present benchmark results competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset.},
archivePrefix = {arXiv},
arxivId = {1606.02492},
author = {Saxena, Shreyas and Verbeek, Jakob},
eprint = {1606.02492},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {evolutive},
mendeley-tags = {evolutive},
pages = {4060--4068},
title = {{Convolutional Neural Fabrics}},
url = {http://arxiv.org/abs/1606.02492},
year = {2016}
}
@article{Zagoruyko2016,
abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https://github.com/szagoruyko/wide-residual-networks},
archivePrefix = {arXiv},
arxivId = {1605.07146},
author = {Zagoruyko, Sergey and Komodakis, Nikos},
eprint = {1605.07146},
journal = {arXiv preprint arXiv:1605.07146},
keywords = {image classification,object detection,state of the art},
mendeley-tags = {image classification,object detection,state of the art},
title = {{Wide Residual Networks}},
url = {http://arxiv.org/abs/1605.07146},
year = {2016}
}
@article{Southall2016a,
abstract = {Automatic drum transcription (ADT) systems attempt to generate a symbolic music notation for percussive in-struments in audio recordings. Neural networks have al-ready been shown to perform well in fields related to ADT such as source separation and onset detection due to their utilisation of time-series data in classification. We pro-pose the use of neural networks for ADT in order to ex-ploit their ability to capture a complex configuration of fea-tures associated with individual or combined drum classes. In this paper we present a bi-directional recurrent neu-ral network for offline detection of percussive onsets from specified drum classes and a recurrent neural network suit-able for online operation. In both systems, a separate net-work is trained to identify onsets for each drum class under observation—that is, kick drum, snare drum, hi-hats, and combinations thereof. We perform four evaluations utilis-ing the IDMT-SMT-Drums and ENST minus one datasets, which cover solo percussion and polyphonic audio respec-tively. The results demonstrate the effectiveness of the pre-sented methods for solo percussion and a capacity for iden-tifying snare drums, which are historically the most diffi-cult drum class to detect.},
author = {Southall, Carl and Stables, Ryan and Hockman, Jason},
isbn = {978-0-692-75506-8},
journal = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
keywords = {music transcription,tesis},
mendeley-tags = {music transcription,tesis},
pages = {591--597},
title = {{Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks}},
year = {2016}
}
@article{l,
abstract = {In this thesis the physical modelling of percussive drums was approached using\ndigital waveguides. The constituent components of a drum were considered individually before connecting them together to complete the model.\nTo model the drumskin techniques were created to incorporate smooth curved\nboundaries, calculate the impedance of a 2D waveguide mesh and include the\neffect of the bearing edge. The accuracy of the curved boundary model, which\nutilised ‘rimguides', was demonstrated with a good reproduction of the first\nseven resonant modes of a circular membrane. The impedance was used in a\nkettledrum model where it correctly controlled the exchange of energy between\nthe drumskin and interior air. Simulations of different bearing edge sizes revealed that a blunt edge takes energy from low frequencies and redistributes\nit into higher frequencies. These decay faster and so the result is a decrease in\nsustain.\nFor the interior air it was necessary to correctly model 3D wave propagation\nand incorporate diffuse reflections, which occur at rough surfaces. Unlike 3D\nmeshes used in previous studies, the new dodecahedral mesh proposed here\nwas found to exhibit near direction independent dispersion error. The effect\nof diffusion was adequately simulated with a technique that was shown to be\ncontrollable, enabling different types of surface to be modelled.\nTo complete the drum model a way of connecting different waveguide meshes\ntogether was found and a new procedure for modelling a mallet exciter was\nproposed. The interfacing method enabled a lossless interconnection between\ntwo 2D meshes and also 2D and 3D meshes. The procedure used for the mallet exciter incorporated non-linear stiffness and the mallet's contact area. Its\nbehaviour was shown to be almost identical to that of a real mallet.\nFinally, a digital waveguide model of a kettledrum was constructed to demonstrate the techniques and the results were promising; the resonant modes were\nreproduced with good accuracy and their decay was sufficient to give the impression of realism, whilst not exactly matching that found through measurement.},
author = {Laird, Joel Augustus},
journal = {Control},
number = {November},
title = {{the Physical Modelling of Drums Using Digital}},
volume = {2001},
year = {2001}
}
@article{Ojha2017,
abstract = {Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN's generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN's application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era.},
archivePrefix = {arXiv},
arxivId = {arXiv:1705.05584v1},
author = {Ojha, Varun Kumar and Abraham, Ajith and Sn{\'{a}}{\v{s}}el, V{\'{a}}clav},
doi = {10.1016/j.engappai.2017.01.013},
eprint = {arXiv:1705.05584v1},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Ensemble,Feedforward neural network,Metaheuristics,Multiobjective,Nature-inspired algorithms,evolutive,review},
mendeley-tags = {evolutive,review},
number = {2017},
pages = {97--116},
publisher = {Elsevier},
title = {{Metaheuristic design of feedforward neural networks: A review of two decades of research}},
volume = {60},
year = {2017}
}
@article{Theis2017,
abstract = {We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.},
archivePrefix = {arXiv},
arxivId = {1703.00395},
author = {Theis, Lucas and Shi, Wenzhe and Cunningham, Andrew and Husz{\'{a}}r, Ferenc},
eprint = {1703.00395},
journal = {arXiv preprint arXiv:1703.00395},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
pages = {1--19},
title = {{Lossy Image Compression with Compressive Autoencoders}},
url = {http://arxiv.org/abs/1703.00395},
year = {2017}
}
@book{18,
address = {GoogleGoogle Dispon�vel em},
publisher = {<},
title = {{NSynthSuper}},
url = {https://nsynthsuper.withgoogle.com/%3E},
year = {2018}
}
@article{a,
author = {Audio, Ivy},
title = {{Ivy Audio}},
url = {http://www.ivyaudio.com/%3E},
volume = {2018}
}
@article{Graves2014,
abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
archivePrefix = {arXiv},
arxivId = {1410.5401},
author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
doi = {10.3389/neuro.12.006.2007},
eprint = {1410.5401},
isbn = {0028-0836},
issn = {2041-1723},
keywords = {other},
mendeley-tags = {other},
pages = {1--26},
pmid = {18958277},
title = {{Neural Turing Machines}},
url = {http://arxiv.org/abs/1410.5401},
year = {2014}
}
@article{Chen2017a,
abstract = {Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Chen, Tao and Xu, Ruifeng and He, Yulan and Wang, Xuan},
doi = {10.1016/j.eswa.2016.10.065},
eprint = {1404.7828},
isbn = {0925-2312},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Deep neural network,Natural language processing,Sentiment analysis,sentence classification,state of the art},
mendeley-tags = {sentence classification,state of the art},
pages = {221--230},
pmid = {19932002},
publisher = {Elsevier Ltd},
title = {{Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.10.065},
volume = {72},
year = {2017}
}
@article{Egmont-Petersen2002,
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments. ?? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
author = {Egmont-Petersen, M. and {De Ridder}, D. and Handels, H.},
doi = {10.1016/S0031-3203(01)00178-9},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Digital image processing,Feature extraction,Image compression,Image understanding,Invariant pattern recognition,Neural networks,Object recognition,Optimization,Preprocessing,Segmentation,image classification,object detection,review},
mendeley-tags = {image classification,object detection,review},
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks- A review}},
volume = {35},
year = {2002}
}
@book{18,
address = {TensorFlow Dispon�vel em},
publisher = {<},
title = {{TensorFlow}},
url = {https://www.tensorflow.org/%3E},
year = {2018}
}
@book{Rosenblatt1957,
abstract = {First publication about the perceptron},
author = {Rosenblatt, F.},
booktitle = {Report 85, Cornell Aeronautical Laboratory},
doi = {85-460-1},
keywords = {seminal},
mendeley-tags = {seminal},
pages = {460--1},
publisher = {Cornell Aeronautical Laboratory},
title = {{The Perceptron - A Perceiving and Recognizing Automaton}},
year = {1957}
}
@article{18,
journal = {Multilayer Perceptron - DeepLearning 0.},
title = {{Theano}},
url = {http://deeplearning.net/software/theano/%3E},
volume = {1},
year = {2018}
}
@article{Fini2010,
abstract = {Research and public policy on academic entrepreneurship are largely based on the assumption that faculty members start businesses to commercialize inventions that have been disclosed to university administrators and have been patented. In this paper, we analyze a sample of 11,572 professors and find that much academic entrepreneurship occurs outside the university intellectual property system. Specifically, about 2/3 of businesses started by academics are not based on disclosed and patented inventions. Moreover, we show that individual characteristics, departmental and organizational affiliations, and time allocation of academics that have started business outside the IP system are different from those of academics that have started businesses to exploit disclosed and patented inventions. We discuss the implications for research on and the practice of academic entrepreneurship. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Fini, Riccardo and Lacetera, Nicola and Shane, Scott},
doi = {10.1016/j.respol.2010.05.014},
isbn = {0048-7333},
issn = {00487333},
journal = {Research Policy},
keywords = {Academic entrepreneurship,Business creation,Knowledge transfer},
month = {oct},
number = {8},
pages = {1060--1069},
title = {{Inside or outside the IP system? Business creation in academia}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0048733310001381},
volume = {39},
year = {2010}
}
@misc{Edmunds2000,
abstract = {This paper reviews the literature on the problem of information overload, with particular reference to business organisations. The literature reveals that although the problem of information overload has existed for many years, in recent years the problem has become more widely recognised and experienced. Both perceptions and the actual effects of information overload have been exacerbated by the rapid advances made in information and communication technology, although it is not clear cut as to whether the Internet has worsened or improved the situation. A theme stressed in the literature is the paradoxical situation that, although there is an abundance of information available, it is often difficult to obtain useful, relevant information when it is needed. Some solutions put forward to reduce information overload are: a reduction in the duplication of information found in the professional literature; the adoption of personal information management strategies, together with the integration of software solutions such as push technology and intelligent agents; and the provision of value-added information (filtered by software or information specialists). An emphasis is placed on technology as a tool and not the driver, while increased information literacy may provide the key to reducing information overload.},
author = {Edmunds, Angela and Morris, Anne},
booktitle = {International Journal of Information Management},
doi = {10.1016/S0268-4012(99)00051-1},
isbn = {0268-4012},
issn = {02684012},
keywords = {infoglut,information fatigue syndrome,information overload},
number = {1},
pages = {17--28},
pmid = {10272},
title = {{The problem of information overload in business organisations: a review of the literature}},
url = {http://www.sciencedirect.com/science/article/pii/S0268401299000511},
volume = {20},
year = {2000}
}
@article{Frans2017a,
abstract = {When creating digital art, coloring and shading are often time consuming tasks that follow the same general patterns. A solution to automatically colorize raw line art would have many practical applications. We propose a setup utilizing two networks in tandem: a color prediction network based only on outlines, and a shading network conditioned on both outlines and a color scheme. We present processing methods to limit information passed in the color scheme, improving generalization. Finally, we demonstrate natural-looking results when colorizing outlines from scratch, as well as from a messy, user-defined color scheme. 834v1 [cs.CV]},
archivePrefix = {arXiv},
arxivId = {1704.08834},
author = {Frans, Kevin},
eprint = {1704.08834},
issn = {23318422},
journal = {arXiv},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
title = {{Outline colorization through tande adversarial networks. 2017}},
url = {http://arxiv.org/abs/1704.08834},
year = {2017}
}
@misc{Moscaritolo,
author = {Moscaritolo, Autores and Angelamoscaritolopcmagcom, Angela},
title = {{Pebble Smartwatch Sells Out , Collects $ 10 Million on Kickstarter}}
}
@misc{,
title = {{Poverty and profits in the information age.pdf}}
}
@article{Liao2016,
abstract = {Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets. The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.},
archivePrefix = {arXiv},
arxivId = {1508.00330},
author = {Liao, Zhibin and Carneiro, Gustavo},
doi = {10.1109/WACV.2016.7477624},
eprint = {1508.00330},
institution = {IEEE},
isbn = {9781509006410},
journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
keywords = {image classification,optimization,theory},
mendeley-tags = {image classification,optimization,theory},
pages = {1--8},
title = {{On the importance of normalisation layers in deep learning with piecewise linear activation units}},
year = {2016}
}
@article{Xu2017,
author = {Xu, Lamei and Lin, Jin and Wang, Lina and Yin, Chunyong and Wang, Jin},
journal = {Advanced Science and Technology Letters},
keywords = {aspect-based sentiment,convolution neural network,sentiment analysis,word2vec},
mendeley-tags = {sentiment analysis},
number = {Ast},
pages = {199--204},
title = {{Deep Convolutional Neural Network based Approach for Aspect-based Sentiment Analysis}},
volume = {143},
year = {2017}
}
@article{Kim2014,
abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
archivePrefix = {arXiv},
arxivId = {1408.5882},
author = {Kim, Yoon},
doi = {10.3115/v1/D14-1181},
eprint = {1408.5882},
isbn = {9781937284961},
issn = {10709908},
journal = {arXiv preprint arXiv:1408.5882},
keywords = {sentence classification,sentiment analysis},
mendeley-tags = {sentence classification,sentiment analysis},
pmid = {10463930},
title = {{Convolutional Neural Networks for Sentence Classification}},
url = {http://arxiv.org/abs/1408.5882},
year = {2014}
}
@article{Barrow2016,
abstract = {This paper evaluates k-fold and Monte Carlo cross-validation and aggregation (crogging) for combining neural network autoregressive forecasts. We introduce Monte Carlo crogging which combines bootstrapping and cross-validation (CV) in a single approach through repeated random splitting of the original time series into mutually exclusive datasets for training. As the training/validation split is independent of the number of folds, the algorithm offers more flexibility in the size, and number of training samples compared to k-fold cross-validation. The study also provides for crogging and bagging: (1) the first systematic evaluation across time series length and combination size, (2) a bias and variance decomposition of the forecast errors to understand improvement gains, and (3) a comparison to established benchmarks of model averaging and selection. Crogging can easily be extended to other autoregressive models. Results on real and simulated series demonstrate significant improvements in forecasting accuracy especially for short time series and long forecast horizons.},
author = {Barrow, Devon K. and Crone, Sven F.},
doi = {10.1016/j.ijforecast.2015.12.011},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bootstrapping,Cross-validation,Forecast combination,Monte Carlo,Time series,forecasting},
mendeley-tags = {forecasting},
number = {4},
pages = {1120--1137},
publisher = {Elsevier B.V.},
title = {{Cross-validation aggregation for combining autoregressive neural network forecasts}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2015.12.011},
volume = {32},
year = {2016}
}
@article{Hinton2012,
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and Kingsbury, Brian},
doi = {10.1109/MSP.2012.2205597},
eprint = {1207.0580},
isbn = {1053-5888},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
number = {November},
pages = {82--97},
pmid = {13057166},
title = {{Deep Neural Networks for Acoustic Modeling in Speech Recognition}},
year = {2012}
}
@book{s16,
abstract = {Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools coming to public. Training a deep network is usually a very time-consuming process. To address the huge computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training and inference time. However, different tools exhibit different features and running performance when they train different types of deep networks on different hardware platforms, making it difficult for end users to select an appropriate pair of software and hardware. In this paper, we present our attempt to benchmark several state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, TensorFlow, and Torch. We focus on evaluating the running time performance (i.e., speed) of these tools with three popular types of neural networks on two representative CPU platforms and three representative GPU platforms. Our contribution is two-fold. First, for end users of deep learning software tools, our benchmarking results can serve as a reference to selecting appropriate hardware platforms and software tools. Second, for developers of deep learning software tools, our in-depth analysis points out possible future directions to further optimize the running performance.},
archivePrefix = {arXiv},
arxivId = {1608.07249},
author = {Shi, Shaohuai and Wang, Qiang and Xu, Pengfei and Chu, Xiaowen},
booktitle = {Proceedings - 2016 7th International Conference on Cloud Computing and Big Data, CCBD 2016},
doi = {10.1109/CCBD.2016.029},
edition = {Cloud Comp},
eprint = {1608.07249},
isbn = {9781509035557},
keywords = {Convolutional Neural Networks,Deep Learning,Feed-forward Neural Networks,GPU,Recurrent Neural Networks},
pages = {99--104},
publisher = {Anais�IEEE},
title = {{Benchmarking state-of-the-art deep learning software tools}},
year = {2017}
}
@book{18,
address = {Caffe | Model Zoo Dispon�vel em},
publisher = {<},
title = {{Caffe}},
url = {http://caffe.berkeleyvision.org/%3E},
year = {2018}
}
@inproceedings{g17,
abstract = {Following recent advances in direct modeling of the speech waveform using a deep neural network, we propose a novel method that directly estimates a physical model of the vocal tract from the speech waveform, rather than magnetic resonance imaging data. This provides a clear relationship between the model and the size and shape of the vocal tract, offering considerable flexibility in terms of speech characteristics such as age and gender. Initial tests indicate that despite a highly simplified physical model, intelligible synthesized speech is obtained. This illustrates the potential of the combined technique for the control of physical models in general, and hence the generation of more natural-sounding synthetic speech.},
author = {Gully, Amelia J. and Yoshimura, Takenori and Murphy, Damian T. and Hashimoto, Kei and Nankaku, Yoshihiko and Tokuda, Keiichi},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
doi = {10.21437/Interspeech.2017-900},
issn = {19909772},
keywords = {Deep neural network,Digital waveguide mesh,Speech synthesis,[Electronic Manuscript]},
pages = {234--238},
publisher = {p. 234�238},
title = {{Articulatory text-to-speech synthesis using the digital waveguide mesh driven by a deep neural network}},
volume = {2017-Augus},
year = {2017}
}
@book{18,
address = {Magenta Dispon�vel em},
publisher = {<},
title = {{Magenta}},
url = {https://magenta.tensorflow.org/%3E},
year = {2018}
}
@article{Boser1992,
abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of classifiaction functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms. 1 INTRODUCTION Good generalization performance of pattern classifiers is achieved when the capacity of the classification function is matched to the size of the training set. Classifiers with a large numb...},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
doi = {10.1145/130385.130401},
eprint = {arXiv:1011.1669v3},
institution = {ACM},
isbn = {089791497X},
issn = {0-89791-497-X},
journal = {Proceedings of the fifth annual workshop on Computational learning theory  - COLT '92},
keywords = {seminal},
mendeley-tags = {seminal},
pages = {144--152},
pmid = {25246403},
title = {{A training algorithm for optimal margin classifiers}},
url = {http://portal.acm.org/citation.cfm?doid=130385.130401},
year = {1992}
}
@article{Lin2013,
abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
archivePrefix = {arXiv},
arxivId = {1312.4400},
author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
doi = {10.1109/ASRU.2015.7404828},
eprint = {1312.4400},
isbn = {9781479972913},
issn = {03029743},
journal = {arXiv preprint arXiv:1312.4400},
keywords = {image classification},
mendeley-tags = {image classification},
pages = {1--10},
pmid = {24356345},
title = {{Network In Network}},
url = {http://arxiv.org/abs/1312.4400},
year = {2013}
}
@article{Janai2017,
abstract = {Recent years have witnessed amazing progress in AI related fields such as computer vision, machine learning and autonomous vehicles. As with any rapidly growing field, however, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several topic specific survey papers have been written, to date no general survey on problems, datasets and methods in computer vision for autonomous vehicles exists. This paper attempts to narrow this gap by providing a state-of-the-art survey on this topic. Our survey includes both the historically most relevant literature as well as the current state-of-the-art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning. Towards this goal, we first provide a taxonomy to classify each approach and then analyze the performance of the state-of-the-art on several challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we will also provide an interactive platform which allows to navigate topics and methods, and provides additional information and project links for each paper.},
archivePrefix = {arXiv},
arxivId = {1704.05519},
author = {Janai, Joel and G{\"{u}}ney, Fatma and Behl, Aseem and Geiger, Andreas},
eprint = {1704.05519},
journal = {arXiv preprint arXiv:1704.05519},
keywords = {and lowers the,autonomous vehicles,autonomous vision,by providing an exhaustive,computer vision,entry barrier for beginners,field of autonomous vision,for researchers in the,image classification,manner 1,object detection,overview,review,survey will become a,useful tool,we hope that our},
mendeley-tags = {image classification,object detection,review},
title = {{Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art}},
url = {http://arxiv.org/abs/1704.05519},
year = {2017}
}
@article{Stanley2002a,
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
archivePrefix = {arXiv},
arxivId = {1407.0576},
author = {Stanley, Kenneth O. and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
eprint = {1407.0576},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
keywords = {evolutive},
mendeley-tags = {evolutive},
number = {2},
pages = {99--127},
pmid = {12180173},
publisher = {MIT Press},
title = {{Evolving Neural Networks through Augmenting Topologies}},
url = {http://www.mitpressjournals.org/doi/10.1162/106365602320169811},
volume = {10},
year = {2002}
}
@article{Shi2016,
abstract = {In this paper, we propose a novel method to im-prove object recognition accuracies of convolu-tional neural networks (CNNs) by embedding the proposed Min-Max objective into a high layer of the models during the training process. The Min-Max objective explicitly enforces the learned object feature maps to have the minimum compactness for each object manifold and the maximum margin be-tween different object manifolds. The Min-Max objective can be universally applied to different CNN models with negligible additional computa-tion cost. Experiments with shallow and deep mod-els on four benchmark datasets including CIFAR-10, CIFAR-100, SVHN and MNIST demonstrate that CNN models trained with the Min-Max ob-jective achieve remarkable performance improve-ments compared to the corresponding baseline models.},
author = {Shi, Weiwei and Gong, Yihong and Wang, Jinjun},
doi = {10.1109/TNNLS.2017.2705682},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning,object detection},
mendeley-tags = {object detection},
pages = {2004--2010},
title = {{Improving CNN performance with min-max objective}},
volume = {2016-Janua},
year = {2016}
}
@article{Palmes2005,
abstract = {Evolving gradient-learning artificial neural networks (ANNs) using an evolutionary algorithm (EA) is a popular approach to address the local optima and design problems of ANN. The typical approach is to combine the strength of backpropagation (BP) in weight learning and EA's capability of searching the architecture space. However, the BP's "gradient descent" approach requires a highly computer-intensive operation that relatively restricts the search coverage of EA by compelling it to use a small population size. To address this problem, we utilized mutation-based genetic neural network (MGNN) to replace BP by using the mutation strategy of local adaptation of evolutionary programming (EP) to effect weight learning. The MGNN's mutation enables the network to dynamically evolve its structure and adapt its weights at the same time. Moreover, MGNN's EP-based encoding scheme allows for a flexible and less restricted formulation of the fitness function and makes fitness computation fast and efficient. This makes it feasible to use larger population sizes and allows MGNN to have a relatively wide search coverage of the architecture space. MGNN implements a stopping criterion where overfitness occurrences are monitored through "sliding-windows" to avoid premature learning and overlearning. Statistical analysis of its performance to some well-known classification problems demonstrate its good generalization capability. It also reveals that locally adapting or scheduling the strategy parameters embedded in each individual network may provide a proper balance between the local and global searching capabilities of MGNN.},
author = {Palmes, Paulito P. and Hayasaka, Taichi and Usui, Shiro},
doi = {10.1109/TNN.2005.844858},
isbn = {1045-9227},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Artificial neural networks (ANNs),Evolutionary algorithm (EA),Evolutionary programming (EP),Evolutionary strategies (ESs),Genetic algorithm (GA),Hybrid algorithm (HA),evolutive},
mendeley-tags = {evolutive},
number = {3},
pages = {587--600},
pmid = {15940989},
publisher = {IEEE},
title = {{Mutation-based genetic neural network}},
volume = {16},
year = {2005}
}
@article{Balle2015,
abstract = {We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. The data are linearly transformed, and each component is then normalized by a pooled activity measure, computed by exponentiating a weighted sum of rectified and exponentiated components and a constant. We optimize the parameters of the full transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. The optimized transformation substantially Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than alternative methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We demonstrate the use of the model as a prior probability density that can be used to remove additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized using the same Gaussianization objective, thus offering an unsupervised method of optimizing a deep network architecture.},
archivePrefix = {arXiv},
arxivId = {1511.06281},
author = {Ball{\'{e}}, Johannes and Laparra, Valero and Simoncelli, Eero P.},
eprint = {1511.06281},
journal = {arXiv preprint arXiv:1511.06281},
keywords = {image classification},
mendeley-tags = {image classification},
pages = {1--14},
title = {{Density Modeling of Images using a Generalized Normalization Transformation}},
url = {http://arxiv.org/abs/1511.06281},
year = {2015}
}
@article{Krishna2016,
author = {Krishna, Tushar and Emer, Joel and Sze, Vivienne and Conference, International Solid-state Circuits and Francisco, San and Chen, Yu-hsin and Krishna, Tushar and Emer, Joel and Sze, Vivienne},
keywords = {hardware},
mendeley-tags = {hardware},
title = {{Eyeriss : An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks The MIT Faculty has made this article openly available . Please share Citation " Eyeriss : An Energy-Efficient Reconfigurable Accelerator for Publisher Version}},
year = {2016}
}
@article{Rehman2014,
abstract = {Image Compression is a demanding field in this era of communication. There is a need to study and analyze the literature for image compression, as the demand for images, video sequences and computer animation has increased at very high rate so that the increment is drastically over the years. Multimedia data whether graphics, audio, video data which is uncompress requires considerable transmission bandwidth and storage capacity. So this leads to the need of compression of images and all multimedia applications to save storage and transmission time. In this study we discuss different compression algorithms used to reduce size of images without quality reduction. {\textcopyright} Maxwell Scientific Organization, 2014.},
author = {Rehman, Mehwish and Sharif, Muhammad and Raza, Mudassar},
isbn = {9233351788872},
issn = {20407459},
journal = {Research Journal of Applied Sciences, Engineering and Technology},
keywords = {Compression,Image,Lossless,Lossy,Review,image compression- lossy},
mendeley-tags = {image compression- lossy},
number = {4},
pages = {656--672},
publisher = {Maxwell Science Publishing},
title = {{Image compression: A survey}},
volume = {7},
year = {2014}
}
@book{Tarjano2019,
abstract = {Two main approaches are currently prevalent in the digital emulation of musical instruments: manipulation of pre-recorded samples and techniques of real-time synthesis, generally based on physical models with varying degrees of accuracy. Concerning the first, while the processing power of present-day computers enables their use in real-time, many restrictions arising from this sample-based design persist; the huge on disk space requirements and the stiffness of musical articulations being the most prominent. On the other side of the spectrum, pure synthesis approaches, while offering greater flexibility, fail to capture and reproduce certain nuances central to the verisimilitude of the generated sound, offering a dry, synthetic output, at a high computational cost. We propose a method where ensembles of lightweight neural networks working in parallel are learned, from crafted frequency-domain features of an instrument sound spectra, an arbitrary instrument's voice and articulations realistically and efficiently. We find that our method, while retaining perceptual sound quality on par with sampled approaches, exhibits 1/10 of latency times of industry standard real-time synthesis algorithms, and 1/100 of the disk space requirements of industry standard sample-based digital musical instruments. This method can, therefore, serve as a basis for more efficient implementations in dedicated devices, such as keyboards and electronic drumkits and in general purpose platforms, like desktops and tablets or open-source hardware like Arduino and Raspberry Pi. From a conceptual point of view, this work highlights the advantages of a closer integration of machine learning with other subjects, especially in the endeavor of new product development. Exploiting the synergy between neural networks, digital signal processing techniques and physical modelling, we illustrate the proposed method via the implementation of two virtual instruments: a conventional grand piano and a hibrid stringed instrument.},
author = {Tarjano, Carlos and Pereira, Valdecy},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-30490-4_30},
isbn = {9783030304898},
issn = {16113349},
keywords = {Acoustic modeling,Digital musical instruments,Neural networks,Real-time audio synthesis},
pages = {362--375},
title = {{Neuro-Spectral Audio Synthesis: Exploiting Characteristics of the Discrete Fourier Transform in the Real-Time Simulation of Musical Instruments Using Parallel Neural Networks}},
volume = {11730 LNCS},
year = {2019}
}
@article{ISI:000183263200010,
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Williams, L and Cockburn, A},
doi = {10.1109/MC.2003.1204373},
issn = {0018-9162},
journal = {COMPUTER},
month = {jun},
number = {6},
pages = {39--43},
publisher = {IEEE COMPUTER SOC},
title = {{Agile software development: It's about feedback and change}},
type = {Editorial Material},
volume = {36},
year = {2003}
}
@article{ISI:000268944000023,
abstract = {Context. AGILE is an Italian Space Agency mission dedicated to observing
the gamma-ray Universe. The AGILE's very innovative instrumentation for
the first time combines a gamma-ray imager (sensitive in the energy
range 30 MeV-50 GeV), a hard X-ray imager (sensitive in the range 18-60
keV), a calorimeter (sensitive in the range 350 keV-100 MeV), and an
anticoincidence system. AGILE was successfully launched on 2007 April 23
from the Indian base of Sriharikota and was inserted in an equatorial
orbit with very low particle background.
Aims. AGILE provides crucial data for the study of active galactic
nuclei, gamma-ray bursts, pulsars, unidentified gamma-ray sources,
galactic compact objects, supernova remnants, TeV sources, and
fundamental physics by microsecond timing.
Methods. An optimal sky angular positioning (reaching 0.1 degrees in
gamma- rays and 1-2 arcmin in hard X-rays) and very large fields of view
(2.5 sr and 1 sr, respectively) are obtained by the use of Silicon
detectors integrated in a very compact instrument.
Results. AGILE surveyed the gamma- ray sky and detected many Galactic
and extragalactic sources during the first months of observations.
Particular emphasis is given to multifrequency observation programs of
extragalactic and galactic objects.
Conclusions. AGILE is a successful high-energy gamma-ray mission that
reached its nominal scientific performance. The AGILE Cycle-1 pointing
program started on 2007 December 1, and is open to the international
community through a Guest Observer Program.},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
author = {Tavani, M and Barbiellini, G and Argan, A and Boffelli, F and Bulgarelli, A and Caraveo, P and Cattaneo, P W and Chen, A W and Cocco, V and Costa, E and D'Ammando, F and {Del Monte}, E and {De Paris}, G and {Di Cocco}, G and {Di Persio}, G and Donnarumma, I and Evangelista, Y and Feroci, M and Ferrari, A and Fiorini, M and Fornari, F and Fuschino, F and Froysland, T and Frutti, M and Galli, M and Gianotti, F and Giuliani, A and Labanti, C and Lapshov, I and Lazzarotto, F and Liello, F and Lipari, P and Longo, F and Mattaini, E and Marisaldi, M and Mastropietro, M and Mauri, A and Mauri, F and Mereghetti, S and Morelli, E and Morselli, A and Pacciani, L and Pellizzoni, A and Perotti, F and Piano, G and Picozza, P and Pontoni, C and Porrovecchio, G and Prest, M and Pucella, G and Rapisarda, M and Rappoldi, A and Rossi, E and Rubini, A and Soffitta, P and Traci, A and Trifoglio, M and Trois, A and Vallazza, E and Vercellone, S and Vittorini, V and Zambra, A and Zanello, D and Pittori, C and Preger, B and Santolamazza, P and Verrecchia, F and Giommi, P and Colafrancesco, S and Antonelli, A and Cutini, S and Gasparrini, D and Stellato, S and Fanari, G and Primavera, R and Tamburelli, F and Viola, F and Guarrera, G and Salotti, L and D'Amico, F and Marchetti, E and Crisconio, M and Sabatini, P and Annoni, G and Alia, S and Longoni, A and Sanquerin, R and Battilana, M and Concari, P and Dessimone, E and Grossi, R and Parise, A and Monzani, F and Artina, E and Pavesi, R and Marseguerra, G and Nicolini, L and Scandelli, L and Soli, L and Vettorello, V and Zardetto, E and Bonati, A and Maltecca, L and D'Alba, E and Patane, M and Babini, G and Onorati, F and Acquaroli, L and Angelucci, M and Morelli, B and Agostara, C and Cerone, M and Michetti, A and Tempesta, P and D'Eramo, S and Rocca, F and Giannini, F and Borghi, G and Garavelli, B and Conte, M and Balasini, M and Ferrario, I and Vanotti, M and Collavo, E and Giacomazzo, M},
doi = {10.1051/0004-6361/200810527},
issn = {1432-0746},
journal = {ASTRONOMY & ASTROPHYSICS},
keywords = {instrumentation: detectors; techniques: high angul},
month = {aug},
number = {3},
pages = {995--1013},
publisher = {EDP SCIENCES S A},
title = {{The AGILE Mission}},
type = {Article},
volume = {502},
year = {2009}
}
@article{ISI:000238141400003,
abstract = {This article explores how agile practices can reduce three kinds of
``distance{''} - temporal, geographical, and sociocultural - in global
software development (GSD). On the basis of two in-depth case studies,
specific Scrum and eXtreme Programming (XP) practices are found to be
useful for reducing communication, coordination, and control problems
that have been associated with GSD.},
address = {C/O CRC PRESS L L C, 2000 CORPORATE BLVD NW, BOCA RATON, FL 33431 USA},
author = {Holmstrom, Helena and Fitzgerald, Brian and Agerfalk, Par J and Conchuir, Eoin O},
doi = {10.1201/1078.10580530/46108.23.3.20060601/93703.2},
issn = {1058-0530},
journal = {INFORMATION SYSTEMS MANAGEMENT},
number = {3},
pages = {7--18},
publisher = {AUERBACH PUBLICATIONS},
title = {{Agile practices reduce distance in global software development}},
type = {Article},
volume = {23},
year = {2006}
}
@article{ISI:000298773100005,
abstract = {The paper reviews the literature on supply partner decision-making
published between 2001 and 2011, a period that has seen a significant
increase in work published in this field. The progress made in
developing new models and methods that can be applied to this task is
assessed in the context of the previous literature. Particular attention
is given to those methods that are especially relevant for use in agile
supply chains. The paper uses a classification framework that enables
models intended for similar purposes to be compared and tracked over
time. It is also used to identify a number of gaps in the literature.
The findings highlight an on-going need to develop methods that are able
to meet the combination of qualitative and quantitative objectives that
are typically found in partner selection problems in practice. (C) 2011
Elsevier Ltd. All rights reserved.},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
author = {Wu, Chong and Barnes, David},
doi = {10.1016/j.pursup.2011.09.002},
issn = {1478-4092},
journal = {JOURNAL OF PURCHASING AND SUPPLY MANAGEMENT},
keywords = {Literature review; Partner selection; Agile supply},
month = {dec},
number = {4},
pages = {256--274},
publisher = {ELSEVIER SCI LTD},
title = {{A literature review of decision-making models and approaches for partner selection in agile supply chains}},
type = {Review},
volume = {17},
year = {2011}
}
@article{ISI:000233567300021,
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
author = {Augustine, S and Payne, B and Sencindiver, F and Woodcock, S},
doi = {10.1145/1101779.1101781},
issn = {0001-0782},
journal = {COMMUNICATIONS OF THE ACM},
month = {dec},
number = {12},
pages = {85--89},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Agile project management: Steering from the edges}},
type = {Article},
volume = {48},
year = {2005}
}
@article{ISI:000277107200002,
abstract = {Context Software development depends significantly on team performance,
as does any process that involves human interaction
Objective Most current development methods argue that teams should
self-manage Our objective is thus to provide a better understanding of
the nature of self-managing agile teams, and the teamwork challenges
that arise when introducing such teams
Method We conducted extensive fieldwork for 0 months in a software
development company that introduced Scrum. We focused on the human
sensemaking, on how mechanisms of teamwork were understood by the people
involved
Results We describe a project through Dickinson and McIntyre's teamwork
model, focusing on the interrelations between essential teamwork
components Problems with team orientation, team leadership and
coordination in addition to highly specialized skills and corresponding
division of work were important barriers for achieving team
effectiveness
Conclusion Transitioning from individual work to self-managing teams
requires a reorientation not only by developers but also by management
This transition takes time and resources, but should not be neglected In
addition to Dickinson and McIntyre's teamwork components, we found trust
and shared mental models to be of fundamental importance (C) 2009
Elsevier B V All rights reserved},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Moe, Nils Brede and Dingsoyr, Torgeir and Dyba, Tore},
doi = {10.1016/j.infsof.2009.11.004},
issn = {0950-5849},
journal = {INFORMATION AND SOFTWARE TECHNOLOGY},
keywords = {Agile software development; Scrum; Software engine},
month = {may},
number = {5, SI},
pages = {480--491},
publisher = {ELSEVIER SCIENCE BV},
title = {{A teamwork model for understanding an agile team: A case study of a Scrum project}},
type = {Article},
volume = {52},
year = {2010}
}
@article{ISI:000084793700002,
abstract = {Feature recognition, from low level geometric entities of product design
representations within a CAD model to facilitate process planning and
manufacturing activities, has been of significant importance in computer
integrated manufacturing (CIM). However, the emerging paradigm of Agile
Manufacturing has imposed additional requirements of `'neutral
format{''} so that form-feature information can be readily shared among
multiple partners of a virtual enterprise. Recently, the STandard for
the Exchange of Product model data (STEP) has emerged as the means for
neutral form exchange of product related data. The ``STEP efforts{''}
have broken down the domain of manufacturing related activities in the
form of application protocols (APs) target for specific functions which
include drafting, configuration control and feature-based process
planning to mention a few. Efforts are still on to increase the
acceptance and use of this international standard (IS). This paper
focuses on our efforts to support the STEP standard with the development
of a standards-oriented form-feature extraction system. The developed
feature extraction system takes as a input a STEP file defining the
geometry and topology of a part and generates as output a STEP file with
form-feature information in AP224 format for form feature-based process
planning. The system can also be interfaced with a recent IGES to AP202
translator {[}M.P. Bhandarkar, B. Downie, M. Hardwick, R. Nagi,
Migration from ICES to STEP: one-to-one translation of IGES drawing to
STEP drafting data, accepted by Computers in Industry, July, 1999; M.P.
Bhandarkar, Satisfying information needs in Agile Manufacturing through
translation and feature extraction into STEP product data models, MS
Thesis, State University of New York at Buffalo, 1997.] to allow
conversion of legacy data. The feature recognition algorithm is
boundary-representation (B-Rep) based and follows a sequential approach
through an existing classification of features. Properties of each
feature class are exploited to enable their extraction. The algorithm is
currently developed for prismatic solids produced by milling operations
and that contain elementary shapes such as plane and cylindrical
surfaces (possibly using non-uniform rational B-splines (NURBS)).
Special attention has been paid to implementation issues. We demonstrate
the efficacy of the system using representative parts. (C) 2000
Published by Elsevier Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Bhandarkar, M P and Nagi, R},
doi = {10.1016/S0166-3615(99)00040-8},
issn = {0166-3615},
journal = {COMPUTERS IN INDUSTRY},
keywords = {STEP; form feature; feature extraction},
month = {jan},
number = {1},
pages = {3--24},
publisher = {ELSEVIER SCIENCE BV},
title = {{STEP-based feature extraction from STEP geometry for agile manufacturing}},
type = {Article},
volume = {41},
year = {2000}
}
@article{ISI:000225756200019,
abstract = {Developers need evidence that a new technology works in a certain
context before they promote and deploy it on a larger scale. This need
looms greater in large organizations because of their complexity and the
need to integrate new technologies and processes with existing ones.
To further evaluate agile methods and their underlying software
development practices, several Software Experience Center member
companies initiated a series of activities to discover if agile
practices match their organizations' needs. Based on the experiences of
these organizations, researchers concluded that agile practices match
the needs of large organizations, but integrating new practices with
existing processes and quality systems that govern the conduct of
software development requires further tailoring. The challenge here lies
not in applying agile practices to a project, but in efficiently
integrating the agile project into its environment.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Lindvall, M and Muthig, D and Dagnino, A and Wallin, C and Stupperick, M and Kiefer, D and May, J and Kahkonen, T},
doi = {10.1109/MC.2004.231},
issn = {0018-9162},
journal = {COMPUTER},
month = {dec},
number = {12},
pages = {26+},
publisher = {IEEE COMPUTER SOC},
title = {{Agile software development in large organizations}},
type = {Article},
volume = {37},
year = {2004}
}
@article{ISI:000309058000012,
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
author = {Palunko, Ivana and Cruz, Patricio and Fierro, Rafael},
doi = {10.1109/MRA.2012.2205617},
issn = {1070-9932},
journal = {IEEE ROBOTICS & AUTOMATION MAGAZINE},
month = {sep},
number = {3},
pages = {69--79},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{Agile Load Transportation Safe and Efficient Load Manipulation with Aerial Robots}},
type = {Article},
volume = {19},
year = {2012}
}
@article{ISI:000272058100007,
abstract = {This paper considers a supply chain design problem for a new market
opportunity with uncertain demand in an agile manufacturing setting. We
consider the integrated optimization of logistics and production costs
associated with the supply chain members. These problems routinely occur
in a wide variety of industries including semiconductor manufacturing,
multi-tier automotive supply chains, and consumer appliances to name a
few. There are two types of decision variables: binary variables for
selection of companies to form the supply chain and continuous variables
associated with production planning. A scenario approach is used to
handle the uncertainty of demand. The formulation is a robust
optimization model with three components in the objective function:
expected total costs, cost variability due to demand uncertainty, and
expected penalty for demand unmet at the end of the planning horizon.
The increase of computational time with the numbers of echelons and
members per echelon necessitates a heuristic. A heuristic based on a
k-shortest path algorithm is developed by using a surrogate distance to
denote the effectiveness of each member in the supply chain. The
heuristic can find an optimal solution very quickly in some small- and
medium-size cases. For large problems, a ``good{''} solution with a
small gap relative to our lower bound is obtained in a short
computational time. (C) 2009 Elsevier Ltd. All rights reserved.},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
author = {Pan, Feng and Nagi, Rakesh},
doi = {10.1016/j.cor.2009.06.017},
issn = {0305-0548},
journal = {COMPUTERS & OPERATIONS RESEARCH},
keywords = {Supply chain formation; Integrated costs; Uncertai},
month = {apr},
number = {4},
pages = {668--683},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
title = {{Robust supply chain design under uncertain demand in agile manufacturing}},
type = {Article},
volume = {37},
year = {2010}
}
@article{ISI:000165846400007,
abstract = {Many enterprises have pursued the lean thinking paradigm to improve the
efficiency of their business processes. More recently, the agile
manufacturing paradigm has been highlighted as an alternative to, and
possibly an improvement on, leanness. In pursuing such arguments in
isolation, the power of each paradigm may be lost, which is basically
that agile manufacturing is adopted where demand is volatile, and lean
manufacturing adopted where there is a stable demand. However, in some
situations it is advisable to utilize a different paradigm on either
side of the material flow de-coupling point to enable a total supply
chain strategy. This approach we have termed the Leagile Paradigm. This
paper therefore considers the effect of the marketplace environment on
strategy selection to ensure optimal supply chain performance.
Real-world case studies in the mechanical precision products, carpet
making, and electronic products market sectors demonstrate the new
approach to matching supply chain design to the actual needs of the
marketplace.},
address = {11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND},
annote = {15th International Conference of Production Research(ICPR-15), UNIV
LIMERICK, LIMERICK, IRELAND, AUG, 1999},
author = {Mason-Jones, R and Naylor, B and Towill, D R},
doi = {10.1080/00207540050204920},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {nov},
number = {17},
pages = {4061--4070},
publisher = {TAYLOR & FRANCIS LTD},
title = {{Lean, agile or leagile? Matching your supply chain to the marketplace}},
type = {Article; Proceedings Paper},
volume = {38},
year = {2000}
}
@article{ISI:000170758100024,
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Highsmith, J and Cockburn, A},
doi = {10.1109/2.947100},
issn = {0018-9162},
journal = {COMPUTER},
month = {sep},
number = {9},
pages = {120--122},
publisher = {IEEE COMPUTER SOC},
title = {{Agile software development: The business of innovation}},
type = {Article},
volume = {34},
year = {2001}
}
@article{ISI:000254515800002,
abstract = {Aims. Since the CGRO operation in 1991-2000, one of the primary
unresolved questions about the blazar gamma-ray emission has been its
possible correlation with the low-energy (in particular optical)
emission. To help answer this problem, the Whole Earth Blazar Telescope
(WEBT) consortium has organized the GLAST-AGILE Support Program (GASP)
to provide the optical-to-radio monitoring data to be compared with the
gamma-ray detections by the AGILE and GLAST satellites. This new WEBT
project started in early September 2007, just before a strong gamma-ray
detection of 0716+714 by AGILE.
Methods. We present the GASP-WEBT optical and radio light curves of this
blazar obtained in July-November 2007, about various AGILE pointings at
the source. We construct NIR-to-UV spectral energy distributions (SEDs),
by assembling GASP-WEBT data together with UV data from the Swift ToO
observations of late October.
Results. We observe a contemporaneous optical-radio outburst, which is a
rare and interesting phenomenon in blazars. The shape of the SEDs during
the outburst appears peculiarly wavy because of an optical excess and a
UV drop- and-rise. The optical light curve is well sampled during the
AGILE pointings, showing prominent and sharp flares. A future
cross-correlation analysis of the optical and AGILE data will shed light
on the expected relationship between these flares and the gamma-ray
events.},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
author = {Villata, M and Raiteri, C M and Larionov, V M and Kurtanidze, O M and Nilsson, K and Aller, M F and Tornikoski, M and Volvach, A and Aller, H D and Arkharov, A A and Bach, U and Beltrame, P and Bhatta, G and Buemi, C S and Boettcher, M and Calcidese, P and Carosati, D and Castro-Tirado, A J and {Da Rio}, D and {Di Paola}, A and Dolci, M and Forne, E and Frasca, A and Hagen-Thorn, V A and Heidt, J and Hiriart, D and Jelinek, M and Kimeridze, G N and Konstantinova, T S and Kopatskaya, E N and Lanteri, L and Leto, P and Ligustri, R and Lindfors, E and Lahteenmaki, A and Marilli, E and Nieppola, E and Nikolashvili, M G and Pasanen, M and Ragozzine, B and Ros, J A and Sigua, L A and Smart, R L and Sorcia, M and Takalo, L O and Tavani, M and Trigilio, C and Turchetti, R and Uckert, K and Umana, G and Vercellone, S and Webb, J R},
doi = {10.1051/0004-6361:200809552},
issn = {0004-6361},
journal = {ASTRONOMY & ASTROPHYSICS},
keywords = {galaxies : active; galaxies : BL Lacertae objects},
month = {apr},
number = {2},
pages = {L79--L82},
publisher = {EDP SCIENCES S A},
title = {{Multifrequency monitoring of the blazar 0716+714 during the GASP-WEBT-AGILE campaign of 2007}},
type = {Article},
volume = {481},
year = {2008}
}
@article{ISI:000303626300001,
abstract = {Ever since the agile manifesto was created in 2001, the research
community has devoted a great deal of attention to agile software
development. This article examines publications and citations to
illustrate how the research on agile has progressed in the 10 years
following the articulation of the manifesto. Specifically, we delineate
the conceptual structure underlying agile scholarship by performing an
analysis of authors who have made notable contributions to the field.
Further, we summarize prior research and introduce contributions in this
special issue on agile software development. We conclude by discussing
directions for future research and urging agile researchers to embrace a
theory-based approach in their scholarship. (C) 2012 Elsevier Inc. All
rights reserved.},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
author = {Dingsoyr, Torgeir and Nerur, Sridhar and Balijepally, VenuGopal and Moe, Nils Brede},
doi = {10.1016/j.jss.2012.02.033},
issn = {0164-1212},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
keywords = {Agile software development; Theory; Software engin,XP; Scrum; Lean software development; Crystal met},
month = {jun},
number = {6},
pages = {1213--1221},
publisher = {ELSEVIER SCIENCE INC},
title = {{A decade of agile methodologies: Towards explaining agile software development}},
type = {Article},
volume = {85},
year = {2012}
}
@article{ISI:000223955900002,
abstract = {This paper outlines approaches for assessing and classifying
manufacturing and service operations in terms of their suitability for
use of cross-trained (flexible) workers. We refer to our overall
framework as agile workforce evaluation. The primary contributions of
this paper are: (i) a strategic assessment framework that structures the
key mechanisms by which cross-training can support organizational
strategy; (ii) a tactical framework that identifies key factors to guide
the selection of an architecture and worker coordination policy for
implementing workforce agility; (iii) a classification of workforce
agility architectures; (iv) a survey of a broad range of archetypical
classes of worker coordination policies; (v) a survey of the literature
with an operational perspective on workforce agility; and (vi)
identification of opportunities for research and development of
architectures for specific production environments.},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Hopp, W J and {Van Oyen}, M P},
doi = {10.1080/07408170490487759},
issn = {0740-817X},
journal = {IIE TRANSACTIONS},
month = {oct},
number = {10},
pages = {919--940},
publisher = {TAYLOR & FRANCIS LTD},
title = {{Agile workforce evaluation: a framework for cross-training and coordination}},
type = {Review},
volume = {36},
year = {2004}
}
@article{ISI:000167124500008,
abstract = {Agility is increasingly mentioned as one of the coming challenges to the
international business world, given volatile markets and increasingly
dynamic performance requirements. Existing literature, however, mainly
presents agility as a general management or a strongly manufacturing
biased concept, but does not explicitly relate the concept to the supply
chain as a whole. Research also shows a bias towards the USA. This paper
presents an attempt to establish an audit of agility in the supply
chain. The audit is used in an empirical investigation of agile
capabilities in Europe. Using existing streams of supply chain research
as building blocks, a preliminary framework is introduced for creating
an agile supply chain. Based on a survey of agile efforts in the UK and
the Benelux the agile capabilities of companies are assessed and
approaches to outscore the benchmark are suggested.},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
author = {van Hoek, R I and Harrison, A and Christopher, M},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {agility; supply chain; audit},
number = {1-2},
pages = {126--147},
publisher = {MCB UNIV PRESS LTD},
title = {{Measuring agile capabilities in the supply chain}},
type = {Article},
volume = {21},
year = {2001}
}
@article{ISI:000256077900014,
abstract = {Metamaterials exhibit numerous novel effects(1-5) and operate over a
large portion of the electromagnetic spectrum(6-10). Metamaterial
devices based on these effects include gradient-index lenses(11,12),
modulators for terahertz radiation(13-15) and compact waveguides(16).
The resonant nature of metamaterials results in frequency dispersion and
narrow bandwidth operation where the centre frequency is fixed by the
geometry and dimensions of the elements comprising the metamaterial
composite. The creation of frequency-agile metamaterials would extend
the spectral range over which devices function and, further, enable the
manufacture of new devices such as dynamically tunable notch filters.
Here, we demonstrate such frequency-agile metamaterials operating in the
far-infrared by incorporating semiconductors in critical regions of
metallic split-ring resonators. For this first-generation device,
external optical control results in tuning of the metamaterial resonance
frequency by similar to 20%. Our approach is integrable with current
semiconductor technologies and can be implemented in other regions of
the electromagnetic spectrum.},
address = {MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND},
author = {Chen, Hou-Tong and O'Hara, John F and Azad, Abul K and Taylor, Antoinette J and Averitt, Richard D and Shrekenhamer, David B and Padilla, Willie J},
doi = {10.1038/nphoton.2008.52},
issn = {1749-4885},
journal = {NATURE PHOTONICS},
month = {may},
number = {5},
pages = {295--298},
publisher = {NATURE PUBLISHING GROUP},
title = {{Experimental demonstration of frequency-agile terahertz metamaterials}},
type = {Article},
volume = {2},
year = {2008}
}
@article{ISI:000171519800001,
abstract = {About a decade ago, the agile manufacturing paradigm was formulated in
response to the constantly changing `new economy' and as a basis for
returning to global competitiveness. While agility means different
things to different enterprises under different contexts, the following
elements capture its essential concept: agility is characterized by
cooperativeness and synergism (possibly resulting in virtual
corporations), by a strategic vision that enables thriving in face of
continuous and unpredictable change, by the responsive creation and
delivery of customer-valued, high quality and mass customized
goods/services, by nimble organization structures of a knowledgeable and
empowered workforce, and facilitated by an information infrastructure
that links constituent partners in a unified electronic network. During
this period, a significant amount of attention from both the academic
and industrial communities has produced a large body of results in
research and development related to this topic. Each contribution has
tackled a different aspect of this large field. In this paper, we review
a wide range of recent literature on agile manufacturing. About 73
papers from premier scientific journals and conferences have been
reviewed, and a classification scheme to organize these is proposed. We
critique these bodies of work and suggest directions for additional
research and identify topics where fruitful opportunities exist.},
address = {11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND},
author = {Sanchez, L M and Nagi, R},
doi = {10.1080/00207540110068790},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {nov},
number = {16},
pages = {3561--3600},
publisher = {TAYLOR & FRANCIS LTD},
title = {{A review of agile manufacturing systems}},
type = {Review},
volume = {39},
year = {2001}
}
@article{ISI:000185086300001,
abstract = {This paper is based on longitudinal case studies of research into
strategy formulation within six plants from large firms - three in the
car industry and three from the computer industry - that have embarked
on mass customisation. The core theme of this paper is that, in spite of
the increasing attention given to manufacturing strategy from the
seminal work of Skinner through to the plethora of articles in recent
times, little is mentioned about its application to paradigms of agility
or mass customisation. As a consequence firms attempt to become agile
and to pursue mass customisation without appreciating the contribution
of plant-specific manufacturing strategies that might enable them to
achieve these aspirations. We examine the enablers and strategic
blockages in pursuing mass customisation, via a mapping process, and
reveal reasons why some firms remain unable to devise and implement
manufacturing strategies.},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
author = {Brown, S and Bessant, J},
doi = {10.1108/01443570310481522},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {strategic planning; mass customization; agile prod},
number = {7-8},
pages = {707--730},
publisher = {EMERALD GROUP PUBLISHING LTD},
title = {{The manufacturing strategy-capabilities links in mass customisation and agile manufacturing - an exploratory study}},
type = {Article},
volume = {23},
year = {2003}
}
@article{ISI:000323654900005,
abstract = {We describe a prototype 75 g micro quadrotor with onboard attitude
estimation and control that operates autonomously with an external
localization system. The motivation for designing quadrotors at this
scale comes from two observations. First, the agility of the robot
increases with a reduction in size, a fact that is supported by
experimental results in this paper. Second, smaller robots are able to
operate in tight formations in constrained, indoor environments. We
describe the hardware and software used to operate the vehicle as well
our dynamic model. We also discuss the aerodynamics of vertical flight
and the contribution of ground effect to the vehicle performance.
Finally, we discuss architecture and algorithms to coordinate a team of
these quadrotors, and provide experimental results for a team of 20
micro quadrotors.},
address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
author = {Kushleyev, Alex and Mellinger, Daniel and Powers, Caitlin and Kumar, Vijay},
doi = {10.1007/s10514-013-9349-9},
issn = {0929-5593},
journal = {AUTONOMOUS ROBOTS},
keywords = {Micro aerial vehicles; Quadrotors; Trajectory gene},
month = {nov},
number = {4, SI},
pages = {287--300},
publisher = {SPRINGER},
title = {{Towards a swarm of agile micro quadrotors}},
type = {Article},
volume = {35},
year = {2013}
}
@article{ISI:000183263200013,
abstract = {Both agile and plan-driven approaches have situation-dependent
shortcomings that, if not addressed, can lead to project failure. The
challenge is to balance the two approaches to take advantage of their
strengths in a given situation while compensating for their weaknesses.
The authors present a risk-based approach for structuring projects to
incorporate both agile and plan-driven approaches in proportion to a
project's needs.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Boehm, B and Turner, R},
doi = {10.1109/MC.2003.1204376},
issn = {0018-9162},
journal = {COMPUTER},
month = {jun},
number = {6},
pages = {57+},
publisher = {IEEE COMPUTER SOC},
title = {{Using risk to balance agile and plan-driven methods}},
type = {Article},
volume = {36},
year = {2003}
}
@article{ISI:000175277300004,
abstract = {Agile Manufacturing (AM) is a relatively new operations concept that is
intended to improve the competitiveness of firms. Manufacturing/service
processes based on AM are characterized by customer-supplier integrated
processes for product design, manufacturing, marketing, and support
services. Agile manufacturing requires enriching of the customer;
cooperating with competitors; organizing to manage change, uncertainty
and complexity; and leveraging people and information. In recent years,
a number of research papers have been published in the area of AM. The
term `agile' was coined in 1991. However, there are still some serious
concerns that prevent companies from taking an entirely different
direction from AM. Considering the potential importance of agile
manufacturing in 21st century manufacturing competitiveness, an attempt
has been made in this paper to re-examine the scope, definitions and
strategies of AM. In addition, a framework has been presented as a basis
for understanding the major strategies and relevant technologies of AM.},
address = {4 PARK SQUARE, MILTON PARK,, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Gunasekaran, A and Yusuf, Y Y},
doi = {10.1080/00207540110118370},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {apr},
number = {6},
pages = {1357--1385},
publisher = {TAYLOR & FRANCIS LTD},
title = {{Agile manufacturing: a taxonomy of strategic and technological imperatives}},
type = {Article},
volume = {40},
year = {2002}
}
@article{ISI:000085104500005,
abstract = {Turbulent and volatile markets are becoming the norm as life cycles
shorten and global economic and competitive forces create additional
uncertainty. The risk attached to lengthy and slow-moving logistics
``pipelines{''} has become unsustainable, forcing organizations to look
again at how their supply chains are structured and managed. This paper
suggests that the key to survival in these changed conditions is through
``agility,{''} in particular by the creation of responsive supply
chains. A distinction is drawn between the philosophies of
``leanness{''} and ``agility, `` and the appropriate application of
these ideas is (C) 2000 Elsevier Science Inc. All rights reserved.},
address = {655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010 USA},
author = {Christopher, M},
doi = {10.1016/S0019-8501(99)00110-8},
issn = {0019-8501},
journal = {INDUSTRIAL MARKETING MANAGEMENT},
month = {jan},
number = {1},
pages = {37--44},
publisher = {ELSEVIER SCIENCE INC},
title = {{The agile supply chain - Competing in volatile markets}},
type = {Article},
volume = {29},
year = {2000}
}
@article{ISI:000247547600012,
abstract = {This paper proposes a small-scale agile wall-climbing robot, which is
able to climb on smooth vertical surfaces using flat adhesive elastomer
materials for attachment. Using two actuated legs with rotary motion and
two passive revolute joints at each foot, this robot can climb and steer
in any orientation. Due to its compact design, a high degree of
miniaturization is possible. It has onboard power, computing, and
wireless communication, which allow for semiautonomous operation.
Various aspects of a functioning prototype design and performance are
discussed in detail, including leg and foot design and gait dynamics. A
model for the adhesion requirements and performance is developed and
verified through experiments. Using an adhesive elastomer (Vytaflex 10),
the current prototype can climb 90 slopes at a speed of up to 6 cm/s and
steer to any angle reliably on a,smooth acrylic surface as well as
transition from floor walking to wall climbing. This robot is intended
for inspection and surveillance applications, and ultimately, for space
missions.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
author = {Murphy, Michael P and Sitti, Metin},
doi = {10.1109/TMECH.2007.897277},
issn = {1083-4435},
journal = {IEEE-ASME TRANSACTIONS ON MECHATRONICS},
keywords = {dry adhesives; mechatronics; miniature robotics; m},
month = {jun},
number = {3},
pages = {330--338},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{Waalbot: An agile small-scale wall-climbing robot utilizing dry elastomer adhesives}},
type = {Article},
volume = {12},
year = {2007}
}
@article{ISI:000251148000017,
abstract = {SuperAGILE is a coded mask experiment based on silicon microstrip
detectors. It operates in the 15-45 keV nominal energy range, providing
crossed one-dimensional images of the X-ray sky with an on-axis angular
resolution of 6 arcmin, over a field of view in excess of 1 sr. It was
designed as the hard X-ray monitor of the AGILE space mission, a small
satellite of the Italian Space Agency devoted to image the gamma-ray sky
in the 30 MeV-50 GeV energy band. The AGILE mission was launched in a
low-earth orbit on 23rd April 2007. In this paper we describe the
SuperAGILE experiment, its construction and test processes, and its
performance before flight, based on the on-ground test and calibrations.
(c) 2007 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Feroci, M and Costa, E and Soffitta, P and {Del Monte}, E and {Di Persio}, G and Donnarumma, I and Evangelista, Y and Frutti, M and Lapshov, I and Lazzarotto, F and Mastropietro, M and Morelli, E and Pacciani, L and Porrovecchio, G and Rapisarda, M and Rubini, A and Tavani, M and Argan, A},
doi = {10.1016/j.nima.2007.07.147},
issn = {0168-9002},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
keywords = {high energy astrophysics; X-ray detectors; microst},
month = {nov},
number = {3},
pages = {728--754},
publisher = {ELSEVIER SCIENCE BV},
title = {{SuperAGILE: The hard X-ray imager for the AGILE space mission}},
type = {Article},
volume = {581},
year = {2007}
}
@article{ISI:000269983900004,
abstract = {In this paper, we draw on control theory to understand the conditions
under which the use of agile practices is most effective in improving
software project quality. Although agile development methodologies offer
the potential of improving software development outcomes, limited
research has examined how project managers can structure the software
development environment to maximize the benefits of agile methodology
use during a project. As a result, project managers have little guidance
on how to manage teams who are using agile methodologies. Arguing that
the most effective control modes are those that provide teams with
autonomy in determining the methods for achieving project objectives, we
propose hypotheses related to the interaction between control modes,
agile methodology use, and requirements change. We test the model in a
field study of 862 software developers in 110 teams. The model explains
substantial variance in four objective measures of project quality-bug
severity, component complexity, coordinative complexity, and dynamic
complexity. Results largely support our hypotheses, highlighting the
interplay between project control, agile methodology use, and
requirements change. The findings contribute to extant literature by
integrating control theory into the growing literature on agile
methodology use and by identifying specific contingencies affecting the
efficacy of different control modes. We discuss the theoretical and
practical implications of our results.},
address = {5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA},
author = {Maruping, Likoebe M and Venkatesh, Viswanath and Agarwal, Ritu},
doi = {10.1287/isre.1090.0238},
issn = {1047-7047},
journal = {INFORMATION SYSTEMS RESEARCH},
keywords = {agile methodologies; agility; control theory; requ},
month = {sep},
number = {3},
pages = {377--399},
publisher = {INFORMS},
title = {{A Control Theory Perspective on Agile Methodology Use and Changing User Requirements}},
type = {Article},
volume = {20},
year = {2009}
}
@article{ISI:A1996VZ99700005,
abstract = {The `'Agile Eye'' is a high-performance mechanism capable of orienting a
camera within a workspace larger than that of a human eye and with
velocities and accelerations larger than those of the human eye. The
mechanical design, control issues, and experimental results are
presented.},
address = {345 E 47TH ST, NEW YORK, NY 10017-2394},
author = {Gosselin, C M and StPierre, E and Gagne, M},
doi = {10.1109/100.556480},
issn = {1070-9932},
journal = {IEEE ROBOTICS & AUTOMATION MAGAZINE},
keywords = {parallel mechanisms; dynamic control; camera-orien},
month = {dec},
number = {4},
pages = {29--37},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{On the development of the Agile Eye}},
type = {Article},
volume = {3},
year = {1996}
}
@article{ISI:000269428600001,
address = {BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND},
author = {Abrahamsson, Pekka and Conboy, Kieran and Wang, Xiaofeng},
doi = {10.1057/ejis.2009.27},
issn = {0960-085X},
journal = {EUROPEAN JOURNAL OF INFORMATION SYSTEMS},
month = {aug},
number = {4},
pages = {281--284},
publisher = {PALGRAVE MACMILLAN LTD},
title = {{`Lots done, more to do': the current state of agile systems development research}},
type = {Editorial Material},
volume = {18},
year = {2009}
}
@article{ISI:000180587100029,
abstract = {A swept-wavelength source is created by connecting four elements in
series: a femtosecond fiber laser at 1.56 mum, a non-linear fiber, a
dispersive fiber and a tunable spectral bandpass filter. The 1.56-mum
pulses are converted to supercontinuum (1.1-2.2 mum) pulses by the
non-linear fiber, and these broadband pulses are stretched and arranged
into wavelength scans by the dispersive fiber. The tunable bandpass
filter is used to select a portion of the super-continuum as a
scan-wavelength output. A variety of scan characteristics are possible
using this approach. As an example, an output with an effective
linewidth of approximately 1 cm(-1) is scanned from 1350-1550 nm every
20 us. Compared to previous scanning benchmarks of approximately 1
nm/mus, such broad, rapid scans offer new capabilities: a gas sensing
application is demonstrated by monitoring absorption bands of H2O, CO2,
C2H2 and C2H6O at a pressure of 10 bar.},
address = {175 FIFTH AVE, NEW YORK, NY 10010 USA},
author = {Sanders, S T},
doi = {10.1007/s00340-002-1044-z},
issn = {0946-2171},
journal = {APPLIED PHYSICS B-LASERS AND OPTICS},
month = {nov},
number = {6-7},
pages = {799--802},
publisher = {SPRINGER-VERLAG},
title = {{Wavelength-agile fiber laser using group-velocity dispersion of pulsed super-continua and application to broadband absorption spectroscopy}},
type = {Article},
volume = {75},
year = {2002}
}
@article{ISI:000235093400003,
abstract = {In the last decades significant changes in the manufacturing environment
have been noticed: moving from a local economy towards a global economy,
with markets asking for products with higher quality at lower costs,
highly customised and with short life cycle. In these circumstances, the
challenge is to develop manufacturing control systems with intelligence
capabilities, fast adaptation to the environment changes and more
robustness against the occurrence of disturbances. This paper presents
an agile and adaptive manufacturing control architecture that addresses
the need for the fast reaction to disturbances at the shop floor level,
increasing the agility and flexibility of the enterprise, when it works
in volatile environments. The proposed architecture introduces an
adaptive control that balances dynamically between a more centralised
structure and a more decentralised one, allowing combining the global
production optimisation with agile reaction to unexpected disturbances.
(c) 2005 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Leitao, P and Restivo, F},
doi = {10.1016/j.compind.2005.05.005},
issn = {0166-3615},
journal = {COMPUTERS IN INDUSTRY},
keywords = {intelligent manufacturing control; holonic manufac},
month = {feb},
number = {2},
pages = {121--130},
publisher = {ELSEVIER SCIENCE BV},
title = {{ADACOR: A holonic architecture for agile and adaptive manufacturing control}},
type = {Article},
volume = {57},
year = {2006}
}
@article{ISI:000184714000004,
abstract = {The paper presents the background to why some manufacturing
organisations require a combination of agile and lean characteristics in
their manufacturing organisations. The paper also describes the
development of the virtual group (VG) concept, which is the application
of virtual cells to functional layouts. VGs enable the appropriate
application of lean and agile concepts to different stages of production
within a factory. The identification of VGs is achieved through the use
of a methodology called enhanced production flow analysis (EPFA), which
is described together with how it differs from Burbidge's PFA. Finally
the results of two case studies are presented which tested the ability
of EFPA to identify VGs, and assess its usability. (C) 2003 Elsevier
B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
annote = {16th International Conference on Production Research (ICPR), CZECH TECH
UNIV, PRAGUE, CZECH REPUBLIC, AUG, 2001},
author = {Prince, J and Kay, J M},
doi = {10.1016/S0925-5273(03)0118-X},
institution = {Czech Assoc Sci & Tech Soc},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {functional layout; lean; agile; virtual groups},
month = {sep},
number = {3},
pages = {305--318},
publisher = {ELSEVIER SCIENCE BV},
title = {{Combining lean and agile characteristics: Creation of virtual groups by enhanced production flow analysis}},
type = {Article; Proceedings Paper},
volume = {85},
year = {2003}
}
@article{ISI:000255490900012,
abstract = {AGILE is an Italian Space Agency mission dedicated to the exploration of
the gamma-ray Universe. The AGILE, very innovative instrument, combines
for the first time a gamma-ray imager (sensitive in the range 30 MeV-50
GeV) and a hard X-ray imager (sensitive in the range 18-60 keV). An
optimal angular resolution and very large fields of view are obtained by
the use of state-of-the-art Silicon detectors integrated in a very
compact instrument. AGILE was successfully launched on April 23, 2007
from the Indian base of Sriharikota and was inserted in an optimal
low-particle background equatorial orbit. AGILE will provide crucial
data for the study of Active Galactic Nuclei, Gamma-Ray Bursts,
unidentified gamma-ray sources, galactic compact objects, supernova
remnants, TeV sources, and fundamental physics by microsecond timing.
The AGILE Cycle-1 pointing program started on 2007 December 1, and is
open to the international community through a Guest Observer Program.
(c) 2008 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
annote = {1st Roma International Conference on Astroparticle Physics, Rome, ITALY,
JUN 20-22, 2007},
author = {Tavani, M and Barbiellini, G and Argan, A and Bulgarelli, A and Caraveo, P and Chen, A and Cocco, V and Costa, E and {De Paris}, G and {Del Monte}, E and {Di Cocco}, G and Donnarumma, I and Feroci, M and Florini, M and Froysland, T and Fuschino, F and Galli, M and Gianotti, F and Giuliani, A and Evangelista, Y and Labanti, C and Lapshov, I and Lazzarotto, F and Lipari, P and Longo, F and Marisaldi, M and Mastropietro, M and Mauri, F and Mereghetti, S and Morelli, E and Morselli, A and Pacciani, L and Pellizzoni, A and Perotti, F and Picozza, P and Pontoni, C and Porrovecchio, G and Prest, M and Pucella, G and Rapisarda, M and Rossi, E and Rubini, A and Soffitta, P and Trifoglio, M and Trois, A and Vallazza, E and Vercellone, S and Zarnbra, A and Zanello, D and Giommi, P and Antonelli, A and Pittori, C},
doi = {10.1016/j.nima.2008.01.023},
issn = {0168-9002},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
keywords = {astronomical and space-research instrumentation; a},
month = {apr},
number = {1-2},
pages = {52--62},
publisher = {ELSEVIER SCIENCE BV},
title = {{The AGILE space mission}},
type = {Article; Proceedings Paper},
volume = {588},
year = {2008}
}
@article{ISI:000080462600004,
abstract = {Agile manufacturing, a recently popularised concept, has been advocated
as the 21st century manufacturing paradigm. It is seen as the winning
strategy to be adopted by manufacturers bracing. themselves for dramatic
performance enhancements to become national and international leaders in
an increasingly competitive market of fast changing customer
requirements. This paper identifies the drivers of agility and discusses
the portfolio of competitive advantages that have emerged over time as a
result of the changing requirements of manufacturing. The need to
achieve the competitive advantages of manufacturing in synergy and
without trade-offs is fundamental to the agile paradigm. To further the
understanding of agility, this paper reviews the meaning of agility from
different perspectives and suggests a comprehensive definition which can
be adopted as a working definition by practitioners. Four underlining
concepts of agility has emerged from the working definition and the
paper presents a representation of these concepts and their
interactions. Finally, the paper highlights some of the key enablers of
agility and identifies potential future research directions. (C) 1999
Elsevier Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Yusuf, Y Y and Sarhadi, M and Gunasekaran, A},
doi = {10.1016/S0925-5273(98)00219-9},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agility; drivers; concepts; attributes; enablers},
month = {may},
number = {1-2},
pages = {33--43},
publisher = {ELSEVIER SCIENCE BV},
title = {{Agile manufacturing: The drivers, concepts and attributes}},
type = {Article},
volume = {62},
year = {1999}
}
@article{ISI:000241037900009,
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
author = {Ramesh, Balasubramaniam and Cao, Lan and Mohan, Kannan and Xu, Peng},
doi = {10.1145/1164394.1164418},
issn = {0001-0782},
journal = {COMMUNICATIONS OF THE ACM},
month = {oct},
number = {10},
pages = {41--46},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Can distributed software development be agile?}},
type = {Article},
volume = {49},
year = {2006}
}
@inproceedings{ISI:000183140900022,
abstract = {Agile software development methods have caught the attention of software
engineers and researchers worldwide. Scientific research is yet scarce.
This paper reports results from a study, which aims to organize, analyze
and make sense out of the dispersed field of agile software development
methods. The comparative analysis is performed using the method's
life-cycle coverage, project management support, type of practical
guidance, fitness-for-use and empirical evidence as the analytical
lenses. The results show that agile software development methods,
without rationalization, cover certain/different phases of the software
development life-cycle and most of them do not offer adequate support
for project management. Yet, many methods still attempt to strive for
universal solutions (as opposed to situation appropriate) and the
empirical evidence is still very limited. Based on the results, new
directions are suggested In principal, it is suggested to place emphasis
on methodological quality - not method quantity.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
annote = {25th International Conference on Software Engineering (ICSE 2003),
PORTLAND, OR, MAY 03-10, 2003},
author = {Abrahamsson, P and Warsta, J and Siponen, M T and Ronkainen, J},
booktitle = {25TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, PROCEEDINGS},
doi = {10.1109/ICSE.2003.1201204},
isbn = {0-7695-1877-X},
issn = {0270-5257},
organization = {IEEE; IEEE Comp Soc, Tech Council Software Engn; ACM; ACM SIGSOFT; IBM; NORTHROP GRUMMAN Space Technol; BMW; NOKIA; SUN Microsyst; DaimlerChrysler; Microsoft Res},
pages = {244--254},
publisher = {IEEE COMPUTER SOC},
series = {International Conference on Software Engineering},
title = {{New directions on agile methods: A comparative analysis}},
type = {Proceedings Paper},
year = {2003}
}
@article{ISI:000251595500020,
abstract = {Weather radars with conventional antenna cannot provide desired volume
scan updates at intervals of one minute or less, which is essential for
significant improvement in warning lead time of impending storm hazards.
The agile-beam multimission phased array radar (MPAR) discussed herein
is one potential candidate that can provide faster scanning. It also
offers a unique potential for multipurpose use to not only sample
weather, but support air traffic needs and track noncooperative
airplanes, thus making it an affordable option. After introducing the
basic idea behind electronic beam steering, the needs for frequent
observations of convective weather are explained. Then, advantages of
the phased array radar (PAR) for weather monitoring and improving data
quality are examined. To explore and develop weather-related
applications of the PAR, a National Weather Radar Testbed (NWRT) has
been established in Norman, Oklahoma. The NWRT's main purpose is to
address the advanced capabilities anticipated within the next decade so
that these could be projected to a possible network of future weather
radars. Examples of data illustrating advantages of this advanced radar
are shown, and forthcoming plans are discussed.},
address = {45 BEACON ST, BOSTON, MA 02108-3693 USA},
author = {Zrnic, D S and Kimpel, J F and Forsyth, D E and Shapiro, A and Crain, G and Ferek, R and Heimmer, J and Benner, W and McNellis, T J and Vogt, R J},
doi = {10.1175/BAMS-88-11-1753},
issn = {0003-0007},
journal = {BULLETIN OF THE AMERICAN METEOROLOGICAL SOCIETY},
month = {nov},
number = {11},
pages = {1753+},
publisher = {AMER METEOROLOGICAL SOC},
title = {{Agile-beam phased array radar for weather observations}},
type = {Article},
volume = {88},
year = {2007}
}
@article{ISI:000173405800012,
abstract = {Study results of developing an attitude control system for agile
spacecraft that require rapid retargeting and fast transient settling
are presented. In particular, a nonlinear feedback control logic is
developed for large-angle, rapid multitarget acquisition and pointing
maneuvers subject to various physical constraints, including actuator
saturation, slew rate limit, and control bandwidth limit. The rapid
multitarget acquisition and pointing capability of the proposed attitude
control system is demonstrated for an agile spacecraft equipped with
redundant single-gimbal control moment gyros. A realistic case of
pointing the line of sight of an imaging satellite in low Earth orbit
toward multiple targets on the ground is also briefly discussed.},
address = {1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091 USA},
author = {Wie, B and Bailey, D and Heiberg, C},
doi = {10.2514/2.4854},
issn = {0731-5090},
journal = {JOURNAL OF GUIDANCE CONTROL AND DYNAMICS},
number = {1},
pages = {96--104},
publisher = {AMER INST AERONAUT ASTRONAUT},
title = {{Rapid multitarget acquisition and pointing control of agile spacecraft}},
type = {Article},
volume = {25},
year = {2002}
}
@article{ISI:000080462600013,
abstract = {The business environment is one which is ever more demanding on
companies, due to its sheer dynamism, which means that they are
constantly having to improve their manufacturing performance.
Organisations are continuously having to cope with changing markets that
are unpredictable and more diversified, increasing global competition
and ever changing customer demands. Companies now have to be able to not
only predict variations and changes within the market and socio-economic
and political environments but must also be able to adapt and change in
accordance with these environments. As a result, this demands that an
organisation develops and sustains an inherent ability to continuously
change. Such a demand can be met by adopting the management philosophy
of agile manufacturing. Tn embracing such an approach, there are a lot
of key concepts and enabling technologies that are required to be able
to implement agile manufacturing and many companies do not know how far
down the path they are towards becoming agile manufacturing
organisations. Hence, in providing a deeper understanding, this paper
proposes a conceptual model, based on joint research, which has been
developed to identify where UK's best practice companies are in their
quest to become agile manufacturing organisations. In support of this, a
questionnaire has been developed and completed by best practitioners of
manufacturing, to assess the model, and establish whether they are
making progress to becoming agile manufacturing organisations. (C) 1999
Elsevier Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Sharp, J M and Irani, Z and Desai, S},
doi = {10.1016/S0925-5273(98)00228-X},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {manufacturing; agility; conceptual model},
month = {may},
number = {1-2},
pages = {155--169},
publisher = {ELSEVIER SCIENCE BV},
title = {{Working towards agile manufacturing in the UK industry}},
type = {Article},
volume = {62},
year = {1999}
}
@article{ISI:000173128600021,
abstract = {Although many of their advocates consider the agile and plan-driven
software development methods polar opposites, synthesizing the two can
provide developers with a comprehensive spectrum of tools and options.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Boehm, B},
doi = {10.1109/2.976920},
issn = {0018-9162},
journal = {COMPUTER},
month = {jan},
number = {1},
pages = {64+},
publisher = {IEEE COMPUTER SOC},
title = {{Get ready for agile methods, with care}},
type = {Article},
volume = {35},
year = {2002}
}
@article{ISI:000222980400008,
abstract = {Changing customer and technological requirements force manufacturers to
develop agile supply chain capabilities in order to be competitive.
Therefore, several companies are stressing flexibility and agility in
order to respond, real time, to the unique needs of customers and
markets. However, the resource competencies required are often difficult
to mobilise and retain by single companies. It is therefore imperative
for companies to co-operate and leverage complementary competencies. To
this end, legally separate and spatially distributed companies are
becoming integrated through Internet-based technologies. The paper
reviews emerging patterns in supply chain integration. It also explores
the relationship between the emerging patterns and attainment of
competitive objectives. The results reported in the paper are based on
the data collected from a survey using the standard questionnaire. The
survey involved 600 companies in the UK, as part of a larger study of
agile manufacturing. The study was driven by a conceptual model, which
relates supply chain practices to competitive objectives. The study
involves the use of factor analysis to reduce research variables to a
few principal components. Subsequently, multiple regression was
conducted to study the relationship amongst the selected variables. The
results validate the proposed conceptual model and lend credence to
current thinking that supply chain integration is a vital tool for
competitive advantage. (C) 2003 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Yusuf, Y Y and Gunasekaran, A and Adeleye, E O and Sivayoganathan, K},
doi = {10.1016/j.ejor.2003.08.022},
issn = {0377-2217},
journal = {EUROPEAN JOURNAL OF OPERATIONAL RESEARCH},
keywords = {agile manufacturing; agile supply chains; enterpri},
month = {dec},
number = {2},
pages = {379--392},
publisher = {ELSEVIER SCIENCE BV},
title = {{Agile supply chain capabilities: Determinants of competitive objectives}},
type = {Article},
volume = {159},
year = {2004}
}
@article{ISI:000245954500003,
abstract = {Empirical validation of software metrics suites to predict fault
proneness in object-oriented (OO) components is essential to ensure
their practical use in industrial settings. In this paper, we
empirically validate three OO metrics suites for their ability to
predict software quality in terms of fault-proneness: the Chidamber and
Kemerer (CK) metrics, Abreu's Metrics for Object-Oriented Design (
MOOD), and Bansiya and Davis' Quality Metrics for Object-Oriented Design
(QMOOD). Some CK class metrics have previously been shown to be good
predictors of initial OO software quality. However, the other two suites
have not been heavily validated except by their original proposers.
Here, we explore the ability of these three metrics suites to predict
fault-prone classes using defect data for six versions of Rhino, an
open-source implementation of JavaScript written in Java. We conclude
that the CK and QMOOD suites contain similar components and produce
statistical models that are effective in detecting error-prone classes.
We also conclude that the class components in the MOOD metrics suite are
not good class fault-proneness predictors. Analyzing multivariate binary
logistic regression models across six Rhino versions indicates these
models may be useful in assessing quality in OO classes produced using
modern highly iterative or agile software development processes.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Olague, Hector M and Etzkorn, Letha H and Gholston, Sampson and Quattlebaum, Stephen},
doi = {10.1109/TSE.2007.1015},
issn = {0098-5589},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
keywords = {object-oriented software metrics; object-oriented},
month = {jun},
number = {6},
pages = {402--419},
publisher = {IEEE COMPUTER SOC},
title = {{Empirical validation of three software metrics suites to predict fault-proneness of object-oriented classes developed using highly iterative or agile software development processes}},
type = {Article},
volume = {33},
year = {2007}
}
@article{ISI:000173405800014,
abstract = {Planning the path of an autonomous, agile vehicle in a dynamic
environment is a very complex problem, especially when the vehicle is
required to use its full maneuvering capabilities. Recent efforts aimed
at using randomized algorithms for planning the path of kinematic and
dynamic vehicles have demonstrated considerable potential for
implementation on future autonomous platforms. This paper builds upon
these efforts by proposing a randomized path planning architecture for
dynamical systems in the presence of fixed and moving obstacles. This
architecture addresses the dynamic constraints on the vehicle's motion,
and it provides at the same time a consistent decoupling between
low-level control and motion planning. The path planning algorithm
retains the convergence properties of its kinematic counterparts. System
safety is also addressed in the face of finite computation times by
analyzing the behavior of the algorithm when the available onboard
computation resources are limited, and the planning must be performed in
real time. The proposed algorithm can be applied to vehicles whose
dynamics are described either by ordinary differential equations or by
higher-level, hybrid representations. Simulation examples involving a
ground robot and a small autonomous helicopter are presented and
discussed.},
address = {1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091-4344 USA},
author = {Frazzoli, E and Dahleh, M A and Feron, E},
doi = {10.2514/2.4856},
issn = {0731-5090},
journal = {JOURNAL OF GUIDANCE CONTROL AND DYNAMICS},
number = {1},
pages = {116--129},
publisher = {AMER INST AERONAUT ASTRONAUT},
title = {{Real-time motion planning for agile autonomous vehicles}},
type = {Article},
volume = {25},
year = {2002}
}
@article{ISI:000243915300010,
abstract = {This paper reports an agile VCO frequency calibration technique and its
application on a 10-GHz CMOS integer-N phase-locked loop. The proposed
calibration method accomplishes efficient search for an optimum VCO
discrete tuning curve among a group of frequency sub-bands. The agility
is attributed to a proposed frequency comparison technique which is
based on measuring the period difference between two signals. Other
mixed-signal circuits are also developed to facilitate this approach.
The PLL incorporating the proposed calibration technique is implemented
in a 0.18-mu m CMOS process. The measured PLL phase noise at 10 GHz is
-102 dBc/Hz at 1-MHz offset frequency and the reference spurs are lower
than -48 dBc. The PLL consumes 44 mW in the low-current mode. The
calibration time is less than 4 mu s.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
author = {Lin, Tsung-Hsien and Lai, Yu-Jen},
doi = {10.1109/JSSC.2006.889360},
issn = {0018-9200},
journal = {IEEE JOURNAL OF SOLID-STATE CIRCUITS},
keywords = {calibration; CMOS integrated circuits; frequency s},
month = {feb},
number = {2},
pages = {340--349},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{An agile VCO frequency-calibration technique for a 10-GHz CMOS PLL}},
type = {Article},
volume = {42},
year = {2007}
}
@article{ISI:000182753200046,
abstract = {AGILE (Light Imager for Gamma-ray Astrophysics) is the first small
scientific mission of ASI, the Italian Space Agency. It is a light (100
kg for the scientific instrument) satellite for the detection of
gamma-ray sources in the energy range 30 MeV-50 GeV within a large field
of view (1 of the sky). It is planned to be operational in the years
2003-2006, a period in which no other gamma-ray mission in the same
energy range is foreseen.
AGILE is made of a silicon tungsten tracker, a CsI(Tl) minicalorimeter
(1.5X(0)), an anticoincidence system of segmented plastic scintillators
and a X-ray imaging detector sensitive in the 10-40 keV range. The
tracker consists of 14 planes, each of them made of two layers of 16
single-sided, AC coupled, 410 mum thick, 9.5 x 9.5 cm(2) silicon
detectors with a readout pitch of 242 mum and a floating strip. The
readout ASIC is the TAA1, an analog-digital, low noise, self-triggering
ASIC used in a very low power configuration (<400 &mu;W/channel) with
full analog readout. The trigger of the satellite is given by the
tracker. The total number of readout channels is around 43 000.
We present a detailed description of the tracker, its trigger and
readout logic, its assembly procedures and the prototype performance in
several testbeam periods at the CERN PS. (C) 2002 Elsevier Science B.V.
All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
annote = {10th International Workshop on Vertex Detectors, BRUNNEN, SWITZERLAND,
SEP 23-28, 2001},
author = {Prest, M and Barbiellini, G and Bordignon, G and Fedel, G and Liello, F and Longo, F and Pontoni, C and Vallazza, E},
doi = {10.1016/S0168-9002(02)02047-8},
issn = {0168-9002},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
keywords = {satellite; silicon detector; self-triggering; floa},
month = {mar},
number = {1},
pages = {280--287},
publisher = {ELSEVIER SCIENCE BV},
title = {{The AGILE silicon tracker: an innovative gamma-ray instrument for space}},
type = {Article; Proceedings Paper},
volume = {501},
year = {2003}
}
@article{ISI:000283606800005,
abstract = {Agile supply chains need to be highly flexible in order to reconfigure
quickly in response to changes in their environment. An effective
supplier selection process is essential for this. This paper develops a
model that helps overcome the information-processing difficulties
inherent in screening a large number of potential suppliers in the early
stages of the selection process. Based on radial basis function
artificial neural network (RBF-ANN), the model enables potential
suppliers to be assessed against multiple criteria using both
quantitative and qualitative measures. Its efficacy is illustrated using
empirical data from the Chinese electrical appliance and equipment
manufacturing industries. (C) 2009 Elsevier Ltd. All rights reserved.},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
author = {Luo, Xinxing and Wu, Chong and Rosenberg, Duska and Barnes, David},
doi = {10.1016/j.pursup.2009.05.004},
issn = {1478-4092},
journal = {JOURNAL OF PURCHASING AND SUPPLY MANAGEMENT},
keywords = {Supplier selection; Agile supply chain; Artificial},
month = {dec},
number = {4},
pages = {249--262},
publisher = {ELSEVIER SCI LTD},
title = {{Supplier selection in agile supply chains: An information-processing model and an illustration}},
type = {Article},
volume = {15},
year = {2009}
}
@article{ISI:000367200400009,
abstract = {Spectroscopic gas sensing and its applications to, for example, trace
detection or chemical kinetics, require ever more demanding measurement
times, acquisition rates, sensitivities, precisions and broad tuning
ranges. Here, we propose a new approach to near-infrared molecular
spectroscopy, utilizing advanced concepts of optical telecommunications
and supercontinuum photonics. We generate, without mode-locked lasers,
two frequency combs of slightly different repetition frequencies and
moderate, but rapidly tunable, spectral span. The output of a
frequency-agile continuous-wave laser is split and sent into two
electro-optic intensity modulators. Flat-top low-noise frequency combs
are produced by wave-breaking in a nonlinear optical fibre of normal
dispersion. With a dual-comb spectrometer, we record Doppler-limited
spectra spanning 60 GHz within 13 mu s and an 80 kHz refresh rate, at a
tuning speed of 10 nm s(-1). The sensitivity for weak absorption is
enhanced by a long gas-filled hollow-core fibre. New opportunities for
real-time diagnostics may be opened up, even outside the laboratory.},
address = {MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND},
author = {Millot, Guy and Pitois, Stephane and Yan, Ming and Hovhannisyan, Tatevik and Bendahmane, Abdelkrim and Haensch, Theodor W and Picque, Nathalie},
doi = {10.1038/NPHOTON.2015.250},
issn = {1749-4885},
journal = {NATURE PHOTONICS},
month = {jan},
number = {1},
pages = {27--U37},
publisher = {NATURE PUBLISHING GROUP},
title = {{Frequency-agile dual-comb spectroscopy}},
type = {Article},
volume = {10},
year = {2016}
}
@article{ISI:000077216500002,
abstract = {As product complexity and the rate of market change have dramatically
increased over the last years, firms find it increasingly difficult to
forecast product requirements in their development processes. This
article redefines the problem from one of improving forecasting to one
of increasing product development agility and thus reducing the need for
accurate long-term forecasts. It introduces the notion of development
flexibility, shows how it can be measured, and presents results from a
large empirical study on integrated systems development, which found
that projects using flexible technologies outperformed projects using
inflexible technologies by a factor of 2.2 (in person-months). Finally,
the article proposes three major strategies for introducing flexibility
into organizations. These strategies can help firms increase their
agility and position themselves to succeed in accelerating and more
turbulent markets.},
address = {GRAD SCH BUSINESS ADMIN, BERKELEY, CA 94720 USA},
author = {Thomke, S and Reinertsen, D},
doi = {10.2307/41165973},
issn = {0008-1256},
journal = {CALIFORNIA MANAGEMENT REVIEW},
number = {1},
pages = {8+},
publisher = {UNIV CALIF},
title = {{Agile product development: Managing development flexibility in uncertain environments}},
type = {Article},
volume = {41},
year = {1998}
}
@article{ISI:000256966600004,
abstract = {Agile software development practices such as eXtreme Programming (XP)
and SCRUM have increasingly been adopted to respond to the challenges of
volatile business environments, where the markets and technologies
evolve rapidly and present the unexpected. In spite of the encouraging
results so far, little is known about how agile practices affect
communication. This article presents the results from a study which
examined the impact of XP and SCRUM practices on communication within
software development teams and within the focal organization. The
research was carried out as a case study in F-Secure where two agile
software development projects were compared from the communication
perspective. The goal of the study is to increase the understanding of
communication in the context of agile software development: internally
among the developers and project leaders and in the interface between
the development team and stakeholders (i.e. customers, testers, other
development teams). The study shows that agile practices improve both
informal and formal communication. However, it further indicates that,
in larger development situations involving multiple external
stakeholders, a mismatch of adequate communication mechanisms can
sometimes even hinder the communication. The study highlights the fact
that hurdles and improvements in the communication process can both
affect the feature requirements and task subtask dependencies as
described in coordination theory. While the use of SCRUM and some XP
practices facilitate team and organizational communication of the
dependencies between product features and working tasks, the use of
agile practices requires that the team and organization use also
additional plan-driven practices to ensure the efficiency of external
communication between all the actors of software development.},
address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
author = {Pikkarainen, M and Haikara, J and Salo, O and Abrahamsson, P and Still, J},
doi = {10.1007/s10664-008-9065-9},
issn = {1382-3256},
journal = {EMPIRICAL SOFTWARE ENGINEERING},
keywords = {agile software development practices; communicatio},
month = {jun},
number = {3},
pages = {303--337},
publisher = {SPRINGER},
title = {{The impact of agile practices on communication in software development}},
type = {Article},
volume = {13},
year = {2008}
}
@article{ISI:000245650200061,
abstract = {Agile Protein Interaction DataAnalyzer (APID) is an interactive
bioinformatics web tool developed to integrate and analyze in a unified
and comparative platform main currently known information about
protein-protein interactions demonstrated by specific small-scale or
large-scale experimental methods. At present, the application includes
information coming from five main source databases enclosing an unified
sever to explore > 35 000 different proteins and 111 000 different
proven interactions. The web includes search tools to query and browse
upon the data, allowing selection of the interaction pairs based in
calculated parameters that weight and qualify the reliability of each
given protein interaction. Such parameters are for the `proteins':
connectivity, cluster coefficient, Gene Ontology ( GO) functional
environment, GO environment enrichment; and for the `interactions':
number of methods, GO overlapping, iPfam domain-domain interaction. APID
also includes a graphic interactive tool to visualize selected
sub-networks and to navigate on them or along the whole interaction
network. The application is available open access at
http://bioinfow.dep.usal.es/apid/.},
address = {GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND},
author = {Prieto, Carlos and Rivas, Javier De Las},
doi = {10.1093/nar/gkl128},
issn = {0305-1048},
journal = {NUCLEIC ACIDS RESEARCH},
month = {jul},
number = {SI},
pages = {W298--W302},
publisher = {OXFORD UNIV PRESS},
title = {{APID: Agile Protein Interaction DataAnalyzer}},
type = {Article},
volume = {34},
year = {2006}
}
@article{ISI:000229359800020,
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
author = {Nerur, S and Mahapatra, R and Mangalaraj, G},
doi = {10.1145/1060710.1060712},
issn = {0001-0782},
journal = {COMMUNICATIONS OF THE ACM},
month = {may},
number = {5},
pages = {72--78},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Challenges of emigrating to agile methodologies}},
type = {Article},
volume = {48},
year = {2005}
}
@article{ISI:000071490100010,
abstract = {In industrial management, the 1980s marked the end of the twentieth
century, an epoch dominated by US manufacturers, the alleged masters of
mass production. This system has now been outstripped in several dynamic
sectors by flexible/agile production. Increases in the pace of
technological progress, training and aspirations have made the modern
context so dynamic that firms which manage to harness the creativity and
initiative of a good part of their workforce have an advantage over
those that can only count on the input of their experts and managers. In
sectors undergoing relatively broad and rapid change, twenty-first
century firms must adopt a more flexible and innovative type of
organization to achieve manufacturing excellence.},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
author = {Duguay, C R and Landry, S and Pasin, F},
doi = {10.1108/01443579710182936},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {agile production; flexible manufacturing systems;},
number = {11-12},
pages = {1183+},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{From mass production to flexible/agile production}},
type = {Article},
volume = {17},
year = {1997}
}
@article{ISI:000235785800021,
abstract = {A new type of microwave radiometer detector has been developed that is
capable of identifying high and low levels of radio-frequency
interference (RFI) and of reducing or eliminating its effect on the
measured brightness temperatures. High-level, localized RFI can be
easily identified by its unnatural appearance in brightness temperature
imagery. Low-level or persistent RFI can be much more difficult to
identify and filter out. The agile digital detector (ADD) can
discriminate between RFI and natural thermal emission signals by
directly measuring higher order moments of the signal than the variance
that is traditionally measured. After detection, the ADD then uses
spectral filtering methods to selectively remove the RFI. ADD
performance is experimentally verified in controlled laboratory tests
and in the field near a commercial air traffic control radar. High-level
RFI is easily identified and removed. Very low level RFI contamination,
with power levels as low as the radiometric measurement uncertainty of
the radiometer, is also shown to be reliably detected and removed.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
author = {Ruf, C S and Gross, S M and Misra, S},
doi = {10.1109/TGRS.2005.861411},
issn = {0196-2892},
journal = {IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING},
keywords = {microwave radiometry; radio spectrum management},
month = {mar},
number = {3},
pages = {694--706},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{RFI detection and mitigation for microwave radiometry with an agile digital detector}},
type = {Article},
volume = {44},
year = {2006}
}
@article{ISI:000080462600009,
abstract = {As the lean thinking and agile manufacturing paradigms have been
developed there has been a tendency to view them in a progression and in
isolation. This article shows that this is too simplistic a view. The
use of either paradigm has to be combined with a total supply chain
strategy particularly considering market knowledge and positioning of
the decoupling point as agile manufacturing is best suited to satisfying
a fluctuating demand and lean manufacturing requires a level schedule.
This view is supported by consideration of a PC supply chain case study.
(C) 1999 Elsevier Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Naylor, J B and Naim, M M and Berry, D},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agile manufacturing; lean thinking; supply chain m},
month = {may},
number = {1-2},
pages = {107--118},
publisher = {ELSEVIER SCIENCE BV},
title = {{Leagility: Integrating the lean and agile manufacturing paradigms in the total supply chain}},
type = {Article},
volume = {62},
year = {1999}
}
@article{ISI:000231943500006,
abstract = {While there are many claims for the successful use of extreme
programming (XP) and agile modeling (AM), and the proponents can often
be vocal in the extreme regarding their supposed benefits, research
evidence supporting proponents' claims is somewhat lacking. Currently,
the only research appearing to investigate the phenomena consists of two
prominent streams. A small number of case studies and experience reports
that generally promote the success of XP in various development
environments, and a well-established stream of research into pair
programming has generated results that in part support the idea of XP
Research into AM appears to be even more sparse than that for XP Case
studies, comparative analyses, and experience reports comprise the
majority of the research in the area, while very few empirical research
efforts have been conducted. This article reviews the state of research
in XP and AM, and recommends areas that could benefit from further
study. Since nearly all empirical XP research relates to pair
programming, a closer look into the unstudied XP core practices would be
beneficial, although interaction between related core practice areas
could confound such efforts. It might also be possible to group related
core XP concepts and study the groups individually. Finally, there are
those who claim that XP and AM, or even agility in general, are really
nothing more than a repackaging of old concepts. This claim needs to be
investigated.},
address = {701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA},
author = {Erickson, J and Lyytinen, K and Siau, K},
doi = {10.4018/jdm.2005100105},
issn = {1063-8016},
journal = {JOURNAL OF DATABASE MANAGEMENT},
keywords = {agile software development; agility; agile modelin},
number = {4},
pages = {88--100},
publisher = {IGI PUBL},
title = {{Agile modeling, agile software development, and extreme programming: The state of research}},
type = {Review},
volume = {16},
year = {2005}
}
@article{ISI:000255824100022,
abstract = {Background: Capsule endoscopy (CE) of the small bowel has become a
standard diagnostic tool, but there have been concerns regarding the
risk of capsule retention in certain high-risk groups. The Agile patency
system, an ingestible and dissolvable capsule with an external scanner,
was developed to allow physicians to perform CE with greater confidence
that the capsule will be safely excreted in patients at risk for capsule
retention.
Objective: Our purpose was to assess the ability of the device to help
physicians identify which patients with known strictures may safely
undergo CE.
Design: Patients with known strictures ingested the new patency capsule
and under-went periodic scanning until it was excreted. The intestinal
tract was considered to be sufficiently patent if the capsule was
excreted intact or if the capsule was not detected by the scanner at 30
hours after ingestion. if patency was established, then standard CE was
performed.
Setting: International multicenter study.
Patients: A total of 106 patients with known strictures.
Intervention: Agile patency system.
Main Outcome Measurements: Performance and safety of Agile patency
system.
Results: A total of 106 patients ingested the patency capsule.
Fifty-nine (56%) excreted it intact and subsequently underwent CE.
There were no cases of capsule retention. Significant findings on CE
were found in 24 (41%). There were 3 severe adverse events.
Conclusions: These results suggest that the Agile patency system is a
useful tool for physicians to use before CE in patients with strictures
to avoid retention. This group of patients may have a high yield of
clinically significant findings at CE. This capsule may determine
whether patients who have a contraindication to CE may safely undergo CE
and obtain useful diagnostic information.},
address = {360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA},
annote = {3rd International Symposium on Natural Orifice Translumenal Endoscopic
Surgery, San Francisco, CA, JUL 10, 2008},
author = {Herrerias, Juan M and Leighton, Jonathan A and Costamagna, Guido and Infantolino, Anthony and Eliakim, Rami and Fischer, Doron and Rubin, David T and Manten, Howard D and Scapa, Eitan and Morgan, Douglas R and Bergwerk, Ari J and Koslowsky, Binyamin and Adler, Samuel N},
doi = {10.1016/j.gie.2007.10.063},
issn = {0016-5107},
journal = {GASTROINTESTINAL ENDOSCOPY},
month = {may},
number = {6},
pages = {902--909},
publisher = {MOSBY-ELSEVIER},
title = {{Agile patency system eliminates risk of capsule retention in patients with known intestinal strictures who undergo capsule endoscopy}},
type = {Article; Proceedings Paper},
volume = {67},
year = {2008}
}
@article{ISI:000073433700004,
abstract = {Tougher competitive situations have led to increasing attention being
paid to customer satisfaction, of which timely and customized services
are the key concepts. As the product life cycle becomes shortened, high
product quality becomes necessary for survival. Markets become highly
diversified and global, and continuous and unexpected change become the
key factors for success. The need for a method of rapidly and
cost-effectively developing products, production facilities and
supporting software, including design, process planning and shop floor
control system has led to the concept of agile manufacturing.
Agile manufacturing can be defined as the capability to survive and
prosper in a competitive environment of continuous and unpredictable
change by reacting quickly and effectively to changing markets, driven
by customer-designed products and services. This article details the key
concepts and enablers of agile manufacturing. The key enablers of agile
manufacturing include: (i) virtual enterprise formation tools/metrics;
(ii) physically distributed manufacturing architecture and teams; (iii)
rapid partnership formation tools/metrics; (iv) concurrent engineering;
(v) integrated product/production/business information system; (vi)
rapid prototyping tools; and (vii) electronic commerce. A conceptual
framework for the development of an agile manufacturing system and
future research directions are presented in this paper. This framework
takes into account the customization and system integration with the
help of business process redesign, legal issues, concurrent engineering,
computer-integrated manufacturing, cost management, total quality
management and information technology.},
address = {ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND},
author = {Gunasekaran, A},
doi = {10.1080/002075498193291},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {may},
number = {5},
pages = {1223--1247},
publisher = {TAYLOR & FRANCIS LTD},
title = {{Agile manufacturing: enablers and an implementation framework}},
type = {Article},
volume = {36},
year = {1998}
}
@article{ISI:000238914800019,
abstract = {A novel basis for beam steering with electrowetting microprisms (EMPs)
is reported. EMPs utilize electrowetting modulation of liquid contact
angle in order to mimic the refractive behavior for various classical
prism geometries. Continuous beam steering through an angle of 14
degrees (+/- 7 degrees) has been demonstrated with a liquid index of
n=1.359. Experimental results are well-matched to theoretical behavior
up to the point of electrowetting contact-angle saturation. Projections
show that use of higher index liquids (n similar to 1.6) will result in
steering through similar to 30 degrees(+/- 15 degrees). Fundamental
factors defining achievable deflection range, and issues for Ladar use,
are reviewed. This approach is capable of good switching speed (similar
to ms), polarization independent operation, modulation of beam
field-of-view (lensing), and high steering efficiency that is
independent of deflection angle. (c) 2006 Optical Society of America.},
address = {2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA},
author = {Smith, Neil R and Abeysinghe, Don C and Haus, Joseph W and Heikenfeld, Jason},
doi = {10.1364/OE.14.006557},
issn = {1094-4087},
journal = {OPTICS EXPRESS},
month = {jul},
number = {14},
pages = {6557--6563},
publisher = {OPTICAL SOC AMER},
title = {{Agile wide-angle beam steering with electrowetting microprisms}},
type = {Article},
volume = {14},
year = {2006}
}
@article{ISI:000228020200008,
abstract = {Western populations of the Italian agile frog (Rana latastei) experience
widespread genetic depletion. Based on population genetic theory,
molecular models of immunity and previous empirical studies, population
genetic depletion predicts increased susceptibility of populations to
emergent pathogens. We experimentally compared susceptibility of R.
latastei populations upon exposure to an emerging strain of Ranavirus,
frog virus 3 (FV3), using six populations spanning the geographical
range and range of population genetic diversity found in nature. Our
findings confirm this prediction, suggesting that the loss of genetic
diversity accompanying range expansion and population isolation is
coincident with increased mortality risk from an emergent pathogen. Loss
of heterozygosity and escape from selection imposed by immunologically
cross-reactive pathogens may potentially generate range-wide variation
in disease resistance.},
address = {9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND},
author = {Pearman, P B and Garner, T W J},
doi = {10.1111/j.1461-0248.2005.00735.x},
issn = {1461-023X},
journal = {ECOLOGY LETTERS},
keywords = {amphibian declines; disease emergence; frog virus},
month = {apr},
number = {4},
pages = {401--408},
publisher = {BLACKWELL PUBLISHING LTD},
title = {{Susceptibility of Italian agile frog populations to an emerging strain of Ranavirus parallels population genetic diversity}},
type = {Article},
volume = {8},
year = {2005}
}
@article{ISI:000308110200009,
abstract = {In modern business environments, an effective supply chain management
(SCM) is crucial to business continuity. Competition between supply
chains (SC) has replaced the traditional competition between companies.
Lean, Agile, Resilient and Green (LARG) paradigms are advocated as the
foundation of a competitive SCM. To make a supply chain more
competitive, capable of responding to the demands of customers with
agility and capable of responding effectively to unexpected disturbance,
in conjugation with environmental responsibilities and the necessity to
eliminate processes that add no value, companies must implement a set of
LARG SCM practices and key performance indicators (KPI) to measure their
influence on the SC performance. However, the selection of the best LARG
SCM practices and KPIs is a complex problem, involving dependencies and
feedbacks. This paper proposes an integrated LARG analytic network
process (ANP) model to support decision-making in choosing the most
appropriate practices and KPIs to be implemented by companies in an SC.
To validate the model in an exploratory approach, a case study in an
automaker supply chain is presented.},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Cabral, Izunildo and Grilo, Antonio and Cruz-Machado, Virgilio},
doi = {10.1080/00207543.2012.657970},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
keywords = {lean; agile; resilient; green; SCM; ANP},
number = {17, SI},
pages = {4830--4845},
publisher = {TAYLOR & FRANCIS LTD},
title = {{A decision-making model for Lean, Agile, Resilient and Green supply chain management}},
type = {Article},
volume = {50},
year = {2012}
}
@article{ISI:000275321000002,
abstract = {We report the detection by the Astrorivelatore Gamma a Immagini Leggero
(AGILE) satellite of terrestrial gamma ray flashes (TGFs) obtained with
the minicalorimeter (MCAL) detector operating in the energy range
0.3-100 MeV. We select events typically lasting a few milliseconds with
spectral and directional selections consistent with the TGF
characteristics previously reported by other space missions. During the
period 1 June 2008 to 31 March 2009 we detect 34 high-confidence events
showing millisecond durations and a geographical distribution peaked
over continental Africa and Southeast Asia. For the first time,
AGILE-MCAL detects photons associated with TGF events up to 40 MeV. We
determine the cumulative spectral properties of the spectrum in the
range 0.5-40 MeV, which can be effectively described by a Bremsstrahlung
spectrum. We find that both the TGF cumulative spectral properties and
their geographical distribution are in good agreement with the Reuven
Ramaty High Energy Solar Spectroscopic Imager (RHESSI) results.},
address = {2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA},
author = {Marisaldi, M and Fuschino, F and Labanti, C and Galli, M and Longo, F and {Del Monte}, E and Barbiellini, G and Tavani, M and Giuliani, A and Moretti, E and Vercellone, S and Costa, E and Cutini, S and Donnarumma, I and Evangelista, Y and Feroci, M and Lapshov, I and Lazzarotto, F and Lipari, P and Mereghetti, S and Pacciani, L and Rapisarda, M and Soffitta, P and Trifoglio, M and Argan, A and Boffelli, F and Bulgarelli, A and Caraveo, P and Cattaneo, P W and Chen, A and Cocco, V and D'Ammando, F and {De Paris}, G and {Di Cocco}, G and {Di Persio}, G and Ferrari, A and Fiorini, M and Froysland, T and Gianotti, F and Morselli, A and Pellizzoni, A and Perotti, F and Picozza, P and Piano, G and Pilia, M and Prest, M and Pucella, G and Rappoldi, A and Rubini, A and Sabatini, S and Striani, E and Trois, A and Vallazza, E and Vittorini, V and Zambra, A and Zanello, D and Antonelli, L A and Colafrancesco, S and Gasparrini, D and Giommi, P and Pittori, C and Preger, B and Santolamazza, P and Verrecchia, F and Salotti, L},
doi = {10.1029/2009JA014502},
issn = {0148-0227},
journal = {JOURNAL OF GEOPHYSICAL RESEARCH-SPACE PHYSICS},
month = {mar},
publisher = {AMER GEOPHYSICAL UNION},
title = {{Detection of terrestrial gamma ray flashes up to 40 MeV by the AGILE satellite}},
type = {Article},
volume = {115},
year = {2010}
}
@article{ISI:000271681800011,
abstract = {Agile software development (ASD) is an emerging approach in software
engineering, initially advocated by a group of 17 software professionals
who practice a set of ``lightweight{''} methods, and share a common set
of values of software development. In this paper, we advance the
state-of-the-art of the research in this area by conducting a
survey-based ex-post-facto study for identifying factors from the
perspective of the ASD practitioners that will influence the success of
projects that adopt ASD practices. In this paper, we describe a
hypothetical success factors framework we developed to address our
research question, the hypotheses we conjectured, the research
methodology, the data analysis techniques we used to validate the
hypotheses, and the results we obtained from data analysis. The study
was conducted using an unprecedentedly large-scale survey-based
methodology, consisting of respondents who practice ASD and who had
experience practicing plan-driven software development in the past. The
study indicates that nine of the 14 hypothesized factors have
statistically significant relationship with ``Success{''}. The important
success factors that were found are: customer satisfaction, customer
collaboration, customer commitment, decision time, corporate culture,
control, personal characteristics, societal culture, and training and
learning. (C) 2009 Elsevier Inc. All rights reserved.},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
author = {Misra, Subhas Chandra and Kumar, Vinod and Kumar, Uma},
doi = {10.1016/j.jss.2009.05.052},
issn = {0164-1212},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
keywords = {Success factors; Agile software},
month = {nov},
number = {11},
pages = {1869--1890},
publisher = {ELSEVIER SCIENCE INC},
title = {{Identifying some important success factors in adopting agile software development practices}},
type = {Article},
volume = {82},
year = {2009}
}
@article{ISI:A1997YE58900002,
abstract = {Agile manufacturing is a new expression that is used to represent the
ability of a producer of goods and services to thrive in the face of
continuous change. These changes can occur in markets, in technologies,
in business relationships and in all facets of the business enterprise.
This paper discusses the genesis of several of the Agile Manufacturing
Research Institutes (AMRIs) and their on-going activities and results to
dale. A vision for agile manufacturing research is articulated and
initial accomplishments identified. Additional research needs are also
discussed.},
address = {2-6 BOUNDARY ROW, LONDON, ENGLAND SE1 8HN},
author = {DeVor, R and Graves, R and Mills, J J},
issn = {0740-817X},
journal = {IIE TRANSACTIONS},
month = {oct},
number = {10},
pages = {813--823},
publisher = {CHAPMAN HALL LTD},
title = {{Agile manufacturing research: accomplishments and opportunities}},
type = {Article},
volume = {29},
year = {1997}
}
@article{ISI:000231388800019,
abstract = {Agile software development processes have shown positive impacts on
cost, schedule, and customer satisfaction. However, most implementations
of agile processes have been in smaller-scale, software-only
environments. In March 2004, a group of researchers and practitioners
addressed the implementation of agile processes in large
systems-engineering projects that rely on traditional development
processes and artifacts. They identified three management challenge
areas. Here, the authors discuss numerous ways in which to address them.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Boehm, B and Turner, R},
doi = {10.1109/MS.2005.129},
issn = {0740-7459},
journal = {IEEE SOFTWARE},
number = {5},
pages = {30+},
publisher = {IEEE COMPUTER SOC},
title = {{Management challanges to implementing Agile Processes in traditional development organizations}},
type = {Article},
volume = {22},
year = {2005}
}
@article{ISI:000078667300001,
abstract = {The objective of this paper is to introduce a decision methodology and
structure for manufacturing land organizational) agility improvement.
The methodology allows for the evaluation of alternatives (e.g.
projects) to help organizations become more agile, with a specific
objective of improving the manufacturing business processes. An agile
enterprise is one whose processes are designed to respond effectively to
unanticipated change. One of the difficulties in designing and analysing
business processes, in general, is that they are operational designs
that need to incorporate strategic attributes. In order to evaluate
alternatives that impact the business processes, a networked
hierarchical analysis model based on the various characteristics of
agility, is proposed. This evaluation model will be based on the
analytic network process methodology for solving complex and systemic
decisions. An actual example of a small manufacturing enterprise
provides some managerial insights into the methodology.},
address = {ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND},
author = {Meade, L M and Sarkis, J},
doi = {10.1080/002075499191751},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {jan},
number = {2},
pages = {241--261},
publisher = {TAYLOR & FRANCIS LTD},
title = {{Analyzing organizational project alternatives for agile manufacturing processes: an analytical network approach}},
type = {Article},
volume = {37},
year = {1999}
}
@article{ISI:000180224400015,
abstract = {In response to changing success factors and environmental pressures,
companies are aspiring to break out of mass production and become lean
or agile. Whereas performance enhancements of lean practices have been
demonstrated, it is now the case that markets have become increasingly
characterized by turbulence, a situation in which reliance on lean
practices is insufficient, and that survival requires adoption of agile
practices. As a result, a comparative study of lean and agile
manufacturing with a related survey of current practices in the UK was
carried out, the results of which is presented in this paper. The paper
explored the threats to lean and the drivers of agile manufacturing.
Using data from a questionnaire survey, four hypotheses were tested,
which was indicative of the benefits of agile manufacturing. In contrast
to their lean counterparts, agile companies paid attention to a wider
range of competitive capabilities. They therefore had a lower range of
mean scores on competitive capabilities. Independent sample tests of
significant difference in business performance measures revealed that
the agile companies consistently outperformed their lean competitors on
all business performance measures studied. In addition, a wider range of
competitive capabilities and performance measures of the agile companies
correlated significantly and positively whilst such correlation was
observed for only a narrow range of capabilities and performance
measures for lean companies. The results suggest that competing
simultaneously on multiple competitive capabilities enhance performance
better than a rather narrow focus on cost and quality.},
address = {4 PARK SQUARE, MILTON PARK,, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Yusuf, Y Y and Adeleye, E O},
doi = {10.1080/00207540210157141},
issn = {0020-7543},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {nov},
number = {17},
pages = {4545--4562},
publisher = {TAYLOR & FRANCIS LTD},
title = {{A comparative study of lean and agile manufacturing with a related survey of current practices in the UK}},
type = {Article},
volume = {40},
year = {2002}
}
@article{ISI:000080462600008,
abstract = {Agile manufacturing (AM) is a new concept in manufacturing intended to
improve the competitiveness of firms. Manufacturing processes based on
AM are characterized by customer-supplier integrated process for product
design, manufacturing, marketing, and support services. This needs
decision-making at functional knowledge levels, stable unit costs,
flexible manufacturing, easy access to integrated data, and modular
production facilities. Agile manufacturing requires enriching of the
customer, co-operating with competitors, organizing to manage change,
uncertainty and complexity, and leveraging people and information. In
the recent years, a number of research papers have been published in the
area of AM. However, a framework for the development of AM has not
received due attention from both researchers and practitioners.
Realizing the importance of agile manufacturing in the 21st century
manufacturing competitiveness, an attempt has been made in this paper to
review the literature available on AM with the objective to: (i)
identify key strategies and techniques of AM,(ii) suggest some future
research directions and (iii) develop a framework for the development of
agile manufacturing systems (AMSs) along four key dimensions which
include strategies, technologies, systems and people. (C) 1999 Elsevier
Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Gunasekaran, A},
doi = {10.1016/S0925-5273(98)00222-9},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agile manufacturing; review; future research; deve},
month = {may},
number = {1-2},
pages = {87--105},
publisher = {ELSEVIER SCIENCE BV},
title = {{Agile manufacturing: A framework for research and development}},
type = {Article},
volume = {62},
year = {1999}
}
@article{ISI:000265879200001,
abstract = {Dynamic capacity provisioning is a useful technique for handling the
multi-time-scale variations seen in Internet workloads. In this article,
we propose a novel dynamic provisioning technique for multi-tier
Internet applications that employs (1) a flexible queuing model to
determine how much of the resources to allocate to each tier of the
application, and (2) a combination of predictive and reactive methods
that determine when to provision these resources, both at large and
small time scales. We propose a novel data center architecture based on
virtual machine monitors to reduce provisioning overheads. Our
experiments on a forty-machine Xen/Linux-based hosting platform
demonstrate the responsiveness of our technique in handling dynamic
workloads. In one scenario where a flash crowd caused the workload of a
three-tier application to double, our technique was able to double the
application capacity within five minutes, thus maintaining response-time
targets. Our technique also reduced the overhead of switching servers
across applications from several minutes to less than a second, while
meeting the performance targets of residual sessions.},
address = {2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA},
annote = {2nd International Conference on Autonomic Computing (ICAC 2005),
Seattle, WA, JUN 13-16, 2005},
author = {Urgaonkar, Bhuvan and Shenoy, Prashant and Chandra, Abhishek and Goyal, Pawan and Wood, Timothy},
doi = {10.1145/1342171.1342172},
institution = {IEEE Comp Soc; Natl Sci Fdn},
issn = {1556-4665},
journal = {ACM TRANSACTIONS ON AUTONOMOUS AND ADAPTIVE SYSTEMS},
keywords = {Design; Experimentation; Performance; Internet app},
month = {mar},
number = {1},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Agile Dynamic Provisioning of Multi-Tier Internet Applications}},
type = {Article},
volume = {3},
year = {2008}
}
@article{ISI:000184713800006,
abstract = {Lean supply is closely associated with enabling flow and the elimination
of wasteful variation within the supply chain. However, lean operations
depend on level scheduling and the growing need to accommodate variety
and demand uncertainty has resulted in the emergence of the concept of
agility. This paper explores the role of inventory and capacity in
accommodating such variation and identifies how TRIZ separation
principles and TOC tools may be combined in the integrated development
of responsive and efficient supply chains. A detailed apparel industry
case study is used to illustrate the application of these concepts and
tools. (C) 2003 Elsevier Science B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
annote = {16th International Conference on Production Research (ICPR), CZECH TECH
UNIV, PRAGUE, CZECH REPUBLIC, AUG, 2001},
author = {Stratton, R and Warburton, R D H},
doi = {10.1016/S0925-5273(03)00109-9},
institution = {Czech Assoc Sci & Tech Soc},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agile; trade-offs; lean; quick response},
month = {aug},
number = {2},
pages = {183--198},
publisher = {ELSEVIER SCIENCE BV},
title = {{The strategic integration of agile and lean supply}},
type = {Article; Proceedings Paper},
volume = {85},
year = {2003}
}
@article{ISI:000080462600006,
abstract = {Agility is herein interpreted as using market knowledge and a virtual
corporation to exploit profitable opportunities in a volatile market
place. This requires the slashing of process lead times throughout the
chain. However, as we demonstrate in the paper such action is simply not
enough to enable agility. Similar steps must also be taken to reduce
information lead times, resulting in the concept of the ``information
enriched{''} supply chain. Simulation results obtained on realistic
models of fashion trade supply chains confirm the superior agility
resulting from information enrichment. The paper concludes with a
Route-Map indicating the steps to be taken in achieving supply chain
agility in real world scenarios. (C) 1999 Elsevier Science B.V. All
rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Mason-Jones, R and Towill, D R},
doi = {10.1016/S0925-5273(98)00221-7},
issn = {0925-5273},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agile; supply chain; information; competitive adva},
month = {may},
number = {1-2},
pages = {61--73},
publisher = {ELSEVIER SCIENCE BV},
title = {{Total cycle time compression and the agile supply chain}},
type = {Article},
volume = {62},
year = {1999}
}
@article{ISI:000171886500026,
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Cockburn, A and Highsmith, J},
doi = {10.1109/2.963450},
issn = {0018-9162},
journal = {COMPUTER},
month = {nov},
number = {11},
pages = {131--133},
publisher = {IEEE COMPUTER SOC},
title = {{Agile software development: The people factor}},
type = {Editorial Material},
volume = {34},
year = {2001}
}
@article{ISI:000234695300029,
abstract = {AGILE is a gamma-ray astrophysics space mission which will operate,
starting from 2006, in the 30 MeV-50 GeV energy range with imaging
capability also in the 15-45 keV energy band. In order to achieve the
required detection sensitivity, all AGILE detectors are surrounded by an
anticoincidence detector aimed at charged particle background rejection
with an inefficiency as low as 10(-4). In this work, the design and the
structure of this anticoincidence detector are presented, as well as its
performances in terms of charged particles detection inefficiency as
derived from extensive calibrations performed at CERN PS. (c) 2005
Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Perotti, F and Fiorini, M and Incorvaia, S and Mattaini, E and Sant'Ambrogio, E},
doi = {10.1016/j.nima.2005.10.016},
issn = {0168-9002},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
keywords = {scintillation detector; charged particles detector},
month = {jan},
number = {1},
pages = {228--236},
publisher = {ELSEVIER SCIENCE BV},
title = {{The AGILE anticoincidence detector}},
type = {Article},
volume = {556},
year = {2006}
}
@article{ISI:000178571700015,
abstract = {Wavelength-agile photonic integrated circuits are fabricated using a
one-step ion implantation quantum-well intermixing process. In this
paper, we discuss the issues in processing optimized widely tunable
multisection lasers using this technique and present the results
achieved using this process. This quantum-well intermixing process is
general in its application and can be used to monolithically integrate a
wide variety of optoelectronic components with widely tunable lasers.},
address = {345 E 47TH ST, NEW YORK, NY 10017-2394 USA},
author = {Skogen, E J and Barton, J S and Denbaars, S P and Coldren, L A},
doi = {10.1109/JSTQE.2002.800849},
issn = {1077-260X},
journal = {IEEE JOURNAL OF SELECTED TOPICS IN QUANTUM ELECTRONICS},
keywords = {ion implantation; laser tuning; semiconductor lase},
number = {4},
pages = {863--869},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{A quantum-well-intermixing process for wavelength-agile photonic integrated circuits}},
type = {Article},
volume = {8},
year = {2002}
}
@article{ISI:000300611700007,
abstract = {Private for-profit institutions have been the fastest-growing part of
the U.S. higher education sector. For-profit enrollment increased from
0.2 percent to 9.1 percent of total enrollment in degree-granting
schools from 1970 to 2009, and for-profit institutions account for the
majority of enrollments in non-degree-granting postsecondary schools. We
describe the schools, students, and programs in the for-profit higher
education sector, its phenomenal recent growth, and its relationship to
the federal and state governments. Using the 2004 to 2009 Beginning
Postsecondary Students (BPS) longitudinal survey, we assess outcomes of
a recent cohort of first-time undergraduates who attended for-profits
relative to comparable students who attended community colleges or other
public or private non-profit institutions. We find that relative to
these other institutions, for-profits educate a larger fraction of
minority, disadvantaged, and older students, and they have greater
success at retaining students in their first year and getting them to
complete short programs at the certificate and AA levels. But we also
find that for-profit students end up with higher unemployment and
``idleness{''} rates and lower earnings six years after entering
programs than do comparable students from other schools and that, not
surprisingly, they have far greater default rates on their loans.},
address = {2014 BROADWAY, STE 305, NASHVILLE, TN 37203 USA},
author = {Deming, David J and Goldin, Claudia and Katz, Lawrence F},
doi = {10.1257/jep.26.1.139},
issn = {0895-3309},
journal = {JOURNAL OF ECONOMIC PERSPECTIVES},
number = {1},
pages = {139--163},
publisher = {AMER ECONOMIC ASSOC},
title = {{The For-Profit Postsecondary School Sector: Nimble Critters or Agile Predators?}},
type = {Article},
volume = {26},
year = {2012}
}
@article{ISI:A1956WD31400011,
address = {1325 MASSACHUSETTS AVENUE, NW, WASHINGTON, DC 20005-4171},
author = {GUNTER, S E and KOHN, H I},
issn = {0021-9193},
journal = {JOURNAL OF BACTERIOLOGY},
number = {5},
pages = {571--581},
publisher = {AMER SOC MICROBIOLOGY},
title = {{THE EFFECT OF X-RAYS ON THE SURVIVAL OF BACTERIA AND YEAST .1. A COMPARATIVE STUDY OF THE DOSE-SURVIVAL CURVES OF AZOTOBACTER-AGILE, ESCHERICHIA-COLI, PSEUDOMONAS-FLUORESCENS, RHODOPSEUDOMONAS-SPHEROIDES, AND SACCHAROMYCES-CEREVISIAE IRRADIATED IN THE RES}},
type = {Article},
volume = {71},
year = {1956}
}
@article{ISI:000342721500040,
abstract = {The graceful and agile movements of animals are difficult to analyze and
emulate because locomotion is the result of a complex interplay of many
components: the central and peripheral nervous systems, the
musculoskeletal system, and the environment. The goals of biorobotics
are to take inspiration from biological principles to design robots that
match the agility of animals, and to use robots as scientific tools to
investigate animal adaptive behavior. Used as physical models, biorobots
contribute to hypothesis testing in fields such as hydrodynamics,
biomechanics, neuroscience, and prosthetics. Their use may contribute to
the design of prosthetic devices that more closely take human locomotion
principles into account.},
address = {1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA},
author = {Ijspeert, Auke J},
doi = {10.1126/science.1254486},
issn = {0036-8075},
journal = {SCIENCE},
month = {oct},
number = {6206},
pages = {196--203},
publisher = {AMER ASSOC ADVANCEMENT SCIENCE},
title = {{Biorobotics: Using robots to emulate and investigate agile locomotion}},
type = {Review},
volume = {346},
year = {2014}
}
@article{ISI:000271206100001,
abstract = {Purpose - Lean and agile manufacturing are two initiatives that are used
by manufacturing plant managers to improve operations capabilities. The
purpose of this paper is to investigate internal and external factors
that drive the choice of lean and agile operations capabilities and
their respective impact on operational performance.
Design/methodology/approach - Lean and agile manufacturing are each
conceptualized as a second-order factor and measured through a bundle of
distinct practices. The competitive intensity of industry and the
competitive strategy are modeled as potential external and internal
drivers, respectively, and the impact on quality, delivery, cost, and
flexibility performance is analyzed using structural equations modeling.
The model is tested with data from the high performance manufacturing
project comprising a total of 211 plants from three industries and seven
countries.
Findings - The results indicate that lean and agile manufacturing differ
in terms of drivers and outcomes. The choice of a cost-leadership
strategy fully mediates the impact of the competitive intensity of
industry as a driver of lean manufacturing, while agile manufacturing is
directly affected by both internal and external drivers, i.e. a
differentiation strategy as well as the competitive intensity of
industry. Agile manufacturing is found to be negatively associated with
a cost-leadership strategy, emphasizing the difference between lean and
agile manufacturing. The major differences in performance outcomes are
related to cost and flexibility, such that lean manufacturing has a
significant impact on cost performance (whereas agile manufacturing has
not), and that agile manufacturing has a stronger relationship with
volume as well as product mix flexibility than does lean manufacturing.
Research limitations/implications - Cross-sectional data from three
industries and seven countries are used, and it would be interesting to
test this model for more industries and countries.
Practical implications - The results provide insights into the factors
that influence the choice of lean or agile manufacturing for improving
operations, and the results that can be obtained.
Originality/value - To the authors' knowledge, this is the first
large-scale empirical survey of leanness and agility simultaneously,
using data from manufacturing firms in Europe, Asia, and North America.
The model incorporates a wide perspective on factors related to lean and
agile manufacturing, to be able to identify similarities and
differences.},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
author = {Hallgren, Mattias and Olhager, Jan},
doi = {10.1108/01443570910993456},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {Lean production; Agile production; Operations mana},
number = {10},
pages = {976--999},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{Lean and agile manufacturing: external and internal drivers and performance outcomes}},
type = {Article},
volume = {29},
year = {2009}
}
@article{ISI:000245226000011,
abstract = {We explore the price dynamics in a competitive market consisting of
spectrum agile network service providers and users. Here, multiple
self,interested spectrum providers operating with different technologies
and costs compete for potential customers. Different buyers or consumers
may evaluate the same seller differently depending on their
applications, operating technologies and locations. Two different buyer
populations, the quality-sensitive and the price-sensitive are
investigated, and the resulting collective price dynamics are studied
using a combination of analysis and simulations. Various scenarios are
considered regarding the nature and accuracy of information available to
the sellers. A myopically optimal strategy is studied when full
information is available, while a stochastic learning based strategy is
considered when the information is limited. Cooperating groups may be
formed among the sellers which will in-turn influence the group profit
for those participants. Free riding phenomenon is observed under certain
circumstances.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
author = {Xing, Yiping and Chandramouli, R and Cordeiro, Carlos},
doi = {10.1109/JSAC.2007.07041},
issn = {0733-8716},
journal = {IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS},
keywords = {wireless communication; radio spectrum management;},
month = {apr},
number = {3},
pages = {613--621},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{Price dynamics in competitive agile spectrum access markets}},
type = {Article},
volume = {25},
year = {2007}
}
@article{ISI:000251876200013,
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Cao, Lan and Ramesh, Balasubramaniam},
doi = {10.1109/MS.2008.1},
issn = {0740-7459},
journal = {IEEE SOFTWARE},
number = {1},
pages = {60--67},
publisher = {IEEE COMPUTER SOC},
title = {{Agile requirements engineering practices: An emprical study}},
type = {Article},
volume = {25},
year = {2008}
}
@article{ISI:000237770500016,
abstract = {With the emergence of a business era that embraces `change' as one of
its major characteristics, manufacturing success and survival are
becoming more and more difficult to ensure. The emphasis is on
adaptability to changes in the business environment and on addressing
market and customer needs proactively. Changes in the business
environment due to varying needs of the customers lead to uncertainty in
the decision parameters. Flexibility is needed in the supply chain to
counter the uncertainty in the decision parameters. A supply chain
adapts the changes if it is flexible and agile in nature. A framework is
presented in this paper, which encapsulates the market sensitiveness,
process integration, information driver and flexibility measures of
supply chain performance. The paper explores the relationship among
lead-time, cost, quality, and service level and the leanness and agility
of a case supply chain in fast moving consumer goods business. The paper
concludes with the justification of the framework, which analyses the
effect of market winning criteria and market qualifying criteria on the
three types of supply chains: lean, agile and leagile. (c) 2005 Elsevier
B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Agarwal, A and Shankar, R and Tiwari, M K},
doi = {10.1016/j.ejor.2004.12.005},
issn = {0377-2217},
journal = {EUROPEAN JOURNAL OF OPERATIONAL RESEARCH},
keywords = {agility; flexibility; supply chain; analytic netwo},
month = {aug},
number = {1},
pages = {211--225},
publisher = {ELSEVIER SCIENCE BV},
title = {{Modeling the metrics of lean, agile and leagile supply chain: An ANP-based approach}},
type = {Article},
volume = {173},
year = {2006}
}
@article{ISI:000271514900043,
abstract = {We present the first catalog of high-confidence gamma-ray sources
detected by the AGILE satellite during observations performed from July
9, 2007 to June 30, 2008. Cataloged sources were detected by merging all
the available data over the entire time period. AGILE, launched in April
2007, is an ASI mission devoted to gamma-ray observations in the 30
MeV-50 GeV energy range, with simultaneous X-ray imaging capability in
the 18-60 keV band. This catalog is based on Gamma-Ray Imaging Detector
(GRID) data for energies greater than 100 MeV. For the first AGILE
catalog, we adopted a conservative analysis, with a high-quality event
filter optimized to select gamma-ray events within the central zone of
the instrument field of view (radius of 40 degrees). This is a
significance-limited (4 sigma) catalog, and it is not a complete
flux-limited sample due to the non-uniform first-year AGILE sky
coverage. The catalog includes 47 sources, 21 of which are associated
with confirmed or candidate pulsars, 13 with blazars (7 FSRQ, 4 BL Lacs,
2 unknown type), 2 with HMXRBs, 2 with SNRs, 1 with a colliding-wind
binary system, and 8 with unidentified sources.},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
author = {Pittori, C and Verrecchia, F and Chen, A W and Bulgarelli, A and Pellizzoni, A and Giuliani, A and Vercellone, S and Longo, F and Tavani, M and Giommi, P and Barbiellini, G and Trifoglio, M and Gianotti, F and Argan, A and Antonelli, A and Boffelli, F and Caraveo, P and Cattaneo, P W and Cocco, V and Colafrancesco, S and Contessi, T and Costa, E and Cutini, S and D'Ammando, F and {Del Monte}, E and {De Paris}, G and {Di Cocco}, G and {Di Persio}, G and Donnarumma, I and Evangelista, Y and Fanari, G and Feroci, M and Ferrari, A and Fiorini, M and Fornari, F and Fuschino, F and Froysland, T and Frutti, M and Galli, M and Gasparrini, D and Labanti, C and Lapshov, I and Lazzarotto, F and Liello, F and Lipari, P and Mattaini, E and Marisaldi, M and Mastropietro, M and Mauri, A and Mauri, F and Mereghetti, S and Morelli, E and Moretti, E and Morselli, A and Pacciani, L and Perotti, F and Piano, G and Picozza, P and Pilia, M and Pontoni, C and Porrovecchio, G and Preger, B and Prest, M and Primavera, R and Pucella, G and Rapisarda, M and Rappoldi, A and Rossi, E and Rubini, A and Sabatini, S and Santolamazza, P and Scalise, E and Soffitta, P and Stellato, S and Striani, E and Tamburelli, F and Traci, A and Trois, A and Vallazza, E and Vittorini, V and Zambra, A and Zanello, D and Salotti, L},
doi = {10.1051/0004-6361/200911783},
issn = {0004-6361},
journal = {ASTRONOMY & ASTROPHYSICS},
keywords = {gamma rays: observations; catalogs},
month = {nov},
number = {3},
pages = {1563--1574},
publisher = {EDP SCIENCES S A},
title = {{First AGILE catalog of high-confidence gamma-ray sources}},
type = {Article},
volume = {506},
year = {2009}
}
@article{ISI:000231943500005,
abstract = {Agile processes focus on the early facilitation and fast production of
working code, and are based on software-development process models that
support iterative, incremental development of software. Although agile
methods have existed for a number of years now, answers to questions
concerning the suitability of agile processes to particular
software-development environments are still often based on anecdotal
accounts of experiences. An appreciation of the (often unstated)
assumptions underlying agile processes can lead to a better
understanding of the applicability of agile processes to particular
situations. Agile processes are less likely to be applicable in
situations in which core assumptions do not hold. This article examines
the principles and advocated practices of agile processes to identify
underlying assumptions. It also identifies limitations that may arise
from these assumptions and outlines how the limitations can be addressed
by incorporating other software-development techniques and practices
into agile development environments.},
address = {701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA},
author = {Turk, D and France, R and Rumpe, B},
doi = {10.4018/jdm.2005100104},
issn = {1063-8016},
journal = {JOURNAL OF DATABASE MANAGEMENT},
keywords = {agile development; assumptions; extreme programmin},
number = {4},
pages = {62--87},
publisher = {IGI PUBL},
title = {{Assumptions underlying agile software-development processes}},
type = {Review},
volume = {16},
year = {2005}
}
@article{ISI:000319705100015,
abstract = {To enhance the therapeutic efficacy and reduce the adverse effects of
traditional Chinese medicine, practitioners often prescribe combinations
of plant species and/or minerals, called formulae. Unfortunately, the
working mechanisms of most of these compounds are difficult to determine
and thus remain unknown. In an attempt to address the benefits of
formulae based on current biomedical approaches, we analyzed the
components of Yinchenhao Tang, a classical formula that has been shown
to be clinically effective for treating hepatic injury syndrome. The
three principal components of Yinchenhao Tang are Artemisia annua L.,
Gardenia jasminoids Ellis, and Rheum Palmatum L., whose major active
ingredients are 6,7-dimethylesculetin (D), geniposide (G), and rhein
(R), respectively. To determine the mechanisms underlying the efficacy
of this formula, we conducted a systematic analysis of the therapeutic
effects of the DGR compound using immunohistochemistry, biochemistry,
metabolomics, and proteomics. Here, we report that the DGR combination
exerts a more robust therapeutic effect than any one or two of the three
individual compounds by hitting multiple targets in a rat model of
hepatic injury. Thus, DGR synergistically causes intensified dynamic
changes in metabolic biomarkers, regulates molecular networks through
target proteins, has a synergistic/additive effect, and activates both
intrinsic and extrinsic pathways.},
address = {9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA},
author = {Wang, Xijun and Zhang, Aihua and Wang, Ping and Sun, Hui and Wu, Gelin and Sun, Wenjun and Lv, Haitao and Jiao, Guozheng and Xu, Hongying and Yuan, Ye and Liu, Lian and Zou, Dixin and Wu, Zeming and Han, Ying and Yan, Guangli and Dong, Wei and Wu, Fangfang and Dong, Tianwei and Yu, Yang and Zhang, Shuxiang and Wu, Xiuhong and Tong, Xin and Meng, Xiangcai},
doi = {10.1074/mcp.M112.021683},
issn = {1535-9476},
journal = {MOLECULAR & CELLULAR PROTEOMICS},
month = {may},
number = {5},
pages = {1226--1238},
publisher = {AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC},
title = {{Metabolomics Coupled with Proteomics Advancing Drug Discovery toward More Agile Development of Targeted Combination Therapies}},
type = {Article},
volume = {12},
year = {2013}
}
@article{ISI:000269983900003,
abstract = {Despite the popularity of agile methods in software development and
increasing adoption by organizations there is debate about what agility
is and how it is achieved. The debate suffers from a lack of
understanding of agile concepts and how agile software development is
practiced. This paper develops a framework for the organization of agile
software development that identifies enablers and inhibitors of agility
and the emergent capabilities of agile teams. The work is grounded in
complex adaptive systems (CAS) and draws on three principles of
coevolving systems: match coevolutionary change rate, maximize
self-organizing, and synchronize exploitation and exploration. These
principles are used to study the processes of two software development
teams, one a team using eXtreme Programming (XP) and the other a team
using a more traditional, waterfall-based development cycle. From the
cases a framework for the organization of agile software development is
developed. Time pacing, self-management with discipline and
routinization of exploration are among the agile enablers found in the
cases studies while event pacing, centralized management, and lack of
resources allocated to exploration are found to be inhibitors to
agility. Emergent capabilities of agile teams that are identified from
the research include coevolution of business value, sustainable working
with rhythm, sharing and team learning, and collective mindfulness.},
address = {7240 PARKWAY DR, STE 310, HANOVER, MD 21076-1344 USA},
author = {Vidgen, Richard and Wang, Xiaofeng},
doi = {10.1287/isre.1090.0237},
issn = {1047-7047},
journal = {INFORMATION SYSTEMS RESEARCH},
keywords = {agile software development; coevolving systems; co},
month = {sep},
number = {3},
pages = {355--376},
publisher = {INFORMS},
title = {{Coevolving Systems and the Organization of Agile Software Development}},
type = {Article},
volume = {20},
year = {2009}
}
@article{ISI:000171242900006,
abstract = {Traditional approach for the design of missile guidance and autopilot
systems has been to design these subsystems separately and then to
integrate them. Such an approach does not exploit any beneficial
relationships between these and other subsystems. A technique for
integrated design of missile guidance and autopilot systems using the
feedback linearization technique is discussed. Numerical results using a
six degree-of-freedom missile simulation are given. Integrated
guidance-autopilot systems are expected to result in significant
improvements in missile performance, leading to lower weight and
enhanced lethality. These design methods have extensive applications in
high performance aircraft autopilot and guidance system design. (C) 2001
Elsevier Science Ltd. All rights reserved.},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
author = {Menon, P K and Ohlmeyer, E J},
doi = {10.1016/S0967-0661(01)00082-X},
issn = {0967-0661},
journal = {CONTROL ENGINEERING PRACTICE},
keywords = {integrated; guidance; autopilot; feedback lineariz},
month = {oct},
number = {10},
pages = {1095--1106},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
title = {{Integrated design of agile missile guidance and autopilot systems}},
type = {Article},
volume = {9},
year = {2001}
}
@article{ISI:000275074600005,
abstract = {As business and technology environments change at an unprecedented rate,
software development agility to respond to changing user requirements
has become increasingly critical for software development performance.
Agile software development approaches, which emphasize
sense-and-respond, self-organization, cross-functional teams, and
continuous adaptation, have been adopted by an increasing number of
organizations to improve their software development agility. However,
the agile development literature is largely anecdotal and prescriptive,
lacking empirical evidence and theoretical foundation to support the
principles and practices of agile development. Little research has
empirically examined the software development agility construct in terms
of its dimensions, determinants, and effects on software development
performance. As a result, there is a lack of understanding about how
organizations can effectively implement an agile development approach.
Using an integrated research approach that combines quantitative and
qualitative data analyses, this research opens the black box of agile
development by empirically examining the relationships among two
dimensions of software development agility (software team response
extensiveness and software team response efficiency), two antecedents
that can be con trolled (team autonomy and team diversity), and three
aspects of software development performance (on-time completion,
on-budget completion, and software functionality). Our PLS results of
survey, responses of 399 software project managers suggest that the
relationships among these variables are more complex than what has been
perceived by the literature. The results suggest a tradeoff relationship
between response extensiveness and response efficiency. These two
agility dimensions impact software development performance differently:
response efficiency positively affects all of on-time completion,
on-budget completion, and software functionality, whereas response
extensiveness positively affects only software functionality. The
results also suggest that team autonomy has a positive effect on
response efficiency and a negative effect on response extensiveness, and
that team diversity has a positive effect on response extensiveness, We
conducted 10 post hoc case studies to qualitatively cross-validate our
PLS results and provide rich, additional insights regarding the complex,
dynamic interplays between autonomy, diversity, agility, and
performance. The qualitative analysis also provides explanations for
both supported and unsupported hypotheses. We discuss these qualitative
analysis results and conclude with the theoretical and practical
implications of our research findings for agile development approaches.},
address = {UNIV MINNESOTA-SCH MANAGEMENT 271 19TH AVE SOUTH, MINNEAPOLIS, MN 55455 USA},
author = {Lee, Gwanhoo and Xia, Weidong},
issn = {0276-7783},
journal = {MIS QUARTERLY},
keywords = {Software development agility; agile software devel},
month = {mar},
number = {1},
pages = {87--114},
publisher = {SOC INFORM MANAGE-MIS RES CENT},
title = {{TOWARD AGILE: AN INTEGRATED ANALYSIS OF QUANTITATIVE AND QUALITATIVE FIELD DATA ON SOFTWARE DEVELOPMENT AGILITY}},
type = {Article},
volume = {34},
year = {2010}
}
@article{ISI:000251845500002,
abstract = {Purpose - Despite the fact that agile manufacturing has been frequently
promoted as a means of improving business competitiveness, little
empirical evidence exists in the literature validating its positive link
with business performance. The purpose of this research paper is to
analyse agile manufacturing in Spain and study whether it is a critical
factor for success in different industries.
Design/methodology/approach - A conceptual model is drawn up, based on
the literature and a previous case study, to relate turbulence in the
environment with agile manufacturing practices and business performance.
The model is tested on a large sample of Spanish manufacturers using a
survey methodology to obtain information and a structural equation model
to analyse the data.
Findings - The results obtained show that, in turbulent environments,
the integrated use of agile manufacturing practices promotes
manufacturing competitive strength, leading to better operational,
market and financial performance.
Research limitations/implications - This study has two main limitations.
First, it is difficult to determine the most suitable unit of analysis
when studying agile manufacturing. Second, single respondent bias may be
considered a limitation.
Practical implications - Managers should consider the integrated
implementation of agile manufacturing practices in order to develop
manufacturing strength and to outperform competitors in turbulent
business environments.
Originality/value - This study adopts a systematic approach to the
analysis of agile manufacturing, considering various agility practices
or enablers in an integrated way and relating them not only to
environmental characteristics but also to business performance. This
approach is especially interesting because most of the literature on
agile manufacturing deals with agility strategies or techniques in an
isolated way. The study also tests the suitability of agile
manufacturing in real organisations - for the first time in the Spanish
context.},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
author = {Vazquez-Bustelo, Daniel and Avella, Lucia and Fernandez, Esteban},
doi = {10.1108/01443570710835633},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {agile production; operations and production manage},
number = {12},
pages = {1303--1332},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{Agility drivers, enablers and outcomes - Empirical test of an integrated agile manufacturing model}},
type = {Article},
volume = {27},
year = {2007}
}
@article{ISI:000244664800021,
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
author = {Nerur, Sridhar and Balijepally, VanuGopal},
doi = {10.1145/1226736.1226739},
issn = {0001-0782},
journal = {COMMUNICATIONS OF THE ACM},
month = {mar},
number = {3},
pages = {79--83},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Theoretical reflections on agile development methodologies - The traditional goal of optimization and control is making way for learning and innovation.}},
type = {Article},
volume = {50},
year = {2007}
}
@article{ISI:000251845300005,
abstract = {Purpose - This paper aims to provide a practical model usable by
organizations to help form agile virtual enterprises. The model helps to
integrate a variety of factors, tangible and intangible, strategic and
operational, for decision-making purposes.
Design/methodology/approach - A comprehensive development of factors is
determined from the literature and an analytical network process (ANP)
methodology is introduced for decision model development. An
illustrative example is presented.
Findings - The results provide a robust model that will aid decision
makers and agile virtual enterprise brokers form partnerships within
these organizational structures.
Research limitations/implications - The paper introduces a conceptual
model with an illustrative validating example. A practical application
and reapplication of the model are required to further validate the
model. ANP can require significant managerial input for its application,
potentially causing fatigue for decision makers.
Practical implications - Practical implications include a partner
selection tool and framework for decision makers. The model may be
easily tweaked by the elimination or addition of decision factors and
their relationships.
Originality/value - The paper is useful to practitioners and
organizations seeking to manage partnership formation of agile virtual
enterprises, an emerging organizational form. This work expands the
number of factors and interrelationships among these factors that no
other model has explicitly addressed for the agile virtual enterprise
formation situation.},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
author = {Sarkis, Joseph and Talluri, Srinivas and Gunasekaran, A},
doi = {10.1108/01443570710830601},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {agile production; partnership; virtual organizatio},
number = {11},
pages = {1213--1234},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{A strategic model for agile virtual enterprise partner selection}},
type = {Article},
volume = {27},
year = {2007}
}
@article{ISI:000237552000009,
abstract = {Tailoring of methods is commonplace in the vast majority of software
development projects and organisations. However, there is not much known
about the tailoring and engineering of agile methods, or about how these
methods can be used to complement each other. This study investigated
tailoring of the agile methods, eXtreme programming (XP) and Scrum, at
Intel Shannon, and involved experienced software engineers who
continuously monitored and reflected on these methods over a 3- year
period. The study shows that agile methods may individually be
incomplete in supporting the overall development process, but XP and
Scrum complement each other well, with XP providing support for
technical aspects and Scrum providing support for project planning and
tracking. The principles of XP and Scrum were carefully selected (only
six of the 12 XP key practices were implemented, for example) and
tailored to suit the needs of the development environment at Intel
Shannon. Thus, the study refutes the suggestion that agile methods are
not divisible or individually selectable but achieve their benefits
through the synergistic combination of individual agile practices;
rather, this study shows that an a la carte selection and tailoring of
practices can work very well. In the case of Scrum, some local tailoring
has led to a very committed usage by developers, in contrast to many
development methods whose usage is limited despite being decreed
mandatory by management. The agile practices that were applied did lead
to significant benefits, including reductions in code defect density by
a factor of 7. Projects of 6-month and 1-year duration have been
delivered ahead of schedule, which bodes well for future ability to
accurately plan development projects.},
address = {BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND},
author = {Fitzgerald, Brian and Hartnett, Gerard and Conboy, Kieran},
doi = {10.1027/palgrave.ejis.300605},
issn = {0960-085X},
journal = {EUROPEAN JOURNAL OF INFORMATION SYSTEMS},
keywords = {agile methods; software development; XP; Scrum; me},
month = {apr},
number = {2},
pages = {200--213},
publisher = {PALGRAVE MACMILLAN LTD},
title = {{Customising agile methods to software practices at Intel Shannon}},
type = {Article},
volume = {15},
year = {2006}
}
@article{ISI:000257529900001,
abstract = {Agile software development represents a major departure from
traditional, plan-based approaches to software engineering. A systematic
review of empirical studies of agile software development up to and
including 2005 was conducted. The search strategy identified 1996
studies, of which 36 were identified as empirical studies. The studies
were grouped into four themes: introduction and adoption, human and
social factors, perceptions on agile methods, and comparative studies.
The review investigates what is currently known about the benefits and
limitations of, and the strength of evidence for, agile methods.
Implications for research and practice are presented. The main
implication for research is a need for more and better empirical studies
of agile software development within a common research agenda. For the
industrial readership, the review provides a map of findings, according
to topic, that can be compared for relevance to their own settings and
situations. (C) 2008 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Dyba, Tore and Dingsoyr, Torgeir},
doi = {10.1016/j.infsof.2008.01.006},
issn = {0950-5849},
journal = {INFORMATION AND SOFTWARE TECHNOLOGY},
keywords = {empirical software engineering; evidence-based sof},
month = {aug},
number = {9-10},
pages = {833--859},
publisher = {ELSEVIER SCIENCE BV},
title = {{Empirical studies of agile software development: A systematic review}},
type = {Review},
volume = {50},
year = {2008}
}
@article{ISI:000296592600022,
abstract = {Coded aperture snapshot spectral imaging (CASSI) provides a mechanism
for capturing a 3D spectral cube with a single shot 2D measurement. In
many applications selective spectral imaging is sought since relevant
information often lies within a subset of spectral bands. Capturing and
reconstructing all the spectral bands in the observed image cube, to
then throw away a large portion of this data, is inefficient. To this
end, this paper extends the concept of CASSI to a system admitting
multiple shot measurements, which leads not only to higher quality of
reconstruction but also to spectrally selective imaging when the
sequence of code aperture patterns is optimized. The aperture code
optimization problem is shown to be analogous to the optimization of a
constrained multichannel filter bank. The optimal code apertures allow
the decomposition of the CASSI measurement into several subsets, each
having information from only a few selected spectral bands. The rich
theory of compressive sensing is used to effectively reconstruct the
spectral bands of interest from the measurements. A number of
simulations are developed to illustrate the spectral imaging
characteristics attained by optimal aperture codes. (C) 2011 Optical
Society of America},
address = {2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA},
author = {Arguello, Henry and Arce, Gonzalo R},
doi = {10.1364/JOSAA.28.002400},
issn = {1084-7529},
journal = {JOURNAL OF THE OPTICAL SOCIETY OF AMERICA A-OPTICS IMAGE SCIENCE AND VISION},
month = {nov},
number = {11},
pages = {2400--2413},
publisher = {OPTICAL SOC AMER},
title = {{Code aperture optimization for spectrally agile compressive imaging}},
type = {Article},
volume = {28},
year = {2011}
}
@article{ISI:000256391400011,
abstract = {While software is so important for all facets of the modern world,
software development itself is not a perfect process. Agile software
engineering methods have recently emerged as a new and different way of
developing software as compared to the traditional methodologies.
However, their success has mostly been anecdotal, and research in this
subject is still scant in the academic circles. This research study was
a survey study on the critical success factors of Agile software
development projects using quantitative approach.
Based on existing literature, a preliminary list of potential critical
success factors of Agile projects were identified and compiled.
Subsequently, reliability analysis and factor analysis were conducted to
consolidate this preliminary list into a final set of 12 possible
critical success factors for each of the four project success categories
- Quality, Scope, Time, and Cost.
A survey was conducted among Agile professionals, gathering survey data
from 109 Agile projects from 25 countries across the world. Multiple
regression techniques were used, both at the full regression model and
at the optimized regression model via the stepwise screening procedure.
The results revealed that only 10 out of 48 hypotheses were supported,
identifying three critical success factors for Agile software
development projects: (a) Delivery Strategy, (b) Agile Software
Engineering Techniques, and (c) Team Capability.
Limitations of the study are discussed together with interpretations for
practitioners. To ensure success of their projects, managers are urged
to focus on choosing a high-caliber team, practicing Agile engineering
techniques and following Agile-style delivery strategy. (C) 2007
Elsevier Inc. All rights reserved.},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
author = {Chow, Tsun and Cao, Dac-Buu},
doi = {10.1016/j.jss.2007.08.020},
issn = {0164-1212},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
keywords = {software development; agile methods; critical succ},
month = {jun},
number = {6},
pages = {961--971},
publisher = {ELSEVIER SCIENCE INC},
title = {{A survey study of critical success factors in agile software projects}},
type = {Article},
volume = {81},
year = {2008}
}
@article{ISI:000178991000007,
abstract = {This article concerns the problem of managing the new generation of
Agile Earth Observing Satellites (AEOS). This kind of satellites is
presently studied by the French Centre National d'Etudes Spatiales
(PLEIADES project). The mission of an Earth Observing Satellite is to
acquire images of specified areas on the Earth surface, in response to
observation requests from customers. Whereas non-agile satellites such
as SPOT5 have only one degree of freedom for acquiring images, the new
generation satellites have three, giving opportunities for a more
efficient use of the satellite imaging capabilities. Counterwise to this
advantage, the selection and scheduling of observations becomes
significantly more difficult, due to the larger search space for
potential solutions. Hence, selecting and scheduling observations of
agile satellites is a highly combinatorial problem. This article sets
out the overall problem and analyses its difficulties. Then it presents
different methods which have been investigated in order to solve a
simplified version of the complete problem: a greedy algorithm, a
dynamic programming algorithm, a constraint programming approach and a
local search method. (C) 2002 Editions scientifiques et medicales
Elsevier SAS. All rights reserved.},
address = {23 RUE LINOIS, 75724 PARIS, FRANCE},
author = {Lemaitre, M and Verfaillie, G and Jouhaud, F and Lachiver, J M and Bataille, N},
doi = {10.1016/S1270-9638(02)01173-2},
issn = {1270-9638},
journal = {AEROSPACE SCIENCE AND TECHNOLOGY},
keywords = {Earth Observing Satellite; agile satellite; missio},
month = {sep},
number = {5},
pages = {367--381},
publisher = {ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER},
title = {{Selecting and scheduling observations of agile satellites}},
type = {Article},
volume = {6},
year = {2002}
}
@article{ISI:000086196000001,
abstract = {Since early anatomical descriptions, the existence of dendritic spines
has stimulated intense curiosity and speculation about their regulation
and function. Research over the past three decades has described an
impressive mutability in dendritic-spine number and morphology under a
variety of physiological circumstances. Current evidence favors a
proposed model in which two pools of actin filaments, one stable and the
other dynamic, support both persistent spine structure and rapid spine
motility. Potential functions of spine motility and dynamic actin
include regulated protein scaffolding, retrograde signaling and synapse
stabilization.},
address = {84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND},
author = {Halpain, S},
doi = {10.1016/S0166-2236(00)01576-9},
issn = {0166-2236},
journal = {TRENDS IN NEUROSCIENCES},
month = {apr},
number = {4},
pages = {141--146},
publisher = {ELSEVIER SCIENCE LONDON},
title = {{Actin and the agile spine: how and why do dendritic spines dance?}},
type = {Editorial Material},
volume = {23},
year = {2000}
}
@article{ISI:A1996UU40400002,
abstract = {As product life cycle becomes shortened, high product quality becomes
necessary for survival, markets become highly diversified and global,
and continuous and unexpected change becomes the key factor for success.
The need for a method of rapidly and cost-effectively developing
products, production facilities and supporting software including
design, process planning, shop door control systems is becoming urgent.
The essence of this concept of manufacturing would be characterized by
introducing a new term agility or rapidity. When compared with computer
integrated manufacturing, agile manufacturing can be defined as the
capability of surviving and prospering in a competitive environment of
continuous and unpredictable change by reacting quickly and effectively
to changing markets, driven by customer-designed products and services.
Critical to successfully accomplishing agile manufacturing are a few
enabling technologies such as the standard for the exchange of products
(STEP), concurrent engineering, virtual manufacturing, component-based
heterarchical shop floor control system, information and communication
infrastructure, etc. This article details key concepts of those enabling
technologies and presents various activities related to agile
manufacturing under development in Korea, especially an agile
manufacturing test-bed at Pohang University of Science and Technology
and a prototype of the life cycle engineering study of a product model
made in a consumer electronic industry. Copyright (C) 1996 Elsevier
Science Ltd.},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB},
author = {Cho, H and Jung, M Y and Kim, M},
doi = {10.1016/0360-8352(96)00001-0},
issn = {0360-8352},
journal = {COMPUTERS & INDUSTRIAL ENGINEERING},
month = {jul},
number = {3},
pages = {323--334},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
title = {{Enabling technologies of agile manufacturing and its related activities in Korea}},
type = {Article},
volume = {30},
year = {1996}
}
@article{ISI:000169462700014,
abstract = {A evolutionary transformation of the business environment, with change
as a main characteristic, is taking place. Manufacturing companies, even
those operating in relatively stable conditions with good market
positions, are facing rapid and often unanticipated changes in their
business environment. Agile manufacturing is proposed in response to the
circumstances as a solution and is perceived as a vital characteristic
that manufacturing companies need to have in order to maintain their
competitive advantages in the new order of world business, Each company
will respond in a specific and different way to the changing
circumstances by deploying its own agile characteristics. Agility in
manufacturing may be achieved through the implementation and integration
of appropriate practices which provide the required abilities for a
company to respond properly to changes. Based on this concept, a
methodology is applied in two manufacturing companies and data collected
from the applications are used to validate the methodology. This paper
provides a brief summary of the methodology and details its
implementation and validation in the two case study companies. Practices
are proposed to support the achievement of agility in the two
organisations.},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
author = {Sharifi, H and Zhang, Z},
doi = {10.1108/01443570110390462},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {agile production; methodology; manufacturing},
number = {5-6},
pages = {772--794},
publisher = {MCB U P LIMITED},
title = {{Agile manufacturing in practice - Application of a methodology}},
type = {Article},
volume = {21},
year = {2001}
}
@article{ISI:000288926200006,
abstract = {A structural model incorporating agile manufacturing as the focal
construct is theorized and tested. The model includes the primary
components of JIT (JIT-purchasing and JIT-production) as antecedents and
operational performance and firm performance as consequences to agile
manufacturing. Using data collected from production and operations
managers working for large U.S. manufacturers, the model is assessed
following a structural equation modeling methodology. The results
indicate that JIT-purchasing has a direct positive relationship with
agile manufacturing while the positive relationship between
JIT-production and agile manufacturing is mediated by JIT-purchasing.
The results also indicate that agile manufacturing has a direct positive
relationship with the operational performance of the firm, that the
operational performance of the firm has a direct positive relationship
with the marketing performance of the firm, and that the positive
relationship between the operational performance of the firm and the
financial performance of the firm is mediated by the marketing
performance of the firm. (C) 2010 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Inman, R Anthony and Sale, R Samuel and {Green Jr.}, Kenneth W and Whitten, Dwayne},
doi = {10.1016/j.jom.2010.06.001},
issn = {0272-6963},
journal = {JOURNAL OF OPERATIONS MANAGEMENT},
keywords = {Agile manufacturing; JIT systems; Organizational p},
month = {may},
number = {4},
pages = {343--355},
publisher = {ELSEVIER SCIENCE BV},
title = {{Agile manufacturing: Relation to JIT, operational performance and firm performance}},
type = {Article},
volume = {29},
year = {2011}
}
@article{ISI:000236672000004,
abstract = {Purpose - The purpose of this article is to investigate the nature of
the humanitarian aid supply chain and discuss the extent to which
certain business supply chain concepts, particularly supply chain
agility, are relevant to humanitarian aid.
Design/methodology/approach - The paper identifies elements of good
practice in conventional business supply chains and applies them to the
humanitarian aid supply chain, making use of published practice-based
literature and web sites associated with humanitarian aid. Particular
emphasis is placed on the concept of ``agility{''} in supply chain
management. A model of an agile supply chain for humanitarian aid is
developed.
Findings - Humanitarian supply chains have similarities with business
supply chains, but there are significant differences. Many humanitarian
supply chains have a short and unstable existence with an inadequate
link between emergency aid and longer-term developmental aid. Unlike
many business supply chains, typical emergency aid appeals assign
inventory to a particular destination at the supply chain source.
Practical implications - This research note is a starting-point for
empirical studies to test the agile humanitarian supply chain model.
Originality/value - This paper seeks to integrate humanitarian aid
practice with concepts in the academic supply chain literature. In
particular, proposes that humanitarian donors need convincing of the
value of supply chain processes.},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
author = {Oloruntoba, R and Gray, R},
doi = {10.1108/13598540610652492},
issn = {1359-8546},
journal = {SUPPLY CHAIN MANAGEMENT-AN INTERNATIONAL JOURNAL},
keywords = {aid agencies; supply chain management},
number = {2},
pages = {115--120},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{Humanitarian aid: an agile supply chain?}},
type = {Article},
volume = {11},
year = {2006}
}
@article{ISI:000256780400001,
abstract = {Wireless networks and devices have rapidly been gaining popularity over
their wired counterparts. This popularity, in turn, has been generating
an explosive and ever-increasing demand for, and hence creating a
shortage of, the radio spectrum. The reason for this foreseen spectrum
shortage is reported not to be the scarcity of the radio spectrum but
the inefficiency of current spectrum access methods, thus leaving
spectrum opportunities along both the time and frequency dimensions that
wireless devices can exploit. Fortunately, recent technological advances
have made it possible to build software-defined radios (SDRs), which,
unlike traditional radios, can switch from one frequency band to another
at little or no cost. We propose a MAC protocol, called Opportunistic
Spectrum MAC (OS-MAC), for wireless networks equipped with cognitive
radios like SDRs. OS-MAC 1) adaptively and dynamically seeks and
exploits opportunities in both licensed and unlicensed spectra and along
both the time and frequency dimensions, 2) accesses and shares spectrum
among different unlicensed and licensed users, and 3) coordinates with
other unlicensed users for better spectrum utilization. Using extensive
simulation, OS-MAC is shown to be far more effective than current access
protocols from both the network's and the user's perspectives. By
comparing its performance with an Ideal-MAC protocol, OS-MAC is also
shown to not only outperform current access protocols, but also achieve
performance very close to that obtainable under the Ideal-MAC protocol.},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
author = {Hamdaoui, Bechir and Shin, Kang G},
doi = {10.1109/TMC.2007.70758},
issn = {1536-1233},
journal = {IEEE TRANSACTIONS ON MOBILE COMPUTING},
keywords = {spectrum agility; opportunistic MAC protocols; sof},
month = {aug},
number = {8},
pages = {915--930},
publisher = {IEEE COMPUTER SOC},
title = {{OS-MAC: An efficient MAC protocol for spectrum-agile wireless networks}},
type = {Article},
volume = {7},
year = {2008}
}
@article{ISI:000220125400007,
abstract = {The textiles and apparel industry has been neglected in terms of supply
chain management research. Recently, the industry has undergone a great
deal of change, particularly with global sourcing and high levels of
price competition. In addition, textiles and clothing has market
characteristics, such as short product lifecycle, high volatility, low
predictability, and a high level of impulse purchase, making such issues
as quick response of Paramount importance. This article discusses
characteristics of the textiles and apparel industry and identifies the
perspectives of lean, agile and leagility (a combination of these)
within existing supply chain literature, which have been proffered as
solutions to achieving quick response and reduced lead times. Through
case studies of textile and apparel companies, different approaches to
supply chain management are illustrated.},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
author = {Bruce, M and Daly, L and Towers, N},
doi = {10.1108/01443570410514867},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
keywords = {supply chain management; textile industry},
number = {1-2},
pages = {151--170},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
title = {{Lean or agile - A solution for supply chain management in the textiles and clothing industry?}},
type = {Article},
volume = {24},
year = {2004}
}
@book{sa97,
abstract = {Markets have always influenced the central thrust of the semiconductor industry. Beginning in the early eighties, the personal computer (PC) market has been the dominant market influencing the semiconductor industry. Single-chip microprocessors (MPUs) enabled what became the huge PC market, which ultimately overshadowed the earlier minicomputer and mainframe computer markets. The popularity of PCs led to investments in increasingly more powerful MPUs and memory chips of ever-growing capacity. MPUs and DRAMs became the semiconductor industry technology drivers for the data processing needs of the PC. But now, DSP, as opposed to conventional data processing, has become the major technology driver for the semiconductor industry as evidenced by its market growth and the fervour of chip vendors to provide new products based on DSP technology. The increasing need to digitally process analog information signals, like audio and video, is causing a major shift in the semiconductor business. Since DSP is the mathematical manipulation of those digitized information signals, specialized math circuitry is required for efficient signal processing-circuitry that was previously confined to classical DSP chips},
author = {Smith, Steven W},
isbn = {0966017633 9780966017632},
keywords = {file},
title = {{The scientist and engineer's guide to digital signal processing}},
year = {1997}
}
@article{r,
author = {Rosenblatt, F},
journal = {Traducao. [s.l.] Cornell Aeronautical Laboratory},
title = {{The perceptron a perceiving and recognizing automaton Project Para.}},
volume = {1957}
}
@unpublished{g17,
abstract = {'Style transfer' among images has recently emerged as a very active research topic, fuelled by the power of convolution neural networks (CNNs), and has become fast a very popular technology in social media. This paper investigates the analogous problem in the audio domain: How to transfer the style of a reference audio signal to a target audio content? We propose a flexible framework for the task, which uses a sound texture model to extract statistics characterizing the reference audio style, followed by an optimization-based audio texture synthesis to modify the target content. In contrast to mainstream optimization-based visual transfer method, the proposed process is initialized by the target content instead of random noise and the optimized loss is only about texture, not structure. These differences proved key for audio style transfer in our experiments. In order to extract features of interest, we investigate different architectures, whether pre-trained on other tasks, as done in image style transfer, or engineered based on the human auditory system. Experimental results on different types of audio signal confirm the potential of the proposed approach.},
annote = {preprint},
archivePrefix = {arXiv},
arxivId = {1710.11385},
author = {Grinstein, Eric and Duong, Ngoc Q.K. and Ozerov, Alexey and Perez, Patrick},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2018.8461711},
eprint = {1710.11385},
isbn = {9781538646588},
issn = {15206149},
keywords = {Audio style transfer,Auditory system,Deep neural network,Sound texture model,Texture synthesis},
pages = {586--590},
title = {{Audio Style Transfer}},
volume = {2018-April},
year = {2018}
}
@article{s,
author = {Samples, Sound},
doi = {10.1007/978-1-349-95810-8_954},
journal = {The Grants Register 2019},
pages = {595--596},
title = {{Philharmonia Orchestra}},
url = {http://www.philharmonia.co.uk/explore/sound_samples%3E},
volume = {2018},
year = {2019}
}
@book{t,
address = {Keras Documentation, [s.d.]. Dispon�vel em},
author = {The, Keras:},
publisher = {<},
title = {{Python Deep Learning library}},
url = {https://keras.io/%3E}
}
@article{f08,
abstract = {Background: In this study we investigated the association between instrumental music training in childhood and outcomes closely related to music training as well as those more distantly related. Methodology/Principal Findings: Children who received at least three years (M=4.6 years) of instrumental music training outperformed their control counterparts on two outcomes closely related to music (auditory discrimination abilities and fine motor skills) and on two outcomes distantly related to music (vocabulary and nonverbal reasoning skills). Duration of training also predicted these outcomes. Contrary to previous research, instrumental music training was not associated with heightened spatial skills, phonemic awareness, or mathematical abilities. Conclusions/Significance: While these results are correlational only, the strong predictive effect of training duration suggests that instrumental music training may enhance auditory discrimination, fine motor skills, vocabulary, and nonverbal reasoning. Alternative explanations for these results are discussed. {\textcopyright} 2008 Forgeard et al.},
author = {Forgeard, Marie and Winner, Ellen and Norton, Andrea and Schlaug, Gottfried},
doi = {10.1371/journal.pone.0003566},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pmid = {18958177},
title = {{Practicing a musical instrument in childhood is associated with enhanced verbal ability and nonverbal reasoning}},
volume = {3},
year = {2008}
}
@article{03,
journal = {The simulation of piano string vibration: From physical models to finite difference schemes and digital waveguides},
title = {___},
volume = {114},
year = {2003}
}
@book{ha17,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Howard, David M. and Angus, Jamie A. S.},
booktitle = {Acoustics and Psychoacoustics},
doi = {10.4324/9781315716879},
publisher = {Traducao. [s.l.] Focal press},
title = {{Acoustics and Psychoacoustics}},
year = {2017}
}
@article{s,
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods. Copyright 2013 by the author(s).},
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
journal = {30th International Conference on Machine Learning, ICML 2013},
number = {PART 3},
pages = {2176--2184},
title = {{On the importance of initialization and momentum in deep learning}},
volume = {2013},
year = {2013}
}
@book{mp69,
abstract = {Perceptrons were invented in the fifties when “learning machine” was an exciting new concept. For a decade thereafter, there has been much describing, experimenting, and speculating about what perceptrons can and cannot do. Discussions of this topic were typically lively and vague, because the underlying model and the concepts used were rarely completely defined. Copyright {\textcopyright} 1969 by The Institute of Electrical and Electronics Engineers, Inc.},
address = {MA},
author = {Nievergelt, J.},
booktitle = {IEEE Transactions on Computers},
doi = {10.1109/T-C.1969.222718},
issn = {00189340},
number = {6},
pages = {572},
publisher = {MIT Press, Cambridge},
title = {{R69-13 Perceptrons: An Introduction to Computational Geometry}},
volume = {C-18},
year = {1969}
}
@book{das93,
abstract = {An extremely efficient method for modeling wave propagation in a membrane is provided by the multidimensional extension of the digital waveguide. The 2-D digital waveguide mesh is constructed out of bidirectional delay units and scattering junctions. We show that it coincides with the standard finite difference approximation scheme for the 2-D wave equation, and we derive the dispersion error. Applications may be found in physical models of drums, soundboards, cymbals, gongs, small-box reverberators, and other acoustic constructs where a one-dimensional model is less desirable.},
author = {Duyne, SA Van},
booktitle = {Proceedings of the International Computer Music Conference (ICMC)},
edition = {Proceeding},
isbn = {1026-1087},
issn = {1026-1087},
pages = {40--47},
publisher = {Anais�INTERNATIONAL COMPUTER MUSIC ACCOCIATION},
title = {{Physical modeling with the 2-D digital waveguide mesh}},
url = {http://people.ece.cornell.edu/land/courses/ece5760/LABS/f2011/vanduyne93physical.pdf},
year = {1993}
}
@article{rhw,
author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
doi = {10.1016/B978-1-4832-1446-7.50035-2},
isbn = {1558600132},
journal = {Readings in Cognitive Science: A Perspective from Psychology and Artificial Intelligence},
pages = {399--421},
title = {{Learning Internal Representations by Error Propagation}},
volume = {1985},
year = {2013}
}
@book{yyk15,
abstract = {Here we are presenting a brief history of neural networks, given in Haykin (Neural networks: a comprehensive foundation, 2002) [7], Zurada (Introduction to artificial neural systems, 2001) [8], Nielsen (Neurocomputing, 1990 [9] in terms of the development of architectures and algorithms that are widely used today. The history of neural networks has been divided in four stages: Beginning of neural networks, First golden age, Quiet Years and Renewed enthusiasm which shows the interplay among biological experimentation, modeling and computer simulation, hardware implementation.},
address = {Traducao. [s.l.]},
author = {Yadav, Neha and Yadav, Anupam and Kumar, Manoj},
booktitle = {SpringerBriefs in Applied Sciences and Technology},
isbn = {978-94-017-9815-0},
issn = {21915318},
keywords = {ADALINE,Biological modeling,Neurocomputing,Pattern recognition,Perceptron,Signal processing},
pages = {13--15},
publisher = {Springer},
title = {{An Introduction to Neural Network Methods for Differential Equations}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84924190922&partnerID=tZOtx3y1},
volume = {16},
year = {2015}
}
@unpublished{,
title = {{No Title}},
url = {https://github.com/tesserato/tesserato.github.io%3E}
}
@unpublished{p85,
abstract = {Early, extensive studies of feed-forward connectionist networks of analog units with sigmoid activation function. Independently derives a generalization of the Perceptron (delta) learning rule that is similar to the formulation of Rumelhart, Hinton & Williams (1986). [AL 3/1/2004, 3/3/2004].},
author = {Plowright, Stephen},
booktitle = {Learning Logic},
doi = {10.20850/9781329443068},
title = {{Learning Logic}},
year = {2017}
}
@article{th12,
author = {Tieleman, Tijmen and Hinton, G},
journal = {Mach. Learn},
number = {2},
title = {{Divide the gradient by a running average of its recent magnitude. COURSERA Neural Netw}},
volume = {6},
year = {2012}
}
@book{s16,
abstract = {applicability for this approach.},
address = {Traducao. [s.l.] v. 99},
author = {Salsa, S},
booktitle = {Choice Reviews Online},
doi = {10.5860/choice.193386},
issn = {0009-4978},
number = {04},
pages = {53--1824--53--1824},
publisher = {Springer},
title = {{Partial differential equations in action: from modelling to theory}},
volume = {53},
year = {2015}
}
@article{b05,
abstract = {As is well-known, digital waveguides offer a computationally efficient, and physically motivated means of simulating wave propagation in strings. The method is based on sampling the traveling wave solution to the ideal wave equation and linearly filtering this solution to simulate dispersive effects due to stiffness and frequency-dependent loss; such digital filters may terminate the waveguide or be embedded along its length. For strings of high stiffness, however, dispersion filters can be difficult to design and expensive to implement. In this article, we show how high-quality time-domain terminating filters may be derived from given frequency-domain specifications which depend on the model parameters. Particular attention is paid to the problem of phase approximation, which, in the case of high stiffness, is strongly nonlinear. Finally, in the interest of determining the limits of applicability of digital waveguide techniques, we make a comparison with more conventional finite difference schemes, in terms of computational cost and numerical dispersion, for a set of string stiffness parameters. {\textcopyright} S. Hirzel Verlag.},
author = {Bensa, Julien and Bilbao, Stefan and Kronland-Martinet, Richard and Smith, Julius O. and Voinier, Thierry},
issn = {16101928},
journal = {Acta Acustica united with Acustica},
number = {2},
pages = {289--298},
title = {{Computational modeling of stiff piano strings using digital waveguides and finite differences}},
volume = {91},
year = {2005}
}
@book{d16,
abstract = {This work aims to improve upon the recently proposed and rapidly popular-ized optimization algorithm Adam (Kingma & Ba, 2014). Adam has two main components—a momentum component and an adaptive learning rate component. However, regular momentum can be shown conceptually and empirically to be in-ferior to a similar algorithm known as Nesterov's accelerated gradient (NAG). We show how to modify Adam's momentum component to take advantage of insights from NAG, and then we present preliminary evidence suggesting that making this substitution improves the speed of convergence and the quality of the learned mod-els.},
author = {Dozat, Timothy},
booktitle = {ICLR Workshop},
number = {1},
pages = {2013--2016},
title = {{Incorporating Nesterov Momentum into Adam}},
year = {2016}
}
@article{58,
journal = {The perceptron: a probabilistic model for information storage and organization in the brain},
title = {___},
volume = {65},
year = {1958}
}
@book{b09,
abstract = {Digital sound synthesis has long been approached using standard digital filtering techniques. Newer synthesis strategies, however, make use of physical descriptions of musical instruments, and allow for much more realistic and complex sound production and thereby synthesis becomes a problem of simulation. This book has a special focus on time domain finite difference methods presented within an audio framework. It covers time series and difference operators, and basic tools for the construction and analysis of finite difference schemes, including frequency-domain and energy-based methods, with special attention paid to problems inherent to sound synthesis. Various basic lumped systems and excitation mechanisms are covered, followed by a look at the 1D wave equation, linear bar and string vibration, acoustic tube modelling, and linear membrane and plate vibration. Various advanced topics, such as the nonlinear vibration of strings and plates, are given an elaborate treatment. Key features: Includes a historical overview of digital sound synthesis techniques, highlighting the links between the various physical modelling methodologies. A pedagogical presentation containing over 150 problems and programming exercises, and numerous figures and diagrams, and code fragments in the MATLAB{\textregistered} programming language helps the reader with limited experience of numerical methods reach an understanding of this subject. Offers a complete treatment of all of the major families of musical instruments, including certain audio effects. Numerical Sound Synthesis is suitable for audio and software engineers, and researchers in digital audio, sound synthesis and more general musical acoustics. Graduate students in electrical engineering, mechanical engineering or computer science, working on the more technical side of digital audio and sound synthesis, will also find this book of interest. {\textcopyright} 2009 John Wiley & Sons, Ltd.},
address = {Traducao. [s.l.] John & Sons},
author = {Bilbao, Stefan},
booktitle = {Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics},
doi = {10.1002/9780470749012},
isbn = {9780470510469},
pages = {1--441},
publisher = {Wiley},
title = {{Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics}},
year = {2009}
}
@article{95,
abstract = {The 2D digital waveguide mesh has proven to be effective and efficient in the modeling of musical membranes and plates, particularly in combination with recent simplifications in modeling stiffness, nonlinearities, and felt mallet excitations. The rectilinear 3D extension to the mesh had been suggested, and has been applied to the case of room acoustics. However, it requires the use of 6-port scattering junctions, which make a multiply-free implementation impossible in the isotropic case. The 4-port scattering junctions of the 2D mesh required only an internal divide by 2, which could be implemented as a right shift in binary arithmetic. However, the 6-port junction requires a divide by 3. The multiply-free cases occur for N-port junctions in which N is a power of two. We propose here a tetrahedral distribution of multiply-free 4-port scattering junctions filling space much like the molecular structure of the diamond crystal, where the placement of the scattering junctions corresponds to the placement of the carbon nuclei, and the bi-directional delay units correspond to the four tetrahedrally spaced single bonds between each pair of nuclei. We show that the tetrahedral mesh is mathematically equivalent to a finite difference scheme (FDS) which approximates the 3D lossless wave equation. We further compute the frequency- and direction-dependent plane wave propagation speed dispersion error},
author = {{Van Duyne}, S.A. and Smith, J.O.},
doi = {10.1109/aspaa.1995.482998},
journal = {Applications of Signal Processing to Audio and Acoustics},
pages = {234--237},
title = {{The tetrahedral digital waveguide mesh}},
volume = {1995},
year = {2002}
}
@article{fra,
author = {Fontana, Federico and Rocchesso, Davide and Apollonio, Enzo},
journal = {Proceedings of the COST G-6 Conference on Digital Audio Effects (DAFX-00)},
pages = {7--10},
title = {{Using the Waveguide Mesh in Modelling 3D Resonators}},
url = {http://ftp.funet.fi/index/Science/audio/dafx/2000/profs.sci.univr.it/%257Edafx/Final-Papers/pdf/Fontana_paper.pdf},
volume = {2000},
year = {2000}
}
@article{k,
abstract = {Convolutional neural networks have been established as an unbelievable class of models for picture confirmation issues. Enabled by these results, we give CNN's extensive trial evaluation a large degree of video-action syllabus using another dataset of 8M YouTube accounts. To get the Chronicles and its effects, we've used a YouTube video specification framework, which gives the names of the accounts they focus on. While the names are machine-generated, they are high-precision and are derived from a group of human-based icons, including metadata and question click signals. We have filtered the video names (Knowledge Graph Components) using both modern and manual curation strategies, including curiosity regarding whether the print is clearly indisputable. After that, we decode each video at one-layout per-second and use the deep CNN adjusted to ImageNet to remove the cover depicted immediately before the course of the action layer. Finally, we've stuffed the packaging features and made available both features and video level names for download. We train unique (ambiguous) game plan models on the dataset, survey them using significant evaluation estimates, and report them as baseline. Regardless of the size of the dataset, a portion of our models train the connection in less than a day on a singular machine using VGG. CNN our course release code for setting up model deals and generating predictions.},
author = {SravyaPranati, Bh and Suma, D. and ManjuLatha, Ch and Putheti, Sudhakar},
doi = {10.1007/978-981-15-7062-9_69},
isbn = {9789811570612},
issn = {21903026},
journal = {Smart Innovation, Systems and Technologies},
keywords = {Convolutional neural networks,Dataset,Labels,Video classification},
pages = {689--695},
title = {{Large-Scale Video Classification with Convolutional Neural Networks}},
volume = {196},
year = {2021}
}
@article{xac,
author = {Xu, W and Auli, M and Clark, S Ccg},
journal = {CL (},
title = {{Supertagging with a Recurrent Neural Network}},
volume = {2}
}
@unpublished{Pse2010,
author = {Pse, C L I and Ed, E Serv},
booktitle = {Source},
pages = {2--5},
title = {{the Open Source}},
url = {https://github.com/crabacus/the-open-source-drumkit%3E},
year = {2010}
}
@article{o,
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
archivePrefix = {arXiv},
arxivId = {1606.05328},
author = {{Van Den Oord}, A{\"{a}}ron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
eprint = {1606.05328},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {4797--4805},
title = {{Conditional image generation with PixelCNN decoders}},
volume = {2016},
year = {2016}
}
@article{k,
author = {Klambauer, G and Others},
journal = {Anais�},
title = {{Self-normalizing neural networksAdvances in Neural Information Processing Systems}},
volume = {2017}
}
@article{w,
author = {Wiki, DrumGizmo},
title = {{DrumGizmo Wiki}},
url = {https://www.drumgizmo.org/wiki/doku.php%3E},
volume = {2018}
}
@book{e,
abstract = {NSynth Super is an open source experimental instrument. It gives musicians the ability to explore completely new sounds generated by the NSynth machine learning algorithm.},
address = {Dispon�vel em},
author = {Google},
keywords = {Creation,Creativity},
publisher = {<},
title = {{Making music using new sounds generated with machine learning}},
url = {https://www.youtube.com/watch?v=iTXU9Z0NYoU},
year = {2018}
}
@book{b16,
abstract = {The great importance of music in Etruscan civilization is attested by several ancient Greek and Latin authors, who place a strong emphasis on the aerophones such as auloi, conches, horns, and trumpets of various kinds-namely the Latin cornu, lituus, and tuba. This assertion has been confirmed in recent times by various scholars, who also take into account the large number of musical instruments and the wide range of iconographic evidence that have been found at Etruscan sites, which span from the beginning of the seventh century to the first century BCE. While the only specimens that survive are, of course, those made of nonperishable materials like metal or clay, the iconographic evidence-such as the tomb paintings and other kinds of representations-clearly show that almost all of the musical instruments that were widespread in the Mediterranean at the time were also used in Etruria on many different occasions, including public and private ceremonies, rituals, and daily life. Tantalizing glimpses of the earlier presence of perishable instruments-such as wooden pipes and string instruments-are provided by the surviving parts made of ivory or bone, including a few pipes, joints between pipe and reed, and plectra. One notable feature in the Etruscan context seems to be the complete lack of membranophones-in particular the frame drum-which had still not appeared by the turn of the fifth century, and by which time all of the other musical instruments were already firmly established in the area.},
address = {Traducao. [s.l.]},
author = {Bovermann, T and Others},
booktitle = {Musical Instruments in the 21st Century},
doi = {10.1007/978-981-10-2951-6},
publisher = {Springer},
title = {{Musical Instruments in the 21st Century}},
year = {2017}
}
@book{ck16,
abstract = {This book, the first English-language translation of Acoustique des instruments de musique, Second Edition, presents the necessary foundations for understanding the complex physical phenomena involved in musical instruments. What is the function of the labium in a flute? Which features of an instrument allow us to make a clear audible distinction between a clarinet and a trumpet? With the help of numerous examples, these questions are addressed in detail. The authors focus in particular on the significant results obtained in the field during the last fifteen years. Their goal is to show that elementary physical models can be used with benefit for various applications in sound synthesis, instrument making, and sound recording. The book is primarily addressed to graduate students and researchers; however it could also be of interest for engineers, musicians, craftsmen, and music lovers who wish to learn about the basics of musical acoustics.},
address = {Traducao. [s.l.]},
author = {Chaigne, Antoine and Kergomard, Jean},
isbn = {978-1-4939-3679-3},
pages = {XXV, 844},
publisher = {Springer},
title = {{Acoustics of Musical Instruments}},
year = {2016}
}
@article{bff09,
abstract = {This paper reviews the field of artificial intelligence focusing on embodied artificial intelligence. It also considers models of artificial consciousness, agent-based artificial intelligence and the philosophical commentary on artificial intelligence. It concludes that there is almost no consensus nor formalism in the field and that the achievements of the field are meager. {\textcopyright}2009 IEEE.},
author = {Brunette, E. S. and Flemmer, R. C. and Flemmer, C. L.},
doi = {10.1109/ICARA.2000.4804025},
isbn = {9781424427130},
journal = {ICARA 2009 - Proceedings of the 4th International Conference on Autonomous Robots and Agents},
keywords = {Artificial intelligence,Consciouness,Embodied intelligence,Machine intelligence},
pages = {385--392},
title = {{A review of artificial intelligence}},
volume = {2009},
year = {2009}
}
@book{16,
abstract = {Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.},
address = {neon, theano, and torch for deep learning},
archivePrefix = {arXiv},
arxivId = {1511.06435},
author = {Bahrampour, Soheil and Ramakrishnan, Naveen and Schott, Lukas and Shah, Mohak},
booktitle = {ArXiv},
eprint = {1511.06435},
isbn = {9150617397},
issn = {19494912},
keywords = {7000:Marketing,8331:Internet services industry,9130:Experiment/theoretical treatment,9175:Western Europe,9190:United States,Business And Economics--Marketing And Purchasing,Comparative studies,Discount coupons,Europe,Lotteries,Older people,Social networks,United States--US,Viral marketing},
number = {1},
pages = {1--14},
publisher = {Comparative study of caffe},
title = {{Comparative Study of Caffe, Neon, Theano, and Torch for Deep Learning}},
url = {http://search.proquest.com/docview/1626785137?accountid=10755%5Cnhttp://sfx.bib-bvb.de/sfx_uben?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=unknown&sid=ProQ:ProQ:abiglobal&atitle=BEHAVIOUR+OF+ELDERLY+USERS+ON+FACEBOOK+TOWARD+VIRAL+M},
volume = {2},
year = {2015}
}
@article{s87,
abstract = {This tutorial paper describes the methods for constructing fast algorithms for the computation of the discrete Fourier transform (DFT) of a real-valued series. The application of these ideas to all the major fast Fourier transform (FFT) algorithms is discussed, and the various algorithms are compared. We present a new implementation of the real-valued split-radix FFT, an algorithm that uses fewer operations than any other real-valued power-of-2-length FFT. We also compare the performance of inherently real-valued transform algorithms such as the fast Hartley transform (FHT) and the fast cosine transform (FCT) to real-valued FFT algorithms for the computation of power spectra and cyclic convolutions. Comparisons of these techniques reveal that the alternative techniques always require more additions than a method based on a real-valued FFT algorithm and result in computer code of equal or greater length and complexity. Copyright {\textcopyright} 1987 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Sorensen, Henrik V. and Jones, Douglas L. and Heideman, Michael T. and Burrus, C. Sidney},
doi = {10.1109/TASSP.1987.1165220},
issn = {00963518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
number = {6},
pages = {849--863},
title = {{Real-Valued Fast Fourier Transform Algorithms}},
volume = {35},
year = {1987}
}
@article{sc,
author = {Sarroff, A M and Casey, M A},
journal = {ICMC},
title = {{Musical audio synthesis using autoencoding neural nets}},
volume = {2014}
}
@article{rn,
author = {Russell, S J and Norvig, P},
title = {{Artificial intelligence: a modern approach}},
volume = {2016}
}
@article{s,
abstract = {The University of Iowa Musical Instrument Samples (MIS) are created by Lawrence Fritts, Director of the Electronic Music Studios and Associate Professor of Composition at the University of Iowa. Since 1997, these recordings have been freely available on this website and may be downloaded and used for any projects, without restrictions. These are used by musicians, application developers, teachers, students, and researchers. These have been used in over 270 published research articles and books.},
author = {Fritts, Lawrence},
journal = {University of Iowa},
title = {{University of Iowa Electronic Music Studios}},
url = {http://theremin.music.uiowa.edu/MIS-Pitches-2012/MISTenorTrombone2012.html%0Ahttp://theremin.music.uiowa.edu/MIS.html},
volume = {2018},
year = {1997}
}
@article{l,
abstract = {The BAIR Blog},
author = {{Ivan Evtimov, Kevin Eykholt, Earlence Fernandes}, and Bo Li},
journal = {Bair},
title = {{The Berkeley Artificial Intelligence Research Blog}},
url = {http://bair.berkeley.edu/blog/},
volume = {2018},
year = {2017}
}
@article{dhs11,
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. The adaptation, in essence, allows us to find needles in haystacks in the form of very predictive yet rarely observed features. Our paradigm stems from recent advances in online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies the task of setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We corroborate our theoretical results with experiments on a text classification task, showing substantial improvements for classification with sparse datasets.},
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
isbn = {9780982252925},
journal = {COLT 2010 - The 23rd Conference on Learning Theory},
pages = {257--269},
title = {{Adaptive subgradient methods for online learning and stochastic optimization}},
volume = {12},
year = {2010}
}
@article{v00,
abstract = {Explores three meta-analyses investigating the relationship between music and mathematics on: (1) correlational studies (n=20); (2) experimental training studies (n=6) instructing students in music performance, then testing them on mathematics skills; and (3) experimental studies (n=15) investigating whether listening to background music during a mathematics test elevated test scores. (CMK)},
author = {Vaughn, Kathryn},
doi = {10.2307/3333641},
issn = {00218510},
journal = {Journal of Aesthetic Education},
number = {3/4},
pages = {149},
title = {{Music and Mathematics: Modest Support for the Oft-Claimed Relationship}},
volume = {34},
year = {2000}
}
@unpublished{z12,
abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
annote = {preprint},
archivePrefix = {arXiv},
arxivId = {1212.5701},
author = {Zeiler, Matthew D.},
eprint = {1212.5701},
title = {{ADADELTA: An Adaptive Learning Rate Method}},
url = {http://arxiv.org/abs/1212.5701},
year = {2012}
}
@article{oa,
abstract = {The subject of Fourier Analysis is at the center of many modern sciences. Physics and engineering depend so heavily on the subject, it is hard to imag- ine even mentioning them without thinking immediately about frequency- dependent phenomena: light, sound, orbits, and vibrations to name a few. Many other scientific fields also are highly dependent upon Fourier Analy- sis for understanding even the most basic of phenomena, such as population dynamics in biology. Fourier Analysis is also essential in understanding what are some of the most common occurrences in everyday life. The various peri- odic phenomena of the sun, the moon, the tides, and the seasons are yet to be completely understood. We know the sun and moon will rise with certainty, and their secondary seasonal effect on wind and tide-related phenomena such as el Nino are still somewhat of a mystery. These periodic effects are drastic and life altering, and are naturally studied with Fourier Analysis.},
author = {Olson, Tim},
doi = {10.1007/978-1-4939-7393-4},
journal = {Applied Fourier Analysis},
title = {{Applied Fourier Analysis}},
volume = {2017},
year = {2017}
}
@book{p17,
author = {Parvat, A and Others},
edition = {Inventive },
publisher = {Anais�IEEE},
title = {{A survey of deep-learning frameworks}},
year = {2017}
}
@article{dsf14,
author = {Dalgleish, Mat and Foster, Chris and Spencer, Steve},
journal = {CIM},
title = {{Blurring the Lines : an Integrated Compositional Model for Digital Music Instrument Design}},
volume = {14},
year = {2014}
}
@book{dv16,
abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
address = {mar},
archivePrefix = {arXiv},
arxivId = {1603.07285},
author = {Dumoulin, Vincent and Visin, Francesco},
eprint = {1603.07285},
publisher = {ArXiv e-prints},
title = {{A guide to convolution arithmetic for deep learning}},
url = {http://arxiv.org/abs/1603.07285},
year = {2016}
}
@article{ssh,
author = {Southall, C and Stables, R and Hockman, J},
journal = {SMIR},
title = {{Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks}},
volume = {2016}
}
@article{r06,
abstract = {Recent research in economic geography has emphasized tacit knowledge as the basis of industrial learning. In contrast, codification and the practices of industrial writing have received little attention for the roles they play in mobilizing knowledge across space. This paper offers insight into the geographies of codification through an examination of technology transfer in the electronic musical instrument industry between 1965 and 1995. The research draws on a variety of primary and secondary data that include interviews with inventors, biographical accounts and patent analysis. These sources offer perspective on the career trajectories of three U.S. inventors who transferred knowledge from various contexts in California's high-tech industry to the Japanese firm, Yamaha. Conceptually, the paper draws on the actor-network theory and Latour's idea of translation to highlight the detours inventors must take to register novelty. The analysis reveals the problematic nature of codified knowledge and its transfer; in this case codified knowledge was mobile internationally but not locally, at least until it reached Japan. The paper argues for the need to understand how texts such as patents are produced-the context of their authorship, the geographies of their circulation and their efficacy for shaping further innovative practice. {\textcopyright} 2006 Canadian Association of Geographers/L'Association canadienne des g{\'{e}}ographes.},
author = {Reiffenstein, Tim},
doi = {10.1111/j.1541-0064.2006.00143.x},
issn = {00083658},
journal = {Canadian Geographer},
number = {3},
pages = {298--318},
title = {{Codification, patents and the geography of knowledge transfer in the electronic musical instrument industry}},
volume = {50},
year = {2006}
}
@article{r,
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
author = {Lee, Wei‐Meng},
doi = {10.1002/9781119557500},
journal = {Python{\textregistered} Machine Learning},
title = {{Python{\textregistered} Machine Learning}},
volume = {2015},
year = {2019}
}
@article{pw,
author = {Pereyra, M C and Ward, L A},
journal = {Traducao. [s.l.] {A}merican Mathematical Soc},
title = {{Harmonic analysis:from Fourier to wavelets.}},
volume = {2012}
}
@inproceedings{nyc15,
abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call 'fooling images' (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
archivePrefix = {arXiv},
arxivId = {1412.1897},
author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2015.7298640},
eprint = {1412.1897},
isbn = {9781467369640},
issn = {10636919},
pages = {427--436},
title = {{Deep neural networks are easily fooled: High confidence predictions for unrecognizable images}},
volume = {07-12-June},
year = {2015}
}
@article{zf,
author = {Zwicker, E and Fastl, H},
journal = {Traducao. [s.l.] Springer Science & Business Media},
title = {{Psychoacoustics: Facts and models.}},
volume = {2013}
}
@article{c,
abstract = {This book is intended for students of computer science at the college level, or students of other subjects that cover Artificial Intelligence. It also is intended to be an interesting and relevant introduction to the subject for other students or individuals who simply have an interest in the subject.},
author = {Coppin, Ben},
isbn = {0763732303},
issn = {02650096},
journal = {Expert Systems},
pages = {768},
title = {{Artificial Intelligence Illuminated}},
volume = {2004},
year = {2004}
}
@book{v,
abstract = {Artificial intelligence computing offers lower cost and greater efficiency.},
address = {Dispon�vel em},
author = {Merlo, Robert J.},
booktitle = {Energy (Norwalk, Connecticut)},
edition = {The Asimov},
issn = {01499386},
number = {2},
pages = {33},
publisher = {<},
title = {{The neural network}},
url = {http://www.asimovinstitute.org/neural-network-zoo/%3E},
volume = {24},
year = {1999}
}
@article{ss,
author = {Stein, Elias M and Pierce, Lillian},
isbn = {9780691113845},
issn = {0002-9920},
journal = {Review},
number = {May},
pages = {641--647},
title = {{Princeton Lectures in Analysis}},
volume = {2003},
year = {2012}
}
@book{haks18,
abstract = {This report is part of the Center for a New American Security's series on Artificial Intelligence and International Security. The series examines the potential consequences of advances in artificial intelligence for the national security community. Nearly every aspect of national security could be transformed by artificial intelligence. AI has applications for defense, intelligence, homeland security, diplomacy, surveillance, cybersecurity, information, and economic tools of statecraft. The United States must not only anticipate these developments, but act decisively to prepare for uses by competitors and take advantage of the opportunities AI presents. ALSO},
author = {Horowitz, M C and Allen, Gregory C. and Kania, Elsa B. and Scharre, Paul},
number = {July},
title = {{Strategic Competition in an Era of Artificial Intelligence | Center for a New American Security}},
url = {https://www.cnas.org/publications/reports/strategic-competition-in-an-era-of-artificial-intelligence},
year = {2018}
}
@article{wh,
abstract = {Use of switching theory for system design is considered. An approach is taken in this paper which does not require an explicit use of the truth table. The design objective is the minimization of the average number of errors, rather than a minimization of the number of logical components used. The nature of the logical elements is quite unconventional. The system design procedure is adaptive, and is based upon an iterative search process. Performance feedback is used to achieve automatic system synthesis, i.e., the selection of the 'best' system from a restricted but useful class of possibilities. The designer 'trains' the system to give the correct responses by 'showing' it examples of inputs and respective desired outputs. The more examples 'seen', the better is the system performance.},
author = {Widrow, Bernard and Hoff, Marcian E.},
journal = {Wescon Conference Record},
pages = {709--717},
title = {{Adaptive switching circuits}},
volume = {1960},
year = {1989}
}
@book{r18,
abstract = {Advances in machine learning have the potential to radically reshape interactions between humans and computers. Deep learning makes it possible to discover powerful representations that are capable of capturing the latent structure of highdimensional data such as music. By creating interactive latent space "palettes" of musical sequences and timbres, we demonstrate interfaces for musical creation made possible by machine learning. We introduce an interface to the intuitive, low-dimensional control spaces for high-dimensional note sequences, allowing users to explore a compositional space of melodies or drum beats in a simple 2-D grid. Furthermore, users can define 1-D trajectories in the 2-D space for autonomous, continuous morphing during improvisation. Similarly for timbre, our interface to a learned latent space of audio provides an intuitive and smooth search space for morphing between the timbres of different instruments. We remove technical and computational barriers by embedding pre-trained networks into a browser-based GPU-accelerated framework, making the systems accessible to a wide range of users while maintaining potential for creative flexibility and personalization.},
author = {Roberts, Adam and Engel, Jesse and Oore, Sageev and Eck, Douglas},
booktitle = {CEUR Workshop Proceedings},
issn = {16130073},
keywords = {Deep learning,Latent space,Musical interface,Variational autoencoder},
title = {{Learning latent representations of music to generate interactive musical palettes}},
volume = {2068},
year = {2018}
}
@unpublished{,
title = {{No Title}},
url = {https://github.com/tesserato/tesserato.github.io%3E}
}
@unpublished{kb14,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
annote = {preprint},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1412.6980},
title = {{Adam: A method for stochastic optimization}},
year = {2015}
}
@unpublished{dmp18,
abstract = {Audio signals are sampled at high temporal resolutions, and learning to synthesize audio requires capturing structure across a range of timescales. Generative adversarial networks (GANs) have seen wide success at generating images that are both locally and globally coherent, but they have seen little application to audio generation. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. WaveGAN is capable of synthesizing one second slices of audio waveforms with global coherence, suitable for sound effect generation. Our experiments demonstrate that-without labels-WaveGAN learns to produce intelligible words when trained on a smallvocabulary speech dataset, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. We compare WaveGAN to a method which applies GANs designed for image generation on image-like audio feature representations, finding both approaches to be promising.},
annote = {preprint},
archivePrefix = {arXiv},
arxivId = {1802.04208},
author = {Donahue, Chris and McAuley, Julian and Puckette, Miller},
booktitle = {arXiv},
eprint = {1802.04208},
issn = {23318422},
title = {{Adversarial audio synthesis}},
year = {2018}
}
@book{rkk18,
abstract = {Along with the development of learning and vision, Alternating Direction Method of Multiplier (ADMM) has become a popular algorithm for separable optimization model with linear constraint. However, the ADMM and its numerical variants (e.g., inexact, proximal or linearized) are awkward to obtain state-of-The-Art performance when dealing with complex learning and vision tasks due to their weak task-Adaption ability. Recently, there has been an increasing interest in incorporating task-specific computational modules (e.g., designed filters or learned architectures) into ADMM iterations. Unfortunately, these task-related modules introduce uncontrolled and unstable iterative flows, they also break the structures of the original optimization model. Therefore, existing theoretical investigations are invalid for these resulted task-specific iterations. In this paper, we develop a simple and generic proximal ADMM framework to incorporate flexible task-specific module for learning and vision problems. We rigorously prove the convergence both in objective function values and the constraint violation and provide the worst-case convergence rate measured by the iteration complexity. Our investigations not only develop new perspectives for analyzing task-Adaptive ADMM but also supply meaningful guidelines on designing practical optimization methods for real-world applications. Numerical experiments are conducted to verify the theoretical results and demonstrate the efficiency of our algorithmic framework.},
archivePrefix = {arXiv},
arxivId = {1909.10819},
author = {Liu, Risheng and Mu, Pan and Zhang, Jin},
booktitle = {arXiv},
eprint = {1909.10819},
issn = {23318422},
keywords = {Computer vision.,Global convergence,Proximal ADMM,Task-Adapted optimization},
title = {{On the convergence of ADMM with task adaption and beyond}},
year = {2019}
}
@article{pg,
author = {Patterson, Josh and Gibson, Adam},
title = {{Deep Learning: A Practitioner's Approach. " O'Reilly Media, Inc."}},
volume = {2017}
}
@unpublished{s16,
abstract = {Several recent works have used deep convolutional networks to generate realistic imagery. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach generates more realistic, diverse, and controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.},
annote = {preprint},
archivePrefix = {arXiv},
arxivId = {1612.00835},
author = {Sangkloy, Patsorn and Lu, Jingwan and Fang, Chen and Yu, Fisher and Hays, James},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.723},
eprint = {1612.00835},
isbn = {9781538604571},
pages = {6836--6845},
title = {{Scribbler: Controlling deep image synthesis with sketch and color}},
volume = {2017-Janua},
year = {2017}
}
@book{p18,
author = {Pfalz, A},
title = {{Generating Audio Using Recurrent Neural Networks}},
year = {2018}
}
@article{m,
abstract = {Acoustical physical modelling synthesis uses mathematical algorithms to describe a real-world sound production process or propagational environ-ment. Digital waveguides can be used to form a 1D model of the vocal tract, simplistically represented as a series of cylindrical tubes of varying radius along a straight axis. This 1D signal propagating element can also be extended to create a digital waveguide mesh (DWM), giving acoustical synthesis of a higher dimensional structure, such as a 2D surface or 3D space. The work contained in this thesis is an investigation into the effects of increased dimensionality in the 1D waveguide vocal tract paradigm. A 2D DWM is configured as a model of the tract, such that shape characteristics are set within the width of the mesh. Wave propagation and reflection is simulated along the tract from the glottis to the lips, as well as across it, between the two inner walls, thereby removing plane-wave limitations inherent in the 1D model. The 2D tract is found to give accurate formant synthesis, producing vowels that give a good match to real-world targets. However, problems associated with high sampling frequency limitations and discontinuous dynamic operation are identified. Movements readily occurring in speech, such as diphthongs, are not easily accommodated by the static mesh structure. A novel alternative approach is also presented which maintains a rect-angular mesh, but maps the changing tract shapes onto the waveguide impedances. This allows for stable dynamic manipulation of the modelled space. Furthermore, sampling frequency limitations are removed, such that real-time operation and interaction with the 2D tract model is achieved. i Contents Abstract i Acknowledgments xi Declaration xii},
author = {Duyne, Scott a Van and {Smith Julius O}, Iii},
journal = {Area},
number = {April},
pages = {40--47},
title = {{Physical modelling of the vocal tract with the 2D digital waveguide mesh}},
url = {http://www-users.york.ac.uk/$\sim$dtm3/Download/JackThesis.pdf},
volume = {2006},
year = {2006}
}
@article{mhn,
author = {Maas, A L and Hannun, A Y and Ng, A Y},
journal = {ICML. Anais�},
title = {{Rectifier nonlinearities improve neural network acoustic models}},
volume = {2013}
}
@article{Poczos1993,
abstract = {The history of artificial neural networks is like a roller-coaster ride. There were times when it was popular(up), and there were times when it wasn't. We are now in one of its very big time. • Progression (1943-1960)-First Mathematical model of neurons * Pitts & McCulloch (1943) [MP43]-Beginning of artificial neural networks-Perceptron, Rosenblatt (1958) [R58] * A single neuron for classification * Perceptron learning rule * Perceptron convergence theorem [N62] • Degression (1960-1980)-Perceptron can't even learn the XOR function [MP69]-We don't know how to train MLP-1963 Backpropagation (Bryson et al.) * But not much attention • Progression (1980-)-1986 Backpropagation reinvented: * Learning representations by back-propagation errors. Rumilhart et al. Nature [RHW88]-Successful applications in * Character recognition, autonomous cars, ..., etc.-But there were still some open questions in * Overfitting? Network structure? Neuron number? Layer number? Bad local minimum points? When to stop training?-Hopfield nets (1982) [H82], Boltzmann machines [AHS85], ..., etc. • Degression (1993-) 1},
author = {Poczos, Lecturer Barnabas},
number = {1982},
pages = {1--10},
title = {{Perceptron History of Artificial Neural Networks The Neuron}},
url = {http://www.cs.cmu.edu/$\sim$10701/slides/Perceptron_Reading_Material.pdf},
year = {1993}
}
@article{,
title = {{UNCLASSIFIED LIMITATION CHANGES TO : FROM :}},
year = {1995}
}
@book{Papert,
author = {Papert, Seymour A},
isbn = {9780262130431},
title = {{Perceptrons}}
}
@article{Diego1985,
author = {Diego, S A N},
number = {V},
title = {862 18 120,},
year = {1985}
}
@article{,
title = {{No Title}}
}
@article{Harrison2015,
abstract = {This paper presents a physical modelling sound synthesis environment for the production of valved brass instrument sounds. The governing equations of the system are solved using finite-difference time-domain (FDTD) methods and the environment is implemented in the C programming language. Users of the environment can create their own custom instruments and are able to control player parameters such as lip frequency, mouth pressure and valve openings through the use of instrument and score files. The algorithm for sound synthesis is presented in detail along with a discussion of optimisation methods used to reduce run time. Binaries for the environment are available for download online for multiple platforms.},
author = {Harrison, Reginald L. and Bilbao, Stefan and Perry, James},
journal = {DAFx 2015 - Proceedings of the 18th International Conference on Digital Audio Effects},
title = {{An algorithm for a valved brass instrument synthesis environment using finite-difference time-domain methods with performance optimisation}},
year = {2015}
}
@article{Sound1990,
abstract = {Spectral modeling synthesis is an analysis-based technique capable of capturing the perceptual characteristics of a wide variety of sounds. The representation that results from the analysis is intuitive and is easily mapped to useful musical parameters. The analysis part is central to the system. It is a complex algorithm that requires the manual setting of a few control parameters. Further work may automate the analysis process, particularly if there is a specialization for a group of sounds. Some aspects of the analysis are also open to further research, in particular the peak-continuation algorithm. The synthesis from the deterministic plus stochastic representation is simple and can be performed in real time with current technology. A real-time implementation of this system would allow the use of this technnique in performance.},
author = {Serra, Xavier and Smith, Julius O.},
doi = {10.2307/3680788},
issn = {01489267},
journal = {Computer Music Journal},
number = {4},
pages = {12--24},
title = {{Spectral modeling synthesis. A sound analysis/synthesis system based on a deterministic plus stochastic decomposition}},
volume = {14},
year = {1990}
}
@article{Serra2000,
abstract = {<!-- .Normal {font-size 10.0pt; font-family "Times New Roman";} --> <p> <span>The basic Spectral Modeling Synthesis (SMS) technique models sounds as the sum of sinusoids plus a residual. Though this analysis/synthesis system has proved to be successful in transforming sounds, more powerful and intuitive musical transformations can be achieved by moving into the SMS high-level attribute plane. In this paper we describe how to extract high level sound attributes from the basic representation, modify them, and add them back before the synthesis stage. In this process new problems come up for which we propose some initial solutions.</span> </p>},
author = {Serra, Xavier and Bonada, Jordi},
journal = {International Conference on Digital Audio Effects},
number = {February 2013},
title = {{Sound Transformations Based on the SMS High Level Attributes}},
url = {http://mtg.upf.edu/files/publications/dafx98-1.pdf},
year = {1998}
}
@article{,
title = {{Percussion Instrument Modelling In 3D : Sound Synthesis Through Time Domain Numerical Simulation University of Edinburgh}}
}
@article{Hahn2017,
abstract = {This thesis addresses imitative digital sound synthesis of acoustically viable instruments with support of expressive, high-level control parameters. A general model is provided for quasi-harmonic instruments that reacts coherently with its acoustical equivalent when control parameters are varied. The approach builds upon recording-based methods and uses signal transformation techniques to manipulate instrument sound signals in a manner that resembles the behavior of their acoustical equivalents using the fundamental control parameters intensity and pitch. The method preserves the inherent quality of discretized recordings of a sound of acoustic instruments and introduces a transformation method that retains the coherency with its timbral variations when control parameters are modified. It is thus meant to introduce parametric control for sampling sound synthesis. The objective of this thesis is to introduce a new general model representing the timbre variations of quasi-harmonic music instruments regarding a parameter space determined by the control parameters pitch as well as global and instantaneous intensity. The model independently represents the deterministic and non-deterministic components of an instrument's signal and an extended source-filter model will be introduced for the former to represent the excitation and resonance characteristics of a music instrument by individual parametric filter functions. The latter component will be represented using a classic source-filter approach using filters with similar parameterization. All filter functions are represented using tensor-product B-splines to support for multivariate control variables. An algorithm will be presented for the estimation of the model's parameters that allows for the joint estimation of the filter functions of either component in a multivariate surface-fitting approach using a data-driven optimization strategy. This procedure also includes smoothness constraints and solutions for missing or sparse data and requires suitable data sets of single note recordings of a particular musical instrument. Another original contribution of the present thesis is an algorithm for the calibration of a note's intensity by means of an analysis of crescendo and decrescendo signals using the presented instrument model. The method enables the adjustment of the note intensity of an instrument sound coherent with the relative differences between varied values of its note intensity. A subjective evaluation procedure is presented to assess the quality of the transformations obtained using a calibrated instrument model and independently varied control parameters pitch and note intensity. Several extends of sound signal manipulations will be presented therein. For the support of inharmonic sounds as present in signals produced by the piano, a new algorithm for the joint estimation of a signal's fundamental frequency and inharmonicity coefficient is presented to extend the range of possible instruments to be manageable by the system. The synthesis system will be evaluated in various ways for sound signals of a trumpet, a clarinet, a violin and a piano.},
author = {Hahn, Henrik},
title = {{Expressive Sampling Synthesis - Learning Extended Source-Filter Models from Instrument Sound Databases for Expressive Sample Manipulations}},
url = {https://hal.archives-ouvertes.fr/tel-01263656},
year = {2015}
}
@article{Serafin1996,
author = {Tasaki, Tsuyoshi and Ogata, Tetsuya and Okuno, Hiroshi G and Iteraction, The and People, Multiple},
doi = {10.1162/COMJ},
number = {12},
pages = {1--8},
title = {{( B ) 有査読学術雑誌論文}},
volume = {52},
year = {2013}
}
@article{Bonada2016,
abstract = {Sample and statistically based singing synthesizers typically require a large amount of data for automatically generating expressive synthetic performances. In this paper we present a singing synthesizer that using two rather small databases is able to generate expressive synthesis from an input consisting of notes and lyrics. The system is based on unit selection and uses the Wide-Band Harmonic Sinusoidal Model for transforming samples. The first database focuses on expression and consists of less than 2 minutes of free expressive singing using solely vowels. The second one is the timbre database which for the English case consists of roughly 35 minutes of monotonic singing of a set of sentences, one syllable per beat. The synthesis is divided in two steps. First, an expressive vowel singing performance of the target song is generated using the expression database. Next, this performance is used as input control of the synthesis using the timbre database and the target lyrics. A selection of synthetic performances have been submitted to the Interspeech Singing Synthesis Challenge 2016, in which they are compared to other competing systems.},
author = {Bonada, Jordi and Umbert, Mart{\'{i}} and Blaauw, Merlijn},
doi = {10.21437/Interspeech.2016-872},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Expression control,Singing voice synthesis,Unitselection},
pages = {1230--1234},
title = {{Expressive singing synthesis based on unit selection for the singing synthesis challenge 2016}},
volume = {08-12-Sept},
year = {2016}
}
@article{Selfridge,
abstract = {A real-time physical sound synthesis model of an Aeolian harp is presented. The model uses semiempirical fluid dynamics equations to inform its operation, providing suitable parameters for users to interact. A basic wind model is included as well as an interface allowing user adjustable parameters. Sounds generated by the model were subject to objective measurements against real-world recordings, which showed that many of the physical properties of the harp were replicated in our model, but a possible link between harmonics and vibration amplitude was not. A perceptual test was performed, where participants were asked to rate sounds in terms of how plausible they were in comparison with spectral modelling synthesis and recorded Aeolian Harp samples. Evaluation showed that our model performed as well as an alternative non-physical synthesis method, but was not as authentic as actual recorded samples.},
author = {Selfridge, Rod and Moffat, David J. and Reiss, Joshua D. and Avital, Eldad J.},
journal = {24th International Congress on Sound and Vibration, ICSV 2017},
keywords = {Aeolian harp,Physical model,Real-time,Sound synthesis},
pages = {1--8},
title = {{Real-time physical model of an Aeolian harp}},
year = {2017}
}
@article{Blaauw2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.03809v3},
author = {Blaauw, Merlijn and Bonada, Jordi and Group, Music Technology and Fabra, Universitat Pompeu},
eprint = {arXiv:1704.03809v3},
pages = {1--9},
title = {{A n p s s}},
year = {2010}
}
@article{Zappi2017,
abstract = {Physical modelling is a sophisticated synthesis technique, often used in the design of Digital Musical Instruments (DMIs). Some of the most precise physical simulations of sound propagation are based on Finite-Difference Time-Domain (FDTD) methods, which are stable, highly parameterizable but characterized by an extremely heavy computational load. This drawback hinders the spread of FDTD from the domain of off-line simulations to the one of DMIs. With this paper, we present a novel approach to real-time physical modelling synthesis, which implements a 2D FDTD solver as a shader program running on the GPU directly within the graphics pipeline. The result is a system capable of running fully interactive, massively sized simulation domains, suitable for novel DMI design. With the help of diagrams and code snippets, we provide the implementation details of a first interactive application, a drum head simulator whose source code is available online. Finally, we evaluate the proposed system, showing how this new approach can work as a valuable alternative to classic GPGPU modelling.},
author = {Zappi, Victor and Allen, Andrew and Fels, Sidney},
journal = {NIME 2017 Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {145--150},
title = {{Shader-based Physical Modelling for the Design of Massive Digital Musical Instruments}},
url = {http://www.nime.org/proceedings/2017/nime2017_paper0028.pdf},
year = {2017}
}
@article{Unterthiner2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1706.02515v5},
author = {Unterthiner, Thomas and Sep, L G and Hochreiter, Sepp},
eprint = {arXiv:1706.02515v5},
title = {{Self-Normalizing Neural Networks}},
year = {2017}
}
@article{Lokki2018,
author = {Lokki, Tapio and M{\"{u}}ller, Meinard and Serafin, Stefania and V{\"{a}}lim{\"{a}}ki, Vesa},
doi = {10.3390/app8040518},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
number = {4},
pages = {1--5},
title = {{Special issue on "Sound and music computing"}},
volume = {8},
year = {2018}
}
@article{Morse,
author = {Morse, Bryan},
journal = {Image Processing},
title = {{Magnitude and Phase The Fourier Transform : Examples , Properties , Common Pairs CS 450 : Introduction to Digital Signal and Image Processing Example : Fourier Transform of a Cosine Example : Fourier Transform of a Cosine Odd and Even Functions Sinusoids }}
}
@article{Karplus1983,
abstract = {There are many techniques currently used for digital music synthesis, including frequency modulation (FM) synthesis, waveshaping, additive synthesis, and subtractive synthesis. To achieve rich, natural sounds, all of them require fast arithmetic capability, such as is found on expensive computers or digital synthesizers. For musicians and experimenters without access to these machines, musically interesting digital synthesis has been almost impossible. The techniques described in this paper can be implemented quite cheaply on almost any computer. Real-time synthesis implementations have been done for Intel 8080A (by Alex Strong), Texas Instruments TMS9900 (by Kevin Karplus), and SC/MP (by Mike Plass) microprocessors. David Jaffe and Julius Smith have programmed the Systems Concept Digital Synthesizer at the Center for Computer Research in Music and Acoustics (CCRMA) to perform several variants of the algorithms (Jaffe and Smith 1983).},
author = {Karplus, Kevin and Strong, Alex},
journal = {Computer Music Journal},
number = {2},
pages = {43--55},
title = {{Digital Synthesis of and Plucked-String Timbres}},
volume = {7},
year = {1983}
}
@article{Chaigne1994,
abstract = {The first attempt to generate musical sounds by solving the equations of vibrating strings by means of finite difference methods (FDM) was made by Hiller and Ruiz [J. Audio Eng. Soc. 19, 462–472 (1971)]. It is shown here how this numerical approach and the underlying physical model can be improved in order to simulate the motion of the piano string with a high degree of realism. Starting from the fundamental equations of a damped, stiff string interacting with a nonlinear hammer, a numerical finite difference scheme is derived, from which the time histories of string displacement and velocity for each point of the string are computed in the time domain. The interacting force between hammer and string, as well as the force acting on the bridge, are given by the same scheme. The performance of the model is illustrated by a few examples of simulated string waveforms. A brief discussion of the aspects of numerical stability and dispersion with reference to the proper choice of sampling parameters is also included. {\textcopyright} 1994, Acoustical Society of America. All rights reserved.},
author = {Chaigne, Antoine and Askenfelt, Anders},
doi = {10.1121/1.408459},
issn = {NA},
journal = {Journal of the Acoustical Society of America},
number = {2},
pages = {1112--1118},
title = {{Numerical simulations of piano strings. I. A physical model for a struck string using finite difference methods}},
volume = {95},
year = {1994}
}
@article{Corporation1959,
author = {Corporation, Westinghouse Electric and Pittsburgh, East and Arbor, Ann},
number = {4},
pages = {978--986},
title = {{L : L : { L : L : { L : L :}}}},
volume = {31},
year = {1959}
}
@misc{,
title = {{1983 Extensions of the Karplus-Strong Plucked String Algorithm.pdf}}
}
@article{Jarvelainen2001,
abstract = {Listening tests were conducted to find the audibility of inharmonicity in musical sounds produced by stringed instruments, such as the piano or the guitar. The audibility threshold of inharmonicity was measured at five fundamental frequencies. Results show that the detection of inharmonicity is strongly dependent on the fundamental frequency f0. A simple model is presented for estimating the threshold as a function of f0. The need to implement inharmonicity in digital sound synthesis is discussed. {\textcopyright}2001 Acoustical Society of America.},
author = {J{\"{a}}rvel{\"{a}}inen, Hanna and V{\"{a}}lim{\"{a}}ki, Vesa and Karjalainen, Matti},
doi = {10.1121/1.1374756},
issn = {15297853},
journal = {Acoustic Research Letters Online},
number = {April},
pages = {79--84},
title = {{Audibility of the timbral effects of inharmonicity in stringed instrument tones}},
volume = {2},
year = {2001}
}
@article{Masri,
author = {Masri, P},
number = {0},
title = {{Using Digital Waveguides}},
volume = {44}
}
@article{Molteno2004,
abstract = {We describe a detailed experimental investigation into the dynamics of a sinusoidally forced string. We find qualitative agreement with the predictions of the averaged equations of motion for a string in the high damping regime. At low damping we observe more complex phenomena not present in the averaged equations. (C) 2004 American Association of Physics Teachers.},
author = {Molteno, Timothy C. and Tufillaro, Nicholas B.},
doi = {10.1119/1.1764557},
issn = {0002-9505},
journal = {American Journal of Physics},
number = {9},
pages = {1157--1169},
title = {{An experimental investigation into the dynamics of a string}},
volume = {72},
year = {2004}
}
@article{Oø,
author = {{\`{O}}{\o}, {\^{O}} {\"{O}} and {\^{U}}{\'{o}}{\"{o}}, {\"{O}} {\O} Ð{\textordmasculine} {\"{O}} {\~{N}} and {\O}{\"{o}}, {\`{O}} {\O} {\`{O}} {\'{O}} {\`{O}} {\^{U}} {\'{O}} {\"{O}} and {\`{O}}{\o}, {\O} {\`{O}} {\O}{\"{o}}{\`{u}}{\~{n}} and {\~{N}}{\'{o}}, Ð {\O} {\O}{\'{y}}{\textordmasculine} {\`{I}} and {\'{O}}{\"{o}}, Ð {\"{O}} {\`{O}}{\o}{\"{o}}{\'{o}} {\`{U}} {\`{O}} {\O} and {\O}, {\"{O}} {\'{O}} {\~{N}} {\O} {\'{O}} {\`{U}} {\O} {\'{O}} {\`{O}} {\'{U}} Ð {\'{O}} and {\"{E}}{\o}{\"{o}}, {\`{O}} {\`{O}} and {\'{O}}{\`{o}}, {\'{A}}{\`{o}}{\o}{\"{o}}{\'{o}} {\`{U}} {\O} and {\'{A}}{\`{o}}, Ð {\`{O}} {\O} and {\'{O}}{\`{o}}, {\O} Ð {\'{O}}{\"{o}}{\~{n}}{\`{u}}ð {\O} and {\O}{\'{o}}{\"{o}}, {\O} {\'{O}}{\`{o}}ð{\'{y}} {\"{O}} and {\`{O}}{\`{u}}, {\`{I}} {\^{O}} {\^{O}} {\"{O}} {\'{U}} {\`{O}} {\O} {\'{O}} {\'{U}} {\O} {\'{O}} {\`{O}} {\`{O}} {\`{O}}{\o}{\"{o}}{\'{o}} {\`{U}}},
title = {{{\`{I}}{\'{o}}{\^{u}} {\"{o}} × {\aa} {\o} {\"{o}} ð {\aa}{\'{o}} ðð {\`{o}} {\`{o}} {\`{e}} {\'{y}}× ð {\aa}{\'{o}} ð× {\'{i}}× {\`{o}} {\"{i}} {\'{u}} {\`{u}} ×}}
}
@article{Garder2005,
abstract = {This report contains an overview of a typical modern rock drum set and the acoustics describing them. Explanations of the modeling methods Digital Waveguides and Digital Waveguide Networks are given and then applied to simulating a tom tom drum. The results are compared to recordings of real tom tom drums made in an anechoic environment. Although clearly distinguishable from real drum sounds, basic acoustic properties are accurately modeled and the model can be used as a basis for more detailed physical modeling.},
author = {G{\"{a}}rder, Anders},
title = {{Physical modeling of percussion instruments}},
year = {2005}
}
@article{Arts2008,
author = {Arts, Sonic},
number = {September},
title = {{Physical modelling of the piano : An investigation into the e ff ect of string sti ff ness on the hammer-string interaction}},
year = {2008}
}
@article{Huang2008,
abstract = {Data analysis has been one of the core activities in scientific research, but limited by the availability of analysis methods in the past, data analysis was often relegated to data processing. To accommodate the variety of data generated by nonlinear and nonstationary processes in nature, the analysis method would have to be adaptive. Hilbert-Huang transform, consisting of empirical mode decomposition and Hilbert spectral analysis, is a newly developed adaptive data analysis method, which has been used extensively in geophysical research. In this review, we will briefly introduce the method, list some recent developments, demonstrate the usefulness of the method, summarize some applications in various geophysical research areas, and finally, discuss the outstanding open problems. We hope this review will serve as an introduction of the method for those new to the concepts, as well as a summary of the present frontiers of its applications for experienced research scientists.},
author = {Huang, Norden E and Wu, Zhaohua},
doi = {10.1029/2007RG000228.1.INTRODUCTION},
isbn = {1944-9208},
issn = {87551209},
journal = {Reviews of Geophysics},
keywords = {Hil,Huang transform,doi:10.102,empirical mode decomposition,http://dx.doi.org/10.1029/2007RG000228},
number = {2007},
pages = {1--23},
title = {{a Review on Hilbert-Huang Transform : Method and Its Applications}},
url = {http://rcada.ncu.edu.tw/reference010.pdf},
volume = {46},
year = {2008}
}
@article{Duda2011,
abstract = {In this paper, we analyze and compare the properties of different well-known and also new nonparametric discrete Fourier transform (DFT)-based methods for resonant frequency and logarithmic decrement estimation in application to mechanical spectroscopy. We derive a new DFT interpolation algorithm for a signal analyzed with Rife-Vincent class-I windows and also propose new formulas that extend Bertocco and Yoshida methods. We study errors of the resonant frequency and logarithmic decrement estimation in realistic conditions that include measurement noise and a zero-point drift. We also investigate the systematic errors of the estimation methods of interest. A nonlinear least squares time-domain parametric signal fitting is used to determine the boundaries of statistical efficiency in all tests. {\textcopyright} 2011 IEEE.},
author = {Duda, Krzysztof and Magalas, Leszek B. and Majewski, Mariusz and Zieli{\'{n}}ski, Tomasz P.},
doi = {10.1109/TIM.2011.2113124},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Damping estimation,discrete Fourier transform (DFT),frequency estimation,interpolated DFT,logarithmic decrement,mechanical spectroscopy,signal processing},
number = {11},
pages = {3608--3618},
title = {{DFT-based estimation of damped oscillation parameters in low-frequency mechanical spectroscopy}},
volume = {60},
year = {2011}
}
@article{Bensa2006,
author = {Bensa, Julien and Bilbao, Stefan and Kronland-martinet, Richard and Smith, Julius and Bensa, Julien and Bilbao, Stefan and Kronland-martinet, Richard and Smith, Julius and Computa-, Thierry Voinier and Bensa, Julien and Bilbao, Stefan and Kronland-martinet, Richard and Iii, Julius O Smith and Voinier, Thierry},
pages = {0--10},
title = {{Computational modeling of stiff piano strings using digital waveguides and finite difference To cite this version : HAL Id : hal-00088061 Computational Modeling of Stiff Piano Strings Using Digital Waveguides and Finite Differences}},
year = {2006}
}
@article{Jos2009,
author = {Rossing, Thomas D.},
doi = {10.1119/1.16713},
issn = {0002-9505},
journal = {American Journal of Physics},
number = {1},
pages = {94--95},
title = {{                            Acoustics of the Piano                          }},
volume = {59},
year = {1991}
}
@article{David2012,
author = {Speed, MDA},
title = {{Voice synthesis using the three-dimensional digital waveguide mesh}},
url = {http://core.kmi.open.ac.uk/download/pdf/9554518.pdf},
year = {2012}
}
@article{Society2012,
abstract = {The snare drum is a complex system, relying on the interaction of multiple components: the drumheads, or membranes, a set of snares, the surrounding acoustic field and an internal cavity. Because these components are multidimensional, and due to a strong distributed non-linearity (the snare interaction), many techniques used frequently in physical modeling synthesis applications, such as digital waveguides and modal methods are difficult to apply. In this article, finite difference time domain techniques are applied to a full 3D system, and various features of interest, such as the coupling between membranes, and the interaction between the membranes and the snares, are examined in detail. Also discussed are various numerical features, such as spurious splitting of degenerate modes and bandwidth limitation, and estimates of computational complexity are provided. Sound examples are presented.},
author = {Bilbao, Stefan},
doi = {10.1121/1.3651240},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {914--925},
title = {{Time domain simulation and sound synthesis for the snare drum}},
volume = {131},
year = {2012}
}
@article{Ptb2015,
abstract = {For the analysis of rotational damping measurements in the time domain, two different identification procedures are compared. The first procedure investigated incorporates a Hilbert transform of the data, which enables an analysis by a linear regression calculation. The second approach is a direct nonlinear regression calculation of a damped sine function. The two approaches are compared using both simulated data and measurement data. The results of the comparison are presented.},
author = {Klaus, Leonard},
journal = {XXI IMEKO World Congress "Measurement in Research and Industry"},
keywords = {Damping coefficient,Decay rate,Rotational damping,Torsional damping},
number = {4},
title = {{Comparison of hilbert transform and sine fit approaches for the determination of damping parameters}},
volume = {1},
year = {2015}
}
@article{Kartofelev,
abstract = {This paper considers dynamic string motion in which the displacement is unilaterally constrained by the termination condition with an arbitrarily chosen geometry. A digital waveguide model is proposed for simulating the nonlin- earity inducing interactions between the vibrating string and the contact condition at the point of string termina- tion. The current work analyzes the resulting string mo- tion influenced by the contact conditions with mostly flat but slightly curved geometries. The effect of a minute im- perfection of the termination condition on the string vibra- tion is investigated. It is shown that the lossless string vi- brates in two distinct vibration regimes. In the beginning the string starts to interact in a nonlinear fashion with the bridge, and the resulting string motion is nonperiodic. The duration of that vibration regime depends on the geome- try of the bridge. After some time of nonperiodic vibra- tion, the string vibration settles in a periodic regime. Pre- sented results are applicable for example in the physics- based sound synthesis of stringed musical instruments, such as the shamisen, biwa, sitar, tambura, veena or even the bray harp and the grand piano.},
author = {Kartofelev, Dmitri and Stulov, Anatoli and Lehtonen, Heidi-Maria and V{\"{a}}lim{\"{a}}ki, Vesa},
journal = {Proc. Stockholm Musical Acoust. Conf},
title = {{Modeling a vibrating string terminated against a bridge with arbitrary geometry}},
url = {http://cs.ioc.ee/$\sim$stulov/smac13.pdf},
year = {2013}
}
@article{,
isbn = {9781467369978},
pages = {594--598},
title = {{MODELLING THE DECAY OF PIANO SOUNDS Tian Cheng , Simon Dixon , Matthias Mauch Centre for Digital Music , Queen Mary University of London , London , United Kingdom}},
volume = {1},
year = {2015}
}
@article{Serra2014,
author = {Serra, Xavier},
journal = {Proceedings of DAFX London},
number = {February},
title = {{Spectral modeling synthesis: Past and present}},
url = {http://138.37.35.209/dafx03/pdfs/XSerra-Presentation.pdf},
year = {1993}
}
@article{Berdahl,
author = {Berdahl, Edgar J and Iii, Julius O Smith},
journal = {Electrical Engineering},
pages = {1--14},
title = {{Plucked String Digital Waveguide Model}}
}
@article{Deserio,
abstract = {How duplicate genes provide genetic robustness remains an unresolved question. We have examined the duplicated histone deacetylases Sir2p and Hst1p in Saccharomyces cerevisiae and find that these paralogs with non-overlapping functions can provide genetic robustness against null mutations through a substitution mechanism. Hst1p is an NAD(+)-dependent histone deacetylase that acts with Sum1p to repress a subset of midsporulation genes. However, hst1Delta mutants show much weaker derepression of target loci than sum1Delta mutants. We show that this modest derepression of target loci in hst1Delta strains occurs in part because Sir2p substitutes for Hst1p. Sir2p contributes to repression of the midsporulation genes only in the absence of Hst1p and is recruited to target promoters by a physical interaction with the Sum1 complex. Furthermore, when Sir2p associates with the Sum1 complex, the complex continues to repress in a promoter-specific manner and does not spread. Our results imply that after the duplication, SIR2 and HST1 subfunctionalized. The single SIR2/HST1 gene from Kluyveromyces lactis, a closely related species that diverged prior to the duplication, can suppress an hst1Delta mutation in S. cerevisiae as well as interact with Sir4p in S. cerevisiae. In addition, the existence of two distinct protein interaction domains for the Sir and Sum1 complexes was revealed through the analysis of a chimeric Sir2-Hst1 molecule. Therefore, the ability of Sir2p to substitute for Hst1p probably results from a retained but reduced affinity for the Sum1 complex that is a consequence of subfunctionalization via the duplication, degeneration, and complementation mechanism. These results suggest that the evolutionary path of duplicate gene preservation may be an important indicator for the ability of duplicated genes to contribute to genetic robustness.},
author = {DeSerio, Robert},
issn = {1553-7404},
number = {6},
title = {{Addendum: The Fourier transform of decaying oscillations (Ilidio Notes)}},
year = {2013}
}
@article{Ði,
author = {Ð{\"{i}}, {\O} {\'{U}} {\`{U}}},
title = {{{\AA}{\`{u}}× ð {\'{a}}{\`{o}}×{\o}{\"{o}}{\`{u}}{\~{n}} {\`{o}}{\o} {\aa}{\'{o}} ðð {\`{o}} {\'{i}}× {\`{o}} {\o} ð{\"{i}} {\'{u}} {\`{u}} ×}}
}
@article{Bank2010,
abstract = {This paper presents a real-time piano synthesizer where both the transverse and longitudinal motion of the string is modeled by modal synthesis, resulting in a coherent and highly parallel model structure. The paper applies recent developments in piano modeling and focuses on the issues related to practical implementation (e.g., numerical stability, aliasing, and efficiency). A strong emphasis is given to modeling nonlinear string vibrations, and a new variation of earlier synthesis techniques is proposed which is particularly well suited for modal synthesis. For soundboard modeling, the possibilities of using fast Fourier transform-based fast convolution and parallel second-order filters are discussed. Additionally, the paper describes the details of the software implementation and discusses the computational complexity of each model block. The piano model runs on current computer hardware with full polyphony in real time. {\textcopyright} 2010 IEEE.},
author = {Bank, Bal{\'{a}}zs and Zambon, Stefano and Fontana, Federico},
doi = {10.1109/TASL.2010.2040524},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Modal synthesis,Physics-based sound synthesis,Piano},
number = {4},
pages = {809--821},
title = {{A modal-based real-time piano synthesizer}},
volume = {18},
year = {2010}
}
@article{Salih2016,
author = {Salih, A},
number = {December},
pages = {1--24},
title = {{Second-Order Wave Equation d ' Alembert ' s Solution in Infinite Domain}},
year = {2016}
}
@article{Feldman2000,
abstract = {We shall formulate the postulates, from which the wave equation can be obtained. In the end it will be understandable, that it is the most natural law describing the motion of a system. The postulates themselves are simple and apparent: the first and the fifth postulate set the definition of the coordinate and the definition of its evolution. The second and the fourth postulate define the momentum and define its evolution. The third postulate sets the superposition principle. On the basis of these statements it is possible to obtain the wave equation.},
author = {Bergman, David R.},
doi = {10.1002/9781119277323.ch3},
journal = {Computational Acoustics},
pages = {19--48},
title = {{Derivation of the Wave Equation}},
year = {2018}
}
@article{h96,
abstract = {Introductory textbook on neural networks that uses MATLAB as a simulator and has a nice annotated bibliography for every chapter.},
author = {Hagan, Martin and Demuth, Howard},
isbn = {978-0971732117},
journal = {Neural Networks in a Softcomputing Framework},
pages = {1--1012},
title = {{Neural Network Design}},
url = {http://scholar.google.com/scholar?hl=en&sugexp=gsih&pq=badminton+training&xhr=t&q=neural+network+design&cp=16&qe=bmV1cmFsIG5ldHdvcmsgZA&qesig=k9_6OUSCnOMtzbLRV7Bxag&pkc=AFgZ2tnXZWxdMzsRdm7bQlAZ9Ouzahw-8F-Iap-NFqR9QR-QaxLC0MI5wrX4F_gMeseaytVjRLbReEMmERZgMf},
volume = {20},
year = {2014}
}
@incollection{l12,
abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
address = {Traducao. [s.l.] p. 9�48},
author = {LeCun, Yann A. and Bottou, L{\'{e}}on and Orr, Genevieve B. and M{\"{u}}ller, Klaus-Robert},
booktitle = {Neural networks: Tricks of the trade},
doi = {10.1007/978-3-642-35289-8_3},
pages = {9--48},
publisher = {Springer},
title = {{Efficient BackProp}},
year = {2012}
}
@unpublished{18,
abstract = {The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the "posterior collapse" problem which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a "flat" baseline model. An implementation of our "MusicVAE" is available online.2.},
annote = {arXiv preprint},
archivePrefix = {arXiv},
arxivId = {1803.05428},
author = {Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne, Curtis and Eck, Douglas},
booktitle = {35th International Conference on Machine Learning, ICML 2018},
eprint = {1803.05428},
isbn = {9781510867963},
pages = {6939--6954},
title = {{A hierarchical latent vector model for learning long-term structure in music}},
volume = {10},
year = {2018}
}
@article{Valin2017,
abstract = {—Despite noise suppression being a mature area in signal processing, it remains highly dependent on fine tuning of estimator algorithms and parameters. In this paper, we demonstrate a hybrid DSP/deep learning approach to noise suppression. We focus strongly on keeping the complexity as low as possible, while still achieving high-quality enhanced speech. A deep recurrent neural network with four hidden layers is used to estimate ideal critical band gains, while a more traditional pitch filter attenuates noise between pitch harmonics. The approach achieves significantly higher quality than a traditional minimum mean squared error spectral estimator, while keeping the complexity low enough for real-time operation at 48 kHz on a low-power CPU.},
archivePrefix = {arXiv},
arxivId = {1709.08243},
author = {Valin, Jean Marc},
eprint = {1709.08243},
issn = {23318422},
journal = {arXiv},
keywords = {Index Terms—noise suppression, recurrent neural ne},
title = {{A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement}},
year = {2017}
}
@article{Liao,
abstract = {Gradient backpropagation (BP) requires symmetric feedforward and feedback connections-the same weights must be used for forward and backward passes. This "weight transport problem" (Grossberg 1987) is thought to be one of the main reasons to doubt BP's biologically plausibility. Using 15 different classification datasets, we systematically investigate to what extent BP really depends on weight symmetry. In a study that turned out to be surprisingly similar in spirit to Lillicrap et al.'s demonstration (Lillicrap et al. 2014) but orthogonal in its results, our experiments indicate that: (1) the magnitudes of feedback weights do not matter to performance (2) the signs of feedback weights do matter-the more concordant signs between feedforward and their corresponding feedback connections, the better (3) with feedback weights having random magnitudes and 100% concordant signs, we were able to achieve the same or even better performance than SGD. (4) some normalizations/stabilizations are indispensable for such asymmetric BP to work, namely Batch Normalization (BN) (Ioffe and Szegedy 2015) and/or a "Batch Manhattan" (BM) update rule.},
archivePrefix = {arXiv},
arxivId = {1510.05067},
author = {Liao, Qianli and Leibo, Joel Z. and Poggio, Tomaso},
eprint = {1510.05067},
isbn = {9781577357605},
journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
pages = {1837--1844},
title = {{How important is weight symmetry in backpropagation?}},
year = {2016}
}
@article{Tomar2017,
abstract = {An online method for amplitude and frequency estimation of exponentially decaying sinusoids is proposed with a moving-window discrete Fourier transform (MWDFT) filter and frequency-locked loop. The tuned filter characteristics of MWDFT is modified into more flat characteristic around the center frequency with negative feedback, which increases the bandwidth of the filter. An adaptive sampling pulse adjustment mechanism is incorporated in the proposed structure for online estimation of frequency. Hence, the frequency error was exploited to achieve synchronization between in-phase component of MWDFT and input signal of estimation. The amplitude is estimated in online from the in-phase and quadrature-phase components of MWDFT. The performance of the proposed method is compared with the existing techniques and experimentally validated on single-link flexible manipulator system for the online estimation of frequency and amplitude of tip deflection signal. The experimental investigation prove that the proposed online technique performs well over the existing techniques.},
author = {Tomar, Shikha and Sumathi, Parasuraman},
doi = {10.1109/TIM.2017.2755998},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Exponentially decaying sinusoid,Single-link flexible manipulator (SLFM),Sinusoidal amplitude and frequency estimation,Vibration estimation},
number = {1},
pages = {229--237},
title = {{Amplitude and frequency estimation of exponentially decaying sinusoids}},
volume = {67},
year = {2018}
}
@article{Smith2015,
abstract = {It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate 'reasonable bounds' - linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.},
archivePrefix = {arXiv},
arxivId = {1506.01186},
author = {Smith, Leslie N.},
doi = {10.1109/WACV.2017.58},
eprint = {1506.01186},
isbn = {9781509048229},
journal = {Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017},
number = {April},
pages = {464--472},
title = {{Cyclical learning rates for training neural networks}},
year = {2017}
}
@article{Nielsen2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1612.01010v2},
author = {Nielsen, Frank},
eprint = {arXiv:1612.01010v2},
title = {{DeepBach: a Steerable Model for Bach Chorales Generation}},
year = {2017}
}
@article{Jaderberg,
abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagaling error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropa-gated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which arc decoupled in both the forward and backwards pass - amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
archivePrefix = {arXiv},
arxivId = {1608.05343},
author = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Silver, David and Kavukcuoglu, Koray},
eprint = {1608.05343},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {2558--2577},
title = {{Decoupled neural interfaces using synthetic gradients}},
volume = {4},
year = {2017}
}
@article{Louizos2017,
abstract = {We propose a practical method for L0norm regularization for neural networks: pruning the network during training by encouraging weights to become exactly zero. Such regularization is interesting since (1) it can greatly speed up training and inference, and (2) it can improve generalization. AIC and BIC, well-known model selection criteria, are special cases of L0regularization. However, since the L0norm of weights is non-differentiable, we cannot incorporate it directly as a regularization term in the objective function. We propose a solution through the inclusion of a collection of non-negative stochastic gates, which collectively determine which weights to set to zero. We show that, somewhat surprisingly, for certain distributions over the gates, the expected L0regularized objective is differentiable with respect to the distribution parameters. We further propose the hard concrete distribution for the gates, which is obtained by "stretching" a binary concrete distribution and then transforming its samples with a hard-sigmoid. The parameters of the distribution over the gates can then be jointly optimized with the original network parameters. As a result our method allows for straightforward and efficient learning of model structures with stochastic gradient descent and allows for conditional computation in a principled way. We perform various experiments to demonstrate the effectiveness of the resulting approach and regularizer.},
archivePrefix = {arXiv},
arxivId = {1712.01312},
author = {Louizos, Christos and Welling, Max and Kingma, Diederik P.},
eprint = {1712.01312},
issn = {23318422},
journal = {arXiv},
pages = {1--13},
title = {{Learning sparse neural networks through L0regularization}},
year = {2017}
}
@article{Gabrielli2017,
abstract = {One of the most challenging tasks in physically-informed sound synthesis is the estimation of model parameters to produce a desired timbre. Automatic parameter estimation procedures have been developed in the past for some specific parameters or application scenarios but, up to now, no approach has been proved applicable to a wide variety of use cases. A general solution to parameters estimation problem is provided along this paper which is based on a supervised convolutional machine learning paradigm. The described approach can be classified as "end-to-end" and requires, thus, no specific knowledge of the model itself. Furthermore, parameters are learned from data generated by the model, requiring no effort in the preparation and labeling of the training dataset. To provide a qualitative and quantitative analysis of the performance, this method is applied to a patented digital waveguide pipe organ model, yielding very promising results.},
author = {Gabrielli, Leonardo and Tomassetti, Stefano and Squartini, Stefano and Zinato, Carlo},
journal = {DAFx 2017 - Proceedings of the 20th International Conference on Digital Audio Effects},
pages = {11--16},
title = {{Introducing deep machine learning for parameter estimation in physical modelling}},
year = {2017}
}
@article{Bello2017,
abstract = {We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string in a specific domain language that describes a mathematical update equation based on a list of primitive functions, such as the gradient, running average of the gradient, etc. The controller is trained with Reinforcement Learning to maximize the performance of a model after a few epochs. On CIFAR-10, our method discovers several update rules that are better than many commonly used optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet model. These optimizers can also be transferred to perform well on different neural network architectures, including Google's neural machine translation system.},
archivePrefix = {arXiv},
arxivId = {1709.07417},
author = {Bello, Irwan and Zoph, Barret and Vasudevan, Vijay and Le, Quoc V.},
eprint = {1709.07417},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
number = {2002},
pages = {712--721},
title = {{Neural optimizer search with Reinforcement learning}},
volume = {1},
year = {2017}
}
@article{Kalchbrenner2016,
abstract = {We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.},
archivePrefix = {arXiv},
arxivId = {1610.10099},
author = {Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and van den Oord, Aaron and Graves, Alex and Kavukcuoglu, Koray},
eprint = {1610.10099},
title = {{Neural Machine Translation in Linear Time}},
url = {http://arxiv.org/abs/1610.10099},
year = {2016}
}
@article{Peng2017,
abstract = {A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing userspecified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the convenience and motion quality of using motion clips to define the desired style and appearance, with the flexibility and generality afforded by RL methods and physics-based animation. We further explore a number of methods for integrating multiple clips into the learning process to develop multi-skilled agents capable of performing a rich repertoire of diverse skills. We demonstrate results using multiple characters (human, Atlas robot, bipedal dinosaur, dragon) and a large variety of skills, including locomotion, acrobatics, and martial arts.},
archivePrefix = {arXiv},
arxivId = {1804.02717},
author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and {Van De Panne}, Michiel},
doi = {10.1145/3197517.3201311},
eprint = {1804.02717},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Motion control,Physics-based character animation,Reinforcement learning},
number = {4},
title = {{DeepMimic: Example-guided deep reinforcement learning of physics-based character skills}},
volume = {37},
year = {2018}
}
@article{Eisenach2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6830v3},
author = {Agostinelli, Forest and Hoffman, Matthew and Sadowski, Peter and Baldi, Pierre},
eprint = {arXiv:1412.6830v3},
number = {2013},
pages = {1--9},
title = {{L Earning a Ctivation F Unctions}},
year = {2015}
}
@article{For2018,
author = {Bell, Taco},
journal = {Health (San Francisco)},
number = {January},
pages = {1--3},
title = {{Earching for}},
year = {2007}
}
@article{Ephrat2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1804.03619v1},
author = {Ephrat, Ariel and Hebrew, The and Freeman, William T and Rubinstein, Michael and Jon, Only and Rory, Only},
eprint = {arXiv:1804.03619v1},
title = {{Looking to Listen at the Cocktail Party : A Speaker-Independent Audio-Visual Model for Speech Separation}},
year = {2017}
}
@article{Donoso2007,
author = {Donoso, Pedro and Tann, Alberto and Guimar, Francisco},
keywords = {acoustics,helmholtz,musical instruments,resonance,violin},
number = {December},
title = {{A f ´ ısica do violino}},
volume = {2305},
year = {2008}
}
@article{Donahue2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1802.04208v1},
author = {Donahue, Chris and Mcauley, Julian and Puckette, Miller},
eprint = {arXiv:1802.04208v1},
title = {{Synthesizing Audio with Generative Adversarial Networks}},
year = {2014}
}
@misc{,
title = {{Parzen - 1962 - On estimation of a probability density function and mode.pdf}}
}
@article{Balkema1974,
abstract = {The asymptotic behaviour of the residual life time at time t is investigated (for t rightarrow infty). We derive weak limit laws and their domains of attraction and treat rates of convergence and moment convergence. The presentation exploits the close similarity with extreme value theory.},
author = {Balkema, a a and {De Haan}, L},
issn = {0091-1798},
journal = {Statistics},
number = {5},
pages = {347--370},
title = {{Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Probability. {\textregistered} www.jstor.org}},
url = {http://projecteuclid.org/euclid.aop/1176996548},
volume = {2},
year = {1974}
}
@article{Bernroider2013,
author = {Bernroider, Edward and Schm{\"{o}}llerl, Patrick},
journal = {European Journal of Operational Research},
number = {224},
pages = {141--153},
title = {{ePub WU Institutional Repository A technological , organisational , and environmental analysis}},
url = {http://epub.wu.ac.at/3913/},
year = {2013}
}
@article{Zopounidis2002,
abstract = {The assignment of alternatives (observations/objects) into predefined homogenous groups is a problem of major practical and research interest. This type of problem is referred to as classification or sorting, depending on whether the groups are nominal or ordinal. Methodologies for addressing classification and sorting problems have been developed from a variety of research disciplines, including statistics/econometrics, artificial intelligent and operations research. The objective of this paper is to review the research conducted on the framework of the multicriteria decision aiding (MCDA). The review covers different forms of MCDA classification/sorting models, different aspects of the model development process, as well as real-world applications of MCDA classification/sorting techniques and their software implementations. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Zopounidis, Constantin and Doumpos, Michael},
doi = {10.1016/S0377-2217(01)00243-0},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Classification,Decision rules,Multiple criteria analysis,Outranking relations,Preference disaggregation,Sorting,Utility functions},
number = {2},
pages = {229--246},
title = {{Multicriteria classification and sorting methods: A literature review}},
volume = {138},
year = {2002}
}
@article{Ishizaka2017,
author = {Ishizaka, Alessio and Siraj, Sajid},
doi = {10.1016/j.ejor.2017.05.041},
issn = {0377-2217},
journal = {European Journal of Operational Research},
keywords = {AHP,Decision analysis,Experimental evaluation,MACBETH,SMART},
publisher = {Elsevier B.V.},
title = {{PT}},
url = {http://dx.doi.org/10.1016/j.ejor.2017.05.041},
year = {2017}
}
@article{Zamani-sabzi2016,
abstract = {Different multi-criteria decision-making (MCDM) techniques require different levels of computational intensity and may produce different outputs, so selecting an appropriate technique largely determines the quality of the recommended decision and the effort required to obtain that decision. In most real environments, criteria and their constraints are not deterministic and cannot be specified precisely; therefore, those criteria are uncertain or fuzzy. To facilitate the selection of an appropriate MCDM method under a fuzzy environment, this study investigates and statistically compares the performances of ten commonly used MCDM techniques: simple additive weights (SAW), weighted product method (WPM), compromise programming (CP), technique for order preference by similarity to ideal solution (TOPSIS), four types of analytical hierarchy process (AHP), VIKOR (in Serbian: VIseKriterijumska Optimizacija I Kompromisno Resenje), and ELECTRE (in French: ELimination Et Choix Traduisant la REalit{\'{e}}). These techniques' performances were compared using fuzzy criteria and constraints, matching the conditions usually found in real applications. To conduct the comparisons, the 10 multi-criteria decision ranking methods were applied to 1250 simulated sets of decision matrices with fuzzy triangular values, and 12,500 sets of ranks were analyzed to compare the ranking methods. SAW and TOPSIS had statistically similar performances. ELECTRE was not preferable in providing full, sorted ranks among the alternatives. VIKOR considering its ranking process, for specific conditions, assigns identical ranks for several alternatives; when full, sorted ranks are required, VIKOR is unfavorable, although it is a powerful technique in introducing the closest alternative to the ideal condition. Types 1 and 3 of AHP and types 2 and 4 of AHP had close performances. Notably, no ranking method was significantly sensitive to uncertainty levels when uncertainty changed symmetrically.},
author = {Zamani-Sabzi, Hamed and King, James Phillip and Gard, Charlotte C. and Abudu, Shalamu},
doi = {10.1016/j.orp.2016.11.001},
issn = {22147160},
journal = {Operations Research Perspectives},
keywords = {Defuzzification,Fuzzy environment,Multi-criteria decision-making,Statistical analysis of ranking methods},
pages = {92--117},
publisher = {Elsevier Ltd},
title = {{Statistical and analytical comparison of multi-criteria decision-making techniques under fuzzy environment}},
url = {http://dx.doi.org/10.1016/j.orp.2016.11.001},
volume = {3},
year = {2016}
}
@article{Carayannis2018,
abstract = {The importance of knowledge in creating value, driving productivity and promoting economic growth has long been recognized. Accompanying this recognition of the central role of knowledge in today's economies has been an added focus on information, technology, learning and the accelerated pace of technical and scientific advance that results therefrom. Closely connected to these developments has been the advent of big data; and as information becomes available at greater volumes and higher speed, the focus is shifting from quantity to the quality of the information collected and the manner in which it is used. In this respect, Multiple Criteria Decision Analysis (MCDA) techniques constitute valuable tools for structuring and evaluating complex decision situations, and can allow for more informed, potentially better decisions. MCDA techniques are able to build on the knowledge of expert participants in a given field, and produce assessment systems based on values and experience. Constructivist in nature, this approach has grown exponentially over the past few decades, causing a change in the decision-making arena in general, and in the field of decision support systems (DSS) in particular. The objective of this special issue is to bring together recent developments and methodological contributions within MCDA, with the challenges which characterize the knowledge-based economy, as they pertain to the themes of technological forecasting and social change.},
author = {Carayannis, Elias G. and Ferreira, Jo{\~{a}}o J.M. and Jalali, Marjan S. and Ferreira, Fernando A.F.},
doi = {10.1016/j.techfore.2018.01.028},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
number = {xxxx},
pages = {1--3},
publisher = {Elsevier},
title = {{MCDA in knowledge-based economies: Methodological developments and real world applications}},
url = {http://dx.doi.org/10.1016/j.techfore.2018.01.028},
volume = {131},
year = {2018}
}
@article{Marttunen2017,
abstract = {Structuring problems for Multi-Criteria Decision Analysis (MCDA) has attracted increasing attention over the past 20 years from both a conceptual and a practical perspective. This is reflected in a significant growth in the number of published applications which use a formal approach to problem structuring in combination with an analytic method for multi-criteria analysis. The problem structuring approaches (PSMs) include general methodologies such as Checkland's Soft Systems Method (SSM), Eden and Ackermann's Strategic Options Design and Analysis (SODA) and other methods that focus on a particular aspect. We carried out a literature review that covers eight PSMs (Cognitive and Causal Maps, DPSIR, Scenario Planning, SSM, Stakeholder Analysis, Strategic Choice Approach, SODA and SWOT) and seven MCDA methods (AHP, ANP, ELECTRE, MAUT, MAVT, PROMETHEE and TOPSIS). We first identified and analysed 333 articles published during 2000-2015, then selected 68 articles covering all PSM-MCDA combinations, which were studied in detail to understand the associated processes, benefits and challenges. The three PSMs most commonly combined with MCDA are SWOT, Scenario Planning and DPSIR. AHP was by far the most commonly applied MCDA method. Combining PSMs with MCDA produces a richer view of the decision situation and enables more effective support for different phases of the decision-making process. Some limitations and challenges in combining PSMs and MCDA are also identified, most importantly relating to building a value tree and assigning criteria weights.},
author = {Marttunen, Mika and Lienert, Judit and Belton, Valerie},
doi = {10.1016/j.ejor.2017.04.041},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Multi-methodology,Multi-stakeholder decision-making,Multiple Criteria Decision Analysis,Problem structuring},
number = {1},
pages = {1--17},
publisher = {Elsevier B.V.},
title = {{Structuring problems for Multi-Criteria Decision Analysis in practice: A literature review of method combinations}},
url = {http://dx.doi.org/10.1016/j.ejor.2017.04.041},
volume = {263},
year = {2017}
}
@article{Guitouni1998,
abstract = {Despite the development of a large number of refined multicriterion decision aid (MCDA) methods, none can be considered as the 'super method' appropriate to all decision making situations. Hence, how can one choose an appropriate method to a specific decision situation? Recent experimental studies in psychology and behaviour have revealed, on the one hand, that the human thinking is not to be modelled by logical rules and calculations, and, on the other hand, that the response mode affects the preference formation as well as the use of compensatory or noncompensatory strategies. The aim of this paper is to draw a conceptual framework for articulating tentative guidelines to choose an appropriate MCDA method. This paper also presents the results of the comparison of well known multicriterion aggregation procedures (MCAP) on the basis of these guidelines. In our opinion this study can constitute a first step for proposing a methodological approach to select an appropriate MCDA method to a specific decision making situation. Such an approach should be validated and may be integrated into a decision support system. Moreover, the framework suggested is helpful to develop useful methods and to address neglected issues within the field. {\textcopyright} 1998 Elsevier Science B.V. All rights reserved.},
author = {Guitouni, Adel and Martel, Jean Marc},
doi = {10.1016/S0377-2217(98)00073-3},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Behavioural considerations,Comparative analysis,Decision making situation,Multicriteria analysis,Multicriterion aggregation procedure,Multicriterion decision aid method,Preferences modelling},
number = {2},
pages = {501--521},
title = {{Tentative guidelines to help choosing an appropriate MCDA method}},
volume = {109},
year = {1998}
}
@article{Solomon1998,
abstract = {Several methods have been proposed for solving multi-attribute decision making problems (MADM). A major criticism of MADM is that different techniques may yield different results when applied to the same problem. The problem considered in this study consists of a decision matrix input of N criteria weights and ratings of L alternatives on each criterion. The comparative performance of some methods has been investigated in a few, mostly field, studies. In this simulation experiment we investigate the performance of eight methods: ELECTRE, TOPSIS, Multiplicative Exponential Weighting (MEW), Simple Additive Weighting (SAW), and four versions of AHP (original vs. geometric scale and right eigenvector vs. mean transformation solution). Simulation parameters are the number of alternatives, criteria and their distribution. The solutions are analyzed using twelve measures of similarity of performance. Similarities and differences in the behavior of these methods are investigated. Dissimilarities in weights produced by these methods become stronger in problems with few alternatives; however, the corresponding final rankings of the alternatives vary across methods more in problems with many alternatives. Although less significant, the distribution of criterion weights affects the methods differently. In general, all AHP versions behave similarly and closer to SAW than the other methods. ELECTRE is the least similar to SAW (except for closer matching the top-ranked alternative), followed by MEW. TOPSIS behaves closer to AHP and differently from ELECTRE and MEW, except for problems with few criteria. A similar rank-reversal experiment produced the following performance order of methods: SAW and MEW (best), followed by TOPSIS, AHPs and ELECTRE. It should be noted that the ELECTRE version used was adapted to the common MADM problem and therefore it did not take advantage of the method's capabilities in handling problems with ordinal or imprecise information. {\textcopyright} 1998 Elsevier Science B.V.},
author = {Zanakis, Stelios H. and Solomon, Anthony and Wishart, Nicole and Dublish, Sandipa},
doi = {10.1016/S0377-2217(97)00147-1},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Decision theory,Multiple criteria analysis,Simulation,Utility theory},
number = {3},
pages = {507--529},
title = {{Multi-attribute decision making: A simulation comparison of select methods}},
volume = {107},
year = {1998}
}
@article{Jacquet-lagr2001,
abstract = {The philosophy of preference disaggregation in multicriteria decision-aid system (MCDA) is to assess/infer global preference models from the given preferential structures and to address decision-aiding activities. A panorama of preference disaggregation methods is presented and the most important results and applications over the last 20 years were discussed.},
author = {Jacquet-Lagr{\`{e}}ze, Eric and Siskos, Yannis},
doi = {10.1016/S0377-2217(00)00035-7},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {1,criteria,general philosophy,goal programming,in decision-making involving multiple,introduction and background,multicriteria analysis,preference disaggregation,regression},
number = {2},
pages = {233--245},
title = {{Preference disaggregation: 20 Years of MCDA experience}},
volume = {130},
year = {2001}
}
@article{Information2000,
author = {Information, Background and Of, Description and Mcdm, Some},
isbn = {978-1-4419-4838-0},
journal = {Multi-criteria Decision Making Methods: A Comparative Study},
pages = {5--21},
title = {{Chapter 2 MULTI-CRITERIA DECISION MAKING METHODS 2.1}},
year = {2000}
}
@article{Dehe2015,
abstract = {When planning a new development, location decisions have always been a major issue. This paper examines and compares two modelling methods used to inform a healthcare infrastructure location decision. Two Multiple Criteria Decision Analysis (MCDA) models were developed to support the optimisation of this decision-making process, within a National Health Service (NHS) organisation, in the UK. The proposed model structure is based on seven criteria (environment and safety, size, total cost, accessibility, design, risks and population profile) and 28 sub-criteria. First, Evidential Reasoning (ER) was used to solve the model, then, the processes and results were compared with the Analytical Hierarchy Process (AHP). It was established that using ER or AHP led to the same solutions. However, the scores between the alternatives were significantly different; which impacted the stakeholders' decision-making. As the processes differ according to the model selected, ER or AHP, it is relevant to establish the practical and managerial implications for selecting one model or the other and providing evidence of which models best fit this specific environment. To achieve an optimum operational decision it is argued, in this study, that the most transparent and robust framework is achieved by merging ER process with the pair-wise comparison, an element of AHP. This paper makes a defined contribution by developing and examining the use of MCDA models, to rationalise new healthcare infrastructure location, with the proposed model to be used for future decision. Moreover, very few studies comparing different MCDA techniques were found, this study results enable practitioners to consider even further the modelling characteristics to ensure the development of a reliable framework, even if this means applying a hybrid approach.},
author = {Dehe, Benjamin and Bamford, David},
doi = {10.1016/j.eswa.2015.04.059},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Analytical Hierarchy Process (AHP),Evidential Reasoning (ER),Location decision,Multiple Criteria Decision Analysis (MCDA)},
number = {19},
pages = {6717--6727},
publisher = {Elsevier Ltd},
title = {{Development, test and comparison of two Multiple Criteria Decision Analysis (MCDA) models: A case of healthcare infrastructure location}},
url = {http://dx.doi.org/10.1016/j.eswa.2015.04.059},
volume = {42},
year = {2015}
}
@article{Behzadian2010,
abstract = {In recent decades, several Multi-Criteria Decision Aid (MCDA) methods have been proposed to help in selecting the best compromise alternatives. In the meantime, the PROMETHEE (Preference Ranking Organization Method for Enrichment Evaluations) family of outranking methods and their applications has attracted much attention from academics and practitioners. In this paper, a classification scheme and a comprehensive literature review are presented in order to uncover, classify, and interpret the current research on PROMETHEE methodologies and applications. Based on the scheme, 217 scholarly papers from 100 journals are categorized into application areas and non-application papers. The application areas include the papers on the topics of Environment Management, Hydrology and Water Management, Business and Financial Management, Chemistry, Logistics and Transportation, Manufacturing and Assembly, Energy Management, Social, and Other Topics. The last area covers the papers published in several fields: Medicine, Agriculture, Education, Design, Government and Sports. The scholarly papers are also classified by (1) year of publication, (2) journal of publication, (3) authors' nationality, (4) PROMETHEE as applied with other MCDA methods, and (5) PROMETHEE as applied with GAIA (Geometrical Analysis for Interactive Aid) plane. It is hoped that the paper can meet the needs of researchers and practitioners for easy references of PROMETHEE methodologies and applications, and hence promote the future of PROMETHEE research. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Behzadian, Majid and Kazemzadeh, R. B. and Albadvi, A. and Aghdasi, M.},
doi = {10.1016/j.ejor.2009.01.021},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Application areas,GAIA,Literature review,MCDA,Outranking,PROMETHEE},
number = {1},
pages = {198--215},
publisher = {Elsevier B.V.},
title = {{PROMETHEE: A comprehensive literature review on methodologies and applications}},
url = {http://dx.doi.org/10.1016/j.ejor.2009.01.021},
volume = {200},
year = {2010}
}
@article{Leoneti2016,
abstract = {To assist in the decision making process, several multicriteria methods have been proposed. However, the existing methods assume a single decision-maker and do not consider decision under risk, which is better addressed by Game Theory. Hence, the aim of this research is to propose a Utility Function that makes it possible to model Group Multicriteria Decision Making problems as games. The advantage of using Game Theory for solving Group Multicriteria Decision Making problems is to evaluate the conflicts between the decision makers using a strategical approach.},
author = {Leoneti, Alexandre Bevilacqua},
doi = {10.1016/j.orp.2016.04.001},
issn = {22147160},
journal = {Operations Research Perspectives},
keywords = {Game Theory,Group Multicriteria Decision,MAUT,Utility function},
pages = {21--26},
publisher = {Elsevier Ltd},
title = {{Utility Function for modeling Group Multicriteria Decision Making problems as games}},
url = {http://dx.doi.org/10.1016/j.orp.2016.04.001},
volume = {3},
year = {2016}
}
@article{Govindan2015,
abstract = {Multi-criteria decision analysis (MCDA) is a valuable resource within operations research and management science. Various MCDA methods have been developed over the years and applied to decision problems in many different areas. The outranking approach, and in particular the family of ELECTRE methods, continues to be a popular research field within MCDA, despite its more than 40 years of existence. In this paper, a comprehensive literature review of English scholarly papers on ELECTRE and ELECTRE-based methods is performed. Our aim is to investigate how ELECTRE and ELECTRE-based methods have been considered in various areas. This includes area of applications, modifications to the methods, comparisons with other methods, and general studies of the ELECTRE methods. Although a significant amount of literature on ELECTRE is in a language different from English, we focus only on English articles, because many researchers may not be able to perform a study in some of the other languages. Each paper is categorized according to its main focus with respect to ELECTRE, i.e. if it considers an application, performs a review, considers ELECTRE with respect to the problem of selecting an MCDA method or considers some methodological aspects of ELECTRE. A total of 686 papers are included in the review. The group of papers considering an application of ELECTRE consists of 544 papers, and these are further categorized into 13 application areas and a number of sub-areas. In addition, all papers are classified according to the country of author affiliation, journal of publication, and year of publication. For the group of applied papers, the distribution by ELECTRE version vs. application area and ELECTRE version vs. year of publication are provided. We believe that this paper can be a valuable source of information for researchers and practitioners in the field of MCDA and ELECTRE in particular.},
author = {Govindan, Kannan and Jepsen, Martin Brandt},
doi = {10.1016/j.ejor.2015.07.019},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {ELECTRE,Literature review,Multiple criteria decision aiding (MCDA),Outranking},
number = {1},
pages = {1--29},
publisher = {Elsevier Ltd.},
title = {{ELECTRE: A comprehensive literature review on methodologies and applications}},
url = {http://dx.doi.org/10.1016/j.ejor.2015.07.019},
volume = {250},
year = {2016}
}
@article{Stefano2015,
abstract = {This paper presents a state-of-the-art literature survey on COPRAS applications and methodologies. The classification this review contains 59 papers, where if analyzed: titles and authors, cited journal, area classification, application areas, other multi-criteria methods combined with the COPRAS, authors nationality and country and most cited articles (or scientific recognition). This document provides useful insights about the COPRAS which is a new method, with many research opportunity.},
author = {Stefano, Nara Medianeira and {Casarotto Filho}, Nelson and {Garcia Lupi Vergara}, Lizandra and {Garbin Da Rocha}, Rodrigo Ulisses},
doi = {10.1109/TLA.2015.7404925},
issn = {15480992},
journal = {IEEE Latin America Transactions},
keywords = {Literature review,MCDA,MCDM,Multi-criteria},
number = {12},
pages = {3899--3906},
title = {{COPRAS (Complex Proportional Assessment): State of the art research and its applications}},
volume = {13},
year = {2015}
}
@article{Costa2016,
abstract = {Purpose – This study aims to use a graphical approach to highlight the differences between outranking and preference relationships. The outranking principle is based on a structure of non-dominance, which differs from the usual structures of preferences. Design/methodology/approach – To reach the objective, the paper makes a deep analysis of outranking and preference relationships and uses graphical representation to highlight the differences between these two concepts. Graphical interpretation is also used to support the results form ELECTRE I and to highlight misinterpretation of results, such as rank reversal in ELECTRE I. Findings – The results show that the assumption of rank reversal while using ELECTRE I is a mistake. Originality/value – It was not found in literature a previous work paper that demonstrates a result like this one.},
author = {Costa, Helder Gomes},
doi = {10.1108/JM2-08-2013-0037},
issn = {17465672},
journal = {Journal of Modelling in Management},
keywords = {Decision analysis,MCDA,Multicriteria,Outranking},
number = {1},
pages = {26--42},
title = {{Graphical interpretation of outranking principles: Avoiding misinterpretation results from ELECTRE I}},
volume = {11},
year = {2016}
}
@article{Oliveira,
abstract = {Since their conception, electric systems have not been through large modifications regarding their topology, solutions and metrics. However, the use of sensors, communications, computational capacity and control to increase and improve the power system functionalities, concept known as Smart Grid (SG), has great potential to revolutionize the electric sector. Nonetheless, many difficulties emerge when implementing SG technologies in a large scale. These difficulties may be technical, financial, environmental, regulatory and managerial. In order to aid in this process, the goal of this research is to propose a novel approach on how to assess the performance of SG implementation projects. The approach is based on the multicriteria decision aid theory, specifically using the Multicriteria Decision Aid Constructive Approach (MCDA-C), due to its logical and data treatment structures. A case study to evaluate the MCDA-C application was conducted, in partnership with a local utility SG pilot-project. With the use of this novel approach, it was possible to build a quantitative roadmap to monitor and improve the project performance. The main contribution of this work is the novel approach proposed, an adaptive model based on a multicriteria decision aid method that can comprehensively assess the performance of any SG project.},
author = {Oliveira, G. A.Q.S.M. and Seleme, R. and Zattar, I. C.},
doi = {10.1109/TLA.2016.7530428},
issn = {15480992},
journal = {IEEE Latin America Transactions},
keywords = {Multicriteria Decision Aid,Project Management,Roadmap,Smart Grids},
number = {5},
pages = {2316--2322},
title = {{Smart Grid Performance Assessment Via Multicriteria Decision Aid Constructive Approach Method}},
volume = {14},
year = {2016}
}
@article{Mix2017,
abstract = {Integration of renewable sources into Brazils power mix is desirable and necessary. The main benefit from these energy sources is maintaining greenhouse gas emissions at low levels. Nevertheless, high penetration of these energy sources into the power mix can lead to many problems, for instance, intermittency in power generation. There are some mechanisms which can be implemented to mitigate intermittency and allow a higher level of participation of these energy sources in the generation mix. One such mechanism is utilizing Energy Storage Systems (ESS). The goal of this paper is to perform a study to find the best ESS options using Multi-criteria Decision Analysis. Moreover, an examination regarding Hydro Power Plants' reservoirs as an ESS is accomplished through a case study using three of Brazils significant Hydro Power Plants.},
author = {Dester, M.},
doi = {10.1109/TLA.2016.7459613},
issn = {15480992},
journal = {IEEE Latin America Transactions},
keywords = {Energy Storage Systems,Intermittent Sources,Multi-Criteria Decision Analysis,Power Mix,Renewable Sources},
number = {3},
pages = {1302--1307},
title = {{Reliability of Electricity Supply Regarding the Integration of Intermittent Sources in Brazil's Power Mix}},
volume = {14},
year = {2016}
}
@article{Jesus,
abstract = {Changes in requirements occur throughout the software process from elicitation and analysis requirements through the operation of the software. Requirements traceability makes it possible to identify the origin and the dependence of the software requirements. Studies show that the tools and current requirements traceability methods are inadequate and hamper the practical use of traceability. In this paper, we carried out analysis of evaluation techniques and requirement traceability tools in order to verify if the techniques are being actually used and are being supported by software tools. As a result, we observed the lack of relationship between the techniques and tools evaluated and that some criteria, such as communication with stakeholders, difficulty, and requirement of stability were little considered in the evaluated tools.},
author = {{Oliveira De Jesus}, Telmo and {Dos Santos Soares}, Michel},
doi = {10.1109/TLA.2017.7910207},
issn = {15480992},
journal = {IEEE Latin America Transactions},
keywords = {Requirements Engineering,Requirements Management,Requirements Traceability},
number = {5},
pages = {922--927},
title = {{A Multi-Criteria Analysis of Techniques and Tools for Tracing Software Requirements}},
volume = {15},
year = {2017}
}
@misc{,
title = {{1988 - A Theoretical Framework for Back-Propagation.pdf}}
}
@article{Makin2006,
author = {Makin, J G},
pages = {1--8},
title = {{Backpropagation}},
year = {2006}
}
@article{Introduction1996,
author = {Introduction, A Systematic},
title = {{Neural Networks}},
year = {1996}
}
@article{,
number = {Xxx},
title = {{t{\~{a}}o simples e compacta quanto poss{\'{i}}vel , adotando-se , para tanto , a nota{\c{c}}{\~{a}}o matricial . Embora matematicamente equivalente {\`{a}}s deriva{\c{c}}{\~{o}}es apresentadas em ( XXX ), optou-se por uma abordagem direta com a inten{\c{c}}{\~{a}}o de tornar mais intuitivo o entendimento do}}
}
@article{Sathyanarayana2014,
author = {Sathyanarayana, Shashi and Ph, D},
pages = {1--15},
title = {{A Gentle Introduction to Backpropagation What is so difficult about designing a neural}},
year = {2014}
}
@misc{,
title = {c1992backpropagationand.pdf}
}
@book{Zocca,
author = {Zocca, Valentino and Slater, Daniel},
isbn = {9781786464453},
title = {{Python Deep Learning}}
}
@misc{,
title = {{Matthieu Ricard, Trinh Xuan Thuan-The quantum and the lotus_ a journey to the frontiers where science and Buddhism meet-Three Rivers Press (2004).pdf}}
}
@article{Bahrampour2016,
abstract = {In the last decade, rapid growth in mobile applications, web technologies, social media generating unstructured data has led to the advent of various nosql data stores. Demands of web scale are in increasing trend everyday and nosql databases are evolving to meet up with stern big data requirements. The purpose of this paper is to explore nosql technologies and present a comparative study of document and column store nosql databases such as cassandra, MongoDB and Hbase in various attributes of relational and distributed database system principles. Detailed study and analysis of architecture and internal working cassandra, Mongo DB and HBase is done theoretically and core concepts are depicted. This paper also presents evaluation of cassandra for an industry specific use case and results are published.},
author = {Reis, Cassius V C},
isbn = {9150617397},
issn = {15760162},
journal = {Neurosurgery},
keywords = {cerebral localization,craniocerebral topography,neurosurgical history,neurosurgical navi-},
number = {2},
pages = {294--310},
title = {{C Omparative S Tudy of C Ranial T Opographic}},
volume = {62},
year = {2008}
}
@article{Grinstein,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.11385v1},
author = {Grinstein, Eric and Duong, Ngoc Q K and Ozerov, Alexey and Patrick, P},
eprint = {arXiv:1710.11385v1},
title = {{No Title}}
}
@article{Jing,
archivePrefix = {arXiv},
arxivId = {arXiv:1705.04058v1},
author = {Jing, Yongcheng},
eprint = {arXiv:1705.04058v1},
title = {{Neural Style Transfer: A Review}}
}
@article{Abnisa2014,
abstract = {What distinguishes a good manuscript from a bad one?},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Abnisa, Faisal and {Wan Daud}, Wan Mohd Ashri and Athanassiou, M and Zabaniotou, A and Bridgwater, a V and Brown, Duncan and Rowe, Andrew and Wild, Peter and Chen, Dezhen and Yin, Lijie and Wang, Huan and He, Pinjing and Chen, Qun and Yang, Ruiming and Zhao, Bo and Li, Yan and Wang, Shujuan Shaobin and Wu, Hongwei and Zhuo, Yuqun and Chen, Changhe and Cross, Andrew and Sohi, Saran P. and Ding, Hong-Sheng and Jiang, Hong and Francescato and G{\'{o}}mez, Natalia and Rosas, Jos{\'{e}} Guillermo and Cara, Jorge and Mart{\'{i}}nez, Olegario and Alburquerque, Jos{\'{e}} Antonio and S{\'{a}}nchez, Marta Elena and Kaiser, E R and Kempegowda, Rajesh S. and Skreiberg, {\O}yvind and Tran, Khanh-quang Quang and Kuppens, Tom and {Van Dael}, Miet and Vanreppelen, Kenny and Thewys, Theo and Yperman, Jan and Carleer, Robert and Schreurs, Sonja and {Van Passel}, Steven and Lehmann, Johannes and S, Naprave Podjetja Paloma D D and Soediono, Budi and Total, Outcome Defective Non-defective and Uslu, Ayla and Faaij, Andr{\'{e}} P.C. and Bergman, P.C.A. and Yang, Hua and Kudo, Shinji and Kuo, Hsiu Po and Norinaga, Koyo and Mori, Aska and Ma{\v{s}}ek, Ondřej and Hayashi, Jun Ichiro and Singh, M and S{\'{e}}t{\'{a}}l{\'{o}}, G and Guan, X and Warren, M and Toran-Allerand, C D and Brownsort, Peter and Dickinson, Dane and Rogers, J.G. and Brammer, J.G. and Sohi, Saran P. and Crombie, Kyle and Ma{\v{s}}ek, Ondřej and S, Naprave Podjetja Paloma D D and Ma{\v{s}}ek, Ondřej and Konno, Miki and Hosokai, Sou and Sonoyama, Nozomu and Norinaga, Koyo and Hayashi, Jun Ichiro and Athanassiou, M and Zabaniotou, A and Input, Biomass and Gases, Uncondensed H O T and Pyrolysis, Slow and Prost, Katharina and Borchard, Nils and Siemens, Jan and Kautz, Timo and S{\'{e}}quaris, Jean-Marie and M{\"{o}}ller, Andreas and Amelung, Wulf and Ronsse, Frederik and van Hecke, Sven and Dickinson, Dane and Prins, Wolter and Abiven, S and Singh, N and Maestrini, B and Rogovska, Natalia and Laird, David A. and Cruse, Richard and Fleming, Pierce and Parkin, Tim and Meek, David and Spokas, Kurt a and Yoder, Jonathan and Galinato, Suzette and Granatstein, David and Garcia-P{\'{e}}rez, Manuel and Galgani, Pietro and van der Voet, Ester and Korevaar, Gijsbert and {San Miguel}, G. and Dom{\'{i}}nguez, M. P. and Hern{\'{a}}ndez, M. and Sanz-P{\'{e}}rez, F. and Results, Publishable and Bernal, M P and Alburquerque, Jos{\'{e}} Antonio and Moral, R and Bott, R and Lewandowski, Clare M. and Co-investigator, New and Lewandowski, Clare M. and {(UKBRC/The University of Edinburgh)}, Peter a Brownsort and {Biochar Farms} and Preto, Fernando and Klinglm, Michaela and Crombie, Kyle and Ma{\v{s}}ek, Ondřej and Shackley, Simon and Hammond, Jim and Gaunt, John and Ibarrola, Rodrigo and Daugaard, Daren E. and Brown, Robert C. and Krull, E and Singh, Bp and Downie, Ms a and D, Deliverable W P and Kemp, Ian C. and Fyhr, B. Christran and Laurent, Stephane and Roques, Michel a. and Groenewold, Carda E. and Tsotsas, Evangelos and Sereno, Alberto a. and Bonazzi, Cathenne B. and Bimbenet, Jean-Jacques and Kind, Mathhues and EBC and Certificate, European Biochar and Troy, Shane M. and Nolan, Tereza and Leahy, James J. and Lawlor, Peadar G. and Healy, Mark G. and Kwapinski, Witold and Organisation, The International and Iso, E N and Iso, E N and Iso, E N and Iso, E N and Kauffman, Nathan and Dumortier, Jerome and Hayes, Dermot J. and Brown, Robert C. and Laird, David A. and Yang, Hua and Kudo, Shinji and Kuo, Hsiu Po and Norinaga, Koyo and Mori, Aska and Ma{\v{s}}ek, Ondřej and Hayashi, Jun Ichiro and Rogers, J.G. and Brammer, J.G. and Coskun, C. and Oktay, Z. and Ilten, N. and Energy, Relative and $\Delta$e, Fwhm $\Gamma$ and Lehmann, Johannes and Hansen, Veronika and M{\"{u}}ller-St{\"{o}}ver, Dorette and Ahrenfeldt, Jesper and Holm, Jens Kai and Henriksen, Ulrik Birk and Hauggaard-Nielsen, Henrik and Rauch, Sidney J. and G{\'{o}}mez, Natalia and Rosas, Jos{\'{e}} Guillermo and Cara, Jorge and Mart{\'{i}}nez, Olegario and Alburquerque, Jos{\'{e}} Antonio and S{\'{a}}nchez, Marta Elena and Chen, Qun and Yang, Ruiming and Zhao, Bo and Li, Yan and Wang, Shujuan Shaobin and Wu, Hongwei and Zhuo, Yuqun and Chen, Changhe and Raveendran, K and Definition, Product and Standards, Specification and Tomlinson, Thayer and Initiative, International Biochar and Minerals, Bio Carbon and Required, Inorganic C and Class, Minimum and Declaration, Required and Declaration, Required and Method, Standard Test and Determination, Rapid and Content, Carbonate and Method, Standard Test and Analysis, Chemical and Charcoal, Wood and Iso, D I N E N and Faculty, Power Engineering and Faculty, Power Engineering and Faculty, Power Engineering and Faculty, Power Engineering and He, Fang and Yi, Weiming and Bai, Xueyuan and Contents, Table O F and Conversion, Energy and Table, O and Kuppens, Tom and Dael, Miet Van and Vanreppelen, Kenny and Carleer, Robert and Miller-robbie, Leslie and Ulrich, Bridget A and Ramey, Dotti F and Spencer, Kathryn S and Herzog, Skuyler P and Cath, Tzahi Y and Stokes, Jennifer R and Higgins, Christopher P and Prot{\'{a}}sio, Thiago De Paula and Trugilho, Paulo Fernando and Napoli, Alfredo and Wei, Quanyuan and Qu, Yongshui and Tan, Tianwei and Dhillon, R S and Wuehlisch, George Von and Huff, G A and Vasalos, I A and Sharma, Abhishek and Pareek, Vishnu and Wang, Shujuan Shaobin and Zhang, Zhezi and Shinde, Yogesh and Pareek, Vishnu and Zhang, Dongke and Cowdery, T B Reed C D and Building, Crew and Gustafsson, Mattias and Reckamp, Joseph M and Garrido, Rene A and Satrio, Justinus A and Crombie, Kyle and Chen, Dezhen and Yin, Lijie and Wang, Huan and He, Pinjing and Chen, Qun and Yang, Ruiming and Zhao, Bo and Li, Yan and Wang, Shujuan Shaobin and Wu, Hongwei and Zhuo, Yuqun and Chen, Changhe and Bridgwater, a V and Crombie, Kyle and Ma{\v{s}}ek, Ondřej and Rosas, Guillermo and Cara, Jorge and Mart{\'{i}}nez, Olegario and Sohi, Saran P. and Brownsort, Peter and Carter, Sarah and Cook, Jason and Cunningham, Colin and Gaunt, John and Ibarrola, Rodrigo and Ma{\v{s}}ek, Ondřej and Sims, Kirsten and Thornley, Patricia and D, Deliverable W P and Welfle, Andrew and Gilbert, Paul and Thornley, Patricia and Him, Tsz and Pleissner, Daniel and Yan, Kin and Venus, Joachim and Pommeret, Aude and Sze, Carol and Lin, Ki and Sommerfeldt, Nelson and Madani, Hatef and Kuppens, Tom and Dael, Miet Van and Vanreppelen, Kenny and Thewys, Theo and Yperman, Jan and Carleer, Robert and Schreurs, Sonja and Passel, Steven Van and Kempegowda, Rajesh S. and Skreiberg, {\O}yvind and Tran, Khanh-quang Quang and Stelt, M J C Van Der and Gerhauser, H and Kiel, J H A and Ptasinski, K J and Uslu, Ayla and Beach, Long and Park, Won Chan and Service, Forest and Simpson, William T and Ivb, Interreg},
doi = {10.1016/j.biortech.2014.03.134},
eprint = {arXiv:1011.1669v3},
isbn = {1757-1693},
issn = {09619534},
journal = {Biomass and Bioenergy},
number = {1},
pages = {1--10},
pmid = {15003161},
title = {{How to get published}},
volume = {5},
year = {2014}
}
@article{,
abstract = {literature review},
journal = {2016},
title = {{A literature review is a description of the literature relevant to a particular field or topic. It gives an overview of:}}
}
@misc{Hastie2009,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
booktitle = {Bayesian Forecasting and Dynamic Models},
doi = {10.1007/b94608},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-387-84857-0},
issn = {0172-7397},
pages = {1--694},
pmid = {12377617},
title = {{The Elements of Statistical Learning}},
url = {http://www.springerlink.com/index/10.1007/b94608},
volume = {1},
year = {2009}
}
@book{Petre2010,
abstract = {"I feel grateful to have found this book only a year into my PhD. It has opened my eyes to the world of academia. There is more to a PhD than just research in the sense of working on a problem, getting some results and publishing your findings. This book has allowed me to open my eyes and see all the other things I should be doing to fully succeed at my endeavour of becoming a researcher myself." Dominic Hosler, University of Sheffield This bestselling book on the process of PhD research provides readers with engaging discussion and comprehensive guidance on aspects that other books don't usually mention. Covering all the key topics of the previous edition, including what a PhD is really about, how to do one well, how to decipher what your supervisor actually means by terms like 'good referencing' and 'clean research question', and how to design, report and defend your research,the authors continue to offer an accessible, down-to-earth, and insightful account of the whole PhD process. Their advice addresses how to avoid some of the pitfalls en route to a successful submission. Updated throughout, the new edition includes new material on: Critical thinking Research skills The route to research independence Different models of study The Unwritten Rules of PhD Research is essential reading for anyone considering a PhD or embarking on one. It will tell you the things many students wish someone had told them before they started.},
author = {Petre, M and Rugg, G},
booktitle = {Vasa},
doi = {10.1049/em:20040508},
isbn = {9780335237029},
issn = {14724677},
pages = {320},
pmid = {1275585},
title = {{The unwritten rules of PhD research}},
url = {http://books.google.com/books?id=_DDwCqx6wpcC&printsec=frontcover&dq=unwritten+rules+of+phd+research&hl=&cd=1&source=gbs_api%255Cnpapers2://publication/uuid/48967E01-55F9-4397-B941-310D9C5405FA%255Cnhttp://medcontent.metapress.com/index/A65RM03P4874243N.p},
year = {2010}
}
@article{Tabei1996,
author = {Tabei, Makoto and Musicus, Bruce R.},
doi = {10.1109/78.506615},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
number = {6},
pages = {1504--1511},
title = {{A simple estimator for frequency and decay rate}},
volume = {44},
year = {1996}
}
@article{Robel,
author = {Robel, Axel},
title = {{Signals}}
}
@article{Brown1991,
abstract = {In two recent papers, a description is given of a means of obtaining an arbitrarily narrow peak in the calculation of the autocorrelation function [J. C. Brown and M. S. Puckette, "Calculation of a narrowed autocorrelation function," J. Acoust. Soc. Am. 85, 1595?1601 (1989)] or of a narrow valley in the calculation of an inverse autocorrelation [J. C. Brown and M. S. Puckette, "Musical information from a narrowed autocorrelation function," Proceedings of the 1987 International Conference on Computer Music, Urbana, Illinois, 84?88 (1987)]. These calculations are applied to the determination of the fundamental frequency of musical signals produced by keyboard, wind, and string instruments. These results are compared to frequency tracking results obtained on these sounds with conventional autocorrelation. In so doing it is determined first whether the method of autocorrelation is well-adapted to the problem of tracking the frequency of musical signals, and, second, under what conditions "narrowed" autocorrelation is advantageous. {\textcopyright}1991 Acoustical Society of America.},
author = {Brown, Judith C and Zhang, Bin},
doi = {10.1121/1.400923},
issn = {00014966},
journal = {J. Acoust. Soc. Am.},
number = {5},
pages = {2346--2354},
title = {{Musical frequency tracking using the methods of conventional and “narrowed” autocorrelation}},
volume = {89},
year = {1991}
}
@article{Provencher1976,
abstract = {A method based on the Fourier convolution theorem is developed for the analysis of data composed of random noise, plus an unknown constant "base line," plus a sum of (or an integral over a continuous spectrum of) exponential decay functions. The Fourier method's usual serious practical limitation of needing high accuracy data over a very wide range is eliminated by the introduction of convergence parameters and a Gaussian taper window. A computer program is described for the analysis of discrete spectra, where the data involves only a sum of exponentials. The program is completely automatic in that the only necessary inputs are the raw data (not necessarily in equal intervals of time); no potentially biased initial guesses concerning either the number or the values of the components are needed. The outputs include the number of components, the amplitudes and time constants together with their estimated errors, and a spectral plot of the solution. The limiting resolving power of the method is studied by analyzing a wide range of simulated two-, three-, and four-component data. The results seem to indicate that the method is applicable over a considerably wider range of conditions than nonlinear least squares or the method of moments. {\textcopyright} 1976, The Biophysical Society. All rights reserved.},
author = {Provencher, S. W.},
doi = {10.1016/S0006-3495(76)85660-3},
isbn = {0006-3495},
issn = {00063495},
journal = {Biophysical Journal},
number = {1},
pages = {27--41},
pmid = {1244888},
title = {{A Fourier method for the analysis of exponential decay curves}},
volume = {16},
year = {1976}
}
@misc{Martucci1994,
abstract = {This paper discusses the use of symmetric convolution and the\ndiscrete sine and cosine transforms (DSTs and DCTs) for general digital\nsignal processing. The operation of symmetric convolution is a\nformalized approach to convolving symmetrically extended sequences. The\nresult is the same as that obtained by taking an inverse discrete\ntrigonometric transform (DTT) of the product of the forward DTTs of\nthose two sequences. There are 16 members in the family of DTTs. Each\nprovides a representation for a corresponding distinct type of\nsymmetric-periodic sequence. The author defines symmetric convolution,\nrelates the DSTs and DCTs to symmetric-periodic sequences, and then use\nthese principles to develop simple but powerful\nconvolution-multiplication properties for the entire family of DSTs and\nDCTs. Symmetric convolution can be used for discrete linear filtering\nwhen the filter is symmetric or antisymmetric. The filtering will be\nefficient because fast algorithms exist for all versions of the DTTs.\nConventional linear convolution is possible if one first zero-pad the\ninput data. Symmetric convolution and its fast implementation using DTTs\nare now an alternative to circular convolution and the DFT},
author = {Martucci, Stephen A.},
booktitle = {IEEE Transactions on Signal Processing},
doi = {10.1109/78.295213},
issn = {19410476},
number = {5},
pages = {1038--1051},
title = {{Symmetric Convolution and the Discrete Sine and Cosine Transforms}},
volume = {42},
year = {1994}
}
@article{Smith1999,
abstract = {Use of a bilinear conformai map to achieve a frequency warping nearly identical to that of the Bark frequency scale is described. Because the map takes the unit circle to itself, its form is that of the transfer function of a first-order allpass filter. Since it is a first-order map, it preserves the model order of rational systems, making it a valuable frequency warping technique for use in audio filter design. A closed-form weighted-equationor method is derived that computes the optimal mapping coefficient as a function of sampling rate, and the solution is shown to be generally indistinguishable from the optimal least-squares solution. The optimal Chebyshev mapping is also found to be essentially identical to the optimal least-squares solution. The expression 0.8517 [arctan(0.06583fs)]1/2-0.916 is shown to accurately approximate the optimal allpass coefficient as a function of sampling rate fs in kHz for sampling rates greater than 1 kHz. A filter design example is included that illustrates improvements due to carrying out the design over a Bark scale. Corresponding results are also given and compared for approximating the related "equivalent rectangular bandwidth (ERB) scale≤ of Moore and Glasberg using a first-order allpass transformation. Due to the higher frequency resolution called for by the ERB scale, particularly at low frequencies, the first-order conformal map is less able to follow the desired mapping, and the error is two to three times greater than the Bark-scale case, depending on the sampling rate. {\textcopyright} 1999 IEEE Publisher Item Identifier S 1063-6676(99)07979-1.},
author = {Smith, Julius O.},
doi = {10.1109/89.799695},
isbn = {- 1063-6676},
issn = {10636676},
journal = {IEEE Transactions on Speech and Audio Processing},
keywords = {Bark,Bilinear transform,ERB,Filter design,Frequency warping},
number = {6},
pages = {697--708},
pmid = {799695},
title = {{Bark and ERB Bilinear Transforms}},
volume = {7},
year = {1999}
}
@article{Silvescu1999,
abstract = {A new kind of neuron model that has a Fourier-like in/out function\nis introduced. The model is discussed in a general theoretical framework\nand some completeness theorems are presented. Current experimental\nresults show that the new model outperforms, by a large margin both in\nrepresentational power and convergence speed, the classical mathematical\nmodel of neuron based on weighted sum of inputs filtered by a nonlinear\nfunction. The new model is also appealing from a neurophysiological\npoint of view because it produces a more realistic representation by\nconsidering the inputs as oscillations},
author = {Silvescu, A.},
doi = {10.1109/IJCNN.1999.831544},
isbn = {0-7803-5529-6},
issn = {1098-7576},
journal = {IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)},
pages = {488--491},
title = {{Fourier neural networks}},
url = {http://ieeexplore.ieee.org/document/831544/},
volume = {1},
year = {1999}
}
@article{Rowland1999,
abstract = {The usual suggestion for the longitudinally propagating momentum carried by a transverse wave on a string is shown to lead to paradoxes. Numerical simulations provide clues for resolving these paradoxes. The usual formula for wave momentum should be changed by a factor of 2 and the involvement of the cogenerated longitudinal waves is shown to be of crucial importance.},
author = {Rowland, David R. and Pask, Colin},
doi = {10.1119/1.19272},
issn = {0002-9505},
journal = {American Journal of Physics},
number = {5},
pages = {378--388},
title = {{The missing wave momentum mystery}},
url = {http://aapt.scitation.org/doi/10.1119/1.19272},
volume = {67},
year = {1999}
}
@article{Cecotti2008,
abstract = {In BCI (brain - computer interface) systems, brain signals must be processed to identify distinct activities that convey different mental states. We propose a new technique for the classification of electroencephalographic (EEG) steady-state visual e...},
author = {Cecotti, Hubert and Graeser, Axel},
isbn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition (ICPR)},
pages = {1--4},
title = {{Convolutional Neural Network with embedded Fourier Transform for EEG classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761638%5Cnpapers3://publication/doi/10.1109/ICPR.2008.4761638},
year = {2008}
}
@article{Uncini,
author = {Uncini, Aurelio},
title = {{Sound Synthesis by Flexible Activation Function Recurrent Neural Networks}}
}
@article{G-1999,
abstract = {This paper presents a model of the envelope of the additive parameters of isolated musical sounds, along with a new method for the estimation of the important envelope split- point times. The model consists of start, attack, sustain, release, and end segments with variable split-point amplitude and time. The estimation of the times is done using smoothed derivatives of the envelopes. The estimated split-point values can be used together with a curve-form model introduced in this paper in the analysis/synthesis of musical sounds. The envelope model can recreate noise-less musical sounds with good fidelity, and the method for the estimation of the envelope times performs significantly better than the classical percentage- based method.},
author = {G-, Cost and Effects, Digital Audio},
doi = {10.1109/MMSP.2001.962718},
journal = {Audio},
number = {1},
pages = {9--12},
title = {{Envelope model of isolated musical sounds}},
year = {1999}
}
@article{Graves2013b,
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
archivePrefix = {arXiv},
arxivId = {1308.0850},
author = {Graves, Alex},
doi = {10.1145/2661829.2661935},
eprint = {1308.0850},
isbn = {2000201075},
issn = {18792782},
pages = {1--43},
pmid = {23459267},
title = {{Generating Sequences With Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1308.0850},
year = {2013}
}
@article{Embrechts2009,
abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used.We give a survey of these tools, point out the respective merits and provide some numerical examples.},
author = {Embrechts, Paul and Frei, Marco},
doi = {10.1007/s00186-008-0249-2},
issn = {14322994},
journal = {Mathematical Methods of Operations Research},
keywords = {Compound distributions,Fast Fourier transform,Panjer recursion,Risk management},
number = {3},
pages = {497--508},
title = {{Panjer recursion versus FFT for compound distributions}},
volume = {69},
year = {2009}
}
@article{Merri2014,
abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
archivePrefix = {arXiv},
arxivId = {1409.1259},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
doi = {10.3115/v1/w14-4012},
eprint = {1409.1259},
pages = {103--111},
title = {{On the Properties of Neural Machine Translation: Encoder–Decoder Approaches}},
year = {2015}
}
@article{Lillicrap,
abstract = {The brain processes information through many layers of neurons. This deep architecture is representationally powerful, but it complicates learning by making it hard to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame to a neuron by computing exactly how it contributed to an error. To do this, it multiplies error signals by matrices consisting of all the synaptic weights on the neuron's axon and farther downstream. This operation requires a precisely choreographed transport of synaptic weight information, which is thought to be impossible in the brain. Here we present a surprisingly simple algorithm for deep learning, which assigns blame by multiplying error signals by random synaptic weights. We show that a network can learn to extract useful information from signals sent through these random feedback connections. In essence, the network learns to learn. We demonstrate that this new mechanism performs as quickly and accurately as backpropagation on a variety of problems and describe the principles which underlie its function. Our demonstration provides a plausible basis for how a neuron can be adapted using error signals generated at distal locations in the brain, and thus dispels long-held assumptions about the algorithmic constraints on learning in neural circuits.},
archivePrefix = {arXiv},
arxivId = {1411.0247},
author = {Lillicrap, Timothy P. and Cownden, Daniel and Tweed, Douglas B. and Akerman, Colin J.},
eprint = {1411.0247},
pages = {1--27},
title = {{Random feedback weights support learning in deep neural networks}},
url = {http://arxiv.org/abs/1411.0247},
year = {2014}
}
@article{Kopparapu,
archivePrefix = {arXiv},
arxivId = {arXiv:1406.3172v1},
author = {Kopparapu, Sunil and Satish, M},
eprint = {arXiv:1406.3172v1},
number = {2},
pages = {1--7},
title = {{Optimal Gaussian Filter for Effective Noise Filtering}}
}
@article{Courtney2015,
abstract = {Fourier transform methods are used to analyze functions and data sets to provide frequencies, amplitudes, and phases of underlying oscillatory components. Fast Fourier transform (FFT) methods offer speed advantages over evaluation of explicit integrals (EI) that define Fourier transforms. This paper compares frequency, amplitude, and phase accuracy of the two methods for well resolved peaks over a wide array of data sets including cosine series with and without random noise and a variety of physical data sets, including atmospheric $\mathrm{CO_2}$ concentrations, tides, temperatures, sound waveforms, and atomic spectra. The FFT uses MIT's FFTW3 library. The EI method uses the rectangle method to compute the areas under the curve via complex math. Results support the hypothesis that EI methods are more accurate than FFT methods. Errors range from 5 to 10 times higher when determining peak frequency by FFT, 1.4 to 60 times higher for peak amplitude, and 6 to 10 times higher for phase under a peak. The ability to compute more accurate Fourier transforms has promise for improved data analysis in many fields, including more sensitive assessment of hypotheses in the environmental sciences related to $\mathrm{CO_2}$ concentrations and temperature. Other methods are available to address different weaknesses in FFTs; however, the EI method always produces the most accurate output possible for a given data set. On the 2011 Lenovo ThinkPad used in this study, an EI transform on a 10,000 point data set took 31 seconds to complete. Source code (C) and Windows executable for the EI method are available at https://sourceforge.net/projects/amoreaccuratefouriertransform/.},
archivePrefix = {arXiv},
arxivId = {1507.01832},
author = {Courtney, Elya and Courtney, Michael},
eprint = {1507.01832},
title = {{A More Accurate Fourier Transform}},
url = {http://arxiv.org/abs/1507.01832},
year = {2015}
}
@article{Vincent,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7091v3},
author = {Vincent, Pascal and Bouthillier, Xavier},
eprint = {arXiv:1412.7091v3},
pages = {1--15},
title = {{Efficient Exact Gradient Update for training Deep Networks with Very Large Sparse Targets [ Technical report ]}}
}
@article{Baharev2015,
abstract = {Abstract Given a directed graph G, a feedback arc set of G is a subset of its edges containing at least one edge of every cycle in G. Finding a feedback arc set of minimum cardinality is the minimum feedback arc set problem. The present paper focuses on large and sparse ...},
author = {Baharev, Ali and Schichl, Hermann and Neumaier, Arnold},
journal = {University of Vienna},
keywords = {1,a directed graph g,e,edges of,graph if it has,introduction,is a pair,it is a simple,linear,maximum acyclic subgraph,minimum feedback arc set,minimum feedback vertex set,no multiple edges or,of finite sets,ordering problem,self-loops,tearing,the edges e,the vertices v and,v},
pages = {35--60},
title = {{An exact method for the minimum feedback arc set problem}},
volume = {10},
year = {2015}
}
@article{Moon2014,
abstract = {Complex sound like speech can be characterized as the sum of number of amplitude-modulated signals representing the outputs of an array of narrow frequency bands. Temporal information at the output of each band can be separated into temporal fine structure (TFS), the rapid oscillations close to the center frequency and temporal envelope (ENV), slower amplitude modulations superimposed on the TFS. TFS information can be carried in the pattern of phase locking to the stimulus waveform, while ENV by the changes in firing rate over time. The relative importance of temporal ENV and TFS information in understanding speech has been studied using various sound-processing techniques. A number of studies demonstrated that ENV cues are associated with speech recognition in quiet, while TFS cues are possibly linked to melody/pitch perception and listening to speech in a competing background. However, there are evidences that recovered ENV from TFS as well as TFS itself may be partially responsible for speech recognition. Current technologies used in cochlear implants (CI) are not efficient in delivering the TFS cues, and new attempts have been made to deliver TFS information into sound-processing strategy in CI. We herein discuss the current updated findings of TFS with a literature review. {\textcopyright} 2014 The Korean Audiological Society.},
author = {Moon, Il Joon and Hong, Sung Hwa},
doi = {10.7874/kja.2014.18.1.1},
issn = {20933797},
journal = {Korean Journal of Audiology},
keywords = {Hearing loss,Speech perception,Temporal envelope,Temporal fine structure},
number = {1},
pages = {1--7},
title = {{What is temporal fine structure and why is it important?}},
volume = {18},
year = {2014}
}
@article{Nayebi,
abstract = {We compare the performance of two different types of recurrent neural networks (RNNs) for the task of algorithmic music generation, with audio waveforms as input. In particular, we focus on RNNs that have a sophisticated gating mecha-nism, namely, the Long Short-Term Memory (LSTM) network and the recently introduced Gated Recurrent Unit (GRU). Our results indicate that the generated outputs of the LSTM network were significantly more musically plausible than those of the GRU.},
author = {Nayebi, Aran and Vitelli, Matt},
isbn = {978-3-531-94308-4},
journal = {Deep Learning for Natural Language Processing},
pages = {1--6},
title = {{GRUV: Algorithmic Music Generation using Recurrent Neural Networks}},
url = {https://web.stanford.edu/$\sim$anayebi/projects/CS_224D_Final_Project_Writeup.pdf},
year = {2015}
}
@article{Ioffe,
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {448--456},
title = {{Batch normalization: Accelerating deep network training by reducing internal covariate shift}},
volume = {1},
year = {2015}
}
@article{Highlander2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1601.06815v1},
author = {Highlander, Tyler},
eprint = {arXiv:1601.06815v1},
pages = {1--9},
title = {{arXiv : 1601 . 06815v1 [ cs . NE ] 25 Jan 2016 Very Efficient Training of Convolutional Neural Networks using Fast Fourier}},
year = {2015}
}
@article{Reyes2015,
abstract = {Following a letter by Bassett, we show first that it is possible to find an analytical approximation to the error function in terms of a finite series of hyperbolic tangents from the supersymmetric (SUSY) solution of the Poschl-Teller eigenvalue problem in quantum mechanics (QM). Afterwards, we show that the second order differential equation for the derivatives of Dawson's function can be found in another SUSY related eigenvalue problem, where the factorization of the simple harmonic oscillator Hamiltonian renders the wrong-sign Hermite differential equation, and that Dawson's second order differential equation possess a singular SUSY type relation to this equation.},
archivePrefix = {arXiv},
arxivId = {1510.03735},
author = {Reyes, Marco A. and Arcos-Olalla, Rafael},
eprint = {1510.03735},
issn = {0035-001X},
keywords = {02,05,1,10,11,30,dawson,error function,gp,ln,mv,pacs numbers,pb,s function,supersymmetry,the error function,the integral,which is defined by},
number = {2},
pages = {1--13},
title = {{Supersymmetric features of the Error and Dawson's functions}},
url = {http://arxiv.org/abs/1510.03735},
year = {2015}
}
@article{He2016,
abstract = {A speech signal can be viewed as a high frequency carrier signal containing the temporal fine structure (TFS) that is modulated by a low frequency envelope (ENV). A widely used method to decompose a speech signal into the TFS and ENV is the Hilbert transform. Although this method has been available for about one century and is widely applied in various kinds of speech processing tasks (e.g. speech chimeras), there are only very few speech processing packages that contain readily available functions for the Hilbert transform, and there is very little textbook type literature tailored for speech scientists to explain the processes behind the transform. With this paper we provide the code for carrying out the Hilbert operation to obtain the TFS and ENV in the widely used speech processing software Praat, and explain the basics of the procedure. To verify our code, we compare the Hilbert transform in Praat with a widely applied function for the same purpose in MATLAB ("hilbert(.)"). We can confirm that both methods arrive at identical outputs.},
author = {He, Lei and Dellwo, Volker},
doi = {10.21437/Interspeech.2016-1447},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Amplitude envelope,Hilbert transform,Praat,Temporal fine structure},
number = {September},
pages = {530--534},
title = {{A Praat-based algorithm to extract the amplitude envelope and temporal fine structure using the Hilbert transform}},
volume = {08-12-Sept},
year = {2016}
}
@article{Esser,
abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (/) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii') can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
archivePrefix = {arXiv},
arxivId = {1603.08270},
author = {Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and {Di Nolfo}, Carmelo and Datta, Pallab and Amir, Arnon and Taba, Brian and Flickner, Myron D. and Modha, Dharmendra S.},
doi = {10.1073/pnas.1604850113},
eprint = {1603.08270},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Convolutional network,Neural network,Neuromorphic,Truenorth},
number = {41},
pages = {11441--11446},
title = {{Convolutional networks for fast, energy-efficient neuromorphic computing}},
volume = {113},
year = {2016}
}
@misc{Dewick2002,
abstract = {This paper seeks to contribute towards the construction and application of a method to assess the long-term impact of the development of their technological technologies on the environment. The paper identifies the effect of three pervasive technologies – biotechnology, information technology and nanotechnology – on the production of a range of sectors and their consequent environmental effects. The sectors are selected according to taxonomies of characteristics. The technological impact is assessed qualitatively in terms of changes in production scale and resource intensity and their resulting impact on industrial greenhouse gas emissions},
author = {Dewick, Paul and Green, Ken and Miozzo, Marcela},
number = {January},
pages = {1--31},
title = {{Technological Change, Industry Structure and the Environment}},
year = {2002}
}
@misc{,
title = {{._Sawhney, Verona e Prandelli_2005(JIM)_COLLABORATING TO CREATE- THE INTERNET AS A PLATFORM FOR CUSTOMER ENGAGEMENT IN PRODUCT INNOVATION.pdf}}
}
@misc{,
title = {{Unknown - Unknown - Leaps and bounds.pdf.pdf}}
}
@misc{,
title = {{Unknown - Unknown - Democratizing Innovation.pdf.pdf}}
}
@misc{Alves1992,
abstract = {O artigo analisa o papel da revis{\~{a}}o da bibliografia em trabalhos de pesquisa e aponta as principais defici{\^{e}}ncias observadas em teses de mestrado e doutorado, no que se refere a esse aspecto. A primeira se{\c{c}}{\~{a}}o destaca a import{\^{a}}ncia da an{\'{a}}lise cr{\'{i}}tica do estado atual do conhecimento na {\'{a}}reade interesse do pesquisador para a problematiza{\c{c}}{\~{a}}o do temaa ser investigado. A segunda trata do referencial te{\'{o}}rico e discute as dificuldades encontradas na constru{\c{c}}{\~{a}}o te{\'{o}}rica no campo da educa{\c{c}}{\~{a}}o. Finalmente, a terceira se{\c{c}}{\~{a}}o apresenta os equ{\'{i}}vocos mais freq{\"{u}}entes observados em revis{\~{o}}es de bibliografia, utilizando o recurso da caricatura para tornar mais vis{\'{i}}veis certos tra{\c{c}}os.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Alves, Alda Judith},
booktitle = {Cadernos de Pesquisa},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
number = {81},
pages = {53--60},
pmid = {25246403},
title = {{A "revis{\~{a}}o da bibliografia"em teses e disserta{\c{c}}{\~{o}}s: meus tipos inesquec{\'{i}}veis}},
url = {http://www.fcc.org.br/pesquisa/publicacoes/cp/arquivos/916.pdf},
year = {1992}
}
@article{,
isbn = {9781479903566},
journal = {Computer Engineering},
pages = {3572--3576},
title = {{KERNEL RECURRENT SYSTEM TRAINED BY REAL-TIME RECURRENT LEARNING ALGORITHM Pingping Zhu , Jos ´ University of Florida Electrical and Computer Engineering}},
year = {2013}
}
@misc{,
title = {{Wang et al. - 2011 - Rapid parametric design methods for shoe-last customization.pdf}}
}
@article{Raczynski2013a,
author = {Raczy{\'{n}}ski, Stanis{\l}aw A. and Vincent, Emmanuel and Sagayama, Shigeki},
doi = {10.1109/TASL.2013.2258012},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
number = {9},
pages = {1830 -- 1840},
title = {{Dynamic Bayesian networks for symbolic polyhonic pitch modeling}},
volume = {21},
year = {2013}
}
@article{Conference2014,
author = {Conference, Ieee International and Processing, Signal},
isbn = {9781479928934},
number = {May},
pages = {3136--3140},
title = {{POLYPHONIC PIANO TRANSCRIPTION USING NON-NEGATIVE MATRIX FACTORISATION WITH GROUP SPARSITY Ken O ' Hanlon and Mark D . Plumbley Queen Mary University of London}},
volume = {1},
year = {2014}
}
@article{Phumrattanaprapin2016a,
author = {Phumrattanaprapin, Khanittha},
keywords = {chine,hierarchical extreme learning ma-,hierarchical learning,multilayer perceptron},
number = {2},
pages = {196--204},
title = {{Machine with Multilayer Perceptron}},
volume = {10},
year = {2016}
}
@article{Schaffner2017,
author = {Schaffner, Michael and Member, Student and Scheidegger, Florian and Cavigelli, Lukas and Member, Student and Kaeslin, Hubert and Member, Senior and Benini, Luca and Smolic, Aljosa},
title = {{Ro of Ro of}},
volume = {4},
year = {2017}
}
@article{DavidA.Cacchione1997,
author = {{David A. Cacchione}},
doi = {10.1511/2011.89.106},
isbn = {2136240900},
issn = {0003-0996},
number = {2},
pages = {108--112},
title = {{American Scientist}},
volume = {85},
year = {1997}
}
@article{,
archivePrefix = {arXiv},
arxivId = {1102.0183},
doi = {10.1109/5.726791},
eprint = {1102.0183},
isbn = {0018-9219},
issn = {00189219},
pmid = {15823584},
title = {{Lecun-98}}
}
@article{Bengio2007a,
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), reasoning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with minimal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally limited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very inefficient in terms of required number of computational elements and examples. Second, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learning) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more abstract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence.},
author = {Bengio, Yoshua and Lecun, Yann},
journal = {New York},
number = {1},
pages = {1--41},
title = {{Scaling Learning Algorithms towards AI To appear in “ Large-Scale Kernel Machines ”,}},
year = {2007}
}
@article{Tang2014a,
abstract = {In this paper, we propose a joint segmenta- tion and classification framework for sen- timent analysis. Existing sentiment clas- sification algorithms typically split a sen- tence as a word sequence, which does not effectively handle the inconsistent senti- ment polarity between a phrase and the words it contains, such as “not bad” and “a great deal of ”. We address this issue by developing a joint segmentation and classification framework (JSC), which si- multaneously conducts sentence segmen- tation and sentence-level sentiment classi- fication. Specifically, we use a log-linear model to score each segmentation candi- date, and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier. A marginal log-likelihood objective function is de- vised for the segmentation model, which is optimized for enhancing the sentiment classification performance. The joint mod- el is trained only based on the annotat- ed sentiment polarity of sentences, with- out any segmentation annotations. Experi- ments on a benchmark Twitter sentimen- t classification dataset in SemEval 2013 show that, our joint model performs com- parably with the state-of-the-art methods.},
author = {Tang, Duyu and Wei, Furu and Qin, Bing and Dong, Li and Liu, Ting and Zhou, Ming},
doi = {10.1109/TASLP.2015.2449071},
isbn = {2329-9290 VO  - 23},
issn = {2329-9290},
journal = {Proceedings of the 2014 Conferenve on Empirical Methods in Natural Language Processing (EMNLP)},
number = {2002},
pages = {477--487},
title = {{A Joint Segmentation and Classification Framework for Sentiment Analysis}},
volume = {23},
year = {2014}
}
@article{Boulanger-lewandowski,
author = {Boulanger-lewandowski, Nicolas},
isbn = {9781479928934},
journal = {Ieee},
number = {2},
pages = {5417--5421},
title = {{PHONE SEQUENCE MODELING WITH RECURRENT NEURAL NETWORKS Universit ´ e de Montr ´ Montr ´ Jasha Droppo Mike Seltzer Dong Yu One Microsoft Way}},
year = {2014}
}
@misc{,
title = {{Estelles-Arolas, Gonzalez-Ladron-de-Guevara - 2012 - Towards an integrated crowdsourcing definition.pdf}}
}
@article{Song2016,
author = {Song, Qing and Zhao, Xu and Fan, Haijin and Wang, Danwei},
doi = {10.1109/TNNLS.2016.2518223},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {forecasting},
mendeley-tags = {forecasting},
number = {5},
pages = {1068--1081},
publisher = {IEEE},
title = {{Robust Recurrent Kernel Online Learning}},
volume = {28},
year = {2016}
}
@article{Sotelo2017,
abstract = {We present Char2Wav, an end-to-end model for speech synthesis. Char2Wav has two components: a reader and a neural vocoder . The reader is an encoder- decoder model with attention. The encoder is a bidirectional recurrent neural net- work that accepts text or phonemes as inputs, while the decoder is a recurrent neu- ral network (RNN) with attention that produces vocoder acoustic features. Neural vocoder refers to a conditional extension of SampleRNN which generates raw waveform samples from intermediate representations. Unlike traditional models for speech synthesis, Char2Wav learns to produce audio directly from text.},
author = {Sotelo, Jose and Mehri, Soroush and Kumar, Kundan and Santos, Joao Felipe and Kastner, Kyle and Courville, Aaron and Bengio, Yoshua},
journal = {Iclr},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
number = {October},
pages = {44--51},
title = {{Char2Wav: End-to-End Speech Synthesis}},
url = {https://openreview.net/pdf?id=B1VWyySKx},
year = {2017}
}
@article{werbos74,
author = {Thesis, Science and Appl, Ph D and Harvard, Math},
journal = {Doctoral Dissertation, Applied Mathematics, Harvard University, MA},
number = {January 1974},
title = {{Beyond Regression : New Tools for Prediction and Analysis in the Behavioral}},
year = {2018}
}
@article{Sangkloy2016,
abstract = {Recently, there have been several promising methods to generate realistic imagery from deep convolutional networks. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to 'scribble' over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach can generate more realistic, more diverse, and more controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.},
archivePrefix = {arXiv},
arxivId = {1612.00835},
author = {Sangkloy, Patsorn and Lu, Jingwan and Fang, Chen and Yu, Fisher and Hays, James},
eprint = {1612.00835},
journal = {arXiv preprint arXiv:1612.00835},
keywords = {image synthesis,state of the art},
mendeley-tags = {image synthesis,state of the art},
title = {{Scribbler: Controlling Deep Image Synthesis with Sketch and Color}},
url = {http://arxiv.org/abs/1612.00835},
year = {2016}
}
@article{Cortes2016,
abstract = {We present new algorithms for adaptively learning artificial neural networks. Our algorithms (AdaNet) adaptively learn both the structure of the network and its weights. They are based on a solid theoretical analysis, including data-dependent generalization guarantees that we prove and discuss in detail. We report the results of large-scale experiments with one of our algorithms on several binary classification tasks extracted from the CIFAR-10 dataset. The results demonstrate that our algorithm can automatically learn network structures with very competitive performance accuracies when compared with those achieved for neural networks found by standard approaches.},
archivePrefix = {arXiv},
arxivId = {1607.01097},
author = {Cortes, Corinna and Gonzalvo, Xavi and Kuznetsov, Vitaly and Mohri, Mehryar and Yang, Scott},
eprint = {1607.01097},
journal = {arXiv preprint arXiv:1607.01097},
keywords = {evolutive},
mendeley-tags = {evolutive},
title = {{AdaNet: Adaptive Structural Learning of Artificial Neural Networks}},
url = {http://arxiv.org/abs/1607.01097},
year = {2016}
}
@article{Li2015,
author = {Li, Junnan and Lam, Edmund Y.},
doi = {10.1109/IST.2015.7294547},
institution = {IEEE},
isbn = {9781479986330},
issn = {1558-2809},
journal = {Imaging Systems and Techniques (IST), 2015 IEEE International Conference on},
keywords = {emo,facial expression,gabor filters,kernel principal component analysis,multi-layer neural network},
mendeley-tags = {facial expression},
pages = {1--6},
title = {{Facial expression recognition using deep neural networks}},
year = {2015}
}
@article{Bas2016,
abstract = {In recent years, artificial neural networks have been commonly used for time series forecasting by researchers from various fields. There are some types of artificial neural networks and feed forward artificial neural networks model is one of them. Although feed forward artificial neural networks gives successful forecasting results they have a basic problem. This problem is architecture selection problem. In order to eliminate this problem, Yadav et al. (2007) proposed multiplicative neuron model artificial neural network. In this study, differential evolution algorithm is proposed for the training of multiplicative neuron model for forecasting. The proposed method is applied to two well-known different real world time series data.},
author = {Bas, Eren},
doi = {10.1515/jaiscr-2016-0001},
issn = {24496499},
journal = {Journal of Artificial Intelligence and Soft Computing Research},
keywords = {Artificial neural networks,Differential evolution algorithm,Forecasting,Multiplicative neuron model,evolutive,forecasting},
mendeley-tags = {evolutive,forecasting},
number = {1},
pages = {5--11},
title = {{The training of multiplicative neuron model based artificial neural networks with differential evolution algorithm for forecasting}},
volume = {6},
year = {2016}
}
@article{PingpingZhu2013,
author = {{Pingping Zhu}, Jos{\'{e}} and Pr{\'{i}}ncipe, e C. and Zhu, Pingping and Pr\'\incipe, Jos{\'{e}} C},
isbn = {9781479903566},
journal = {Computer Engineering},
keywords = {forecasting},
mendeley-tags = {forecasting},
pages = {3572--3576},
title = {{KERNEL RECURRENT SYSTEM TRAINED BY REAL-TIME RECURRENT LEARNING ALGORITHM}},
year = {2013}
}
@article{Maas2013,
abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
author = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
journal = {in ICML Workshop on Deep Learning for Audio, Speech and Language Processing},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
number = {1},
pages = {6},
title = {{Rectifier nonlinearities improve neural network acoustic models}},
url = {https://web.stanford.edu/$\sim$awni/papers/relu_hybrid_icml2013_final.pdf},
volume = {28},
year = {2013}
}
@inproceedings{he2016deep,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
year = {2016}
}
@book{bishop06,
author = {Abramson, N. and Braverman, D. and Sebestyen, G.},
booktitle = {IEEE Transactions on Information Theory},
doi = {10.1109/TIT.1963.1057854},
issn = {15579654},
number = {4},
pages = {257--261},
publisher = {springer},
title = {{Pattern recognition and machine learning}},
volume = {9},
year = {1963}
}
@article{leshno93,
abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold. {\textcopyright} 1993 Pergamon Press Ltd.},
author = {Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
doi = {10.1016/S0893-6080(05)80131-5},
issn = {08936080},
journal = {Neural Networks},
keywords = {Activation functions,Lp($\mu$) approximation,Multilayer feedforward networks,Role of threshold,Universal approximation capabilities},
number = {6},
pages = {861--867},
publisher = {Elsevier},
title = {{Multilayer feedforward networks with a nonpolynomial activation function can approximate any function}},
volume = {6},
year = {1993}
}
@article{socher2014recursive,
abstract = {I introduced a max-margin,structure prediction framework based on Recursive Neural Networks (RNNs) for nding hierarchical structure in multiple modalities. Recursion in this case pertains to the idea that the same neural network is applied repeatedly on different components of a sentence. Since this model showed much promise for both language and image understanding, I decided to further investigate the space of recursive deep learning models. In this thesis, I explore model variations along three major axes in order to gain insights into hierarchical feature learning, building fast, practical, state of the art NLP systems and semantic compositionality, the important quality of natural language that allows speakers to determine the meaning of a longer expression based on the meanings of its words and the rules used to combine them. I explore unsupervised learning of word and sentence vectors using reconstruction errors. My my parsing work uses a simple linear scoring function and sentiment and relation classi cation use softmax classi ers to predict a label for each node and phrase in the tree. The standard RNN composition function is based on a single neural network layer that takes as input two phrase or word vectors and uses the same set of weights at every node in the parse tree to compute higher order phrase vectors. It is not expressive enough to capture all types of compositions. I explored several variants of composition functions. I have worked on constituency parsing, whose goal it is to learn the correct grammatical analysis of a sentence and produce a tree structure. Another approach allowed the actual task, such as sentiment prediction or reconstruction error, to determine the tree structure. CHANGES vs. 2011a [Dynamic pooling and unfolding recursive autoencoders for paraphrase detection], mentioned by Zhou, Troyanskaya - Deep Supervised and Convolutional Generative Stochastic Network for Protein Secondary Structure Prediction [2014] 1. For optimization of objective function, the diagonal variant of AdaGrad has much better optima in various experiments of this thesis, and converges more quickly than L-BFGS used in 2011a 2. The standard RNN composition function [used in 2011a] it is not expressive enough to capture all types of compositions. Hence, I explored several variants of composition functions.},
author = {Socher, Richard},
journal = {PhD thesis},
keywords = {Richard Socher},
number = {August},
pages = {189},
publisher = {Citeseer},
title = {{Recursive Deep Learning for Natural Language Processing and Computer Vision}},
year = {2014}
}
@inproceedings{choi2017convolutional,
abstract = {We propose two deep neural network architectures for classification of arbitrary-length electrocardiogram (ECG) recordings and evaluate them on the atrial fibrillation (AF) classification data set provided by the PhysioNet/CinC Challenge 2017. The first architecture is a deep convolutional neural network (CNN) with averaging-based feature aggregation across time. The second architecture combines convolutional layers for feature extraction with long-short term memory (LSTM) layers for temporal aggregation of features. As a key ingredient of our training procedure we introduce a simple data augmentation scheme for ECG data and demonstrate its effectiveness in the AF classification task at hand. The second architecture was found to outperform the first one, obtaining an F1score of 82.1% on the hidden challenge testing set.},
author = {Zihlmann, Martin and Perekrestenko, Dmytro and Tschannen, Michael},
booktitle = {arXiv},
issn = {23318422},
organization = {IEEE},
pages = {2392--2396},
title = {{Convolutional recurrent neural networks for electrocardiogram classification}},
year = {2017}
}
@article{mao2000probabilistic,
author = {Mao, Ke Zhi and Tan, K-C and Ser, Wee},
journal = {IEEE Transactions on neural networks},
number = {4},
pages = {1009--1016},
publisher = {IEEE},
title = {{Probabilistic neural-network structure determination for pattern classification}},
volume = {11},
year = {2000}
}
@article{egmont2002image,
author = {Egmont-Petersen, Michael and de Ridder, Dick and Handels, Heinz},
journal = {Pattern recognition},
number = {10},
pages = {2279--2301},
publisher = {Elsevier},
title = {{Image processing with neural networks—a review}},
volume = {35},
year = {2002}
}
@inproceedings{kasabov2012neucube,
author = {Kasabov, Nikola},
booktitle = {ANNPR},
organization = {Springer},
pages = {225--243},
title = {{NeuCube EvoSpike Architecture for Spatio-temporal Modelling and Pattern Recognition of Brain Signals.}},
year = {2012}
}
@article{jiang1999image,
author = {Jiang, J},
journal = {Signal Processing: Image Communication},
number = {9},
pages = {737--760},
publisher = {Elsevier},
title = {{Image compression with neural networks--a survey}},
volume = {14},
year = {1999}
}
@article{hinton2012deep,
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition. {\textcopyright} 2012 IEEE.},
author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel Rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara and Kingsbury, Brian},
doi = {10.1109/MSP.2012.2205597},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {6},
pages = {82--97},
publisher = {IEEE},
title = {{Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups}},
volume = {29},
year = {2012}
}
@article{ritchie2003optimizationof,
author = {Ritchie, Marylyn D and White, Bill C and Parker, Joel S and Hahn, Lance W and Moore, Jason H},
journal = {BMC bioinformatics},
number = {1},
pages = {28},
publisher = {BioMed Central},
title = {{Optimizationof neural network architecture using genetic programming improvesdetection and modeling of gene-gene interactions in studies of humandiseases}},
volume = {4},
year = {2003}
}
@inproceedings{goodfellow2014generative,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in neural information processing systems},
pages = {2672--2680},
title = {{Generative adversarial nets}},
year = {2014}
}
@article{Raczynski2013,
abstract = {Symbolic pitch modeling is a way of incorporating knowledge about relations between pitches into the process of analyzing musical information or signals. In this paper, we propose a family of probabilistic symbolic polyphonic pitch models, which account for both the 'horizontal' and the 'vertical' pitch structure. These models are formulated as linear or log-linear interpolations of up to five sub-models, each of which is responsible for modeling a different type of relation. The ability of the models to predict symbolic pitch data is evaluated in terms of their cross-entropy, and of a newly proposed 'contextual cross-entropy' measure. Their performance is then measured on synthesized polyphonic audio signals in terms of the accuracy of multiple pitch estimation in combination with a Nonnegative Matrix Factorization-based acoustic model. In both experiments, the log-linear combination of at least one 'vertical' (e.g., harmony) and one 'horizontal' (e.g., note duration) sub-model outperformed a pitch-dependent Bernoulli prior by more than 60% in relative cross-entropy and 3% in absolute multiple pitch estimation accuracy. This work provides a proof of concept of the usefulness of model interpolation, which may be used for improved symbolic modeling of other aspects of music in the future. {\textcopyright} 2013 IEEE.},
author = {Raczynski, Stanislaw A. and Vincent, Emmanuel and Sagayama, Shigeki},
doi = {10.1109/TASL.2013.2258012},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Dynamic Bayesian Networks,multipitch analysis,music transcription,symbolic pitch modeling},
mendeley-tags = {music transcription},
number = {9},
pages = {1830--1840},
title = {{Dynamic bayesian networks for symbolic polyphonic pitch modeling}},
volume = {21},
year = {2013}
}
@article{Bengio2007,
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), rea- soning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, withmin- imal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally lim- ited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very ineffi- cient in terms of required number of computational elements and examples. Sec- ond, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learn- ing) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more ab- stract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence. 1},
author = {Bengio, Yoshua and {LeCun}, Yann and Lecun, Yann},
doi = {10.1.1.72.4580},
isbn = {1002620262},
issn = {00099104},
journal = {Large Scale Kernel Machines},
keywords = {theory},
mendeley-tags = {theory},
number = {1},
pages = {321--360},
pmid = {11359439},
title = {{Scaling Learning Algorithms towards AI}},
year = {2007}
}
@article{Clune2013,
abstract = {A central biological question is how natural organisms are so evolvable (capable of quickly adapting to new environments). A key driver of evolvability is the widespread modularity of biological networks--their organization as functional, sparsely connected subunits--but there is no consensus regarding why modularity itself evolved. Although most hypotheses assume indirect selection for evolvability, here we demonstrate that the ubiquitous, direct selection pressure to reduce the cost of connections between network nodes causes the emergence of modular networks. Computational evolution experiments with selection pressures to maximize network performance and minimize connection costs yield networks that are significantly more modular and more evolvable than control experiments that only select for performance. These results will catalyse research in numerous disciplines, such as neuroscience and genetics, and enhance our ability to harness evolution for engineering purposes.},
archivePrefix = {arXiv},
arxivId = {1207.2743v1},
author = {Clune, J. and Mouret, J.-B. and Lipson, H.},
doi = {10.1098/rspb.2012.2863},
eprint = {1207.2743v1},
isbn = {1471-2954 (Electronic)\n0962-8452 (Linking)},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {computational biology,evolution},
number = {1755},
pages = {20122863--20122863},
pmid = {23363632},
title = {{The evolutionary origins of modularity}},
url = {http://rspb.royalsocietypublishing.org/cgi/doi/10.1098/rspb.2012.2863},
volume = {280},
year = {2013}
}
@article{Leshno1991,
author = {Leshno, Moshe and Schocken, Shimon},
keywords = {theory},
mendeley-tags = {theory},
number = {21},
pages = {1--16},
title = {{Multilayer Feedforward Networks with Non-Polynomial Activation Functions Can Approximate Any Function}},
url = {https://archive.nyu.edu/bitstream/2451/14384/1/IS-91-26.pdf},
year = {1991}
}
@article{M??ller2001,
abstract = {This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by discussing applications such as optical character recognition and DNA analysis.},
author = {M??ller, Klaus Robert and Mika, Sebastian and R??tsch, Gunnar and Tsuda, Koji and Sch??lkopf, Bernhard},
doi = {10.1109/72.914517},
isbn = {1045-9227},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Boosting,Fisher's discriminant,Kernel PCA,Kernel methods,Mathematical programming machines,Mercer kernels,Principal component analysis (PCA),Single-class classification,Support vector machines (SVMs),seminal},
mendeley-tags = {seminal},
number = {2},
pages = {181--201},
pmid = {18244377},
title = {{An introduction to kernel-based learning algorithms}},
volume = {12},
year = {2001}
}
@article{Tang2014,
abstract = {In this paper, we propose a joint segmentation and classification framework for sentence-level sentiment classification. It is widely recognized that phrasal information is crucial for sentiment classification. However, existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains, such as {'not bad,' 'bad'} and {'a great deal of,' 'great'}. We address this issue by developing a joint framework for sentence-level sentiment classification. It simultaneously generates useful segmentations and predicts sentence-level polarity based on the segmentation results. Specifically, we develop a candidate generation model to produce segmentation candidates of a sentence; a segmentation ranking model to score the usefulness of a segmentation candidate for sentiment classification; and a classification model for predicting the sentiment polarity of a segmentation. We train the joint framework directly from sentences annotated with only sentiment polarity, without using any syntactic or sentiment annotations in segmentation level. We conduct experiments for sentiment classification on two benchmark datasets: a tweet dataset and a review dataset. Experimental results show that: 1) our method performs comparably with state-of-The-art methods on both datasets; 2) joint modeling segmentation and classification outperforms pipelined baseline methods in various experimental settings.},
author = {Tang, Duyu and Qin, Bing and Wei, Furu and Dong, Li and Liu, Ting and Zhou, Ming},
doi = {10.1109/TASLP.2015.2449071},
isbn = {2329-9290 VO - 23},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Artificial intelligence,joint segmentation and classification,natural language processing,sentiment analysis,sentiment classification},
mendeley-tags = {sentiment analysis},
number = {11},
pages = {1750--1761},
title = {{A Joint Segmentation and Classification Framework for Sentence Level Sentiment Classification}},
volume = {23},
year = {2015}
}
@article{Mao2000,
author = {Mao, K Z and Tan, K C and Ser, W},
journal = {IEEE Transactions on Neural Networks},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
number = {4},
pages = {1009--1016},
title = {{Probabilistic neural network structure determination for pattern classification}},
volume = {11},
year = {2000}
}
@article{Ritchie2003,
abstract = {BACKGROUND: Appropriate definition of neural network architecture prior to data analysis is crucial for successful data mining. This can be challenging when the underlying model of the data is unknown. The goal of this study was to determine whether optimizing neural network architecture using genetic programming as a machine learning strategy would improve the ability of neural networks to model and detect nonlinear interactions among genes in studies of common human diseases. RESULTS: Using simulated data, we show that a genetic programming optimized neural network approach is able to model gene-gene interactions as well as a traditional back propagation neural network. Furthermore, the genetic programming optimized neural network is better than the traditional back propagation neural network approach in terms of predictive ability and power to detect gene-gene interactions when non-functional polymorphisms are present. CONCLUSION: This study suggests that a machine learning strategy for optimizing neural network architecture may be preferable to traditional trial-and-error approaches for the identification and characterization of gene-gene interactions in common, complex human diseases.},
author = {Ritchie, M D and White, B C and Parker, J S and Hahn, L W and Moore, J H},
doi = {10.1186/1471-2105-4-28},
isbn = {1471-2105 (Electronic)\r1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {*Epistasis,*Models,*Neural Networks (Computer),*Software,Algorithms,Artificial Intelligence,Gene Expression Regulation/*genetics,Genetic,Humans,Molecular Epidemiology/*methods/*trends,Polymorphism,Predictive Value of Tests,Research Design,Single Nucleotide/genetics,Software Validation,evolutive},
mendeley-tags = {evolutive},
pages = {28},
pmid = {12846935},
title = {{Optimization of neural network architecture using genetic programming improves detection and modeling of gene-gene interactions in studies of human diseases}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12846935},
volume = {4},
year = {2003}
}
@article{Srivastava2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different " thinned " networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
archivePrefix = {arXiv},
arxivId = {1102.4807},
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,model combination,neural networks,regularization,seminal},
mendeley-tags = {seminal},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversar- ial process; in which we simultaneously train two models: a generative model G that captures the data distribution; and a discriminative model D that estimates the probability that a sample came from the training data rather thanG. The train- ing procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D; a unique solution exists; with G recovering the training data distribution andD equal to 1 2 everywhere. In the case where G andD are defined by multilayer perceptrons; the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference net- works during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 1},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.2661v1},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
doi = {10.1001/jamainternmed.2016.8245},
eprint = {arXiv:1406.2661v1},
isbn = {1406.2661},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 27},
keywords = {seminal},
mendeley-tags = {seminal},
pages = {2672--2680},
title = {{Generative Adversarial Nets (NIPS version)}},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
year = {2014}
}
@article{Hayes2013,
author = {Hayes, Brian},
doi = {10.1511/2013.101.92},
issn = {00030996},
journal = {American Scientist},
number = {2},
pages = {92--97},
title = {{First links in the Markov chain}},
volume = {101},
year = {2013}
}
@article{Yosinski2014,
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
archivePrefix = {arXiv},
arxivId = {1411.1792},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
eprint = {1411.1792},
issn = {10495258},
keywords = {theory},
mendeley-tags = {theory},
pages = {1--9},
title = {{How transferable are features in deep neural networks?}},
url = {http://arxiv.org/abs/1411.1792},
year = {2014}
}
@article{Wu2017,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {Wu, Songtao and Zhong, Shenghua and Liu, Yan},
doi = {10.1007/s11042-017-4440-4},
eprint = {1512.03385},
isbn = {978-1-4673-6964-0},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Convolutional neural networks,Image steganalysis,Residual learning,object detection},
mendeley-tags = {object detection},
pages = {1--17},
pmid = {23554596},
title = {{Deep residual learning for image Recognition}},
year = {2017}
}
@article{Jiang1999,
abstract = {Apart from the existing technology on image compression represented by series of JPEG, MPEG and H.26x standards, new technology such as neural networks and genetic algorithms are being developed to explore the future of image coding. Successful applications of neural networks to vector quantization have now become well established, and other aspects of neural network involvement in this area are stepping up to play significant roles in assisting with those traditional technologies. This paper presents an extensive survey on the development of neural networks for image compression which covers three categories: direct image compression by neural networks; neural network implementation of existing techniques, and neural network based technology which provide improvement over traditional algorithms.},
author = {Jiang, J.},
doi = {10.1016/S0923-5965(98)00041-1},
isbn = {0923-5965},
issn = {09235965},
journal = {Signal Processing: Image Communication},
keywords = {image compression and coding,image compression- lossy,neural network},
mendeley-tags = {image compression- lossy},
number = {9},
pages = {737--760},
title = {{Image compression with neural networks - a survey}},
volume = {14},
year = {1999}
}
@article{Silver2016,
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks' to evaluate board positions and ‘policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
archivePrefix = {arXiv},
arxivId = {1610.00633},
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature16961},
eprint = {1610.00633},
isbn = {1476-4687 (Electronic)\r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
keywords = {games},
mendeley-tags = {games},
number = {7587},
pages = {484--489},
pmid = {26819042},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go with deep neural networks and tree search}},
url = {http://www.nature.com/doifinder/10.1038/nature16961},
volume = {529},
year = {2016}
}
@article{Hayashi2017,
abstract = {Today's economy, production activity, and our life are sustained by social and technological network infrastructures, while new threats of network attacks by destructing loops have been found recently in network science. We inversely take into account the weakness, and propose a new design principle for incrementally growing robust networks. The networks are self-organized by enhancing interwoven long loops. In particular, we consider the range-limited approximation of linking by intermediations in a few hops, and show the strong robustness in the growth without degrading efficiency of paths. Moreover, we demonstrate that the tolerance of connectivity is reformable even from extremely vulnerable real networks according to our proposed growing process with some investment. These results may indicate a prospective direction to the future growth of our network infrastructures.},
archivePrefix = {arXiv},
arxivId = {1706.03910},
author = {Hayashi, Yukio},
doi = {10.1017/nws.2017.25},
eprint = {1706.03910},
issn = {20501250},
journal = {Network Science},
keywords = {coexistence of efficiency and robustness,evolutive,interwoven loops,long-distance relations,onion-like structure,unselfish self-organization},
mendeley-tags = {evolutive},
number = {1},
pages = {54--70},
title = {{A new design principle of robust onion-like networks self-organized in growth}},
url = {http://arxiv.org/abs/1706.03910},
volume = {6},
year = {2018}
}
@article{Hausknecht2017,
abstract = {This paper describes the learning and control capabilities of a biologically constrained bottom-up model of the mammalian cerebellum. Results are presented from six tasks: 1) eyelid conditioning; 2) pendulum balancing; 3) proportional-integral-derivative control; 4) robot balancing; 5) pattern recognition; and 6) MNIST handwritten digit recognition. These tasks span several paradigms of machine learning, including supervised learning, reinforcement learning, control, and pattern recognition. Results over these six domains indicate that the cerebellar simulation is capable of robustly identifying static input patterns even when randomized across the sensory apparatus. This capability allows the simulated cerebellum to perform several different supervised learning and control tasks. On the other hand, both reinforcement learning and temporal pattern recognition prove problematic due to the delayed nature of error signals and the simulator's inability to solve the credit assignment problem. These results are consistent with previous findings which hypothesize that in the human brain, the basal ganglia is responsible for reinforcement learning, while the cerebellum handles supervised learning.},
author = {Hausknecht, Matthew and Li, Wen Ke and Mauk, Michael and Stone, Peter},
doi = {10.1109/TNNLS.2015.2512838},
isbn = {8750141007},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Cerebellar pattern recognition,MNIST handwritten digit recognition,Robot balance,cerebellum,health,inverted pendulum balancing (cart-pole),proportional-integral-derivative (PID) control},
mendeley-tags = {health},
number = {3},
pages = {510--522},
pmid = {26829807},
title = {{Machine Learning Capabilities of a Simulated Cerebellum}},
volume = {28},
year = {2017}
}
@article{Bennasar2015,
abstract = {Feature selection is used in many application areas relevant to expert and intelligent systems, such as data mining and machine learning, image processing, anomaly detection, bioinformatics and natural language processing. Feature selection based on information theory is a popular approach due its computational efficiency, scalability in terms of the dataset dimensionality, and independence from the classifier. Common drawbacks of this approach are the lack of information about the interaction between the features and the classifier, and the selection of redundant and irrelevant features. The latter is due to the limitations of the employed goal functions leading to overestimation of the feature significance. To address this problem, this article introduces two new nonlinear feature selection methods, namely Joint Mutual Information Maximisation (JMIM) and Normalised Joint Mutual Information Maximisation (NJMIM); both these methods use mutual information and the 'maximum of the minimum' criterion, which alleviates the problem of overestimation of the feature significance as demonstrated both theoretically and experimentally. The proposed methods are compared using eleven publically available datasets with five competing methods. The results demonstrate that the JMIM method outperforms the other methods on most tested public datasets, reducing the relative average classification error by almost 6% in comparison to the next best performing method. The statistical significance of the results is confirmed by the ANOVA test. Moreover, this method produces the best trade-off between accuracy and stability.},
author = {Bennasar, Mohamed and Hicks, Yulia and Setchi, Rossitza},
doi = {10.1016/j.eswa.2015.07.007},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Classification,Conditional mutual information,Dimensionality reduction,Feature selection,Feature selection stability,Joint mutual information,Mutual information,Subset feature selection,other},
mendeley-tags = {other},
number = {22},
pages = {8520--8532},
publisher = {Elsevier Ltd.},
title = {{Feature selection using Joint Mutual Information Maximisation}},
url = {http://dx.doi.org/10.1016/j.eswa.2015.07.007},
volume = {42},
year = {2015}
}
@article{Phumrattanaprapin2016,
author = {Phumrattanaprapin, Khanittha;Punyaphol Horata},
keywords = {ELM,chine,hierarchical extreme learning ma-,hierarchical learning,multilayer perceptron},
mendeley-tags = {ELM},
number = {2},
pages = {196--204},
title = {{Extended Hierarchical Extreme Learning Machine with Multilayer Perceptron}},
volume = {10},
year = {2016}
}
@article{Huang2015,
abstract = {Abstract—The emergent machine learning technique - Ex- treme Learning Machines (ELMs) - has become a hot area of research over the past years, which is attributed to the growing research activities and significant contributions made by numerous researchers around the world. Recently, it has come to our attention that a number of misplaced notions and misunderstandings are being dissipated on the relationships between ELM and some earlier works. This paper wishes to clarify that i) ELM theories manage to address the open problem which has puzzled the neural networks, machine learning and neuroscience communities for 60 years: whether hidden nodes / neurons need to be tuned in learning, and proved that in contrast to the common knowledge and conventional neural network learning tenets, hidden nodes / neurons do not need to be iteratively tuned in wide types of neural networks and learning models (Fourier series, biological learning, etc). Unlike ELM theories, none of those earlier works provides theoretical foundations on feedforward neural networks with random hidden nodes; ii) ELM is proposed for both generalized single hidden layer feedfoward network and multi hidden layers feedforward networks; iii) Homogeneous architecture based ELM is proposed for feature learning, clustering, regression and (binary / multi- class) classification. iv) Compared to ELM, SVM and LS-SVM tend to provide suboptimal solutions, and SVM and LS-SVM do not consider feature representations in hidden layers of multi layers of networks either.},
author = {Huang, Guang Bin},
doi = {10.1007/s12559-015-9333-0},
isbn = {1866-9956},
issn = {18669964},
journal = {Cognitive Computation},
keywords = {ELM,Extreme learning machine,Feedforward neural network,QuickNet,Radial basis function network,Random vector functional link,Randomness},
mendeley-tags = {ELM},
number = {3},
pages = {263--278},
publisher = {Springer US},
title = {{What are Extreme Learning Machines? Filling the Gap Between Frank Rosenblatt's Dream and John von Neumann's Puzzle}},
volume = {7},
year = {2015}
}
@article{KenOHanlonandMarkD.PlumbleyQueenMaryUniversityofLondon2014,
abstract = {Non-negative Matrix Factorisation (NMF) is a popular tool in musical signal processing. However, problems using this methodology in the context of Automatic Music Transcription (AMT) have been noted resulting in the proposal of supervised and constrained variants of NMF for this purpose. Group sparsity has previously been seen to be effective for AMT when used with stepwise methods. In this paper group sparsity is introduced to supervised NMF decompositions and a dictionary tuning approach to AMT is proposed based upon group sparse NMF using the $\beta$-divergence. Experimental results are given showing improved AMT results over the state-of-the-art NMF-based AMT system. {\textcopyright} 2014 IEEE.},
author = {O'Hanlon, Ken and Plumbley, Mark D.},
doi = {10.1109/ICASSP.2014.6854173},
isbn = {9781479928927},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Automatic music transcription,group sparsity,nonnegative matrix factorisation},
number = {May},
pages = {3112--3116},
title = {{Polyphonic piano transcription using non-negative Matrix Factorisation with group sparsity}},
volume = {1},
year = {2014}
}
@article{Leite2016,
abstract = {The systematic innovation has been considered one of the most important practices in the business environment, increasingly uncertain and changeable. Understanding how changes they are occurring in society motivated by advances in information technology have impacted the innovation process, through the lens of startups. it is essential for the economic growth of a country, since most new products come these processes. The aim of this study is to develop a new model of development products in startups and small organizations seeking to develop physical products from innovations based on creativity.},
author = {Leite, M L G and Purcidonio, P M and Tarjano, C},
issn = {07981015 (ISSN)},
journal = {Espacios},
keywords = {Innovation,Product development,Startups},
number = {7},
title = {{The process of product development for startups based on creative innovation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966709823&partnerID=40&md5=fb40f17143479a7221ff1b696cdfd846},
volume = {37},
year = {2016}
}
@article{Berthon2007,
abstract = {Creative consumers (defined as customers who adapt, modify, or transform a proprietary offering) represent an intriguing paradox for business. On one hand, they can signify a black hole for future revenue, with breach of copyright and intellectual property. On the other hand, they represent a gold mine of ideas and business opportunities. Central to business is the need to create and capture value, and creative consumers demand a shift in the mindsets and business models of how firms accomplish both. Based upon their attitude and action toward customer innovation, we develop a typology of firms' stances toward creative consumers. We then consider the implications of the stances model for corporate strategy and examine a three-step approach to dealing with creative consumers: awareness, analysis, and response. {\textcopyright} 2006 Kelley School of Business, Indiana University.},
author = {Berthon, Pierre R. and Pitt, Leyland F. and McCarthy, Ian and Kates, Steven M.},
doi = {10.1016/j.bushor.2006.05.005},
issn = {00076813},
journal = {Business Horizons},
keywords = {Creative customers,Diagnostics,Firm stance,Strategic response},
month = {jan},
number = {1},
pages = {39--47},
title = {{When customers get clever: Managerial approaches to dealing with creative consumers}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007681306000796},
volume = {50},
year = {2007}
}
@article{Index2013,
author = {Index, Industrial},
pages = {2013--2014},
title = {{Technology Is Wiping Out Companies Faster than Ever}},
year = {2013}
}
@article{Estelles-Arolas2012,
abstract = {'Crowdsourcing' is a relatively recent concept that encompasses many practices. This diversity leads to the blurring of the limits of crowdsourcing that may be identified virtually with any type of internet-based collaborative activity, such as co-creation or user innovation. Varying definitions of crowdsourcing exist, and therefore some authors present certain specific examples of crowdsourcing as paradigmatic, while others present the same examples as the opposite. In this article, existing definitions of crowdsourcing are analysed to extract common elements and to establish the basic characteristics of any crowdsourcing initiative. Based on these existing definitions, an exhaustive and consistent definition for crowdsourcing is presented and contrasted in 11 cases. {\textcopyright} The Author(s) 2012.},
author = {Estell{\'{e}}s-Arolas, Enrique and Gonz{\'{a}}lez-Ladr{\'{o}}n-De-Guevara, Fernando},
doi = {10.1177/0165551512437638},
isbn = {0165551500000},
issn = {01655515},
journal = {Journal of Information Science},
keywords = {crowdsourcing,definition,innovation},
number = {2},
pages = {189--200},
title = {{Towards an integrated crowdsourcing definition}},
volume = {38},
year = {2012}
}
@article{Angell,
author = {Homer-Dixon, Thomas},
doi = {10.1109/MSPEC.2003.1197480},
issn = {00189235},
journal = {IEEE Spectrum},
number = {5},
pages = {11--12},
title = {{Winners and losers in the information age}},
volume = {40},
year = {2003}
}
@article{Pisano2008,
abstract = {Nowadays, virtually no companies innovate alone. Firms team up with a variety of partners, in a wide number of ways, to create new technologies, products, and services. But what is the best way to leverage the power of outsiders? To help executives answer that question, Pisano, of Harvard Business School, and Verganti, of Politecnico di Milano, developed a simple framework focused on two questions: Given your strategy, how open or closed should your network of collaborators be? And who should decide which problems to tackle and which solutions to adopt? There are four basic modes of collaboration, say the authors. An elite circle is a closed network with a hierarchical governance: One company selects the participants, defines the problem, and chooses the solution. For instance, Alessi, an Italian home-products company, invited 200 outside experts in postmodern architecture to contribute ideas for new home-product designs. An innovation mall is hierarchical but open: Anyone can post a problem or propose solutions in it, but the company posting the problem chooses the solution. An example is lnnoCentive.com, an eBay-like site where companies post scientific challenges. An innovation community is open and decentralized: Anyone can propose problems, offer solutions, and decide which ideas to use - as happens in the Linux open-source software community. A consortium is a private group of participants that operate as equals and jointly select problems, decide how to conduct work, and choose solutions. IBM has set up a number of consortia with other companies to develop nextgeneration semiconductor technologies. No one approach is superior; each involves strategic trade-offs. When choosing among modes, firms must weigh their advantages and challenges, and assess which will work best with their strategy, capabilities, structure, and assets.},
author = {Pisano, Gary P. and Verganti, Roberto},
doi = {10.1108/sd.2009.05625dad.001},
issn = {00178012},
journal = {Harvard Business Review},
number = {12},
pages = {78--86},
title = {{Which kind of collaboration is right for you?}},
url = {http://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=35387060&site=ehost-live%5Cnhttp://content.ebscohost.com/ContentServer.asp?T=P&P=AN&K=35387060&S=R&D=buh&EbscoContent=dGJyMMvl7ESep7Q4wtvhOLCmr0uep65Ssqu4TLGWxWXS&ContentCustomer=dGJyMPGotk%2Bxr},
volume = {86},
year = {2008}
}
@article{Dodgson2006,
abstract = {As with all new ideas, the concept of Open Innovation requires extensive empirical investigation, testing and development. This paper analyzes Procter and Gamble's 'Connect and Develop' strategy as a case study of the major organizational and technological changes associated with open innovation. It argues that although some of the organizational changes accompanying open innovation are beginning to be described in the literature, more analysis is warranted into the ways technological changes have facilitated open innovation strategies, particularly related to new product development. Information and communications technologies enable the exchange of distributed sources of information in the open innovation process. The case study shows that furthermore a suite of new technologies for data mining, simulation, prototyping and visual representation, what we call 'innovation technology', help to support open innovation in Procter and Gamble. The paper concludes with a suggested research agenda for furthering understanding of the role played by and consequences of this technology. {\textcopyright} 2006 Blackwell Publishing Ltd.},
author = {Dodgson, Mark and Gann, David and Salter, Ammon},
doi = {10.1111/j.1467-9310.2006.00429.x},
issn = {00336807},
journal = {R and D Management},
number = {3},
pages = {333--346},
title = {{The role of technology in the shift towards open innovation: The case of Procter & Gamble}},
volume = {36},
year = {2006}
}
@article{Piller2006,
abstract = {Research has shown that many innovations originate not in the manufacturer but the user domain. Internet-based toolkits for idea competitions (TIC) are a novel way for manufacturers to access innovative ideas and solutions from users. Idea competitions build on the nature of competition as a means to encourage users to participate at an open innovation process, to inspire their creativity, and to increase the quality of the submissions. When the contest ends, submissions are evaluated by an expert panel. Users whose submissions score highest receive an award from the manufacturer, which is often granted in exchange for the right to exploit the solution in its domain. Following the idea of evolutionary prototyping, we developed a TIC in cooperation with a manufacturer of sports goods. The TIC was launched as a pilot in one of the company's markets. Submissions were evaluated using the consensual assessment technique. The evaluation of this study provides suggestions for further research, but also implications for managers willing to explore TIC in their organization. {\textcopyright} 2006 Blackwell Publishing Ltd.},
author = {Piller, Frank T. and Walcher, Dominik},
doi = {10.1111/j.1467-9310.2006.00432.x},
issn = {00336807},
journal = {R and D Management},
number = {3},
pages = {307--318},
title = {{Toolkits for idea competitions: A novel method to integrate users in new product development}},
url = {http://doi.wiley.com/10.1111/j.1467-9310.2006.00432.x},
volume = {36},
year = {2006}
}
@article{Poetz2012,
abstract = {Generating ideas for new products used to be the exclusive domain of marketers, engineers, and/or designers. Users have only recently been recognized as an alternative source of new product ideas. Whereas some have attributed great potential to outsourcing idea generation to the "crowd" of users ("crowdsourcing"), others have clearly been more skeptical. The authors join this debate by presenting a real-world comparison of ideas actually generated by a firm's professionals with those generated by users in the course of an idea generation contest. Both professionals and users provided ideas to solve an effective and relevant problem in the consumer goods market for baby products. Executives from the underlying company evaluated all ideas (blind to their source) in terms of key quality dimensions including novelty, customer benefit, and feasibility. The study reveals that the crowdsourcing process generated user ideas that score significantly higher in terms of novelty and customer benefit, and somewhat lower in terms of feasibility. However, the average values for feasibility-in sharp contrast to novelty and customer benefit-tended to be relatively high overall, meaning that feasibility did not constitute a narrow bottleneck in this study. Even more interestingly, it is found that user ideas are placed more frequently than expected among the very best in terms of novelty and customer benefit. These findings, which are quite counterintuitive from the perspective of classic new product development (NPD) literature, suggest that, at least under certain conditions, crowdsourcing might constitute a promising method to gather user ideas that can complement those of a firm's professionals at the idea generation stage in NPD. {\textcopyright} 2012 Product Development & Management Association.},
author = {Poetz, Marion K. and Schreier, Martin},
doi = {10.1111/j.1540-5885.2011.00893.x},
issn = {07376782},
journal = {Journal of Product Innovation Management},
month = {mar},
number = {2},
pages = {245--256},
title = {{The value of crowdsourcing: Can users really compete with professionals in generating new product ideas?}},
url = {http://doi.wiley.com/10.1111/j.1540-5885.2011.00893.x},
volume = {29},
year = {2012}
}
@article{Alberts1997,
author = {Alberts, David S and Papp, Daniel S},
isbn = {1579060412},
journal = {CCRP Publication Series},
title = {{The Information Age : An Anthology on Its Impact and Consequences Table of Contents}},
year = {1997}
}
@book{Norman,
abstract = {Even the smartest among us can feel inept as we fail to figure out which switch turns on which light or stove burner, or whether to push, pull, or slide a door. The fault lies in product designs that ignore the needs of users and the principles of cognitive psychology. A bestseller in the United States, this classic work on the cognitive aspects of design contains examples of both good and bad design and simple rules that designers can use to improve the usability of objects as diverse as cars, computers, doors, and telephones.-From publisher description.},
author = {Norman, Don},
booktitle = {The Design of Everyday Things},
doi = {10.15358/9783800648108},
isbn = {9780465050659},
title = {{The Design of Everyday Things}},
year = {2016}
}
@article{Lee-mortimer1994,
abstract = {This article emphasises the importance of product development which can only be achieved through the application of appropriate designs. Thus, design is probably the single most powerful tool that can be used to position the company as 'world class' and motivate staff to excellence. The UK has excellent design skills, bit poor processes. As a result, companies do not translate skills into goods that people want to buy.},
author = {Lee-Mortimer, Andrew},
doi = {10.1108/09642369210054252},
issn = {13523074},
journal = {World Class Design to Manufacture},
number = {2},
pages = {31--34},
title = {{Strategic design}},
volume = {1},
year = {1994}
}
@article{Dewick2002a,
abstract = {This paper contributes towards the construction and application of a method to assess the long-term impact of the development of pervasive technologies on the environment. It seeks to integrate insights from studies of technology regarding long-term growth with questions of sustainability. Using a methodology based on long-wave theory and a sector classification based on technological characteristics, the likely effects of the three pervasive technologies (information technology, biotechnology and nanotechnology) on the input-output structure of selected sectors and on the levels of emissions of industrial greenhouse gases are considered. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Dewick, Paul and Green, Ken and Miozzo, Marcela},
doi = {10.1016/S0016-3287(03)00157-5},
issn = {00163287},
journal = {Futures},
number = {3},
pages = {267--293},
title = {{Technological change, industry structure and the environment}},
volume = {36},
year = {2004}
}
@article{Wang2011,
abstract = {With the development of computer-aided design (CAD) technology and increasing demands of customized footwear, shoe-lasts are requested to be designed rapidly so as to speed-up the process of footwear manufacturing. Thus, this study presents a CAD system for shoe-last rapid customized design based on the piecewise reconstruction to realize the interactive deformation and separate/global shoe-last form reuse. First, piecewise remodeling method is proposed based on the multi-layer parametric definition and contour curves are extracted from the mesh. Then, five types of proper constraints to support surface manipulation are proposed, and the draft-driven deformation by the contour curve bending can realize the interactive local surface design in free angle of view. Finally, shoe-last styles can be saved and reused globally or separately to share design results between different shoe-lasts. Experimental examples show that customized shoe-lasts can be easily and rapidly generated by adopting the parametric design methods. {\textcopyright} Springer-Verlag London Limited 2010.},
author = {Wang, Jin and Zhang, Haining and Lu, Guodong and Liu, Zheng},
doi = {10.1007/s00170-010-3144-y},
issn = {02683768},
journal = {International Journal of Advanced Manufacturing Technology},
keywords = {Form reus,Interactive deformation,Parametric design,Shoe-last},
month = {jan},
number = {1-4},
pages = {173--186},
title = {{Rapid parametric design methods for shoe-last customization}},
url = {http://link.springer.com/10.1007/s00170-010-3144-y},
volume = {54},
year = {2011}
}
@article{Schumpeter1994,
abstract = {Schumpeter began by proclaiming that histories of economics should confine themselves to economic analysis, which he defined as " the analytic or scientific aspects of economic thought" (1954: 1). Schumpeter then proceeded to ignore his own edict, for over 1000 small-print pages. Having preached analysis-only Schumpeter practiced more ecumenically, weaving together intellectual history, biography, and economic sociology. Indeed, Schumpeter spent most of his last decade writing the 800,000 words of the ferociously erudite History, and thereby failing to complete a long-planned work of economic analysis. Thomas McCraw's splendid new book brilliantly illuminates this Schumpeterian paradox, and the many others that made Schumpeter, as Phillip Mirowski put it, " a living, breathing contradiction " (1994: 5). Prophet of Innovation is not just a beautifully drawn portrait of Schumpeter's life and times, it is also a distinguished business historian's meditation on the two opposed cultures of political economy post-1870: history and theory. The Prophet of Innovation, among its other accomplishments, tells the story of how a great and productive intellect wrestled with the two-cultures problem in political economy. In the work of Schumpeter, McCraw finds the very personification of political economy's struggle between history and theory. Just as Schumpeter's work personifies the roles for history and theory in economics, so too does McCraw make Schumpeter's turbulent life and times a metaphor for Schumpeter's great subject, capitalism. Schumpeter was four when his father died. An exile, he moved his household 23 times in his lifetime, living in five different countries. His first marriage failed. Though brilliant and widely accomplished, Schumpeter had to reinvent himself many times. He failed as a lawyer, was dismissed as president of a private Vienna bank, and, as the new Austrian republic's finance minister, lasted a mere seven months. Most damaging of all, in 1926 Schumpeter's second wife Annie died in childbirth, and the child died as well. Schumpeter's beloved mother died in the same year, a three-fold emotional wounding from which Schumpeter, then 42, never fully recovered. Ahead still lay the Great Depression and another murderous war},
author = {Schumpeter, Joseph A and Mccraw, Thomas and Mirowski, Phillip},
pages = {1--8},
title = {{Thomas K . McCraw , Cambridge : Harvard University Press , 719 pages ,}},
year = {1994}
}
@article{Sampler1998,
abstract = {An account is given on what constitutes the real boundaries of competition for the new millennium, as well as the impact that it has on firms' competitive behavior. To analyze industry structure, the concepts of information separability and information specificity, are introduced. Propositions characterizing the nature of industry structure in information-intensive industries are also suggested.},
author = {Sampler, Jeffrey L.},
issn = {03608581},
journal = {IEEE Engineering Management Review},
keywords = {industry boundary,industry structure,information,information age,information separability},
number = {2},
pages = {68--78},
publisher = {Wiley Online Library},
title = {{Redefining industry structure for the information age}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0266(199804)19:4%3C343::AID-SMJ975%3E3.0.CO;2-G/abstract},
volume = {27},
year = {1999}
}
@book{Zikmund2012,
abstract = {This is an electronic version of the print textbook. Due to electronic rights restrictions, some third party content may be suppressed. Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. The publisher reserves the right to remove content from this title at any time if subsequent rights restrictions require it. For valuable information on pricing, previous editions, changes to current editions, and alternate formats, please visit www.cengage.com/highered to search by ISBN#, author, title, or keyword for materials in your areas of interest.},
author = {Zikmund, William G. and Babin, Barry J. and Carr, Jon and Griffin, Mitch},
booktitle = {IEEE Transactions on Information Theory},
isbn = {9781111221294},
issn = {14683156},
number = {3},
pages = {1743--1756},
pmid = {880153},
title = {{Licensed to : CengageBrain User Licensed to : CengageBrain User}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6071007},
volume = {58},
year = {2012}
}
@misc{,
title = {{Leaps and bounds.pdf}}
}
@article{Noble2011,
abstract = {While the popular understanding of the influence of design is growing, academic research has largely been restricted to considering consumer-level responses to design elements. This paper reviews this past work and proposes a more strategic research agenda for the field, with the potential to explicate linkages between design elements and strategies and outcomes related to innovation and corporate performance. {\textcopyright} 2011 Product Development & Management Association.},
author = {Noble, Charles H.},
doi = {10.1111/j.1540-5885.2011.00808.x},
issn = {07376782},
journal = {Journal of Product Innovation Management},
number = {3},
pages = {389--393},
publisher = {Blackwell Publishing Inc},
title = {{On elevating strategic design research}},
url = {http://dx.doi.org/10.1111/j.1540-5885.2011.00808.x},
volume = {28},
year = {2011}
}
@article{,
title = {{Copyright {\textcopyright}2000. All Rights Reserved.}},
year = {2000}
}
@article{Arthur1875,
author = {Arthur, By W Brian},
title = {{Is the Information Revolution Dead ?}},
year = {1875}
}
@article{Stilgoe2013,
abstract = {The governance of emerging science and innovation is a major challenge for contemporary democracies. In this paper we present a framework for understanding and supporting efforts aimed at 'responsible innovation'. The framework was developed in part through work with one of the first major research projects in the controversial area of geoengineering, funded by the UK Research Councils. We describe this case study, and how this became a location to articulate and explore four integrated dimensions of responsible innovation: anticipation, reflexivity, inclusion and responsiveness. Although the framework for responsible innovation was designed for use by the UK Research Councils and the scientific communities they support, we argue that it has more general application and relevance. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Stilgoe, Jack and Owen, Richard and Macnaghten, Phil},
doi = {10.1016/j.respol.2013.05.008},
issn = {00487333},
journal = {Research Policy},
keywords = {Emerging technologies,Ethics,Geoengineering,Governance,Responsible innovation},
month = {nov},
number = {9},
pages = {1568--1580},
publisher = {Elsevier B.V.},
title = {{Developing a framework for responsible innovation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0048733313000930},
volume = {42},
year = {2013}
}
@misc{,
title = {{Democratizing innovation.pdf}}
}
@article{Scott1987,
abstract = {As a small business develops it moves through five growth stages, each with its own distinctive characteristics. Because the transition from one stage to the next requires change, it will be accompanied by some crisis or another. Crises tend to be disruptive and the problems of change can be minimized if managers are proactive rather than reactive. Prior knowledge of what generates crises and what to expect in each stage will smooth the process of change. This article proposes a model of small business growth to enable managers of small businesses to plan for future growth. The model has been successfully tested and used by the authors in analysing and solving the problem of growing small businesses. The model isolates the five growth stages, the sort of things that will precipitate crises and the major strategies that should be considered at each stage. Its main purpose is as a diagnostic tool in analysing the firm's present position and in planning what will be required as it progresses to the next stage of its development. {\textcopyright} 1987.},
author = {Scott, Mel and Bruce, Richard},
doi = {10.1016/0024-6301(87)90071-9},
issn = {00246301},
journal = {Long Range Planning},
number = {3},
pages = {45--52},
title = {{Five stages of growth in small business}},
volume = {20},
year = {1987}
}
@article{Ordanini2011,
abstract = {Purpose – The purpose of this paper is to analyze the emerging crowd-funding phenomenon, that is a collective effort by consumers who network and pool their money together, usually via the internet, in order to invest in and support efforts initiated by other people or organizations. Successful service businesses that organize crowd-funding and act as intermediaries are emerging, attesting to the viability of this means of attracting investment. Design/methodology/approach – The research employs a “grounded theory” approach, performing an in-depth qualitative analysis of three cases involving crowd-funding initiatives: SellaBand in the music business, Trampoline in financial services, and Kapipal in non-profit services. These cases were selected to represent a diverse set of crowd-funding operations that vary in terms of risk/return for the investor and the type of payoff associated to the investment. Findings – The research addresses two research questions: how and why do consumers turn into crowd-funding participants? and how and why do service providers set up a crowd-funding initiative? Concerning the first research question, the authors' findings reveal purposes, characteristics, roles and tasks, and investment size of crowd-funding activity from the consumer's point of view. Regarding the second research question, the authors' analysis reveals purposes, service roles, and network effects of crowd-funding activity investigated from the point of view of the service organization that set up the initiative. Practical implications – The findings also have implications for service managers interested in launching and/or managing crowd-funding initiatives. Originality/value – The paper addresses an emerging phenomenon and contributes to service theory in terms of extending the consumer's role from co-production and co-creation to investment. {\textcopyright} 2011, Emerald Group Publishing Limited.},
author = {Ordanini, Andrea and Miceli, Lucia and Pizzetti, Marta and Parasuraman, A.},
doi = {10.1108/09564231111155079},
issn = {17575818},
journal = {Journal of Service Management},
keywords = {Crowd-funding,Customer-investors,Customers,Investments,Service innovation},
number = {4},
pages = {443--470},
title = {{Crowd-funding: Transforming customers into investors through innovative service platforms}},
url = {http://www.emeraldinsight.com/10.1108/09564231111155079},
volume = {22},
year = {2011}
}
@article{Bettis-Outland2012,
abstract = {Although an abundance of academic literature positions organizational information processing as antecedent to decision making, little attention is paid to the possibility that decision making can be antecedent to certain elements of organizational information processing. Specifically, does the decision making process impact the type of organizational learning that takes place? Do different approaches to decision making alter the amount and variety of information made available to the organization, that is, the level of information overload? This paper examines incremental and comprehensive decision making to understand the effects of different decision making types on organizational learning and information overload. Incrementalism suggests that decision making should take place in small steps or increments. This approach analyzes only a few scenarios to make decisions resulting in few, if any, major organizational changes. However, comprehensive decision making requires the consideration of all possible scenarios and potential outcomes, resulting in a major overhaul of traditions and procedures within the organization. Consequently, each decision making approach has a different impact on organizational learning and information overload. {\textcopyright} 2011 Elsevier Inc.},
author = {Bettis-Outland, Harriette},
doi = {10.1016/j.jbusres.2010.12.021},
issn = {01482963},
journal = {Journal of Business Research},
keywords = {Decision making,Incrementalism,Information overload,Organizational learning},
month = {jun},
number = {6},
pages = {814--820},
publisher = {Elsevier Inc.},
title = {{Decision-making's impact on organizational learning and information overload}},
url = {http://www.sciencedirect.com/science/article/pii/S0148296310002845},
volume = {65},
year = {2012}
}
@article{Brabham2008,
abstract = {Crowdsourcing is an online, distributed problem-solving and production model that has emerged in recent years. Notable examples of the model include Threadless, iStockphoto, InnoCentive, the Goldcorp Challenge, and user-generated advertising contests. This article provides an introduction to crowdsourcing, both its theoretical grounding and exemplar cases, taking care to distinguish crowdsourcing from open source production. This article also explores the possibilities for the model, its potential to exploit a crowd of innovators, and its potential for use beyond forprofit sectors. Finally, this article proposes an agenda for research into crowdsourcing. Copyright {\textcopyright} 2008 Sage Publications.},
author = {Brabham, Daren C.},
doi = {10.1177/1354856507084420},
isbn = {1354856507084},
issn = {13548565},
journal = {Convergence},
keywords = {Collective intelligence,Crowdsourcing,Distributed problem solving,Goldcorp challenge,InnoCentive,Open source,Threadless,Wisdom of crowds,iStockphoto},
month = {feb},
number = {1},
pages = {75--90},
title = {{Crowdsourcing as a model for problem solving: An introduction and cases}},
url = {http://con.sagepub.com/cgi/doi/10.1177/1354856507084420},
volume = {14},
year = {2008}
}
@article{Elliot2013,
abstract = {In today's global business environment, where multinational companies are pressed to increase revenues in order to survive, creativity may hold the key to ensuring their new product development (NPD) efforts lead to innovations with worldwide appeal, such as Apple's iPad and Gillette's Fusion Razor. To leverage creativity for effective global NPD, businesses want to know how cultures differ in their concepts of creativity and the impact of those differences on approaches to developing new products. Because global new products are increasingly developed in, by, and for multiple cultures, a particular need is for a culturally reflective understanding, or conceptualization, of creativity. While creativity is believed to be culturally tied, the dominant framework of creativity used in business and management assumes that creativity is culturally indifferent or insensitive. This knowledge gap is addressed by studying the role of creativity in NPD practices in a cross-cultural or global context. The study begins by first developing a culturally anchored conceptualization of creativity. Called cross-cultural creativity, the concept draws on creativity insights from the field of art and aesthetics. The concept specifies two modes of creativity, neither of which is superior to the other, called the spontaneous or S route and the divergent or D route. The S route emphasizes adaptiveness, processes, intuitiveness, and metamorphism, while the D route focuses on disruptiveness, results, rationality, and literalism. Next, this new concept is applied to NPD by positing how creativity in distinct cultures may shape NPD practices, as illustrated by Japanese and U.S. firms. Research propositions are formulated to capture these patterns, and thereafter, theoretical and practical implications of the framework and propositions are discussed. The implications center on global NPD, which is a complex enterprise involving typically more than one culture to design and develop new products for several geographic markets. The study is of interest to researchers needing a globally situated, culturally attached framework of creativity for international NPD studies, and managers seeking to exploit creativity in multinational and multicultural innovation projects. {\textcopyright} 2013 Product Development & Management Association.},
author = {Elliot, Esi Abbam and Nakata, Cheryl},
doi = {10.1111/jpim.12066},
issn = {15405885},
journal = {Journal of Product Innovation Management},
month = {dec},
number = {SUPPL 1},
pages = {110--125},
title = {{Cross-cultural creativity: Conceptualization and propositions for global new product development}},
url = {http://doi.wiley.com/10.1111/jpim.12066},
volume = {30},
year = {2013}
}
@article{Foster2012,
author = {Innosight},
journal = {Innosight},
keywords = {Kodak, Radio Shack, Bear Stearns},
title = {{Creative Destruction Whips through Corporate America}},
url = {http://www.innosight.com/innovation-resources/strategy-innovation/creative-destruction-whips-through-corporate-america.cfm},
year = {2012}
}
@misc{Alves1922,
abstract = {O artigo analisa o papel da revis{\~{a}}o da bibliografia em trabalhos de pesquisa e aponta as principais defici{\^{e}}ncias observadas em teses de mestrado e doutorado, no que se refere a esse aspecto. A primeira se{\c{c}}{\~{a}}o destaca a import{\^{a}}ncia da an{\'{a}}lise cr{\'{i}}tica do estado atual do conhecimento na {\'{a}}rea de interesse do pesquisador para a problematiza{\c{c}}{\~{a}}o do tema a ser investigado. A segunda trata do referencial te{\'{o}}rico e discute as dificuldades encontradas na constru{\c{c}}{\~{a}}o te{\'{o}}rica no campo da educa{\c{c}}{\~{a}}o. Finalmente, a terceira se{\c{c}}{\~{a}}o apresenta os equ{\'{i}}vocos mais freq{\"{u}}entes observados em revis{\~{o}}es de bibliografia, utilizando o recurso da caricatura para tornar mais vis{\'{i}}veis certos tra{\c{c}}os.},
author = {Alves, Alda Judith},
booktitle = {Cadernos de Pesquisa},
keywords = {Ensino Superior,Metodologia de Pesquisa,P{\'{o}}s-Gradua{\c{c}}{\~{a}}o,Revis{\~{a}}o de Bibliografia},
number = {81},
pages = {53--60},
title = {{A Revis{\~{a}}o da bibliografia em teses e disserta{\c{c}}{\~{o}}es}},
year = {1922}
}
@article{Sawhney2005,
abstract = {In the networked world, firms are recognizing the power of the Internet as a platform for co-creating value with customers. We focus on how the Internet has impacted the process of collaborative innovation - a key process in value co-creation. We outline the distinctive capabilities of the Internet as a platform for customer engagement, including interactivity, enhanced reach, persistence, speed, and flexibility, and suggest that firms can use these capabilities to engage customers in collaborative product innovation through a variety of Internet-based mechanisms. We discuss how these mechanisms can facilitate collaborative innovation at different stages of the New Product Development process (back end vs. front end stages) and for differing levels of customer involvement (high reach vs. high richness). We present two detailed exploratory case studies to illustrate the integrated and systematic usage of Internet-based collaborative innovation mechanisms - Ducati from the motorbike industry and Eli Lilly from the pharmaceutical industry. We derive implications for managerial practice and academic research on collaborative innovation. {\textcopyright} 2005 Wiley Periodicals, Inc. and Direct Marketing Educational Foundation, Inc.},
author = {Sawhney, Mohanbir and Verona, Gianmario and Prandelli, Emanuela},
doi = {10.1002/dir.20046},
issn = {10949968},
journal = {Journal of Interactive Marketing},
month = {jan},
number = {4},
pages = {4--17},
publisher = {Elsevier},
title = {{Collaborating to create: The internet as a platform for customer engagement in product innovation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1094996805700785},
volume = {19},
year = {2005}
}
@article{Dewick2006,
abstract = {Future disruptive, pervasive technologies will have important consequences for industrial structure, economic growth and the environment. Drawing on theories of technological diffusion, industrial evolution and long-term technological change this paper explores the effect of the development and diffusion of two future pervasive technologies on five industrial sectors in three regions during the 21st century in terms of their effect on economic structural change. Through semi-structured interviews with over 100 experts in the two technologies, the paper quantifies the effects of future biotechnologies and nanotechnologies on the industrial structure of the EU, USA and China in 2020 and 2050. The paper finds that as a result of the development and diffusion of future biotechnologies and nanotechnologies, some industries grow whilst others decline and some new ones emerge. The evidence suggests that the effect is different across countries and time; whereas the experts commonly believe that effect of the technologies on the industrial structure of the EU and US is likely to be similar, the effect in China is considered to be less by 2020 but the same as in the EU and US by 2050. This finding has important implications for the location of production, economic growth and energy demand in the future. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Dewick, Paul and Green, Ken and Fleetwood, Toby and Miozzo, Marcela},
doi = {10.1016/j.techfore.2006.04.002},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Biotechnologies,Energy,Industrial structure,Nanotechnologies,Technological diffusion},
month = {nov},
number = {9},
pages = {1084--1106},
title = {{Modelling creative destruction: Technological diffusion and industrial structure change to 2050}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0040162506000862},
volume = {73},
year = {2006}
}
@article{Anderson2012,
abstract = {The Information Age has a surfeit of information received relative to what is processed. We model multiple sectors competing for consumer attention, with competition in price within each sector. Sector advertising levels follow a constant elasticity of substitution (CES) form, and within-sector prices are dispersed with a truncated Pareto distribution. The "information hump" shows highest ad levels for intermediate attention levels. Overall, advertising is excessive, although the allocation across sectors is optimal. The blame for information overload falls most on product categories with low information transmission costs and low profits. {\textcopyright} 2012, RAND.},
author = {Anderson, Simon P. and de Palma, Andr{\'{e}}},
doi = {10.1111/j.1756-2171.2011.00155.x},
issn = {07416261},
journal = {RAND Journal of Economics},
number = {1},
pages = {1--25},
title = {{Competition for attention in the Information (overload) Age}},
url = {http://doi.wiley.com/10.1111/j.1756-2171.2011.00155.x},
volume = {43},
year = {2012}
}
@book{Adler,
author = {Adler, Isabel K},
isbn = {9788565424004},
title = {{Design Thinking Design Thinking Inova{\c{c}}{\~{a}}o em neg{\'{o}}cios}}
}
@article{Sampieri,
author = {Sampieri, Roberto Hernandez},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sampieri - Unknown - No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title(2).pdf:pdf},
isbn = {9783540773405},
pages = {634},
title = {{No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title}}
}
@article{Maeda,
author = {Maeda, John},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maeda - Unknown - l aw s o f.pdf:pdf},
title = {l aw s o f}
}
@book{,
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title.pdf:pdf},
isbn = {9780983648703},
title = {{No Title}}
}
@article{Ledford2013,
author = {Ledford, B Y Heidi},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ledford - 2013 - START-UP.pdf:pdf},
title = {{START-UP}},
year = {2013}
}
@book{Thea,
author = {The, Rossing},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The - Unknown - No Title.pdf:pdf},
isbn = {0060189878},
title = {{No Title}}
}
@article{Hutchins2013,
author = {Hutchins, Aaron},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutchins - 2013 - Top of page.pdf:pdf},
pages = {649206},
title = {{Top of page}},
year = {2013}
}
@article{1942,
author = {Ｔ, ＮＡＫＡＩ},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 1942 - No Title.pdf:pdf},
journal = {Botany},
pages = {467},
title = {{Ｎｏｔｕｌａ ａｄ ｐｌａｎｔａｓ Ａｓｉａ ＯｒｉｅｎｔａｌｉｓNo Title}},
year = {1942}
}
@article{Weinman2014,
author = {Parts, Camera and Shots, Camera and Angles, Shot and Movement, Shot and Sources, Light and Motion, Tripod},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinman - 2014 - Top of page.pdf:pdf},
number = {May 2012},
pages = {1--7},
title = {{Top of Page Top of Page}},
volume = {7},
year = {2014}
}
@article{The,
author = {Arthur, W. Brian},
file = {:C\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The - Unknown - DEAD.pdf:pdf},
journal = {Business},
number = {March 2002},
pages = {65--72},
title = {{Is the information revolution dead?.If history is a guide, it is not}},
year = {2002}
}
