@article{1943McCullochlogical,
author = {Warren S. McCulloch and Walter Pitts},
journaltitle = {The Bulletin of Mathematical Biophysics},
date = {1943-12},
number = {4},
doi = {10.1007/bf02478259},
abstract = {Because of the "all-or-none" character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
url = {https://link.springer.com/article/10.1007/BF02478259},
volume = {5},
pages = {115--133},
title = {A logical calculus of the ideas immanent in nervous activity},
file = {C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Seminal/1943 A Logical Calculus of the Ideas Immanent in Nervous Activity_1943McCullochlogical.pdf,\:bibliography/ Seminal/1943 A Logical Calculus of the Ideas Immanent in Nervous Activity_1943McCullochlogical.pdf\:PDF,\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/Seminal/1943 A Logical Calculus of the Ideas Immanent in Nervous Activity_1943McCullochlogical.pdf\:pdf},
keywords = {neural networks,seminal},
mendeley-tags = {neural networks,seminal},
}

@techreport{1957RosenblattPerceptron,
author = {Frank Rosenblatt},
note = {(Project PARA)},
title = {The Perceptron: A Perceiving and Recognizing Automaton},
publisher = {Cornell Aeronautical Laboratory},
volume = {1957},
id = {1},
type = {techreport},
number = {85-460-1},
url = {https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf},
abstract = {First publication about the perceptron},
institution = {Cornell Aeronautical Laboratory},
pages = {460--1},
booktitle = {Report 85, Cornell Aeronautical Laboratory},
date = {1957},
file = {\:bibliography/ Seminal/1957 The Perceptron_ a Perceiving and Recognizing Automaton_1957RosenblattPerceptron.pdf\:PDF},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{1999YaoEvolving,
author = {Xin Yao},
volume = {87},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
journaltitle = {PROCEEDINGS OF THE IEEE},
year = {1999},
title = {Evolving Artiﬁcial Neural Networks},
pages = {25},
journal = {Proceedings of the IEEE},
doi = {10.1109/5.784219},
date = {1999},
number = {9},
langid = {english},
file = {\:bibliography/ Seminal/1999 Evolving Artiﬁcial Neural Networks_1999YaoEvolving.pdf\:PDF},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{1956RosenblattRemarks,
author = {Murray Rosenblatt},
publisher = {Institute of Mathematical Statistics},
volume = {27},
abstract = {This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymptotic mean square error of a particular class of estimates is evaluated.},
pages = {832--837},
title = {Remarks on Some Nonparametric Estimates of a Density Function},
journaltitle = {The Annals of Mathematical Statistics},
date = {1956},
issn = {0003-4851},
url = {http://www.jstor.org/stable/2237390},
number = {3},
file = {\:bibliography/ Seminal/1956 Remarks on Some Nonparametric Estimates of a Density Function_1956RosenblattRemarks.pdf\:PDF},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{1962ParzenEstimation,
author = {Emanuel Parzen},
journaltitle = {The Annals of Mathematical Statistics},
title = {On Estimation of a Probability Density Function and Mode},
date = {1962},
pages = {1065--1076},
number = {3},
urldate = {2019-03-28},
volume = {33},
url = {https://www.jstor.org/stable/2237880},
issn = {0003-4851},
file = {\:bibliography/ Seminal/1962 On Estimation of a Probability Density Function and Mode_1962ParzenEstimation.pdf\:PDF},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{2012HoogenboomHow,
author = {Barbara J. Hoogenboom and Robert C. Manske},
date = {2012},
abstract = {Successful production of a written product for submission to a peer-reviewed scientific journal requires substantial effort. Such an effort can be maximized by following a few simple suggestions when composing/ creating the product for submission. By following some suggested guidelines and avoiding common errors, the process can be streamlined and success realized for even beginning/novice authors as they negotiate the publication process. The purpose of this invited commentary is to offer practical suggestions for achieving success when writing and submitting manuscripts to The International Journal of Sports Physical Therapy and other professional journals.},
journaltitle = {The International Journal of Sports Physical Therapy},
pages = {6},
langid = {english},
title = {How To Write A Scientific Article},
file = {\:bibliography/ Writing/2012 How to Write a Scientific Article_2012HoogenboomHow.pdf\:PDF},
keywords = {writing},
mendeley-tags = {writing},
}

@unpublished{2018Elsevier4,
author = { Elsevier},
title = {4 step guide to writing a literature review},
url = {http://www.emeraldgrouppublishing.com/authors/guides/write/literature.htm},
date = {2018},
publisher = {Emerald Publishing},
file = {\:bibliography/ Writing/2018 4 Step Guide to Writing a Literature Review_2018Elsevier4.pdf\:PDF},
keywords = {writing},
mendeley-tags = {writing},
}

@inproceedings{2013KartofelevModeling,
author = {Dmitri Kartofelev and Anatoli Stulov and Heidi-Maria Lehtonen and Vesa Va},
url = {http://homes.ioc.ee/stulov/smac13.pdf},
booktitle = {4th Stockholm Music Acoustics Conference},
pages = {7},
langid = {english},
date = {2013},
title = {Modeling a vibrating string terminated against a bridge with arbitrary geometry},
file = {\:bibliography/ Acoustics/2013 Modeling a Vibrating String Terminated against a Bridge with Arbitrary Geometry_2013KartofelevModeling.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{2009TorresInfluence,
author = {Jesús Alej Torres and  ro and Ricardo R. Boullosa},
title = {Influence of the bridge on the vibrations of the top plate of a classical guitar},
langid = {english},
journaltitle = {Applied Acoustics},
pages = {1371--1377},
number = {11},
doi = {10.1016/j.apacoust.2009.07.002},
issn = {0003-682X},
volume = {70},
abstract = {In this work the effect of two different bridge conﬁgurations on the vibrations of the top plate of a classical guitar is presented. Experimental harmonic analysis and visualization techniques, in addition to detailed damped simulations using the ﬁnite element method, were used to obtain mobility functions and operating deﬂection shapes of a top plate. The mobility functions were obtained in the following sequence. First the mobility functions were obtained on the top plate without a bridge attached. Then a bridge was glued to the top plate and new measurements were made. Finally the already attached bridge was cross-cut in situ without detaching it from the top plate, and the measurements were repeated. Those speciﬁc designs were chosen on the grounds of simplicity of construction both experimentally and in FEM simulations (no particular preference for those designs is implied). The assembly and the speciﬁc design of the bridge have shown to have considerable inﬂuence on the response of the top plate regarding the mode shapes above 300 Hz. Depending on the geometry of the bridge, its deﬂections can either be comparable to the maximum deﬂections of the top plate or can have amplitudes so small that the bridge effectively creates a nodal zone on the plate vibrations. This suggests that the shape, the stiffness, and the mass properties of the bridge may play a role in the sound quality of the instrument. Ó 2009 Elsevier Ltd. All rights reserved.},
urldate = {2019-04-05},
date = {2009-12},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X09001613},
file = {\:bibliography/ Acoustics/2009 Influence of the Bridge on the Vibrations of the Top Plate of a Classical Guitar_2009TorresInfluence.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@collection{2009BruneauMaterials,
date = {2009},
pagetotal = {919},
publisher = {ISTE ; Hoboken, NJ : J. Wiley},
isbn = {978-1-84821-074-5},
langid = {english},
title = {Materials and acoustics handbook},
editor = {Bruneau, Michel and Potel, Catherine},
location = {London, UK},
file = {\:bibliography/ Acoustics/2009 Materials and Acoustics Handbook_2009BruneauMaterials.pdf\:application/pdf},
keywords = {acoustical engineering,acoustical materials,etc,handbooks,manuals,materials,testing},
mendeley-tags = {acoustical engineering,acoustical materials,etc,handbooks,manuals,materials,testing},
}

@article{2006WagnerLarge,
author = {Claus Wagner and Thomas Huttl and Pierre Sagaut},
pages = {471},
langid = {english},
title = {Large-Eddy Simulation for Acoustics},
date = {2006},
file = {\:bibliography/ Acoustics/2006 Large Eddy Simulation for Acoustics_2006WagnerLarge.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@inproceedings{2003KarjalainenCompilation,
author = {M. Karjalainen and C. Erkut and L. Savioja},
booktitle = {2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},
doi = {10.1109/ICASSP.2003.1199999},
eventtitle = {International Conference on Acoustics, Speech and Signal Processing (ICASSP'03)},
location = {Hong Kong, China},
publisher = {IEEE},
abstract = {This paper describes a systematic approach to specification and compilation of different physical modeling schemes particularly for sound synthesis studies. First we formulate theoretically a unified way of constructing physical interaction models which include elements that use both wave variables and Kirchhoff variables. These elements can be applied to build 1-D and multidimensional structures as well as lumped element models. In addition, typical signal processing algorithms are supported. A software environment (Block Compiler) has been developed, allowing for high-level object-based specification of physical models and their compilation to efficient code for execution.},
title = {Compilation of unified physical models for efficient sound synthesis},
pages = {V–433–6},
isbn = {978-0-7803-7663-2},
url = {http://ieeexplore.ieee.org/document/1199999/},
volume = {5},
date = {2003},
langid = {english},
urldate = {2019-03-31},
file = {\:bibliography/ Acoustics/2003 Compilation of Unified Physical Models for Efficient Sound Synthesis_2003KarjalainenCompilation.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{2002BoullosaVibration,
author = {Ricardo R. Boullosa},
abstract = {Some measurements are described that pertain to the high frequency behaviour of the vibrations of the string and soundboard of the guitar.Three isolated soundboards of diﬀerent woods were compared with respect to their early decay times (by means of measurements of their vibrational impulse responses), in order to assess its possible use as an objective measure of the reverberation time of the plates. The results of all these measurements show that high frequency vibrations and radiation occurs signiﬁcantly from 1 to 14 kHz, but that the sound radiation has harmonics at frequencies up to 20 kHz. This report does not produce any experimental evidence as to the importance of the high frequency region from the subjective point of view, or to the correlation of the subjective impression of reverberation of the plates with measured data of early decay times, as these aspects were not addressed at this point.},
langid = {english},
journaltitle = {Applied Acoustics},
doi = {10.1016/S0003-682X(01)00037-8},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0003682X01000378},
date = {2002-03},
volume = {63},
number = {3},
pages = {311--322},
title = {Vibration measurements in the classical guitar},
issn = {0003-682X},
urldate = {2019-04-05},
file = {\:bibliography/ Acoustics/2002 Vibration Measurements in the Classical Guitar_2002BoullosaVibration.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{2001JaervelaeinenAudibility,
author = {Hanna Järveläinen and Vesa Välimäki and Matti Karjalainen},
pages = {79--84},
volume = {2},
journaltitle = {Acoustics Research Letters Online},
title = {Audibility of the timbral effects of inharmonicity in stringed instrument tones},
urldate = {2019-03-28},
number = {3},
date = {2001-07},
langid = {english},
doi = {10.1121/1.1374756},
issn = {1529-7853},
file = {\:bibliography/ Acoustics/2001 Audibility of the Timbral Effects of Inharmonicity in Stringed Instrument Tones_2001JaervelaeinenAudibility.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{1995CaldersmithDesigning,
author = {Graham Caldersmith},
langid = {english},
journaltitle = {Applied Acoustics},
pages = {3--17},
doi = {10.1016/0003-682X(95)93949-I},
abstract = {When the standard classical guitar is scaled up a musical fourth to a treble guitar, down a musical fifth to a baritone guitar, and down an octave to a bass guitar, design compromises are necessary to maintain playability and favourable tone qulality. The resulting instruments exhibit interesting natural vibration mode and sound radiation physics. The tone qualities of the new instruments suggest relations between the guitar response envelope and human sound perception. Translating the principle natural modes of the guitar up or down with string frequencies does not necessarily produce pleasing tone qualities nor optimal playing dynamics. However, designing bracing configurations for both classical and folk baritone and bass guitars to maximise low frequency radiation eficiency does seem to produce new instruments of musical appeal, Frequency response records of standard and guitar family variants illustrate the physical behaviour of the difierent designs. Experience of musicians with the guitar family instruments indicates that creative new guitar territory is available.},
title = {Designing a guitar family},
urldate = {2019-04-05},
url = {http://linkinghub.elsevier.com/retrieve/pii/0003682X9593949I},
volume = {46},
issn = {0003-682X},
number = {1},
date = {1995},
file = {\:bibliography/ Acoustics/1995 Designing a Guitar Family_1995CaldersmithDesigning.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@collection{2007BeauchampAnalysis,
editor = {Beauchamp, James W.},
title = {Analysis, synthesis, and perception of musical sounds: the sound of music},
isbn = {978-0-387-32496-8},
location = {New York, NY},
publisher = {Springer},
langid = {english},
series = {Modern acoustics and signal processing},
shorttitle = {Analysis, synthesis, and perception of musical sounds},
date = {2007},
pagetotal = {325},
note = {OCLC: 237018036},
file = {\:bibliography/ Acoustics/2007 Analysis, Synthesis, and Perception of Musical Sounds_ the Sound of Music_2007BeauchampAnalysis.pdf\:PDF},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{2018MartinMartinGoogle,
author = {Alberto Martín-Martín and Enrique Orduna-Malea and Mike Thelwall and Emilio Delgado López-Cózar},
abstract = {Despite citation counts from Google Scholar (GS), Web of Science (WoS), and Scopus being widely consulted by researchers and sometimes used in research evaluations, there is no recent or systematic evidence about the differences between them. In response, this paper investigates 2,448,055 citations to 2299 English-language highly-cited documents from 252 GS subject categories published in 2006, comparing GS, the WoS Core Collection, and Scopus. GS consistently found the largest percentage of citations across all areas (93/////// %–96/////// %), far ahead of Scopus (35/////// %–77/////// %) and WoS (27/////// %–73/////// %). GS found nearly all the WoS (95/////// %) and Scopus (92/////// %) citations. Most citations found only by GS were from non-journal sources (48/////// %–65/////// %), including theses, books, conference papers, and unpublished materials. Many were non-English (19/////// %–38/////// %), and they tended to be much less cited than citing sources that were also in Scopus or WoS. Despite the many unique GS citing sources, Spearman correlations between citation counts in GS and WoS or Scopus are high (0.78-0.99). They are lower in the Humanities, and lower between GS and WoS than between GS and Scopus. The results suggest that in all areas GS citation data is essentially a superset of WoS and Scopus, with substantial extra coverage.},
pages = {1160--1177},
journaltitle = {Journal of Informetrics},
langid = {english},
urldate = {2019-04-07},
date = {2018-11},
number = {4},
issn = {1751-1577},
shorttitle = {Google Scholar, Web of Science, and Scopus},
volume = {12},
doi = {10.1016/j.joi.2018.09.002},
title = {Google Scholar, Web of Science, and Scopus: A systematic comparison of citations in 252 subject categories},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1751157718303249},
file = {\:bibliography/ Bibliometry/2018 Google Scholar, Web of Science, and Scopus_ a Systematic Comparison of Citations in 252 Subject Categories_2018MartinMartinGoogle.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2017ZatorskiYoung,
author = {Hubert Zatorski and Jakub Fichna},
pages = {1151--1152},
date = {2017-12},
langid = {english},
issn = {2050-6406},
volume = {5},
shorttitle = {Young GI angle},
title = {Young GI angle: The role of bibliometrics in scientist’s career development},
doi = {10.1177/2050640617744497},
urldate = {2019-04-07},
number = {8},
journaltitle = {United European Gastroenterology Journal},
file = {\:bibliography/ Bibliometry/2017 Young GI Angle_ the Role of Bibliometrics in Scientist’s Career Development_2017ZatorskiYoung.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2016PerianesRodriguezConstructing,
author = {Antonio Perianes-Rodriguez and Ludo Waltman and Nees Jan van Eck},
volume = {10},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1751157716302036},
langid = {english},
pages = {1178--1195},
number = {4},
issn = {1751-1577},
journaltitle = {Journal of Informetrics},
shorttitle = {Constructing bibliometric networks},
doi = {10.1016/j.joi.2016.10.006},
urldate = {2019-04-07},
title = {Constructing bibliometric networks: A comparison between full and fractional counting},
date = {2016-11},
file = {\:bibliography/ Bibliometry/2016 Constructing Bibliometric Networks_ a Comparison between Full and Fractional Counting_2016PerianesRodriguezConstructing.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2016Mongeonjournal,
author = {Philippe Mongeon and Adèle Paul-Hus},
doi = {10.1007/s11192-015-1765-5},
urldate = {2019-04-07},
volume = {106},
abstract = {Bibliometric methods are used in multiple ﬁelds for a variety of purposes, namely for research evaluation. Most bibliometric analyses have in common their data sources: Thomson Reuters’ Web of Science (WoS) and Elsevier’s Scopus. The objective of this research is to describe the journal coverage of those two databases and to assess whether some ﬁeld, publishing country and language are over or underrepresented. To do this we compared the coverage of active scholarly journals in WoS (13,605 journals) and Scopus (20,346 journals) with Ulrich’s extensive periodical directory (63,013 journals). Results indicate that the use of either WoS or Scopus for research evaluation may introduce biases that favor Natural Sciences and Engineering as well as Biomedical Research to the detriment of Social Sciences and Arts and Humanities. Similarly, English-language journals are overrepresented to the detriment of other languages. While both databases share these biases, their coverage differs substantially. As a consequence, the results of bibliometric analyses may vary depending on the database used. These results imply that in the context of comparative research evaluation, WoS and Scopus should be used with caution, especially when comparing different ﬁelds, institutions, countries or languages. The bibliometric community should continue its efforts to develop methods and indicators that include scientiﬁc output that are not covered in WoS or Scopus, such as ﬁeld-speciﬁc and national citation indexes.},
langid = {english},
shorttitle = {The journal coverage of Web of Science and Scopus},
issn = {0138-9130},
date = {2016-01},
journaltitle = {Scientometrics},
pages = {213--228},
number = {1},
title = {The journal coverage of Web of Science and Scopus: a comparative analysis},
file = {\:bibliography/ Bibliometry/2016 The Journal Coverage of Web of Science and Scopus_ a Comparative Analysis_2016Mongeonjournal.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2016HarzingGoogle,
author = {Anne-Wil Harzing and Satu Alakangas},
title = {Google Scholar, Scopus and the Web of Science: a longitudinal and cross-disciplinary comparison},
date = {2016-02},
langid = {english},
number = {2},
journaltitle = {Scientometrics},
volume = {106},
doi = {10.1007/s11192-015-1798-9},
shorttitle = {Google Scholar, Scopus and the Web of Science},
abstract = {This article aims to provide a systematic and comprehensive comparison of the coverage of the three major bibliometric databases: Google Scholar, Scopus and the Web of Science. Based on a sample of 146 senior academics in ﬁve broad disciplinary areas, we therefore provide both a longitudinal and a cross-disciplinary comparison of the three databases. Our longitudinal comparison of eight data points between 2013 and 2015 shows a consistent and reasonably stable quarterly growth for both publications and citations across the three databases. This suggests that all three databases provide sufﬁcient stability of coverage to be used for more detailed cross-disciplinary comparisons. Our cross-disciplinary comparison of the three databases includes four key research metrics (publications, citations, h-index, and hI, annual, an annualised individual h-index) and ﬁve major disciplines (Humanities, Social Sciences, Engineering, Sciences and Life Sciences). We show that both the data source and the speciﬁc metrics used change the conclusions that can be drawn from cross-disciplinary comparisons.},
urldate = {2019-04-07},
pages = {787--804},
issn = {0138-9130},
file = {\:bibliography/ Bibliometry/2016 Google Scholar, Scopus and the Web of Science_ a Longitudinal and Cross Disciplinary Comparison_2016HarzingGoogle.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2014ZahediHow,
author = {Zohreh Zahedi and Rodrigo Costas and Paul Wouters},
langid = {english},
volume = {101},
pages = {1491--1513},
doi = {10.1007/s11192-014-1264-0},
shorttitle = {How well developed are altmetrics?},
date = {2014-11},
abstract = {In this paper an analysis of the presence and possibilities of altmetrics for bibliometric and performance analysis is carried out. Using the web based tool Impact Story, we collected metrics for 20,000 random publications from the Web of Science. We studied both the presence and distribution of altmetrics in the set of publications, across ﬁelds, document types and over publication years, as well as the extent to which altmetrics correlate with citation indicators. The main result of the study is that the altmetrics source that provides the most metrics is Mendeley, with metrics on readerships for 62.6 /////// % of all the publications studied, other sources only provide marginal information. In terms of relation with citations, a moderate spearman correlation (r = 0.49) has been found between Mendeley readership counts and citation indicators. Other possibilities and limitations of these indicators are discussed and future research lines are outlined.},
number = {2},
title = {How well developed are altmetrics? A cross-disciplinary analysis of the presence of ‘alternative metrics’ in scientific publications},
journaltitle = {Scientometrics},
issn = {0138-9130},
urldate = {2019-04-07},
file = {\:bibliography/ Bibliometry/2014 How Well Developed Are Altmetrics_ a Cross Disciplinary Analysis of the Presence of ‘alternative Metrics’ in Scientific Publications_2014ZahediHow.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2014Winterexpansion,
author = {Joost C. F. de Winter and Amir A. Zadpoor and Dimitra Dodou},
date = {2014-02},
langid = {english},
shorttitle = {The expansion of Google Scholar versus Web of Science},
issn = {0138-9130},
abstract = {Web of Science (WoS) and Google Scholar (GS) are prominent citation services with distinct indexing mechanisms. Comprehensive knowledge about the growth patterns of these two citation services is lacking. We analyzed the development of citation counts in WoS and GS for two classic articles and 56 articles from diverse research ﬁelds, making a distinction between retroactive growth (i.e., the relative difference between citation counts up to mid-2005 measured in mid-2005 and citation counts up to mid-2005 measured in April 2013) and actual growth (i.e., the relative difference between citation counts up to mid-2005 measured in April 2013 and citation counts up to April 2013 measured in April 2013). One of the classic articles was used for a citation-by-citation analysis. Results showed that GS has substantially grown in a retroactive manner (median of 170 /////// % across articles), especially for articles that initially had low citations counts in GS as compared to WoS. Retroactive growth of WoS was small, with a median of 2 /////// % across articles. Actual growth percentages were moderately higher for GS than for WoS (medians of 54 vs. 41 /////// %). The citation-by-citation analysis showed that the percentage of citations being unique in WoS was lower for more recent citations (6.8 /////// % for citations from 1995 and later vs. 41 /////// % for citations from before 1995), whereas the opposite was noted for GS (57 vs. 33 /////// %). It is concluded that, since its inception, GS has shown substantial expansion, and that the majority of recent works indexed in WoS are now also retrievable via GS. A discussion is provided on quantity versus quality of citations, threats for WoS, weaknesses of GS, and implications for literature research and research evaluation.},
doi = {10.1007/s11192-013-1089-2},
urldate = {2019-04-07},
title = {The expansion of Google Scholar versus Web of Science: a longitudinal study},
pages = {1547--1565},
volume = {98},
journaltitle = {Scientometrics},
number = {2},
file = {\:bibliography/ Bibliometry/2014 The Expansion of Google Scholar Versus Web of Science_ a Longitudinal Study_2014Winterexpansion.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2014HausteinCoverage,
author = {Stefanie Haustein and Isabella Peters and Judit Bar-Ilan and Jason Priem and Hadas Shema and Jens Terliesner},
title = {Coverage and adoption of altmetrics sources in the bibliometric community},
urldate = {2019-04-07},
issn = {0138-9130},
number = {2},
volume = {101},
pages = {1145--1163},
doi = {10.1007/s11192-013-1221-3},
journaltitle = {Scientometrics},
date = {2014-11},
langid = {english},
file = {\:bibliography/ Bibliometry/2014 Coverage and Adoption of Altmetrics Sources in the Bibliometric Community_2014HausteinCoverage.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@misc{2014HarinarayanaData,
author = {N. Harinarayana},
url = {https://epgp.inflibnet.ac.in/epgpdata/uploads/epgp///////\\_content/library///////\\_and///////\\_information///////\\_science/informetrics///////\\_///////\\&///////\\_scientometrics/data///////\\_sources///////\\_and///////\\_software///////\\_tools///////\\_for///////\\_bibliometric///////\\_studies/et/333///////\\_et///////\\_m2.pdf},
date = {2014},
title = {Data sources and software tools for bibliometric studies},
file = {\:bibliography/ Bibliometry/2014 Data Sources and Software Tools for Bibliometric Studies_2014HarinarayanaData.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2014BornmannValidity,
author = {Lutz Bornmann},
pages = {935--950},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1751157714000881},
shorttitle = {Validity of altmetrics data for measuring societal impact},
abstract = {Can altmetric data be validly used for the measurement of societal impact? The current study seeks to answer this question with a comprehensive dataset (about 100,000 records) from very disparate sources (F1000, Altmetric, and an in-house database based on Web of Science). In the F1000 peer review system, experts attach particular tags to scientiﬁc papers which indicate whether a paper could be of interest for science or rather for other segments of society. The results show that papers with the tag "good for teaching" do achieve higher altmetric counts than papers without this tag – if the quality of the papers is controlled. At the same time, a higher citation count is shown especially by papers with a tag that is speciﬁcally scientiﬁcally oriented ("new ﬁnding"). The ﬁndings indicate that papers tailored for a readership outside the area of research should lead to societal impact.},
issn = {1751-1577},
number = {4},
volume = {8},
doi = {10.1016/j.joi.2014.09.007},
title = {Validity of altmetrics data for measuring societal impact: A study using data from Altmetric and F1000Prime},
journaltitle = {Journal of Informetrics},
urldate = {2019-04-07},
langid = {english},
date = {2014-10},
file = {\:bibliography/ Bibliometry/2014 Validity of Altmetrics Data for Measuring Societal Impact_ a Study Using Data from Altmetric and F1000Prime_2014BornmannValidity.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2014BornmannDo,
author = {Lutz Bornmann},
issn = {1751-1577},
shorttitle = {Do altmetrics point to the broader impact of research?},
volume = {8},
title = {Do altmetrics point to the broader impact of research? An overview of benefits and disadvantages of altmetrics},
pages = {895--903},
journaltitle = {Journal of Informetrics},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1751157714000868},
langid = {english},
number = {4},
doi = {10.1016/j.joi.2014.09.005},
date = {2014-10},
urldate = {2019-04-07},
file = {\:bibliography/ Bibliometry/2014 Do Altmetrics Point to the Broader Impact of Research_ an Overview of Benefits and Disadvantages of Altmetrics_2014BornmannDo.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2013ThelwallDo,
author = {Mike Thelwall and Stefanie Haustein and Vincent Larivière and Cassidy R. Sugimoto},
doi = {10.1371/journal.pone.0064841},
number = {5},
date = {2013-05-28},
abstract = {Altmetric measurements derived from the social web are increasingly advocated and used as early indicators of article impact and usefulness. Nevertheless, there is a lack of systematic scientific evidence that altmetrics are valid proxies of either impact or utility although a few case studies have reported medium correlations between specific altmetrics and citation rates for individual journals or fields. To fill this gap, this study compares 11 altmetrics with Web of Science citations for 76 to 208,739 PubMed articles with at least one altmetric mention in each case and up to 1,891 journals per metric. It also introduces a simple sign test to overcome biases caused by different citation and usage windows. Statistically significant associations were found between higher metric scores and higher citations for articles with positive altmetric scores in all cases with sufficient evidence (Twitter, Facebook wall posts, research highlights, blogs, mainstream media and forums) except perhaps for Google+ posts. Evidence was insufficient for LinkedIn, Pinterest, question and answer sites, and Reddit, and no conclusions should be drawn about articles with zero altmetric scores or the strength of any correlation between altmetrics and citations. Nevertheless, comparisons between citations and metric values for articles published at different times, even within the same year, can remove or reverse this association and so publishers and scientometricians should consider the effect of time when using altmetrics to rank articles. Finally, the coverage of all the altmetrics except for Twitter seems to be low and so it is not clear if they are prevalent enough to be useful in practice.},
journaltitle = {PLoS ONE},
editor = {Bornmann, Lutz},
shorttitle = {Do Altmetrics Work?},
volume = {8},
title = {Do Altmetrics Work? Twitter and Ten Other Social Web Services},
pages = {e64841},
urldate = {2019-04-07},
langid = {english},
issn = {1932-6203},
file = {\:bibliography/ Bibliometry/2013 Do Altmetrics Work_ Twitter and Ten Other Social Web Services_2013ThelwallDo.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2013S.AdriaanseWeb,
author = {Leslie S. Adriaanse and Chris Rensleigh},
abstract = {Purpose – The research aim for this study was to compare three citation resources with one another to identify the citation resource with the most representative South African scholarly environmental sciences citation coverage. This paper focuses on the results of the content veriﬁcation process which measured amongst others the citation counts, multiple copies and inconsistencies encountered across the three citation resources ISI Web of Science, Scopus and Google Scholar.},
date = {2013-11-18},
title = {Web of Science, Scopus and Google Scholar: A content comprehensiveness comparison},
journaltitle = {The Electronic Library},
doi = {10.1108/EL-12-2011-0174},
volume = {31},
langid = {english},
pages = {727--744},
number = {6},
urldate = {2019-04-07},
issn = {0264-0473},
shorttitle = {Web of Science, Scopus and Google Scholar},
file = {\:bibliography/ Bibliometry/2013 Web of Science, Scopus and Google Scholar_ a Content Comprehensiveness Comparison_2013S.AdriaanseWeb.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2013GalliganAltmetrics,
author = {Finbar Galligan and Sharon Dyas-Correia},
doi = {10.1016/j.serrev.2013.01.003},
date = {2013-03},
issn = {0098-7913},
number = {1},
title = {Altmetrics: Rethinking the Way We Measure},
pages = {56--61},
url = {http://linkinghub.elsevier.com/retrieve/pii/S009879131300004X},
urldate = {2019-04-07},
journaltitle = {Serials Review},
volume = {39},
abstract = {Altmetrics is the focus for this edition of "Balance Point." The column editor invited Finbar Galligan who has gained considerable knowledge of altmetrics to co-author the column. Altmetrics, their relationship to traditional metrics, their importance, uses, potential impacts, and possible future directions are examined. The authors conclude that altmetrics have an important future role to play and that they offer the potential to revolutionize the analysis of the value and impact of scholarly work.},
langid = {english},
shorttitle = {Altmetrics},
file = {\:bibliography/ Bibliometry/2013 Altmetrics_ Rethinking the Way We Measure_2013GalliganAltmetrics.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2012VanclayImpact,
author = {Jerome K. Vanclay},
journaltitle = {Scientometrics},
issn = {0138-9130},
number = {2},
title = {Impact factor: outdated artefact or stepping-stone to journal certification?},
doi = {10.1007/s11192-011-0561-0},
volume = {92},
urldate = {2019-04-07},
abstract = {A review of Garﬁeld’s journal impact factor and its speciﬁc implementation as the Thomson Reuters impact factor reveals several weaknesses in this commonly-used indicator of journal standing. Key limitations include the mismatch between citing and cited documents, the deceptive display of three decimals that belies the real precision, and the absence of conﬁdence intervals. These are minor issues that are easily amended and should be corrected, but more substantive improvements are needed. There are indications that the scientiﬁc community seeks and needs better certiﬁcation of journal procedures to improve the quality of published science. Comprehensive certiﬁcation of editorial and review procedures could help ensure adequate procedures to detect duplicate and fraudulent submissions.},
langid = {english},
date = {2012-08},
pages = {211--238},
shorttitle = {Impact factor},
file = {\:bibliography/ Bibliometry/2012 Impact Factor_ Outdated Artefact or Stepping Stone to Journal Certification__2012VanclayImpact.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@article{2006BakkalbasiThree,
author = {Nisa Bakkalbasi and Kathleen Bauer and Janis Glover and Lei Wang},
abstract = {Background: Researchers turn to citation tracking to find the most influential articles for a particular topic and to see how often their own published papers are cited. For years researchers looking for this type of information had only one resource to consult: the Web of Science from Thomson Scientific. In 2004 two competitors emerged – Scopus from Elsevier and Google Scholar from Google. The research reported here uses citation analysis in an observational study examining these three databases; comparing citation counts for articles from two disciplines (oncology and condensed matter physics) and two years (1993 and 2003) to test the hypothesis that the different scholarly publication coverage provided by the three search tools will lead to different citation counts from each. Methods: Eleven journal titles with varying impact factors were selected from each discipline (oncology and condensed matter physics) using the Journal Citation Reports (JCR). All articles published in the selected titles were retrieved for the years 1993 and 2003, and a stratified random sample of articles was chosen, resulting in four sets of articles. During the week of November 7–12, 2005, the citation counts for each research article were extracted from the three sources. The actual citing references for a subset of the articles published in 2003 were also gathered from each of the three sources. Results: For oncology 1993 Web of Science returned the highest average number of citations, 45.3. Scopus returned the highest average number of citations (8.9) for oncology 2003. Web of Science returned the highest number of citations for condensed matter physics 1993 and 2003 (22.5 and 3.9 respectively). The data showed a significant difference in the mean citation rates between all pairs of resources except between Google Scholar and Scopus for condensed matter physics 2003. For articles published in 2003 Google Scholar returned the largest amount of unique citing material for oncology and Web of Science returned the most for condensed matter physics. Conclusion: This study did not identify any one of these three resources as the answer to all citation tracking needs. Scopus showed strength in providing citing literature for current (2003) oncology articles, while Web of Science produced more citing material for 2003 and 1993 condensed matter physics, and 1993 oncology articles. All three tools returned some unique material. Our data indicate that the question of which tool provides the most complete set of citing literature may depend on the subject and publication year of a given article.},
doi = {10.1186/1742-5581-3-7},
title = {Three options for citation tracking: Google Scholar, Scopus and Web of Science},
shorttitle = {Three options for citation tracking},
journaltitle = {Biomedical Digital Libraries},
number = {1},
date = {2006-12},
urldate = {2019-04-07},
volume = {3},
langid = {english},
issn = {1742-5581},
file = {\:bibliography/ Bibliometry/2006 Three Options for Citation Tracking_ Google Scholar, Scopus and Web of Science_2006BakkalbasiThree.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@collection{2018ErdtAltmetrics,
isbn = {9789811310522},
urldate = {2019-04-07},
title = {Altmetrics for Research Outputs Measurement and Scholarly Information Management},
doi = {10.1007/978-981-13-1053-9},
date = {2018},
publisher = {Springer Singapore},
editor = {Erdt, Mojisola and Sesagiri Raamkumar, Aravind and Rasmussen, Edie and Theng, Yin-Leng},
location = {Singapore},
series = {Communications in Computer and Information Science},
volume = {856},
langid = {english},
file = {\:bibliography/ Bibliometry/2018 Altmetrics for Research Outputs Measurement and Scholarly Information Management_2018ErdtAltmetrics.pdf\:PDF},
keywords = {bibliometry},
mendeley-tags = {bibliometry},
}

@misc{2017EbrahimHow,
author = {Nader Ale Ebrahim},
date = {2017},
urldate = {2019-04-07},
doi = {10.6084/m9.figshare.5374615.v1},
title = {How to Write a Bibliometric Paper},
publisher = {Figshare},
langid = {english},
abstract = {Bibliometrics can be defined as the statistical analysis of publications. Bibliometrics has focused on the quantitative analysis of citations and citation counts which is complex. It is so complex and specialized that personal knowledge and experience are insufficient for understanding trends and then making decisions. We need tools for analysis of bibliometrics information to recognize the research trends and evaluate scientific/institution/country’s research productivity. This presentation will provide procedure to write a Bibliometrics paper.},
url = {https://figshare.com/articles/How///////\\_to///////\\_Write///////\\_a///////\\_Bibliometric///////\\_Paper/5374615/1},
file = {\:bibliography/ Writing/2017 How to Write a Bibliometric Paper_2017EbrahimHow.pdf\:PDF},
keywords = {writing},
mendeley-tags = {writing},
}

@article{HendryInharmonicity,
author = {Simon Hendry},
pages = {32},
title = {Inharmonicity of Piano Strings},
abstract = {Piano partials deviate from integer harmonics due to the stiffness and linear density of the strings. Values for the inharmonicity coefficient of six strings were determined experimentally and compared with calculated values. An investigation into stretched tuning was also performed with detailed readings taken from a well tuned Steinway Model D grand piano. These results are compared with Railsback‟s predictions of 1938.},
langid = {english},
file = {\:bibliography/ Piano/Inharmonicity of Piano Strings_HendryInharmonicity.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{2016Graciawave,
author = {X. Gracia and T. Sanz-perela},
journaltitle = {Reports@SCM},
eprinttype = {arXiv},
title = {The wave equation for stiff strings and piano tuning.},
url = {http://revistes.iec.cat/index.php/reports/article/view/142136/141068},
arxivid = {1603.05516},
annotation = {preprint},
number = {1},
volume = {3},
eprint = {1603.05516},
date = {2016},
pages = {1--16},
file = {\:bibliography/ Piano/2016 The Wave Equation for Stiff Strings and Piano Tuning._2016Graciawave.pdf\:PDF},
keywords = {inharmonic spectrum,musical,stiffness,vibrating string,wave equation},
mendeley-tags = {inharmonic spectrum,musical,stiffness,vibrating string,wave equation},
}

@article{2015GiordanoExplaining,
author = {N. Giordano},
volume = {138},
number = {4},
title = {Explaining the Railsback stretch in terms of the inharmonicity of piano tones and sensory dissonance},
journaltitle = {The Journal of the Acoustical Society of America},
urldate = {2019-03-26},
langid = {english},
doi = {10.1121/1.4931439},
date = {2015-10},
issn = {0001-4966},
pages = {2359--2366},
file = {\:bibliography/ Piano/2015 Explaining the Railsback Stretch in Terms of the Inharmonicity of Piano Tones and Sensory Dissonance_2015GiordanoExplaining.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@inproceedings{2015ChengModelling,
author = {Tian Cheng and Simon Dixon and Matthias Mauch},
abstract = {We investigate piano acoustics and compare the theoretical temporal decay of individual partials to recordings of real-world piano notes from the RWC Music Database. We ﬁrst describe the theory behind double decay and beats, known phenomena caused by the interaction between strings and soundboard. Then we ﬁt the decay of the ﬁrst 30 partials to a standard linear model and two physically-motivated non-linear models that take into account the coupling of strings and soundboard. We show that the use of non-linear models provides a better ﬁt to the data. We use these estimated decay rates to parameterise the characteristic decay response (decay rates along frequencies) of the piano under investigation. The results also show that dynamics have no signiﬁcant effect on the decay rate.},
langid = {english},
title = {Modelling the decay of piano sounds},
eventtitle = {ICASSP 2015 - 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
isbn = {978-1-4673-6997-8},
pages = {594--598},
doi = {10.1109/ICASSP.2015.7178038},
date = {2015-04},
publisher = {IEEE},
location = {South Brisbane, Queensland, Australia},
url = {http://ieeexplore.ieee.org/document/7178038/},
urldate = {2019-03-28},
file = {\:bibliography/ Piano/2015 Modelling the Decay of Piano Sounds_2015ChengModelling.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@report{2004BurredAcoustics,
author = {Juan Jose Burred},
institution = {Professional Conservatory of Music Arturo Soria},
pages = {43},
langid = {english},
date = {2004},
type = {resreport},
title = {The Acoustics of the Piano},
year = {2004},
file = {\:bibliography/ Piano/2004 The Acoustics of the Piano_2004BurredAcoustics.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@report{1992ChaigneNumerical,
author = {A. Chaigne and A. Askenfelt},
title = {Numerical simulations of piano strings},
pages = {24},
institution = {KTH},
langid = {english},
date = {1992},
type = {resreport},
year = {1992},
abstract = {Thefirst attempt to generate musical sounds by solving the equations of vibrating strings by means of Finite Difference Methods (FDM)was made by Hiller /& Ruiz (].AudioEng.Soc. 19, pp. 462-472, 19711. It is shown here how their numerical approach and the underlying physical model can be improved in order to simulate the motion of the piano string with a high d e g e e of realism. Starting from the fundamental equations of a damped, stlff string interacting with a nonlinear hammer, a numericalfinite difference scheme is derived,from which the time and spatial dependence of string displacement, velocity, and interactingforce between hammer and string, as well as theforce acting on the bridge, are computed in the time-domain. The strength of the model is illustrated by comparisons between measured and simulated piano tones. After this verification of the accuracy of the method, the model is used as a tool for systematically exploring the influence of string stiffness, relative strikin, position, and hammer-string mass ratio on string waveforms and spectra.},
file = {\:bibliography/ Piano/1992 Numerical Simulations of Piano Strings_1992ChaigneNumerical.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{1964FletcherNormal,
author = {Harvey Fletcher},
year = {1964},
journaltitle = {The Journal of the Acoustical Society of America},
doi = {10.1121/1.1918933},
number = {1},
publisher = {Acoustical Society of America (ASA)},
journal = {The Journal Of The Acoustical Society Of America},
volume = {36},
title = {Normal Vibration Frequencies of a Stiff Piano String},
month = {jan},
date = {1964-01},
pages = {203--209},
urldate = {2019-03-28},
langid = {english},
issn = {0001-4966},
file = {\:bibliography/ Piano/1964 Normal Vibration Frequencies of a Stiff Piano String_1964FletcherNormal.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{1961MartinSubjective,
author = {Daniel W. Martin and W. D. Ward},
number = {5},
pages = {582--585},
volume = {33},
publisher = {ASA},
date = {1961},
journaltitle = {The Journal of the Acoustical Society of America},
title = {Subjective evaluation of musical scale temperament in pianos},
file = {\:bibliography/ Piano/1961 Subjective Evaluation of Musical Scale Temperament in Pianos_1961MartinSubjective.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{2016ChabassierTime,
author = {Juliette Chabassier and Marc Duruflé and Patrick Joly},
title = {Time domain simulation of a piano. Part 2: numerical aspects},
shorttitle = {Time domain simulation of a piano. Part 2},
volume = {50},
pages = {93--133},
issn = {0764-583X},
number = {1},
langid = {english},
journaltitle = {ESAIM: Mathematical Modelling and Numerical Analysis},
doi = {10.1051/m2an/2015007},
date = {2016-01},
urldate = {2019-03-26},
abstract = {This article is the second of a series of two papers devoted to the numerical simulation of the piano. It concerns the numerical aspects of the work, the implementation of a piano code and the presentation of corresponding simulations. The main diﬃculty is time discretisation and stability is achieved via energy methods. Numerical illustrations are provided for a realistic piano and compared to experimental recordings.},
file = {\:bibliography/ Piano/2016 Time Domain Simulation of a Piano. Part 2_ Numerical Aspects_2016ChabassierTime.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{2014ChabassierTime,
author = {J. Chabassier and A. Chaigne and P. Joly},
number = {5},
doi = {10.1051/m2an/2013136},
abstract = {The purpose of this study is the time domain modeling of a piano. We aim at explaining the vibratory and acoustical behavior of the piano, by taking into account the main elements that contribute to sound production. The soundboard is modeled as a bidimensional thick, orthotropic, heterogeneous, frequency dependant damped plate, using Reissner Mindlin equations. The vibroacoustics equations allow the soundboard to radiate into the surrounding air, in which we wish to compute the complete acoustical ﬁeld around the perfectly rigid rim. The soundboard is also coupled to the strings at the bridge, where they form a slight angle from the horizontal plane. Each string is modeled by a one dimensional damped system of equations, taking into account not only the transversal waves excited by the hammer, but also the stiﬀness thanks to shear waves, as well as the longitudinal waves arising from geometric nonlinearities. The hammer is given an initial velocity that projects it towards a choir of strings, before being repelled. The interacting force is a nonlinear function of the hammer compression. The ﬁnal piano model is a coupled system of partial diﬀerential equations, each of them exhibiting speciﬁc diﬃculties (nonlinear nature of the string system of equations, frequency dependant damping of the soundboard, great number of unknowns required for the acoustic propagation), in addition to couplings’ inherent diﬃculties.},
journaltitle = {ESAIM: Mathematical Modelling and Numerical Analysis},
date = {2014-09},
shorttitle = {Time domain simulation of a piano. Part 1},
issn = {0764-583X},
urldate = {2019-03-26},
langid = {english},
pages = {1241--1278},
volume = {48},
title = {Time domain simulation of a piano. Part 1: model description},
file = {\:bibliography/ Piano/2014 Time Domain Simulation of a Piano. Part 1_ Model Description_2014ChabassierTime.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@article{2009BrynerStiff,
author = {John C. Bryner},
date = {2009-12},
title = {Stiff-string theory: Richard Feynman on piano tuning},
langid = {english},
shorttitle = {Stiff-string theory},
number = {12},
journaltitle = {Physics Today},
doi = {10.1063/1.3273016},
pages = {46--49},
urldate = {2019-03-26},
volume = {62},
issn = {0031-9228},
file = {\:bibliography/ Piano/2009 Stiff String Theory_ Richard Feynman on Piano Tuning_2009BrynerStiff.pdf\:PDF},
keywords = {piano},
mendeley-tags = {piano},
}

@unpublished{2009TaoFourier,
author = {Terence Tao},
title = {Fourier Transform},
url = {https://www.math.ucla.edu//textasciitilde tao/preprints/fourier.pdf},
date = {2009},
file = {\:bibliography/ Harmonic Analysis/2009 Fourier Transform_2009TaoFourier.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@misc{2004FesslerDiscrete,
author = {Jeffrey Fessler},
title = {The Discrete Fourier Transform},
note = {chapter 5},
url = {https://web.eecs.umich.edu//textasciitilde fessler/course/451/l/pdf/c5.pdf},
date = {2004},
file = {\:bibliography/ Harmonic Analysis/2004 The Discrete Fourier Transform_2004FesslerDiscrete.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@unpublished{2009MorinFourier,
author = {David Morin},
year = {2009},
url = {http://www.people.fas.harvard.edu//textasciitilde djmorin/waves/Fourier.pdf},
date = {2009},
title = {Fourier analysis.pdf},
note = {Chapter 3},
file = {\:bibliography/ Harmonic Analysis/2009 Fourier Analysis.pdf_2009MorinFourier.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@article{2015CourtneyMore,
author = {Elya Courtney and Michael Courtney},
title = {A More Accurate Fourier Transform},
eprintclass = {physics},
date = {2015-07-06},
eprint = {1507.01832},
abstract = {Fourier transform methods are used to analyze functions and data sets to provide frequencies, amplitudes, and phases of underlying oscillatory components. Fast Fourier transform (FFT) methods oﬀer speed advantages over evaluation of explicit integrals (EI) that deﬁne Fourier transforms. This paper compares frequency, amplitude, and phase accuracy of the two methods for well resolved peaks over a wide array of data sets including cosine series with and without random noise and a variety of physical data sets, including atmospheric CO2 concentrations, tides, temperatures, sound waveforms, and atomic spectra. The FFT uses MIT’s FFTW3 library. The EI method uses the rectangle method to compute the areas under the curve via complex math. Results support the hypothesis that EI methods are more accurate than FFT methods. Errors range from 5 to 10 times higher when determining peak frequency by FFT, 1.4 to 60 times higher for peak amplitude, and 6 to 10 times higher for phase under a peak. The ability to compute more accurate Fourier transforms has promise for improved data analysis in many ﬁelds, including more sensitive assessment of hypotheses in the environmental sciences related to CO2 concentrations and temperature. Other methods are available to address diﬀerent weaknesses in FFTs; however, the EI method always produces the most accurate output possible for a given data set. On the 2011 Lenovo ThinkPad used in this study, an EI transform on a 10,000 point data set took 31 seconds to complete. Source code (C) and Windows executable for the EI method are available at https://sourceforge.net/projects/amoreaccuratefouriertransform/.},
langid = {english},
eprinttype = {arxiv},
file = {\:bibliography/ Harmonic Analysis/2015 A More Accurate Fourier Transform_2015CourtneyMore.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@article{1987SorensenReal,
author = {H. Sorensen and D. Jones and M. Heideman and C. Burrus},
issn = {0096-3518},
journaltitle = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
number = {6},
pages = {849--863},
title = {Real-valued fast Fourier transform algorithms},
date = {1987-06},
doi = {10.1109/TASSP.1987.1165220},
volume = {35},
file = {\:bibliography/ Harmonic Analysis/1987 Real Valued Fast Fourier Transform Algorithms_1987SorensenReal.pdf\:PDF},
keywords = {algorithm design and analysis,application software,convolutional codes,digital images,discrete fourier transforms,discrete transforms,fast fourier transforms,nasa,signal processing algorithms},
mendeley-tags = {algorithm design and analysis,application software,convolutional codes,digital images,discrete fourier transforms,discrete transforms,fast fourier transforms,nasa,signal processing algorithms},
}

@inproceedings{2015LiaoAnalytical,
author = {Jan-Ray Liao},
title = {Analytical solution of DFT interpolated frequency estimator for Hanning windowed signal},
pages = {177--180},
url = {http://ieeexplore.ieee.org/document/7458336/},
location = {Nara, Japan},
urldate = {2019-03-26},
booktitle = {2015 15th International Symposium on Communications and Information Technologies (ISCIT)},
date = {2015-10},
doi = {10.1109/ISCIT.2015.7458336},
publisher = {IEEE},
abstract = {Frequency estimation from discrete Fourier transform (DFT) coefﬁcients of a rectangular windowed signal under the inﬂuence of additive white noise is a well studied problem in signal processing. In its simplest form, the process involves ﬁnding the spectral peaks. When higher frequency resolution is required, a frequency offset can be found from the interpolation of DFT coefﬁcients. However, most of the past researches focus on monotonic cisoid signals. In practical situations where multiple harmonics are present, the sidelobes from other harmonics interfere with the estimation of the harmonic being considered. In this case, windows with smaller sidelobes such as Hanning window are preferred over rectangular window. Given the increased mathematical complexity of Hanning window, analytical solution has not yet been available for DFT interpolation. In this paper, we derive an exact analytical solution of the estimated frequency from DFT interpolation of Hanning windowed signal. In experiments, we show that the new analytical solution is accurate for monotonic cisoid signal and can considerably reduce the effect of interharmonic interference as compared to previous rectangular windowed methods.},
langid = {english},
isbn = {978-1-4673-6820-9},
eventtitle = {2015 15th International Symposium on Communications and Information Technologies (ISCIT)},
file = {\:bibliography/ Harmonic Analysis/2015 Analytical Solution of DFT Interpolated Frequency Estimator for Hanning Windowed Signal_2015LiaoAnalytical.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@unpublished{2012MorseFourier,
author = {Bryan Morse},
langid = {english},
pages = {4},
date = {2012},
title = {The Fourier Transform: Examples, Properties, Common Pairs},
file = {\:bibliography/ Harmonic Analysis/2012 The Fourier Transform_ Examples, Properties, Common Pairs_2012MorseFourier.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@collection{1979CarmonaNon,
location = {Berlin ; New York},
title = {Non-commutative harmonic analysis: proceedings, Marseille-Luminy, France, June 26 to 30, 1978: actes du Colloque d'analyse harmonique non commutative},
date = {1979},
editor = {Carmona, Jacques and Vergne, Michèle},
series = {Lecture notes in mathematics ; 728},
isbn = {978-0-387-09516-5},
publisher = {Springer-Verlag},
shorttitle = {Non-commutative harmonic analysis},
pagetotal = {244},
file = {\:bibliography/ Harmonic Analysis/1979 Non Commutative Harmonic Analysis_ Proceedings, Marseille Luminy, France, June 26 to 30, 1978_ Actes Du Colloque D'analyse Harmonique Non Commutative_1979CarmonaNon.pdf\:PDF},
keywords = {congresses,harmonic analysis,lie algebras,lie groups},
mendeley-tags = {congresses,harmonic analysis,lie algebras,lie groups},
}

@collection{2010SzoekefalviNagyHarmonic,
date = {2010},
title = {Harmonic analysis of operators on Hilbert space},
isbn = {978-1-4419-6093-1},
note = {OCLC: 845818617},
series = {Universitext},
edition = {2},
location = {New York, NY},
editor = {Szőkefalvi-Nagy, Béla},
langid = {english},
pagetotal = {474},
publisher = {Springer},
file = {\:bibliography/ Harmonic Analysis/2010 Harmonic Analysis of Operators on Hilbert Space_2010SzoekefalviNagyHarmonic.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@unpublished{2007AnandBrief,
author = { An and Aashirwad Viswanathan },
date = {2007},
langid = {english},
year = {2007},
pages = {11},
abstract = {This paper studies the mathematical machinery underlying the Discrete and Fast Fourier Transforms, algorithmic processes widely used in quantum mechanics, signal analysis, options pricing, and other diverse ﬁelds. Beginning with the basic properties of Fourier Transform, we proceed to study the derivation of the Discrete Fourier Transform, as well as computational considerations that necessitate the development of a faster way to calculate the DFT. With these considerations in mind, we study the construction of the Fast Fourier Transform, as proposed by Cooley and Tukey [7].},
title = {A Brief Study Of Discrete And Fast Fourier Transforms},
file = {\:bibliography/ Harmonic Analysis/2007 A Brief Study of Discrete and Fast Fourier Transforms_2007AnandBrief.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@unpublished{2003KornerFirst,
author = {T. W. Korner},
date = {2003},
title = {A First Look at Fourier Analysis},
langid = {english},
pages = {60},
file = {\:bibliography/ Harmonic Analysis/2003 A First Look at Fourier Analysis_2003KornerFirst.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@misc{2017BattyDiscrete,
author = {C. Batty},
date = {2017},
title = {Discrete Fourier Transform Derivation},
file = {\:bibliography/ Harmonic Analysis/2017 Discrete Fourier Transform Derivation_2017BattyDiscrete.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@unpublished{2017DeSerioAddendum,
author = {Robert DeSerio},
number = {6},
langid = {english},
date = {2017},
pages = {12},
title = {Addendum : The Fourier transform of decaying oscillations},
file = {\:bibliography/ Harmonic Analysis/2017 Addendum _ the Fourier Transform of Decaying Oscillations_2017DeSerioAddendum.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@article{2014SerraSpectral,
author = {Xavier Serra},
date = {2014},
number = {November},
title = {Spectral Modeling Synthesis: Past and Present},
pages = {26},
langid = {english},
file = {\:bibliography/ Harmonic Analysis/2014 Spectral Modeling Synthesis_ Past and Present_2014SerraSpectral.pdf\:PDF},
keywords = {harmonic analysis},
mendeley-tags = {harmonic analysis},
}

@misc{2017OliehoekGANGs,
author = {Frans A. Oliehoek and Rahul Savani and Jose Gallego-Posada and Elise van der Pol and Edwin D. de Jong and Roderich Gross},
eprint = {1712.00679},
shorttitle = {GANGs},
eprinttype = {arXiv},
date = {2017-12-02},
title = {GANGs: Generative Adversarial Network Games},
abstract = {Generative Adversarial Networks (GAN) have become one of the most successful frameworks for unsupervised generative modeling. As GANs are difficult to train much research has focused on this. However, very little of this research has directly exploited gametheoretic techniques. We introduce Generative Adversarial Network Games (GANGs), which explicitly model a finite zero-sum game between a generator (G) and classifier (C) that use mixed strategies. The size of these games precludes exact solution methods, therefore we define resource-bounded best responses (RBBRs), and a resourcebounded Nash Equilibrium (RB-NE) as a pair of mixed strategies such that neither G or C can find a better RBBR. The RB-NE solution concept is richer than the notion of ‘local Nash equilibria’ in that it captures not only failures of escaping local optima of gradient descent, but applies to any approximate best response computations, including methods with random restarts. To validate our approach, we solve GANGs with the Parallel Nash Memory algorithm, which provably monotonically converges to an RB-NE. We compare our results to standard GAN setups, and demonstrate that our method deals well with typical GAN problems such as mode collapse, partial mode coverage and forgetting.},
journaltitle = {arXiv},
langid = {english},
file = {\:bibliography/ Game Theory/2017 GANGs_ Generative Adversarial Network Games_2017OliehoekGANGs.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@incollection{2017AnStackelberg,
author = {Bo An and Milind Tambe},
editor = {Abbas, Ali E. and Tambe, Milind and von Winterfeldt, Detlof},
langid = {english},
title = {Stackelberg Security Games (SSG) Basics and Application Overview},
doi = {10.1017/9781316676714.021},
abstract = {Security is a critical concern around the world, whether it is the challenge of protecting ports, airports and other critical infrastructure, interdicting the illegal ﬂow of drugs, weapons and money, protecting endangered species, forests and ﬁsheries, suppressing urban crime or security in cyberspace. Unfortunately, limited security resources prevent full security coverage at all times; instead, we must optimize the use of limited security resources. To that end, we founded the "security games" framework to build decision-aids for security agencies. Security games is a novel area of research that is based on computational and behavioral game theory, while also incorporating elements of AI planning under uncertainty and machine learning. We have deployed securitygames based decision aids for infrastructure security such as at the ports and ferry trafﬁc with the US coast guard (in the ports of New York, Boston, Los Angeles/Long Beach, Houston and others), for security of airports and air trafﬁc with the US Federal Air Marshals and the Los Angeles World Airport (LAX) police, and tested this framework for security of metro trains with the Los Angeles Sheriff’s Department. Moreover, recent work on "green security games" has led to testing our decision aids for protection of ﬁsheries with the US Coast Guard and protection of wildlife at sites in multiple countries, and opportunistic crime security games have focused on suppressing urban crime. This chapter will discuss applications of security games, and outline research challenges in security games including algorithms for scaling up security games as well as for handling signiﬁcant adversarial uncertainty and learning models of human adversary behaviors.},
pages = {485--507},
isbn = {978-1-316-67671-4},
date = {2017-11-02},
url = {https://www.cambridge.org/core/product/identifier/9781316676714///////\\%23CN-bp-21/type/book///////\\_part},
urldate = {2019-03-28},
edition = {1},
publisher = {Cambridge University Press},
booktitle = {Improving Homeland Security Decisions},
file = {\:bibliography/ Game Theory/2017 Stackelberg Security Games (SSG) Basics and Application Overview_2017AnStackelberg.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@collection{2016RotheEconomics,
pagetotal = {612},
note = {OCLC: 923541416},
publisher = {Springer},
langid = {english},
editor = {Rothe, Jörg},
location = {Berlin},
shorttitle = {Economics and computation},
date = {2016},
isbn = {978-3-662-47903-2},
title = {Economics and computation: an introduction to algorithmic game theory, computational social choice, and fair division},
series = {Springer texts in business and economics},
file = {\:bibliography/ Game Theory/2016 Economics and Computation_ an Introduction to Algorithmic Game Theory, Computational Social Choice, and Fair Division_2016RotheEconomics.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2016PerolatLearning,
author = {Julien Pérolat and Florian Strub and Bilal Piot and Olivier Pietquin},
eprint = {1606.08718},
eprintclass = {cs},
date = {2016-06-28},
title = {Learning Nash Equilibrium for General-Sum Markov Games from Batch Data},
eprinttype = {arxiv},
abstract = {This paper addresses the problem of learning a Nash equilibrium in γ-discounted multiplayer general-sum Markov Games (MGs) in a batch setting. As the number of players increases in MG, the agents may either collaborate or team apart to increase their ﬁnal rewards. One solution to address this problem is to look for a Nash equilibrium. Although, several techniques were found for the subcase of two-player zero-sum MGs, those techniques fail to ﬁnd a Nash equilibrium in general-sum Markov Games. In this paper, we introduce a new deﬁnition of ǫ-Nash equilibrium in MGs which grasps the strategy’s quality for multiplayer games. We prove that minimizing the norm of two Bellmanlike residuals implies to learn such an ǫ-Nash equilibrium. Then, we show that minimizing an empirical estimate of the Lp norm of these Bellman-like residuals allows learning for general-sum games within the batch setting. Finally, we introduce a neural network architecture that successfully learns a Nash equilibrium in generic multiplayer generalsum turn-based MGs.},
langid = {english},
file = {\:bibliography/ Game Theory/2016 Learning Nash Equilibrium for General Sum Markov Games from Batch Data_2016PerolatLearning.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@incollection{2016KrawczykMultistage,
author = {Jacek B. Krawczyk and Vladimir Petkov},
editor = {Basar, Tamer and Zaccour, Georges},
publisher = {Springer International Publishing},
abstract = {In this chapter, we build on the concept of a repeated game discussed in Chap. Repeated Games and introduce the notion of a multistage game. In both types of games, several antagonistic agents interact with each other over time. The difference is that, in a multistage game, there is a dynamic system whose state keeps changing: the controls chosen by the agents in the current period affect the system’s future. In contrast with repeated games, the agents’ payoffs in multistage games depend directly on the state of this system. Examples of such settings range from a microeconomic dynamic model of a ﬁsh biomass exploited by several agents to a macroeconomic interaction between the government and the business sector. In some multistage games, physically different decisionmakers engage in simultaneous-move competition. In others, agents execute their actions sequentially rather than simultaneously. We also study hierarchical games, where a leader moves ahead of a follower. This chapter concludes with an example of memory-based strategies that can support Pareto-efﬁcient outcomes.},
langid = {english},
doi = {10.1007/978-3-319-27335-8///////\\_3-1},
isbn = {978-3-319-27335-8},
booktitle = {Handbook of Dynamic Game Theory},
date = {2016},
location = {Cham},
urldate = {2019-03-28},
pages = {1--57},
title = {Multistage Games},
file = {\:bibliography/ Game Theory/2016 Multistage Games_2016KrawczykMultistage.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@inproceedings{2015LiuComplex,
author = {Xingfeng Liu and Tiansong Zhou and Zhongxia Zheng},
title = {Complex Information Game Problem Based on Artificial Neural Network},
publisher = {Atlantis Press},
date = {2015},
urldate = {2019-03-28},
url = {http://www.atlantis-press.com/php/paper-details.php?id=25838084},
doi = {10.2991/lemcs-15.2015.34},
abstract = {The assumption of game theory is that the players in game must be rational. In the game of incomplete information, participants are not completely clear about the game. Therefore, usually there is a probability distribution of strategy selection in game. It is very complicated to know the real game information of the social and economic problems. In fact, the actual situation for many problems is that game players are irrational, or the probability distribution of game players’ strategies cannot be gotten, even the strategy sets are not complete (infinite strategy sets).There are many limitations in application of the traditional game theory. In this paper, the concept of complex information game and its Nash equilibrium are presented. It is proved that the complex information game problem can be solved by artificial neural network. An example on how to solve the complex information game problem with artificial neural network is given as well. Researchers hope that more and more scholars can use artificial intelligence theory to analyze the game theory problem. Therefore, the complex information game problems can be dealt more efficiently.},
langid = {english},
isbn = {978-94-6252-102-5},
booktitle = {Proceedings of the International Conference on Logistics, Engineering, Management and Computer Science},
location = {Shenyang, China},
eventtitle = {International Conference on Logistics Engineering, Management and Computer Science (LEMCS 2015)},
file = {\:bibliography/ Game Theory/2015 Complex Information Game Problem Based on Artificial Neural Network_2015LiuComplex.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@inproceedings{2014BhatiaRecurrent,
author = {Sudeep Bhatia and Russell Golman},
langid = {english},
abstract = {We describe the properties of a connectionist network that is able to make decisions in strategic games. We use the structure of Bidirectional Associative Memory (BAM), a minimal two-layer recurrent neural network with binary activation functions and binary connection weights. We apply BAM to finite-strategy two-player games, and show that network activation in the long run is restricted to the set of rationalizable strategies. The network is not guaranteed to reach a stable activation state, but any pure strategy profile that constitutes a stable state in the network must be a pure strategy Nash equilibrium.},
pages = {6},
volume = {36},
date = {2014},
title = {A Recurrent Neural Network for Game Theoretic Decision Making},
booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
file = {\:bibliography/ Game Theory/2014 A Recurrent Neural Network for Game Theoretic Decision Making_2014BhatiaRecurrent.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@incollection{2012NoweGame,
author = {Ann Nowé and Peter Vrancx and Yann-Michaël De Hauwere},
title = {Game Theory and Multi-agent Reinforcement Learning},
editor = {Wiering, Marco and van Otterlo, Martijn},
booktitle = {Reinforcement Learning},
urldate = {2019-04-16},
date = {2012},
pages = {441--470},
location = {Berlin, Heidelberg},
publisher = {Springer Berlin Heidelberg},
volume = {12},
doi = {10.1007/978-3-642-27645-3///////\\_14},
isbn = {978-3-642-27644-6},
file = {\:bibliography/ Game Theory/2012 Game Theory and Multi Agent Reinforcement Learning_2012NoweGame.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2012FriedrichSpike,
author = {Johannes Friedrich and Walter Senn},
volume = {8},
abstract = {Humans and animals face decision tasks in an uncertain multi-agent environment where an agent’s strategy may change in time due to the co-adaptation of others strategies. The neuronal substrate and the computational algorithms underlying such adaptive decision making, however, is largely unknown. We propose a population coding model of spiking neurons with a policy gradient procedure that successfully acquires optimal strategies for classical game-theoretical tasks. The suggested population reinforcement learning reproduces data from human behavioral experiments for the blackjack and the inspector game. It performs optimally according to a pure (deterministic) and mixed (stochastic) Nash equilibrium, respectively. In contrast, temporal-difference(TD)-learning, covariance-learning, and basic reinforcement learning fail to perform optimally for the stochastic strategy. Spike-based population reinforcement learning, shown to follow the stochastic reward gradient, is therefore a viable candidate to explain automated decision learning of a Nash equilibrium in two-player games.},
issn = {1553-7358},
number = {9},
doi = {10.1371/journal.pcbi.1002691},
urldate = {2019-03-28},
date = {2012-09-27},
langid = {english},
editor = {Sporns, Olaf},
journaltitle = {PLoS Computational Biology},
title = {Spike-based Decision Learning of Nash Equilibria in Two-Player Games},
pages = {e1002691},
file = {\:bibliography/ Game Theory/2012 Spike Based Decision Learning of Nash Equilibria in Two Player Games_2012FriedrichSpike.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2010SchusterApplication,
author = {Alfons Schuster and Yoko Yamaguchi},
doi = {10.1155/2010/521606},
journaltitle = {Advances in Artificial Intelligence},
date = {2010},
langid = {english},
issn = {1687-7470},
title = {Application of Game Theory to Neuronal Networks},
volume = {2010},
urldate = {2019-03-28},
pages = {1--12},
file = {\:bibliography/ Game Theory/2010 Application of Game Theory to Neuronal Networks_2010SchusterApplication.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2010ElkindAlgorithmic,
author = {Edith Elkind and Kevin Leyton-Brown},
urldate = {2019-03-26},
volume = {31},
journaltitle = {AI Magazine},
issn = {0738-4602},
url = {https://aaai.org/ojs/index.php/aimagazine/article/view/2310},
date = {2010-09-20},
doi = {10.1609/aimag.v31i4.2310},
number = {4},
pages = {9},
title = {Algorithmic Game Theory and Artificial Intelligence},
abstract = {We brieﬂy survey the rise of game theory as a topic of study in artiﬁcial intelligence, and explain the term algorithmic game theory. We then describe three broad areas of current inquiry by AI researchers in algorithmic game theory: game playing, social choice, and mechanism design. Finally, we give short summaries of each of the six articles appearing in this issue.},
langid = {english},
file = {\:bibliography/ Game Theory/2010 Algorithmic Game Theory and Artificial Intelligence_2010ElkindAlgorithmic.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2009SgroiLearning,
author = {Daniel Sgroi and Daniel John Zizzo},
doi = {10.1016/j.jebo.2008.09.008},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167268108001959},
urldate = {2019-03-28},
abstract = {We present a neural network methodology for learning game-playing rules in general. Existing research suggests learning to …nd a Nash equilibrium in a new game is too di¢ cult a task for a neural network, but says little about what it will do instead. We observe that a neural network trained to …nd Nash equilibria in a known subset of games, will use self-taught rules developed endogenously when facing new games. These rules are close to payo¤ dominance and its best response. Our …ndings are consistent with existing experimental results, both in terms of subject’s methodology and success rates.},
pages = {27--38},
volume = {69},
journaltitle = {Journal of Economic Behavior & Organization},
shorttitle = {Learning to play games},
langid = {english},
number = {1},
title = {Learning to play games: Neural networks as bounded-rational players},
issn = {0167-2681},
date = {2009-01},
file = {\:bibliography/ Game Theory/2009 Learning to Play Games_ Neural Networks As Bounded Rational Players_2009SgroiLearning.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@collection{2007NisanAlgorithmic,
editor = {Nisan, Noam},
title = {Algorithmic game theory},
location = {Cambridge ; New York},
note = {OCLC: ocn122526907},
langid = {english},
pagetotal = {754},
publisher = {Cambridge University Press},
isbn = {978-0-521-87282-9},
date = {2007},
file = {\:bibliography/ Game Theory/2007 Algorithmic Game Theory_2007NisanAlgorithmic.pdf\:PDF},
keywords = {algorithms,game theory},
mendeley-tags = {algorithms,game theory},
}

@misc{2006BlumMachine,
author = {A. Blum and M. Blum and M. Kearns and  S and T. holm and M. T. Hajiaghayi},
pages = {18},
title = {Machine Learning, Game Theory, and Mechanism Design for a Networked World},
date = {2006},
langid = {english},
file = {\:bibliography/ Game Theory/2006 Machine Learning, Game Theory, and Mechanism Design for a Networked World_2006BlumMachine.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@article{2005DarmonConvergence,
author = {Eric Darmon and Roger Waldeck},
doi = {10.1016/j.physa.2005.02.074},
journaltitle = {Physica A: Statistical Mechanics and its Applications},
issn = {0378-4371},
pages = {119--130},
number = {1},
date = {2005-09},
urldate = {2019-03-28},
langid = {english},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437105002839},
shorttitle = {Convergence of reinforcement learning to Nash equilibrium},
title = {Convergence of reinforcement learning to Nash equilibrium: A search-market experiment},
volume = {355},
abstract = {Since the introduction of Reinforcement Learning (RL) in Game Theory, a growing literature is concerned with the theoretical convergence of RL-driven outcomes towards Nash equilibrium. In this paper, we apply this issue to a search-theoretic framework (posted-price market) where sellers are confronted with a population of imperfectly informed buyers and take one decision per period (posted prices) with no direct interactions between sellers. We focus on three different scenarios with varying buyers’ characteristics. For each of these scenarios, we quantitatively and qualitatively test whether the learned variable (price strategy) converges to the Nash equilibrium. We also study the impact of the temperature parameter (deﬁning the exploitation/exploration trade off) on these results.},
file = {\:bibliography/ Game Theory/2005 Convergence of Reinforcement Learning to Nash Equilibrium_ a Search Market Experiment_2005DarmonConvergence.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@unpublished{2005AgrawalWhen,
author = {Anurag Agrawal and Deepak Jaiswal},
title = {When Machine Learning Meets AI and Game Theory},
langid = {english},
pages = {5},
date = {2005},
abstract = {We study the problem of development of intelligent machine learning applications to exploit the problems of adaptation that arise in multi-agent systems, for expected-long-termproﬁt maximization. We present two results. First, we propose a learning algorithm for the Iterated Prisoners Dilemma (IPD) problem. Using numerical analysis we show that it performs strictly better than the tit-for-tat algorithm and many other adaptive and non-adaptive strategies. Second, we study the same problem from the aspect of zero-sum games. We discuss how AI and Machine Learning techniques work closely to give our agent a ’mind-reading’ capability.},
file = {\:bibliography/ Game Theory/2005 When Machine Learning Meets AI and Game Theory_2005AgrawalWhen.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@inproceedings{2003WangReinforcement,
author = {Xiaofeng Wang and  S and Tuomas holm},
pages = {1603--1610},
abstract = {Multiagent learning is a key problem in AI. In the presence of multiple Nash equilibria, even agents with non-conﬂicting interests may not be able to learn an optimal coordination policy. The problem is exaccerbated if the agents do not know the game and independently receive noisy payoffs. So, multiagent reinforfcement learning involves two interrelated problems: identifying the game and learning to play. In this paper, we present optimal adaptive learning, the ﬁrst algorithm that converges to an optimal Nash equilibrium with probability 1 in any team Markov game. We provide a convergence proof, and show that the algorithm’s parameters are easy to set to meet the convergence conditions.},
booktitle = {Advances in neural information processing systems},
date = {2003},
title = {Reinforcement learning to play an optimal Nash equilibrium in team Markov games},
file = {\:bibliography/ Game Theory/2003 Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games_2003WangReinforcement.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@incollection{2002TennenholtzGame,
author = {Moshe Tennenholtz},
date = {2002},
urldate = {2019-03-26},
editorbtype = {redactor},
title = {Game Theory and Artificial Intelligence},
pages = {49--58},
editor = {d’Inverno, Mark and Luck, Michael and Fisher, Michael and Preist, Chris},
location = {Berlin, Heidelberg},
volume = {2403},
langid = {english},
booktitle = {Foundations and Applications of Multi-Agent Systems},
doi = {10.1007/3-540-45634-1///////\\_4},
editorb = {Goos, G. and Hartmanis, J. and van Leeuwen, J.},
publisher = {Springer Berlin Heidelberg},
isbn = {978-3-540-43962-2},
abstract = {Game Theory and Artiﬁcial Intelligence are two mature areas of research, originating from similar roots, which have taken diﬀerent research directions in the last 50 years. Recent research however shows that the connections between these areas are deep, and that the time had come for bridging the gap between these research disciplines. In this paper we concentrate on basic issues in representation, reasoning, and learning, and discuss work that lies in the intersection of Artiﬁcial Intelligence and Game Theory, for each of these subjects.},
file = {\:bibliography/ Game Theory/2002 Game Theory and Artificial Intelligence_2002TennenholtzGame.pdf\:PDF},
keywords = {game theory},
mendeley-tags = {game theory},
}

@inproceedings{2014GoodfellowGenerative,
author = {Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
eprint = {arXiv:1406.2661v1},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
booktitle = {Procedings},
doi = {10.1001/jamainternmed.2016.8245},
pages = {9},
date = {2014},
abstract = {We propose a new framework for estimating generative models via an adversar- ial process; in which we simultaneously train two models: a generative model G that captures the data distribution; and a discriminative model D that estimates the probability that a sample came from the training data rather thanG. The train- ing procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D; a unique solution exists; with G recovering the training data distribution andD equal to 1 2 everywhere. In the case where G andD are defined by multilayer perceptrons; the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference net- works during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 1},
eprinttype = {arXiv},
langid = {english},
title = {Generative Adversarial Nets},
journaltitle = {Advances in Neural Information Processing Systems},
arxivid = {arXiv:1406.2661v1},
issn = {1049-5258},
file = {\:done/2014GoodfellowGenerative Generative Adversarial Nets.pdf\:application/pdf},
keywords = {seminal},
mendeley-tags = {seminal},
}

@thesis{2011EroecalAlgebraic,
author = {Burçin Eröcal},
date = {2011},
langid = {english},
institution = {Johannes Kepler University Linz},
abstract = {The main result of this thesis is an eﬀective method to extend Karr’s symbolic summation framework to algebraic extensions. These arise, for example, when working with expressions involving (−1)n. An implementation of this method, including a modernised version of Karr’s algorithm is also presented. Karr’s algorithm is the summation analogue of the Risch algorithm for indeﬁnite integration. In the summation case, towers of specialized diﬀerence ﬁelds called ΠΣ-ﬁelds are used to model nested sums and products. This is similar to the way elementary functions involving nested logarithms and exponentials are represented in diﬀerential ﬁelds in the integration case. In contrast to the integration framework, only transcendental extensions are allowed in Karr’s construction. Algebraic extensions of ΠΣ-ﬁelds can even be rings with zero divisors. Karr’s methods rely heavily on the ability to solve ﬁrst-order linear diﬀerence equations and they are no longer applicable over these rings. Based on Bronstein’s formulation of a method used by Singer for the solution of diﬀerential equations over algebraic extensions, we transform a ﬁrst-order linear equation over an algebraic extension to a system of ﬁrst-order equations over a purely transcendental extension ﬁeld. However, this domain is not necessarily a ΠΣ-ﬁeld. Using a structure theorem by Singer and van der Put, we reduce this system to a single ﬁrst-order equation over a ΠΣ-ﬁeld, which can be solved by Karr’s algorithm. We also describe how to construct towers of diﬀerence ring extensions on an algebraic extension, where the same reduction methods can be used. A common bottleneck for symbolic summation algorithms is the computation of nullspaces of matrices over rational function ﬁelds. We present a fast algorithm for matrices over Q(x) which uses fast arithmetic at the hardware level with calls to BLAS subroutines after modular reduction. This part is joint work with Arne Storjohann.},
type = {phdthesis},
title = {Algebraic Extensions for Symbolic Summation},
file = {\:bibliography/ Mathematics/2011 Algebraic Extensions for Symbolic Summation_2011EroecalAlgebraic.pdf\:application/pdf},
keywords = {mathematics},
mendeley-tags = {mathematics},
}

@misc{Kotlin,
title = {Kotlin Language Documentation},
file = {\:bibliography/ Programming/Kotlin Language Documentation_Kotlin.pdf\:application/pdf},
keywords = {programming},
mendeley-tags = {programming},
}

@article{LowtherTeaching,
author = {John Lowther and Ching-Kuang Shene},
title = {Teaching B-splines Is Not Difficult!},
langid = {english},
abstract = {This paper describes the authors’ approach of introducing important concepts and algorithms of B-splines to junior computer science students with the help of a pedagogical tool DesignMentor. This approach is non-mathematical and intuitive, and has been used and reﬁned in the past six years.},
pages = {5},
file = {\:bibliography/ Computer Graphics/Teaching B Splines Is Not Difficult!_LowtherTeaching.pdf\:application/pdf},
keywords = {computer graphics},
mendeley-tags = {computer graphics},
}

@unpublished{2008LycheSpline,
author = {Tom Lyche and Knut Mørken},
note = {draft},
doi = {10/undervisningsmateriale},
year = {2008},
date = {2008},
title = {Spline Methods.pdf},
file = {\:bibliography/ Computer Graphics/2008 Spline Methods.pdf_2008LycheSpline.pdf\:application/pdf},
keywords = {computer graphics},
mendeley-tags = {computer graphics},
}

@incollection{1999PollockSmoothing,
author = {D. S. G. Pollock},
urldate = {2019-03-28},
langid = {english},
title = {Smoothing with Cubic Splines},
pages = {293--322},
publisher = {Elsevier},
booktitle = {Handbook of Time Series Analysis, Signal Processing, and Dynamics},
date = {1999},
doi = {10.1016/B978-012560990-6/50013-0},
isbn = {978-0-12-560990-6},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9780125609906500130},
file = {\:bibliography/ Computer Graphics/1999 Smoothing with Cubic Splines_1999PollockSmoothing.pdf\:application/pdf},
keywords = {computer graphics},
mendeley-tags = {computer graphics},
}

@article{1996Loesinusoidal,
author = {K. F. Loe},
urldate = {2019-03-28},
volume = {71},
langid = {english},
number = {2},
abstract = {Functional polynomials composed of sinusoidal functions are introduced as basis functions to construct an interpolatory spline. An interpolant constructed in this way does not require solving a system of linear equations as many approaches do. However there are vanishing tangent vectors at the interpolating points. By blending with a Bezier curve using the data points as the control points, the blended curve is a proper smooth interpolant. The blending factor has the effect similar to the "tension" control of tension splines. Piecewise interpolants can be constructed in an analogous way as a connection of Bezier curve segments to achieve C 1 continuity at the connecting points. Smooth interpolating surface patches can also be defined by blending sinusoidal polynomial tensor surfaces and Bezier tensor surfaces. The interpolant can very efficiently be evaluated by tabulating the sinusoidal function.},
date = {1996-07},
doi = {10.1016/0377-0427(95)00241-3},
journaltitle = {Journal of Computational and Applied Mathematics},
issn = {0377-0427},
pages = {383--393},
url = {http://linkinghub.elsevier.com/retrieve/pii/0377042795002413},
title = {A sinusoidal polynomial spline and its Bezier blended interpolant},
file = {\:bibliography/ Computer Graphics/1996 A Sinusoidal Polynomial Spline and Its Bezier Blended Interpolant_1996Loesinusoidal.pdf\:application/pdf},
keywords = {computer graphics},
mendeley-tags = {computer graphics},
}

@article{1986HobbySmooth,
author = {John D. Hobby},
number = {2},
pages = {123--140},
journaltitle = {Discrete & Computational Geometry},
volume = {1},
publisher = {Springer Nature},
date = {1986},
langid = {english},
title = {Smooth, easy to compute interpolating splines},
doi = {10.1007/BF02187690},
abstract = {We present a system of interpolating splines with first and approximate second order geometric continuity. The curves are easily computed in linear time by solving a system of linear equations without the need to resort to any kind of successive approximation scheme. Emphasis is placed on the need to find aesthetically pleasing curves in a wide range of circumstances; favorable results are obtained even when the knots are very unequally spaced or widely separated. The curves are invariant under scaling, rotation, and reflection, and the effects of a local change fall off exponentially as one moves away from the disturbed knot.},
journal = {Discrete & Computational Geometry},
issn = {0179-5376},
urldate = {2019-03-31},
month = {6},
year = {1986},
file = {\:bibliography/ Computer Graphics/1986 Smooth, Easy to Compute Interpolating Splines_1986HobbySmooth.pdf\:application/pdf},
keywords = {computer graphics},
mendeley-tags = {computer graphics},
}

@phdthesis{2009LevienSpiral,
author = {Raph Levien},
title = {From Spiral to Spline: Optimal Techniques in Interactive Curve Design},
institution = {Berkeley},
date = {2009},
file = {\:bibliography/ Computer Graphics/From Spiral to Spline_ Optimal Techniques in Interactive Curve Design_LevienSpirala.pdf\:PDF},
keywords = {curves,elastica,euler spirals,splines},
mendeley-tags = {curves,elastica,euler spirals,splines},
}

@report{1974Smithsmoothing,
author = {R. E. Smith},
url = {https://ntrs.nasa.gov/search.jsp?R=19740008165},
abstract = {Two algorithms are presented for smoothing arbitrary sets of data. They are the explicit variable algorithm and the parametric variable algorithm. The former would be used where large gradients are not encountered because of the smaller amount of calculation required. The latter would be used if the data being smoothed were double valued or experienced large gradients. Both algorithms use a least-squares technique to obtain a cubic spline fit to the data. The advantage of the spline fit is that the first and second derivatives are continuous. This method is best used in an interactive graphics environment so that the junction values for the spline curve can be manipulated to improve the fit.},
date = {1974-02-01},
month = {feb},
title = {A smoothing algorithm using cubic spline functions},
urldate = {2019-03-31},
year = {1974},
file = {\:bibliography/ Computer Graphics/1974 A Smoothing Algorithm Using Cubic Spline Functions_1974Smithsmoothing.pdf\:PDF},
keywords = {computer graphics,tesse},
mendeley-tags = {computer graphics,tesse},
}

@unpublished{w18,
author = {Aaron van den Oord and S Dieleman and  er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu and Ryuichi Yamamoto and Aaron van den Oord and S Dieleman and  er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
arxivid = {1609.03499},
address = {DeepMind Dispon�vel em},
eprint = {1609.03499},
year = {2018},
archiveprefix = {arXiv},
pages = {1--15},
url = {http://arxiv.org/abs/1609.03499 https://deepmind.com/blog/wavenet-generative-model-raw-audio/%3E},
annote = {From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Yamamoto, Ryuichi; Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray)From Duplicate 1 (WaveNet: A Generative Model for Raw Audio - Oord, Aaron van den; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray). arXiv preprint},
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
publisher = {<},
title = {WaveNet: A Generative Model for Raw Audio},
}

@unpublished{gs16,
author = {Xavier Gr\`acia and Tom\'as Sanz-perela and Xavier Gr and X Gracia and Tom\'as Sanz-perela},
annote = {From Duplicate 2 (The wave equation for stiff strings and piano tuning - Gr\`acia, Xavier; Sanz-perela, Tom\'as; Gr, Xavier; Gracia, X; Sanz-perela, Tom\'as)From Duplicate 1 (The wave equation for stiff strings and piano tuning. - Gracia, X; Sanz-perela, T)And Duplicate 3 (The wave equation for stiff strings and piano tuning - Gr\`acia, Xavier; Sanz-Perela, Tom\'as)preprint},
archiveprefix = {arXiv},
year = {2016},
volume = {3},
doi = {10.2436/20.2002.02.11},
title = {The wave equation for stiff strings and piano tuning},
pages = {1--16},
eprint = {1603.05516},
abstract = {We study the wave equation for a string with stiffness. We solve the equation and provide a uniqueness theorem with suitable boundary conditions. For a pinned string we compute the spectrum, which is slightly inharmonic. Therefore, the widespread scale of 12 equal divisions of the just octave is not the best choice to tune instruments like the piano. Basing on the theory of dissonance, we provide a way to tune the piano in order to improve its consonance. A good solution is obtained by tuning a note and its fifth by minimizing their beats.},
url = {http://arxiv.org/abs/1603.05516%0Ahttp://dx.doi.org/10.2436/20.2002.02.11},
arxivid = {1603.05516},
keywords = {a,dissonance,g,inharmonic spectrum,l,msc,musical,musical scale,stiffness,string,vibrating,vibrating string,wave equation},
mendeley-tags = {a,dissonance,g,inharmonic spectrum,l,msc,musical,musical scale,stiffness,string,vibrating,vibrating string,wave equation},
}

@article{Patterson,
author = {Anthony So Mirza Rahim Baig, Thomas V. Joseph, Nipun Sadvilkar, Mohan Kumar Silaparasetty and Ian Goodfellow Courville and Yoshua Bengio and  Aaron},
journal = {Nature},
title = {Deep learning 简介 一 、 什么是 Deep Learning ？},
number = {7553},
abstract = {"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors"--Page 4 of cover. Introduction -- Applied math and machine learning basics. Linear algebra -- Probability and information theory -- Numerical computation -- Machine learning basics -- Deep networks: modern practices. Deep feedforward networks -- Regularization for deep learning -- Optimization for training deep models -- Convolutional networks -- Sequence modeling: recurrent and recursive nets -- Practical methodology -- Applications -- Deep learning research. Linear factor models -- Autoencoders -- Representation learning -- Structured probabilistic models for deep learning -- Monte Carlo methods -- Confronting the partition function -- Approximate inference -- Deep generative models.},
volume = {29},
pages = {1--73},
year = {2016},
isbn = {3463353563306},
keywords = {cnn,convolutional neural networks,deep learning,plant disease},
mendeley-tags = {cnn,convolutional neural networks,deep learning,plant disease},
}

@article{He2015,
author = {Lang He and Dongmei Jiang and Le Yang and Ercheng Pei and Peng Wu and Hichem Sahli and  Others and Dongmei Jiang and Le Yang and Ercheng Pei and Peng Wu and Hichem Sahli},
publisher = {Anais�ACM},
pages = {73--80},
number = {October 2015},
journal = {AVEC 2015 - Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015},
title = {Multimodal affective dimension prediction using deep bidirectional long short-term memory recurrent neural networks},
edition = {Proceeding},
institution = {ACM},
year = {2015},
abstract = {This paper presents our system design for the Audio-Visual Emotion Challenge (AV +EC 2015). Besides the baseline features, we extract from audio the functionals on low-level descriptors (LLDs) obtained via the YAAFE toolbox, and from video the Local Phase Quantization from Three Orthogonal Planes (LPQ-TOP) features. From the physiological signals, we extract 52 electro-cardiogram (ECG) features and 22 electro-dermal activity (EDA) features from various analysis domains. The extracted features along with the AV +EC 2015 baseline features of audio, ECG or EDA are concatenated for a further feature selection step, in which the concordance correlation coefficient (CCC), instead of the usual Pearson correlation coefficient (CC), has been used as objective function. In addition, offsets between the features and the arousal/valence labels are considered in both feature selection and modeling of the affective dimensions. For the fusion of multimodal features, we propose a Deep Bidirectional Long Short-Term Memory Recurrent Neural Network (DBLSTM-RNN) based multimodal affect prediction framework, in which the initial predictions from the single modalities via the DBLSTM-RNNs are firstly smoothed with Gaussian smoothing, then input into a second layer of DBLSTMRNN for the final prediction of affective state. Experimental results show that our proposed features and the DBLSTMRNN based fusion framework obtain very promising results. On the development set, the obtained CCC is up to 0.824 for arousal and 0.688 for valence, and on the test set, the CCC is 0.747 for arousal and 0.609 for valence.},
url = {http://dl.acm.org/citation.cfm?doid=2808196.2811641},
isbn = {9781450337434},
doi = {10.1145/2808196.2811641},
keywords = {state of the art,video classification},
mendeley-tags = {state of the art,video classification},
}

@unpublished{e17,
author = {Jesse Engel and Cinjon Resnick and Adam Roberts and S Dieleman and  er and Mohammad Norouzi and Douglas Eck and Karen Simonyan and  Others and Cinjon Resnick and Adam Roberts and S Dieleman and  er and Douglas Eck},
volume = {3},
abstract = {Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autocncodcr model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.},
booktitle = {34th International Conference on Machine Learning, ICML 2017},
year = {2017},
arxivid = {1704.01279},
annote = {From Duplicate 2 (Neural audio synthesis of musical notes with wavenet autoencoders. - Engel, J; others)And Duplicate 3 (Neural audio synthesis of musical notes with WaveNet autoencoders - Engel, Jesse; Resnick, Cinjon; Roberts, Adam; Dieleman, Sander; Norouzi, Mohammad; Eck, Douglas; Simonyan, Karen)preprint},
archiveprefix = {arXiv},
eprint = {1704.01279},
isbn = {9781510855144},
pages = {1771--1780},
title = {Neural audio synthesis of musical notes with wavenet autoencoders.},
}

@article{Thesis,
author = {Fitria Savira and Yudi Suharsono and American Journal of Sociology and  中島 and Fitria Savira and Yudi Suharsono},
arxivid = {arXiv:1011.1669v3},
number = {01},
issn = {1098-6596},
year = {2013},
pages = {1689--1699},
archiveprefix = {arXiv},
isbn = {9788578110796},
pmid = {25246403},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
eprint = {arXiv:1011.1669v3},
url = {https://github.com/tesserato/tesserato.github.io%3E},
title = {済無No Title No Title},
journal = {Journal of Chemical Information and Modeling},
volume = {01},
keywords = {icle},
mendeley-tags = {icle},
}

@article{Johnston2017a,
author = {Nick Johnston and Damien Vincent and David Minnen and Michele Covell and Saurabh Singh and Troy Chinen and Sung Jin Hwang and Joel Shor and George Toderici and Sung Jin Hwang and Joel Shor and George Toderici and Sung Jin Hwang and Joel Shor and George Toderici},
archiveprefix = {arXiv},
issn = {10636919},
abstract = {We propose a method for lossy image compression based on recurrent, convolutional neural networks that outperforms BPG (4:2:0), WebP, JPEG2000, and JPEG as measured by MS-SSIM. We introduce three improvements over previous research that lead to this state-of-the-art result using a single model. First, we modify the recurrent architecture to improve spatial diffusion, which allows the network to more effectively capture and propagate image information through the network's hidden state. Second, in addition to lossless entropy coding, we use a spatially adaptive bit allocation algorithm to more efficiently use the limited number of bits to encode visually complex image regions. Finally, we show that training with a pixel-wise loss weighted by SSIM increases reconstruction quality according to multiple metrics. We evaluate our method on the Kodak and Tecnick image sets and compare against standard codecs as well as recently published methods based on deep neural networks.},
isbn = {9781538664209},
journal = {arXiv preprint arXiv:1703.10114},
doi = {10.1109/CVPR.2018.00461},
title = {Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks},
year = {2017},
arxivid = {1703.10114},
eprint = {1703.10114},
url = {http://arxiv.org/abs/1703.10114},
pages = {4385--4393},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@incollection{08,
author = {Julius O. Smith and Julius O Smith Iii},
booktitle = {Handbook of Signal Processing in Acoustics},
pages = {399--417},
abstract = {This chapter summarizes some ecient signal processing structures used for virtual musical instruments based on physical models. Instruments in the string and wind families are considered.},
address = {Traducao. [s.l.] p. 399�417},
doi = {10.1007/978-0-387-30441-0_25},
title = {Digital Waveguide Architectures for Virtual Musical Instruments},
publisher = {Springer},
year = {2008},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2008 Digital Waveguide Architectures for Virtual Musical Instruments - Smith.pdf\:pdf},
}

@article{Pang2017,
author = {Yanwei Pang and Manli Sun and Xiaoheng Jiang and Xuelong Li and  Others and Manli Sun and Xiaoheng Jiang and Xuelong Li},
abstract = {Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and $ 1\times 1 $ convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.},
eprint = {1603.06759},
pages = {1587--1597},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
volume = {29},
number = {5},
year = {2017},
doi = {10.1109/TNNLS.2017.2676130},
issn = {21622388},
publisher = {IEEE},
title = {Convolution in convolution for network in network},
arxivid = {1603.06759},
pmid = {28328517},
archiveprefix = {arXiv},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Oord2016,
author = {Aaron Van Den Oord and Nal Kalchbrenner and Koray Kavukcuoglu and A\"aron Van Den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
journal = {arXiv preprint arXiv:1601.06759},
archiveprefix = {arXiv},
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
eprint = {1601.06759},
year = {2016},
title = {Pixel Recurrent Neural Networks},
arxivid = {1601.06759},
isbn = {9781510829008},
annote = {From Duplicate 2 (Pixel recurrent neural networks. - Oord, A Van Den; Kalchbrenner, N; Kavukcuoglu, K)preprint},
pages = {2611--2620},
url = {http://arxiv.org/abs/1601.06759},
volume = {48},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Toderici2015,
author = {George Toderici and Sean M. O'Malley and Sung Jin Hwang and Damien Vincent and David Minnen and Shumeet Baluja and Michele Covell and Rahul Sukthankar and Sean M. O'Malley and Sung Jin Hwang and Damien Vincent and David Minnen and Shumeet Baluja and Michele Covell and Rahul Sukthankar},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
archiveprefix = {arXiv},
arxivid = {1511.06085},
abstract = {A large fraction of Internet traffic is now driven by requests from mobile devices with relatively small screens and often stringent bandwidth requirements. Due to these factors, it has become the norm for modern graphics-heavy websites to transmit low-resolution, low-bytecount image previews (thumbnails) as part of the initial page load process to improve apparent page responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore a current research focus, as any byte savings will significantly enhance the experience of mobile device users. Toward this end, we propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional LSTM recurrent networks. Our models address the main issues that have prevented autoencoder neural networks from competing with existing image compression algorithms: (1) our networks only need to be trained once (not per-image), regardless of input image dimensions and the desired compression rate; (2) our networks are progressive, meaning that the more bits are sent, the more accurate the image reconstruction; and (3) the proposed architecture is at least as efficient as a standard purpose-trained autoencoder for a given number of bits. On a large-scale benchmark of 32$\times$32 thumbnails, our LSTM-based approaches provide better visual quality than (headerless) JPEG, JPEG2000 and WebP, with a storage size that is reduced by 10% or more.},
eprint = {1511.06085},
pages = {1--12},
year = {2015},
title = {Variable Rate Image Compression with Recurrent Neural Networks},
url = {http://arxiv.org/abs/1511.06085},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Kecerdasan,
author = {Inventori Kecerdasan and Pelbagai Ikep},
pages = {6},
isbn = {080581258X},
title = {No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title},
}

@article{DIppolito2014a,
author = {Beatrice D'Ippolito},
number = {11},
isbn = {0166-4972},
abstract = {Scholars dedicated increasing attention towards appreciating how design has changed individualsperception of new products, firmsunderstanding and formulation of strategy, or other relevant actorsapproach to innovation and technology management. By emphasising the importance of design for the definition of consumersneeds, the restructuring of firmsorganisational structures and strategies, and the evolution of firmsvalue creation processes, this review paper identifies relevant research gaps and questions that would benefit from future scholarly attention. In particular, it is suggested that such effort should address the analysis of how design consumption can help better comprehend consumersneeds; what are the implications of design thinking on the skill sets of design professionals; the organisational structure of firms, including the reconfiguration of other business functions, and their strategy; and whether and how design thinking can shape firmsvalue creation processes and contribute to the formalisation of design tasks.},
journal = {Technovation},
pages = {716--730},
issn = {01664972},
pmid = {1629546633},
publisher = {Elsevier},
month = {feb},
url = {http://www.sciencedirect.com/science/article/pii/S016649721400008X},
volume = {34},
doi = {10.1016/j.technovation.2014.01.007},
title = {The importance of design for firms competitiveness: A review of the literature},
year = {2014},
keywords = {consumers' needs,design,firm competitiveness,literature review,research gaps,strategy making,value creation},
mendeley-tags = {consumers' needs,design,firm competitiveness,literature review,research gaps,strategy making,value creation},
}

@article{s06,
author = {Jo Smith Iii},
title = {A basic introduction to digital waveguide synthesis (for the technically inclined)},
publisher = {Center for Computer Research in Music and Acoustics (CCRMA)},
pages = {1--5},
url = {http://virtualmusic.mysteria.cz/docs/orion1.pdf},
year = {2006},
address = {Stanford University. stanford. edu/ jos/swgt},
journal = {Center for Computer Research in Music and \ldots},
}

@article{Agerfalk2008a,
author = {P\"ar J. \AAgerfalk and Brian Fitzgerald and Par J Agerfalk and Brian Fitzgerald},
doi = {Article},
journal = {MIS Quarterly: Management Information Systems},
number = {2},
pmid = {31831011},
isbn = {02767783},
abstract = {This paper presents a psychological contract perspective on the use of the open source development model as a global sourcing strategy-opensourcing, as we term it here-whereby commerical companies and open source communities collaborate on development of software of commercial interest to the company. Building on previous research on information systems outsourcing, a theoretical framework for exploring the opensourcing phenomenon is derived. The first phase of the research concerned qualitative case studies involving three commercial organizations (IONA Technologies, Philips Medical Systems, and Telefonica) that had "liberated" what had hitherto been proprietary software and sought to grow a global open source community around their product. We followed this with a large-scale survey involving additional exemplars of the phenomenon. The study identifies a number of symmetrical and complementary customer and community obligations that are associated with opensourcing success. We also identify a number of tension points on which customer and community perceptions tend to vary. Overall the key watchwords for opensourcing are openness, trust, tact, professionalism, transparency, and complementariness: The customer and community need to establish a trusted partnership of shared responsibility in building an overall opensourcing ecosystem. The study reveals an ongoing shift from OSS as a community of individual developers to OSS as a community of commercial organizations, primarily small to medium-sized enterprises. It also reveals that opensourcing provides ample opportunity for companies to headhunt top developers, hence moving from outsourcing to a largely unknown OSS workforce toward recruitment of developers from a global open source community whose talents have become known as a result of the opensourcing experience.},
issn = {02767783},
pages = {385--409},
title = {Outsourcing to an unknown workforce: exploring opensourcing as a global sourcing strategy},
year = {2008},
volume = {32},
shorttitle = {OUTSOURCING TO AN UNKNOWN WORKFORCE},
keywords = {crowdsourcing,crowdsourcing,global software development,global software development,multi-method research,multimethod research,offshoreing,offshoring,open source,open source,opensourcing,opensourcing,outsourcing,outsourcing},
mendeley-tags = {crowdsourcing,crowdsourcing,global software development,global software development,multi-method research,multimethod research,offshoreing,offshoring,open source,open source,opensourcing,opensourcing,outsourcing,outsourcing},
}

@article{Hinton2018,
author = {Geoffrey Hinton and Sara Sabour and Nicholas Frosst},
pages = {1--15},
abstract = {A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagat-ing through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
year = {2018},
title = {Matrix capsules with EM routing},
}

@article{Wang2016a,
author = {Zhenyang Wang and Zhidong Deng and Shiyao Wang},
isbn = {9781509006205},
institution = {IEEE},
year = {2016},
title = {SAM : A Rethinking of Prominent Convolutional Neural Network Architectures for Visual Object Recognition},
abstract = {Convolutional neural networks play an increasingly important role in computer vision tasks, especially in the field of visual object recognition. Many prominent models, such as Inception, Maxout, ResNet, and NIN, have been proposed to significantly improve recognition performance. Inspired from those models, we propose a novel module called self-adaptive module (SAM). SAM consists of four passes and one selector. Specifically, the four passes include two direct passes with different receptive fields and depths, one residual pass, and one Maxout pass. Actually, the residual pass is used to speed up convergence, while we take advantage of the Maxout pass to enhance approximate capabilities of SAM. The selector is further designed to help choose reasonable output. Basically, SAM is intended to simplify design of any new deep learning architecture, since it no longer requires consideration of how to select receptive fields and depths. Our SAM is tested on the visual object recognition datasets including CIFAR-10, CIFAR-100, MNIST, and SVHN. The experimental results demonstrate that the SAM-Net has superior recognition performances on the four benchmarks, which achieve test errors of 5.76%, 28.56%, 0.31%, and 1.98%, respectively.},
pages = {1008--1014},
journal = {Neural Networks (IJCNN), 2016 International Joint Conference on},
number = {July},
volume = {2016-Octob},
doi = {10.1109/IJCNN.2016.7727308},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Mizutani,
author = {Eiji Mizutani and Stuart E. Dreyfus and Kenichi Nishio},
volume = {2},
pages = {167--172},
title = {On derivation of MLP backpropagation from the Kelley-Bryson optimal-control gradient formula and its application},
year = {2000},
doi = {10.1109/ijcnn.2000.857892},
journal = {Proceedings of the International Joint Conference on Neural Networks},
abstract = {The well-known backpropagation (BP) derivative computation process for multilayer perceptrons (MLP) learning can be viewed as a simplified version of the Kelley-Bryson gradient formula in the classical discrete-time optimal control theory. We detail the derivation in the spirit of dynamic programming, showing how they can serve to implement more elaborate learning whereby teacher signals can be presented to any nodes at any hidden layers, as well as at the terminal output layer. We illustrate such an elaborate training scheme using a small-scale industrial problem as a concrete example, in which some hidden nodes are taught to produce specified target values. In this context, part of the hidden layer is no longer `hidden.'},
}

@article{s92,
author = {Julius O. Smith},
journal = {Computer Music Journal},
abstract = {Music synthesis based on a physical model promises the highest quality when it comes to imitating natural instruments. Because the artificial instrument can have the same control parameters as the real instrument, expressivity of control is unbounded. Historically, physical models have led to prohibitively expensive synthesis algorithms, and commercially available synthesizers do not yet appear to make use of them. These days, most synthesizers use either processed digital recordings ("sampling synthesis") or an abstract algorithm such as frequency modulation (FM). However, as computers become faster and cheaper, and as algorithms based on physical models become more efficient, we may expect to hear more from them. Most attempts to synthesize sounds based on a physical model have been based on numerical integration of the wave equation (covered in any textbook on acoustics). These methods generally require at least one operation (multiplication and/or addition) for each point on a grid that permeates the instrument. In principle, the grid spacing must be less than half a wavelength at the highest audio frequency. This is essentially why the computational costs are so high in "brute force" numerical solutions of the wave equation. More recently developed "digital waveguide" methods follow a different path to the physical model; the wave equation is first solved in a general way to obtain traveling waves in the medium interior. The traveling waves are explicitly simulated in the waveguide model, in contrast to computing a physical variable. (The traveling waves must be summed together to produce a physical output.) In the lossless case, a traveling wave between two points in the medium can be simulated using nothing but a digital delay line. In the general linear case, in which there are frequency-dependent losses and dispersion, the commutativity of linear time-invariant systems allows the losses and dispersion to be lumped at discrete points such that most of the simulation still consists of multiply-free delay lines. This is essentially why computational costs are so low in "waveguide synthesis" algorithms. Computer-music programmers know very well that a delay line can be implemented by a single fetch, store, and pointer update for each sample of output. If the delay line is, say, 500 samples long (corresponding to a pitch of 44,100/500=88 Hz in a string or bore model of compact disk quality), computational requirements relative to "brute force" numerical integration on the grid are reduced by three orders of magnitude. As a result, for very simple physical models, several CD-quality voices can be sustained in real time on a single digital signal processing (DSP) chip costing only a few dollars. This article develops waveguide synthesis beginning with the wave equation for vibrating strings. Transverse waves on a string are taken as the primary example due to the relative clarity of the underlying physics, but the formulation for string simulation is unified with that of the acoustic tube. The technique of lumping losses at discrete points in the waveguide, replacing more expensive distributed losses, is described.},
number = {4},
year = {1992},
title = {Physical Modeling Using Digital Waveguides},
doi = {10.2307/3680470},
volume = {16},
pages = {74},
issn = {01489267},
}

@unpublished{m17,
author = {Parag K. Mital},
annote = {From Duplicate 2 (Time Domain Neural Audio Style Transfer. - Mital, P K)preprint},
abstract = {A recently published method for audio style transfer has shown how to extend the process of image style transfer to audio. This method synthesizes audio "content" and "style" independently using the magnitudes of a short time Fourier transform, shallow convolutional networks with randomly initialized filters, and iterative phase reconstruction with Griffin-Lim. In this work, we explore whether it is possible to directly optimize a time domain audio signal, removing the process of phase reconstruction and opening up possibilities for real-time applications and higher quality syntheses. We explore a variety of style transfer processes on neural networks that operate directly on time domain audio signals and demonstrate one such network capable of audio stylization.},
issn = {23318422},
number = {Nips},
booktitle = {arXiv},
year = {2017},
archiveprefix = {arXiv},
arxivid = {1711.11160},
title = {Time Domain Neural Audio Style Transfer.},
eprint = {1711.11160},
}

@article{Frans2017,
author = {Kevin Frans},
url = {http://arxiv.org/abs/1704.08834},
year = {2017},
archiveprefix = {arXiv},
abstract = {When creating digital art, coloring and shading are often time consuming tasks that follow the same general patterns. A solution to automatically colorize raw line art would have many practical applications. We propose a setup utilizing two networks in tandem: a color prediction network based only on outlines, and a shading network conditioned on both outlines and a color scheme. We present processing methods to limit information passed in the color scheme, improving generalization. Finally, we demonstrate natural-looking results when colorizing outlines from scratch, as well as from a messy, user-defined color scheme.},
annote = {From Duplicate 2 (Outline Colorization through Tandem Adversarial Networks. - Frans, K)preprint},
eprint = {1704.08834},
journal = {arXiv preprint arXiv:1704.08834},
title = {Outline Colorization through Tandem Adversarial Networks},
arxivid = {1704.08834},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{sfh,
author = {Sara Sabour and Nicholas Frosst and Geoffrey E. Hinton and C V Oct and Geoffrey E. Hinton},
issn = {23318422},
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-The-Art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-Agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
journal = {arXiv},
number = {Nips},
archiveprefix = {arXiv},
title = {Dynamic routing between capsules},
year = {2017},
arxivid = {arXiv:1710.09829v1},
volume = {2017},
eprint = {arXiv:1710.09829v1},
}

@article{Serafin,
author = {Stefania Serafin and Patty Huang and Jo Smith},
journal = {Mosart meeting},
abstract = {In this paper we propose a new technique to model complex resonators, which uses a combination of digital waveguides and waveguide meshes banded in frequency. An application for simulating a bowed cymbal is discussed.},
title = {The banded digital waveguide mesh},
url = {http://www.media.aau.dk/people/sts/publications/mosart.pdf},
year = {2001},
volume = {1},
pages = {2--5},
}

@article{Kulkarni2015,
author = {Tejas D. Kulkarni and  Others and William F Whitney and Pushmeet Kohli and Joshua B. Tenenbaum},
title = {Deep Convolutional Inverse Graphics Network},
url = {http://arxiv.org/abs/1503.03167},
archiveprefix = {arXiv},
pages = {1--10},
volume = {2015},
year = {2015},
abstract = {This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a model that learns an interpretable representation of images. This representation is disentangled with respect to transformations such as out-of-plane rotations and lighting variations. The DC-IGN model is composed of multiple layers of convolution and de-convolution operators and is trained using the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a training procedure to encourage neurons in the graphics code layer to represent a specific transformation (e.g. pose or light). Given a single input image, our model can generate new images of the same object with variations in pose and lighting. We present qualitative and quantitative results of the model's efficacy at learning a 3D rendering engine.},
journal = {Advances in Neural Information Processing Systems},
issn = {10897550},
arxivid = {1503.03167},
doi = {10.1063/1.4914407},
eprint = {1503.03167},
keywords = {image synthesis,tesis},
mendeley-tags = {image synthesis,tesis},
}

@article{Guang-BinHuang2014,
author = {Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew and Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew and Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew},
year = {2014},
doi = {10.1109/IJCNN.2004.1380068},
volume = {2},
url = {http://ieeexplore.ieee.org/document/1380068/},
title = {Extreme learning machine: a new learning scheme of feedforward neural networks},
journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
institution = {IEEE},
isbn = {0-7803-8359-1},
number = {August 2004},
pages = {985--990},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Khorrami2016a,
author = {Pooya Khorrami and Tom Le Paine and Kevin Brady and Charlie Dagli and Thomas S. Huang and Tom Le Paine and Kevin Brady and Charlie Dagli and Thomas S. Huang and Tom Le Paine and Kevin Brady and Charlie Dagli and Thomas S. Huang and Tom Le Paine and Kevin Brady and Charlie Dagli and Thomas S. Huang and Tom Le Paine and Kevin Brady and Charlie Dagli and Thomas S. Huang},
pages = {619--623},
edition = {(ICIP), 20},
institution = {IEEE},
doi = {10.1017/pasa.2016.3},
journal = {Proceedings - International Conference on Image Processing, ICIP},
publisher = {Anais�IEEE},
issn = {15224880},
volume = {2016-Augus},
abstract = {We consider the task of dimensional emotion recognition on video data using deep learning. While several previous methods have shown the benefits of training temporal neural network models such as recurrent neural networks (RNNs) on hand-crafted features, few works have considered combining convolutional neural networks (CNNs) with RNNs. In this work, we present a system that performs emotion recognition on video data using both CNNs and RNNs, and we also analyze how much each neural network component contributes to the system's overall performance. We present our findings on videos from the Audio/Visual+Emotion Challenge (AV+EC2015). In our experiments, we analyze the effects of several hyperparameters on overall performance while also achieving superior performance to the baseline and other competing methods.},
url = {http://arxiv.org/abs/1602.07377},
arxivid = {1602.07377},
archiveprefix = {arXiv},
eprint = {1602.07377},
year = {2016},
title = {How Deep Neural Networks Can Improve Emotion Recognition on Video Data},
isbn = {9781467399616},
keywords = {sentiment analysis,video classification},
mendeley-tags = {sentiment analysis,video classification},
}

@article{Isola2016,
author = {Phillip Isola and Jun-Yan Yan Zhu and Tinghui Zhou and Alexei A. Efros and  Others},
pages = {5967--5976},
url = {http://arxiv.org/abs/1611.07004},
volume = {2017-Janua},
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
year = {2016},
doi = {10.1109/CVPR.2017.632},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
arxivid = {1611.07004},
eprint = {1611.07004},
isbn = {9781538604571},
title = {Image-to-image translation with conditional adversarial networks},
archiveprefix = {arXiv},
annote = {From Duplicate 1 (Image-to-image translation with conditional adversarial networks. - Isola, P; others)preprint},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Zhu2016,
author = {Jun-Yan Yan J.-y. Zhu and Philipp Kr??henb??hl and Eli Shechtman and Alexei A. Efros and Philipp Kr\"ahenb\"uhl and Eli Shechtman and Alexei A. Efros and  Others and Philipp Kr\"ahenb\"uhl and Eli Shechtman and Alexei A. Efros},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
arxivid = {1609.03552},
eprint = {1609.03552},
year = {2016},
abstract = {Realistic image manipulation is challenging because it requires modifying the image appearance in a user-controlled way, while preserving the realism of the result. Unless the user has considerable artistic skill, it is easy to "fall off" the manifold of natural images while editing. In this paper, we propose to learn the natural image manifold directly from data using a generative adversarial neural network. We then define a class of image editing operations, and constrain their output to lie on that learned manifold at all times. The model automatically adjusts the output keeping all edits as realistic as possible. All our manipulations are expressed in terms of constrained optimization and are applied in near-real time. We evaluate our algorithm on the task of realistic photo manipulation of shape and color. The presented method can further be used for changing one image to look like the other, as well as generating novel imagery from scratch based on user's scribbles.},
edition = {European C},
issn = {16113349},
pmid = {4520227},
volume = {9909 LNCS},
institution = {Springer},
doi = {10.1007/978-3-319-46454-1_36},
address = {Anais�},
publisher = {Springer},
isbn = {9783319464534},
title = {Generative visual manipulation on the natural image manifold},
pages = {597--613},
archiveprefix = {arXiv},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{L.Elman1990,
author = {Jeffrey L. Elman and Jeffrey L.Elman and Jeffrey L. Elman},
pages = {179--211},
issn = {03640213},
abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction. \textcopyright 1990.},
publisher = {Wiley Online Library},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed&cmd=Retrieve&dopt=AbstractPlus&list_uids=17969258453606390073related:OdlkvFuhX_kJ%5Cnpapers2://publication/uuid/3DEB06EE-B169-47A0-BD84-BFEE3386098E http://linkinghub.elsevier.com/retrieve/pii/036402},
volume = {14},
year = {1990},
pmid = {19563812},
isbn = {1551-6709},
doi = {10.1207/s15516709cog1402_1},
number = {2},
title = {Finding structure in time},
journal = {Cognitive science},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Wu2012,
author = {Conference Paper and Yue Wu and Jianqing Hu and Wei Wu and Yong Zhou and K. L. Du},
number = {January},
journal = {Proceedings - 2012 5th International Conference on Intelligent Computation Technology and Automation, ICICTA 2012},
doi = {10.1109/ICICTA.2012.89},
abstract = {The Hop field model is a well-known dynamic associative-memory model. In this paper, we investigate various aspects of the Hop field model for associative memory. We conduct a systematic simulation investigation of several storage algorithms for Hop field networks, and conclude that the perceptron learning based storage algorithms can achieve much better storage capacity than the Hebbian learning based algorithms.},
title = {Storage capacity of the hopfield network associative memory},
year = {2012},
pages = {330--336},
isbn = {9780769546377},
institution = {IEEE},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Rosenblatt1958,
author = {F. Rosenblatt and Contract Nonr-},
issn = {0033-295X},
year = {1958},
title = {The perceptron: A probabilistic model for information storage and organization in the brain.},
pages = {386--408},
number = {6},
journal = {Psychological Review},
isbn = {0033-295X},
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
doi = {10.1037/h0042519},
url = {http://content.apa.org/journals/rev/65/6/386},
volume = {65},
pmid = {13602029},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Shizhou2016,
author = {Shizhou Zhang and Yihong Gong and Jinjun Wang and Zhang Shizhou and Yihong Gong and Wang Jinjun},
issn = {10450823},
title = {Improving DCNN performance with sparse category-selective objective function},
year = {2016},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {2343--2349},
volume = {2016-Janua},
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human vi-sual cortex, and propose a DCNN performance im-provement method without the need for increasing the network complexity. Inspired by the category-selective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As ex-perimental results show, when applying the pro-posed method to the " Quick " model and NIN models, image classification performances are re-markably improved on four widely used bench-mark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Sainath2015,
author = {Tara N. Sainath and Brian Kingsbury and George Saon and Hagen Soltau and Abdel-rahman rahman Mohamed and George Dahl and Bhuvana Ramabhadran and  Others and Brian Kingsbury and George Saon and Hagen Soltau and Abdel-rahman rahman Mohamed and George Dahl and Bhuvana Ramabhadran},
archiveprefix = {arXiv},
issn = {18792782},
journal = {Neural Networks},
doi = {10.1016/j.neunet.2014.08.005},
isbn = {0893-6080},
publisher = {Elsevier Ltd},
title = {Deep Convolutional Neural Networks for Large-scale Speech Tasks},
abstract = {Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, we hypothesize that CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs). In this paper, we explore applying CNNs to large vocabulary continuous speech recognition (LVCSR) tasks. First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks. Specifically, we focus on how many convolutional layers are needed, what is an appropriate number of hidden units, what is the best pooling strategy. Second, investigate how to incorporate speaker-adapted features, which cannot directly be modeled by CNNs as they do not obey locality in frequency, into the CNN framework. Third, given the importance of sequence training for speech tasks, we introduce a strategy to use ReLU+dropout during Hessian-free sequence training of CNNs. Experiments on 3 LVCSR tasks indicate that a CNN with the proposed speaker-adapted and ReLU+dropout ideas allow for a 12%-14% relative improvement in WER over a strong DNN system, achieving state-of-the art results in these 3 tasks.},
volume = {64},
year = {2015},
pages = {39--48},
url = {http://dx.doi.org/10.1016/j.neunet.2014.08.005},
arxivid = {1309.1501},
eprint = {1309.1501},
pmid = {25439765},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Gatys2016,
author = {Leon A. Gatys and Alex Ecker and er S. and Matthias Bethge},
abstract = {Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic in-formation and, thus, allow to separate image content from style. Here we use image representations derived from Con-volutional Neural Networks optimised for object recogni-tion, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can sep-arate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an ar-bitrary photograph with the appearance of numerous well-known artworks. Our results provide new insights into the deep image representations learned by Convolutional Neu-ral Networks and demonstrate their potential for high level image synthesis and manipulation.},
arxivid = {1505.07376},
isbn = {9781467388511},
journal = {The IEEE conference on computer vision and pattern recognition},
volume = {2016-Decem},
pmid = {15430064963552939126},
doi = {10.1109/CVPR.2016.265},
eprint = {1505.07376},
title = {Image style transfer using convolutional neural networks},
pages = {2414--2423},
archiveprefix = {arXiv},
issn = {10636919},
year = {2016},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Tuohy2006,
author = {Daniel R. Tuohy and Walter D. Potter and Artificial Intelligence Center},
isbn = {%(},
url = {http://quod.lib.umich.edu/cgi/p/pod/dod-idx?c=icmc;idno=bbp2372.2006.119},
number = {January 2006},
pages = {576--579},
title = {An Evolved Neural Network/HC Hybrid for Tablature Creation in GA- based Guitar Arranging},
year = {2006},
volume = {2006},
abstract = {In this paper we describe a technique for creating guitar tablature using a neural network. Training data was parsed from an online repository of human-created tablatures. The contents of both the input layer and the set of training data have been optimized through genetic search in order to maximize the accuracy of the network. The output of the network is im- proved upon with a local heuristic hill-climber (HC). We implement this model in an existing system for generating guitar arrangements via genetic algorithm (GA). When compared to the original system for generating tablature, we note modest improvement in tablature quality and drastic improvements in execution time.},
journal = {Procs. of the International Computer Music Conference (ICMC06)},
keywords = {ga,music transcription},
mendeley-tags = {ga,music transcription},
}

@article{Choi2016a,
author = {Keunwoo Choi and George Gy\"orgy Fazekas and  S and Mark ler},
doi = {10.5281/zenodo.1416253},
url = {http://arxiv.org/abs/1606.00298},
isbn = {9780692755068},
title = {Automatic tagging using deep convolutional neural networks},
year = {2016},
eprint = {1606.00298},
abstract = {We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.},
arxivid = {1606.00298},
annote = {From Duplicate 4 (Automatic tagging using deep convolutional neural networks. - Choi, K; Fazekas, G; Sandler, M)preprint},
pages = {805--811},
archiveprefix = {arXiv},
journal = {arXiv preprint arXiv:1606.00298},
keywords = {music classification},
mendeley-tags = {music classification},
}

@article{Bell2015a,
author = {Sean Bell and C Lawrence Zitnick and Kavita Bala and Ross Girshick and C. Lawrence Zitnick and Kavita Bala and Ross Girshick and C Lawrence Zitnick and Kavita Bala and Ross Girshick and C. Lawrence Zitnick and Kavita Bala and Ross Girshick},
doi = {10.1109/CVPR.2016.314},
archiveprefix = {arXiv},
isbn = {9781467388504},
issn = {10636919},
pages = {2874--2883},
title = {Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks},
url = {http://arxiv.org/abs/1512.04143},
abstract = {It is well known that contextual and multi-scale representations are important for accurate visual recognition. In this paper we present the Inside-Outside Net (ION), an object detector that exploits information both inside and outside the region of interest. Contextual information outside the region of interest is integrated using spatial recurrent neural networks. Inside, we use skip pooling to extract information at multiple scales and levels of abstraction. Through extensive experiments we evaluate the design space and provide readers with an overview of what tricks of the trade are important. ION improves state-of-the-art on PASCAL VOC 2012 object detection from 73.9% to 77.9% mAP. On the new and more challenging MS COCO dataset, we improve state-of-the-art from 19.7% to 33.1% mAP. In the 2015 MS COCO Detection Challenge, our ION model won 'Best Student Entry' and finished 3rd place overall. As intuition suggests, our detection results provide strong evidence that context and multi-scale representations improve small object detection.},
year = {2016},
arxivid = {1512.04143},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pmid = {21803542},
volume = {2016-Decem},
eprint = {1512.04143},
keywords = {object detection},
mendeley-tags = {object detection},
}

@article{Huang2016,
author = {Ke-Kun Kun Huang and Dao-Qing Qing Dai and Chuan-Xian Xian Ren and Zhao-Rong Rong Lai},
pmid = {26890929},
pages = {1082--1094},
title = {Learning Kernel Extended Dictionary for Face Recognition},
doi = {10.1109/TNNLS.2016.2522431},
abstract = {A sparse representation classifier (SRC) and a kernel discriminant analysis (KDA) are two successful methods for face recognition. An SRC is good at dealing with occlusion, while a KDA does well in suppressing intraclass variations. In this paper, we propose kernel extended dictionary (KED) for face recognition, which provides an efficient way for combining KDA and SRC. We first learn several kernel principal components of occlusion variations as an occlusion model, which can represent the possible occlusion variations efficiently. Then, the occlusion model is projected by KDA to get the KED, which can be computed via the same kernel trick as new testing samples. Finally, we use structured SRC for classification, which is fast as only a small number of atoms are appended to the basic dictionary, and the feature dimension is low. We also extend KED to multikernel space to fuse different types of features at kernel level. Experiments are done on several large-scale data sets, demonstrating that not only does KED get impressive results for nonoccluded samples, but it also handles the occlusion well without overfitting, even with a single gallery sample per subject.},
issn = {21622388},
number = {5},
volume = {28},
year = {2017},
publisher = {IEEE},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Zhang2017,
author = {Ying Zhang and Mohammad Pezeshki and Philemon Phil\'emon Philemon Brakel and Saizheng Zhang and Cesar Laurent Yoshua Bengio and Aaron Courville and C\'esar Laurent and Yoshua Bengio and Aaron Courville},
volume = {08-12-Sept},
abstract = {Convolutional Neural Networks (CNNs) are effective models for reducing spectral variations and modeling spectral correlations in acoustic features for automatic speech recognition (ASR). Hybrid speech recognition systems incorporating CNNs with Hidden Markov Models/Gaussian Mixture Models (HMMs/GMMs) have achieved the state-of-the-art in various benchmarks. Meanwhile, Connectionist Temporal Classification (CTC) with Recurrent Neural Networks (RNNs), which is proposed for labeling unsegmented sequences, makes it feasible to train an end-to-end speech recognition system instead of hybrid settings. However, RNNs are computationally expensive and sometimes difficult to train. In this paper, inspired by the advantages of both CNNs and the CTC approach, we propose an end-to-end speech framework for sequence labeling, by combining hierarchical CNNs with CTC directly without recurrent connections. By evaluating the approach on the TIMIT phoneme recognition task, we show that the proposed model is not only computationally efficient, but also competitive with the existing baseline systems. Moreover, we argue that CNNs have the capability to model temporal correlations with appropriate context information.},
arxivid = {1701.02720},
journal = {arXiv preprint arXiv:1701.02720},
url = {http://arxiv.org/abs/1701.02720},
archiveprefix = {arXiv},
doi = {10.21437/Interspeech.2016-1446},
eprint = {1701.02720},
pages = {410--414},
year = {2017},
title = {Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks},
annote = {From Duplicate 1 (Towards end-to-end speech recognition with deep convolutional neural networks - Zhang, Ying; Pezeshki, Mohammad; Brakel, Phil\'emon; Zhang, Saizheng; Laurent, C\'esar; Bengio, Yoshua; Courville, Aaron)preprint},
issn = {19909772},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Graves2013,
author = {Alex Graves and A.-r. Abdel-rahman Rahman Mohamed and Geoffrey Hinton},
institution = {IEEE},
isbn = {978-1-4799-0356-6},
pmid = {27295638},
edition = {Acoustics,},
archiveprefix = {arXiv},
pages = {6645--6649},
eprint = {1303.5778},
doi = {10.1109/ICASSP.2013.6638947},
journal = {Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},
number = {3},
url = {http://arxiv.org/abs/1303.5778},
year = {2013},
issn = {1520-6149},
abstract = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates \emphdeep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.},
publisher = {Anais�IEEE},
arxivid = {1303.5778},
title = {Speech Recognition with Deep Recurrent Neural Networks},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Mollahosseini2015a,
author = {Ali Mollahosseini and David Chan and Mohammad H. Mahoor},
pages = {1--10},
arxivid = {1511.04110},
institution = {IEEE},
journal = {Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on},
isbn = {9781509006410},
abstract = {Automated Facial Expression Recognition (FER) has remained a challenging and interesting problem. Despite efforts made in developing various methods for FER, existing approaches traditionally lack generalizability when applied to unseen images or those that are captured in wild setting. Most of the existing approaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where the classifier's hyperparameters are tuned to give best recognition accuracies across a single database, or a small collection of similar databases. Nevertheless, the results are not significant when they are applied to novel data. This paper proposes a deep neural network architecture to address the FER problem across multiple well-known standard face datasets. Specifically, our network consists of two convolutional layers each followed by max pooling and then four Inception layers. The network is a single component architecture that takes registered facial images as the input and classifies them into either of the six basic or the neutral expressions. We conducted comprehensive experiments on seven publically available facial expression databases, viz. MultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of proposed architecture are comparable to or better than the state-of-the-art methods and better than traditional convolutional neural networks and in both accuracy and training time.},
doi = {10.1109/WACV.2016.7477450},
url = {http://arxiv.org/abs/1511.04110%0Ahttp://dx.doi.org/10.1109/WACV.2016.7477450},
archiveprefix = {arXiv},
year = {2016},
title = {Going deeper in facial expression recognition using deep neural networks},
eprint = {1511.04110},
keywords = {facial expression},
mendeley-tags = {facial expression},
}

@article{ke04,
author = {Matti Karjalainen and Cumhur Erkut},
pages = {978--989},
issn = {11108657},
journal = {Eurasip Journal on Applied Signal Processing},
title = {Digital waveguides versus finite difference structures: Equivalence and mixed modeling},
volume = {2004},
year = {2004},
number = {7},
doi = {10.1155/S1110865704401176},
abstract = {Digital waveguides and finite difference time domain schemes have been used in physical modeling of spatially distributed systems. Both of them are known to provide exact modeling of ideal one-dimensional (ID) band-limited wave propagation, and both of them can be composed to approximate two-dimensional (2D) and three-dimensional (3D) mesh structures. Their equal capabilities in physical modeling have been shown for special cases and have been assumed to cover generalized cases as well. The ability to form mixed models by joining substructures of both classes through converter elements has been proposed recently. In this paper, we formulate a general digital signal processing (DSP)-oriented framework where the functional equivalence of these two approaches is systematically elaborated and the conditions of building mixed models are studied. An example of mixed modeling of a 2D waveguide is presented.},
keywords = {acoustic signal processing,acoustic signal processing,and phrases,digital waveguides,digital waveguides,fdtd model structures,fdtd model structures,hybrid models,hybrid models,scattering,scattering},
mendeley-tags = {acoustic signal processing,acoustic signal processing,and phrases,digital waveguides,digital waveguides,fdtd model structures,fdtd model structures,hybrid models,hybrid models,scattering,scattering},
}

@article{e17,
author = {Bradley J. Erickson and Panagiotis Korfiatis and Zeynettin Akkus and Timothy Kline and Kenneth Philbrick and  Others},
volume = {30},
issn = {1618727X},
number = {4},
pages = {400--405},
title = {Toolkits and Libraries for Deep Learning},
journal = {Journal of digital imaging, v.},
abstract = {Deep learning is an important new area of machine learning which encompasses a wide range of neural network architectures designed to complete various tasks. In the medical imaging domain, example tasks include organ segmentation, lesion detection, and tumor classification. The most popular network architecture for deep learning for images is the convolutional neural network (CNN). Whereas traditional machine learning requires determination and calculation of features from which the algorithm learns, deep learning approaches learn the important features as well as the proper weighting of those features to make predictions for new data. In this paper, we will describe some of the libraries and tools that are available to aid in the construction and efficient execution of deep learning as applied to medical images.},
publisher = {Journal of Digital Imaging},
pmid = {28315069},
doi = {10.1007/s10278-017-9965-6},
year = {2017},
keywords = {artificial intelligence,convolutional neural network,deep learning,machine learning},
mendeley-tags = {artificial intelligence,convolutional neural network,deep learning,machine learning},
}

@article{Santurkar2017,
author = {Shibani Santurkar and David Budden and Nir Shavit},
year = {2017},
journal = {arXiv preprint arXiv:1703.01467},
url = {http://arxiv.org/abs/1703.01467},
eprint = {1703.01467},
doi = {10.1109/PCS.2018.8456298},
arxivid = {1703.01467},
archiveprefix = {arXiv},
abstract = {Traditional image and video compression algorithms rely on hand-crafted encoder/decoder pairs (codecs) that lack adaptability and are agnostic to the data being compressed. Here we describe the concept of generative compression, the compression of data using generative models, and show its potential to produce more accurate and visually pleasing reconstructions at much deeper compression levels for both image and video data. We also demonstrate that generative compression is orders-of-magnitude more resilient to bit error rates (e.g. from noisy wireless channels) than traditional variable-length entropy coding schemes.},
isbn = {9781538641606},
pages = {258--262},
title = {Generative Compression},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Leung2003,
author = {F.H.F. Frank Hung-Fat F Leung and Hak-Keung K Lam and S.H. Sai-Ho H Ling and Peter Kwong-Shun S P.K.S. Tam},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
arxivid = {arXiv:1403.7012v1},
publisher = {IEEE},
year = {2003},
isbn = {1045-9227 (Print)\r1045-9227 (Linking)},
doi = {10.1109/TNN.2002.804317},
issn = {1045-9227},
pages = {79--88},
title = {Tuning of the structure and parameters of a neural network using an improved genetic algorithm.},
pmid = {18237992},
abstract = {This paper presents the tuning of the structure and parameters of a neural network using an improved genetic algorithm (GA). It is also shown that the improved GA performs better than the standard GA based on some benchmark test functions. A neural network with switches introduced to its links is proposed. By doing this, the proposed neural network can learn both the input-output relationships of an application and the network structure using the improved GA. The number of hidden nodes is chosen manually by increasing it from a small number until the learning performance in terms of fitness value is good enough. Application examples on sunspot forecasting and associative memory are given to show the merits of the improved GA and the proposed neural network.},
eprint = {arXiv:1403.7012v1},
archiveprefix = {arXiv},
number = {1},
url = {http://ieeexplore.ieee.org/document/1176129/},
volume = {14},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Floreano2008a,
author = {Dario Floreano and Peter D\"urr and Claudio Mattiussi and Peter D??rr and Claudio Mattiussi and Peter D\"urr and Claudio Mattiussi},
doi = {10.1007/s12065-007-0002-4},
abstract = {Artificial neural networks are applied to many\nreal-world problems, ranging from pattern classification\nto robot control. In order to design a neural network for\na particular task, the choice of an architecture\n(including the choice of a neuron model), and the choice\nof a learning algorithm have to be addressed.\nEvolutionary search methods can provide an automatic\nsolution to these problems. New insights in both\nneuroscience and evolutionary biology have led to the\ndevelopment of increasingly powerful neuroevolution\ntechniques over the last decade. This paper gives an\noverview of the most prominent methods for evolving\nartificial neural networks with a special focus on recent\nadvances in the synthesis of learning architectures.},
volume = {1},
title = {Neuroevolution: From architectures to learning},
year = {2008},
publisher = {Springer},
isbn = {1206500700},
issn = {18645909},
pages = {47--62},
journal = {Evolutionary Intelligence},
number = {1},
keywords = {evolutive,review},
mendeley-tags = {evolutive,review},
}

@article{Sak2015,
author = {Haşim Ha\csim Haşim Sak and  Others and Andrew Senior and Kanishka Rao and Fran\ccoise Francoise Beaufays},
url = {http://arxiv.org/abs/1507.06947},
issn = {19909772},
journal = {arXiv preprint arXiv:1507.06947},
year = {2015},
title = {Fast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition},
volume = {2015-Janua},
arxivid = {1507.06947},
eprint = {1507.06947},
archiveprefix = {arXiv},
annote = {From Duplicate 4 (Fast and accurate recurrent neural network acoustic models for speech recognition. - Sak, H; others)preprint},
abstract = {We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition. More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC). In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition. We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding. CD phone modeling leads to further improvements. We also present initial results for LSTM RNN models outputting words directly.},
pages = {1468--1472},
pmid = {1000285842},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Esteva2017,
author = {Andre Esteva and  Others and Brett Kuprel and Roberto A. Novoa and Justin Ko and Susan M. Swetter and Helen M. Blau and Sebastian Thrun},
pmid = {28117445},
title = {Dermatologist-level classification of skin cancer with deep neural networks},
doi = {10.1038/nature21056},
number = {7639},
pages = {115--118},
publisher = {Nature Publishing Group},
issn = {14764687},
year = {2017},
url = {http://dx.doi.org/10.1038/nature21056 http://www.nature.com/doifinder/10.1038/nature21056},
volume = {542},
journal = {Nature},
abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images - two orders of magnitude larger than previous datasets - consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
isbn = {0028-0836},
keywords = {health,image classification,state of the art},
mendeley-tags = {health,image classification,state of the art},
}

@article{Costa2017,
author = {Y Costa and re M.G. G and Luiz S. Oliveira and Carlos N. Silla},
publisher = {Elsevier B.V.},
doi = {10.1016/j.asoc.2016.12.024},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616306421},
year = {2017},
volume = {52},
issn = {15684946},
title = {An evaluation of Convolutional Neural Networks for music classification using spectrograms},
abstract = {Music genre recognition based on visual representation has been successfully explored over the last years. Classifiers trained with textural descriptors (e.g., Local Binary Patterns, Local Phase Quantization, and Gabor filters) extracted from the spectrograms have achieved state-of-the-art results on several music datasets. In this work, though, we argue that we can go further with the time-frequency analysis through the use of representation learning. To show that, we compare the results obtained with a Convolutional Neural Network (CNN) with the results obtained by using handcrafted features and SVM classifiers. In addition, we have performed experiments fusing the results obtained with learned features and handcrafted features to assess the complementarity between these representations for the music classification task. Experiments were conducted on three music databases with distinct characteristics, specifically a western music collection largely used in research benchmarks (ISMIR 2004 Database), a collection of Latin American music (LMD database), and a collection of field recordings of ethnic African music. Our experiments show that the CNN compares favorably to other classifiers in several scenarios, hence, it is a very interesting alternative for music genre recognition. Considering the African database, the CNN surpassed the handcrafted representations and also the state-of-the-art by a margin. In the case of the LMD database, the combination of CNN and Robust Local Binary Pattern achieved a recognition rate of 92%, which to the best of our knowledge, is the best result (using an artist filter) on this dataset so far. On the ISMIR 2004 dataset, although the CNN did not improve the state of the art, it performed better than the classifiers based individually on other kind of features.},
pages = {28--38},
journal = {Applied Soft Computing},
keywords = {music classification,state of the art},
mendeley-tags = {music classification,state of the art},
}

@article{LeCun1998,
author = {Yann LeCun and L\'eon L??on L\'eon L??on L\'eon Bottou and Yoshua Bengio and Patrick Haffner},
abstract = {Multilayer neural networks trained with the back-propagation\nalgorithm constitute the best example of a successful gradient based\nlearning technique. Given an appropriate network architecture,\ngradient-based learning algorithms can be used to synthesize a complex\ndecision surface that can classify high-dimensional patterns, such as\nhandwritten characters, with minimal preprocessing. This paper reviews\nvarious methods applied to handwritten character recognition and\ncompares them on a standard handwritten digit recognition task.\nConvolutional neural networks, which are specifically designed to deal\nwith the variability of 2D shapes, are shown to outperform all other\ntechniques. Real-life document recognition systems are composed of\nmultiple modules including field extraction, segmentation recognition,\nand language modeling. A new learning paradigm, called graph transformer\nnetworks (GTN), allows such multimodule systems to be trained globally\nusing gradient-based methods so as to minimize an overall performance\nmeasure. Two systems for online handwriting recognition are described.\nExperiments demonstrate the advantage of global training, and the\nflexibility of graph transformer networks. A graph transformer network\nfor reading a bank cheque is also described. It uses convolutional\nneural network character recognizers combined with global training\ntechniques to provide record accuracy on business and personal cheques.\nIt is deployed commercially and reads several million cheques per day\n},
archiveprefix = {arXiv},
issn = {00189219},
publisher = {IEEE},
title = {Gradient-based learning applied to document recognition},
arxivid = {1102.0183},
eprint = {1102.0183},
journal = {Proceedings of the IEEE},
year = {1998},
number = {11},
doi = {10.1109/5.726791},
pages = {2278--2323},
pmid = {15823584},
volume = {86},
isbn = {0018-9219},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Veit2016,
author = {Andreas Veit and Michael J Wilber and Serge Belongie},
title = {Residual networks behave like ensembles of relatively shallow networks},
volume = {2016},
year = {2016},
pages = {550--558},
abstract = {In this work we propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training. To support this observation, we rewrite residual networks as an explicit collection of paths. Unlike traditional models, paths through residual networks vary in length. Further, a lesion study reveals that these paths show ensemble-like behavior in the sense that they do not strongly depend on each other. Finally, and most surprising, most paths are shorter than one might expect, and only the short paths are needed during training, as longer paths do not contribute any gradient. For example, most of the gradient in a residual network with 110 layers comes from paths that are only 10-34 layers deep. Our results reveal one of the key characteristics that seem to enable the training of very deep networks: Residual networks avoid the vanishing gradient problem by introducing short paths which can carry gradient throughout the extent of very deep networks.},
eprint = {1605.06431},
url = {http://arxiv.org/abs/1605.06431},
archiveprefix = {arXiv},
arxivid = {1605.06431},
journal = {Advances in Neural Information Processing Systems},
issn = {10495258},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Hornik1991,
author = {Kurt Hornik},
eprint = {arXiv:1011.1669v3},
pmid = {25246403},
title = {Approximation capabilities of multilayer feedforward networks},
issn = {08936080},
arxivid = {arXiv:1011.1669v3},
publisher = {Elsevier},
archiveprefix = {arXiv},
isbn = {0893-6080},
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp($\mu$) performance criteria, for arbitrary finite input environment measures $\mu$, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. \textcopyright 1991.},
number = {2},
doi = {10.1016/0893-6080(91)90009-T},
pages = {251--257},
journal = {Neural Networks},
year = {1991},
volume = {4},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Zen2015,
author = {Heiga Zen and Hasim Ha\csim Ha\csim Sak},
institution = {IEEE},
abstract = {Long short-term memory recurrent neural networks (LSTM-RNNs) have been applied to various speech applications including acoustic modeling for statistical parametric speech synthesis. One of the con- cerns for applying them to text-to-speech applications is its effect on latency. To address this concern, this paper proposes a low-latency, streaming speech synthesis architecture using unidirectional LSTM- RNNs with a recurrent output layer. The use of unidirectional RNN architecture allows frame-synchronous streaming inference of out- put acoustic features given input linguistic features. The recurrent output layer further encourages smooth transition between acoustic features at consecutive frames. Experimental results in subjective listening tests show that the proposed architecture can synthesize natural sounding speech without requiring utterance-level batch pro- cessing.},
pages = {4470--4474},
doi = {10.1109/ICASSP.2015.7178816},
title = {Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis},
isbn = {9781467369978},
volume = {2015-Augus},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
pmid = {18557655},
issn = {9781467369978},
year = {2015},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
}

@article{03,
author = {Julien Bensa and Stefan Bilbao and  Kronl and Richard -Martinet and Julius O. Smith and Julius O Smith Iii},
doi = {10.1121/1.1587146},
title = {The simulation of piano string vibration: From physical models to finite difference schemes and digital waveguides},
volume = {114},
journal = {The Journal of the Acoustical Society of America},
year = {2003},
pmid = {12942987},
abstract = {A model of transverse piano string vibration, second order in time, which models frequency-dependent loss and dispersion effects is presented here. This model has many desirable properties, in particular that it can be written as a well-posed initial-boundary value problem (permitting stable finite difference schemes) and that it may be directly related to a digital waveguide model, a digital filter-based algorithm which can be used for musical sound synthesis. Techniques for the extraction of model parameters from experimental data over the full range of the grand piano are discussed, as is the link between the model parameters and the filter responses in a digital waveguide. Simulations are performed. Finally, the waveguide model is extended to the case of several coupled strings.},
pages = {1095--1107},
number = {2},
issn = {0001-4966},
}

@article{Widrob1990,
author = {Bernard Widrow and Michael A. Lehr},
publisher = {v. 78},
pages = {1415--1442},
doi = {10.1109/5.58323},
abstract = {Fundamental developments in feedforward artificial neural networks from the past thirty years are reviewed. The central theme of this paper is a description of the history, origination, operating characteristics, and basic theory of several supervised neural network training algorithms including the Perceptron rule, the LMS algorithm, three Madaline rules, and the backpropagation technique. These methods were developed independently, but with the perspective of history they can all be related to each other. The concept underlying these algorithms is the "minimal disturbance principle," which suggests that during training it is advisable to inject new information into a network in a manner that disturbs stored information to the smallest extent possible. \textcopyright 1990 IEEE},
issn = {15582256},
volume = {78},
year = {1990},
address = {n. 9, p. 1415�1442},
isbn = {0018-9219},
number = {9},
journal = {Proceedings of the IEEE},
title = {30 Years of Adaptive Neural Networks: Perceptron, Madaline, and Backpropagation},
keywords = {review},
mendeley-tags = {review},
}

@article{Wang2016,
author = {Jun Jie Jun Jie Wang and Jun Jie Jun Jie Wang and Wen Fang and Hongli Niu},
journal = {Computational Intelligence and Neuroscience},
volume = {2016},
issn = {16875273},
title = {Financial Time Series Prediction Using Elman Recurrent Random Neural Networks},
abstract = {In recent years, financialmarket dynamics forecasting has been a focus of economic research. To predict the price indices of stock markets,we developed an architecturewhich combinedElman recurrent neural networkswith stochastic time effective function.By analyzing the proposedmodelwith the linear regression, complexity invariant distance (CID), andmultiscaleCID(MCID) analysis methods and taking themodel compared with differentmodels such as the backpropagation neural network (BPNN), the stochastic time effective neural network (STNN), and the Elman recurrent neural network (ERNN), the empirical results show that the proposed neural network displays the best performance among these neural networks in financial time series forecasting. Further, the empirical research is performed in testing the predictive effects of SSE, TWSE, KOSPI, and Nikkei225 with the established model, and the corresponding statistical comparisons of the above market indices are also exhibited. The experimental results show that this approach gives good performance in predicting the values fromthe stockmarket indices. 1.},
isbn = {1687-5265},
doi = {10.1155/2016/4742515},
publisher = {Hindawi Publishing Corporation},
year = {2016},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Theis2015,
author = {Lucas Theis and Matthias Bethge},
url = {http://arxiv.org/abs/1506.03478},
arxivid = {1506.03478},
archiveprefix = {arXiv},
issn = {10495258},
eprint = {1506.03478},
journal = {Advances in Neural Information Processing Systems},
volume = {2015-Janua},
year = {2015},
pages = {1927--1935},
abstract = {Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multidimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.},
title = {Generative image modeling using spatial LSTMs},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Bagozzi2006,
author = {Richard P. Bagozzi and Utpal M. Dholakia},
volume = {52},
month = {jul},
year = {2006},
issn = {0025-1909},
pmid = {21517591},
pages = {1099--1115},
abstract = {We conceptualize participation in Linux user groups (LUGs) in terms of group-referent intentional actions and investigate cognitive (attitudes, perceived behavioral control, identification with the open source movement), affective (positive and negative anticipated emotions), and social (social identity) determinants of participation and its consequences on Linux-related behaviors of users. This survey-based study, conducted with 402 active LUG members representing 191 different LUGs from 23 countries and employing structural equation modeling methodology, supports the proposed model. Furthermore, we find that the Linux user's experience level moderates the extent of the LUG's social influence and its impact on the user's participation. We conclude with a consideration of the managerial and research implications of the study's findings.},
journal = {Management Science},
title = {Open Source Software User Communities: A Study of Participation in Linux User Groups},
doi = {10.1287/mnsc.1060.0545},
isbn = {0025-1909},
number = {7},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0545},
keywords = {accepted by eric von,anticipated emotions,for 3 revisions,hippel and georg von,history,krogh,linux,model of goal-directed behavior,novice versus experienced users,open source software,received september,social identity,special issue editors,the authors 4 months,this paper was with,virtual communities,we-intentions},
mendeley-tags = {accepted by eric von,anticipated emotions,for 3 revisions,hippel and georg von,history,krogh,linux,model of goal-directed behavior,novice versus experienced users,open source software,received september,social identity,special issue editors,the authors 4 months,this paper was with,virtual communities,we-intentions},
}

@article{Iizuka2016a,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
doi = {10.1145/2897824.2925974},
isbn = {9781450342797},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
pages = {1--11},
journal = {ACM Transactions on Graphics},
year = {2016},
publisher = {ACM},
issn = {15577368},
number = {4},
volume = {35},
title = {Let there be color! :Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Gregor2016a,
author = {Karol Gregor and Frederic Besse and Danilo Jimenez Rezende and Ivo Danihelka and Daan Wierstra},
archiveprefix = {arXiv},
arxivid = {1604.08772},
journal = {Advances In Neural Information Processing Systems},
url = {http://arxiv.org/abs/1604.08772},
abstract = {We introduce convolutional DRAW, a homogeneous deep generative model achieving state-of-the-art performance in latent variable image modeling. The algorithm naturally stratifies information into higher and lower level details, creating abstract features and as such addressing one of the fundamentally desired properties of representation learning. Furthermore, the hierarchical ordering of its latents creates the opportunity to selectively store global information about an image, yielding a high quality 'conceptual compression' framework.},
number = {Nips},
issn = {10495258},
year = {2016},
title = {Towards conceptual compression},
pages = {3549--3557},
eprint = {1604.08772},
keywords = {image compression - conceptual,state of the art},
mendeley-tags = {image compression - conceptual,state of the art},
}

@article{Risi2017,
author = {Sebastian Risi and Julian Togelius},
archiveprefix = {arXiv},
isbn = {1943-068X VO  - PP},
year = {2017},
number = {1},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
arxivid = {1410.7326},
volume = {9},
pages = {25--41},
doi = {10.1109/TCIAIG.2015.2494596},
title = {Neuroevolution in Games: State of the Art and Open Challenges},
eprint = {1410.7326},
abstract = {This paper surveys research on applying neuroevolution (NE) to games. In neuroevolution, artificial neural networks are trained through evolutionary algorithms, taking inspiration from the way biological brains evolved. We analyse the application of NE in games along five different axes, which are the role NE is chosen to play in a game, the different types of neural networks used, the way these networks are evolved, how the fitness is determined and what type of input the network receives. The article also highlights important open research challenges in the field.},
issn = {1943068X},
publisher = {IEEE},
keywords = {evolutive,games,review},
mendeley-tags = {evolutive,games,review},
}

@article{Yang2017,
author = {Yinchong Yang and Denis Krompass and Volker Tresp},
arxivid = {1707.01786},
title = {Tensor-Train Recurrent Neural Networks for Video Classification},
journal = {34th International Conference on Machine Learning, ICML 2017},
volume = {8},
year = {2017},
isbn = {9781510855144},
archiveprefix = {arXiv},
abstract = {The Recurrent Neural Networks and their variants have shown promising performances in sequence modeling tasks such as Natural Language Processing. These models, however, turn out to be impractical and difficult to train when exposed to very high-dimensional inputs due to the large input-to-hidden weight matrix. This may have prevented RNNs' large-scale application in tasks that involve very high input dimensions such as video modeling; current approaches reduce the input dimensions using various feature extractors. To address this challenge, we propose a new, more general and efficient approach by factorizing the input-to-hidden weight matrix using Tensor-Train decomposition which is trained simultaneously with the weights themselves. We test our model on classification tasks using multiple real-world video datasets and achieve competitive performances with state-of-the-art models, even though our model architecture is orders of magnitude less complex. We believe that the proposed approach provides a novel and fundamental building block for modeling high-dimensional sequential data with RNN architectures and opens up many possibilities to transfer the expressive and advanced architectures from other domains such as NLP to modeling high-dimensional sequential data.},
eprint = {1707.01786},
pages = {5929--5938},
url = {https://arxiv.org/pdf/1707.01786.pdf},
keywords = {video classification},
mendeley-tags = {video classification},
}

@article{Schmidhuber2015,
author = {J??rgen J\"urgen Schmidhuber},
year = {2015},
arxivid = {1404.7828},
pmid = {25462637},
eprint = {1404.7828},
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archiveprefix = {arXiv},
volume = {61},
doi = {10.1016/j.neunet.2014.09.003},
isbn = {0893-6080},
title = {Deep Learning in neural networks: An overview},
issn = {18792782},
journal = {Neural Networks},
pages = {85--117},
keywords = {review},
mendeley-tags = {review},
}

@article{Hornik1989,
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
arxivid = {arXiv:1011.1669v3},
pages = {359--366},
publisher = {Elsevier},
volume = {2},
doi = {10.1016/0893-6080(89)90020-8},
journal = {Neural Networks},
year = {1989},
isbn = {08936080 (ISSN)},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators. ?? 1989.},
issn = {08936080},
title = {Multilayer feedforward networks are universal approximators},
archiveprefix = {arXiv},
pmid = {74},
number = {5},
eprint = {arXiv:1011.1669v3},
keywords = {seminal,theory},
mendeley-tags = {seminal,theory},
}

@article{Deng2016,
author = {Shuiguang Deng and Longtao Huang and Gu Xu and  ong and Xindong Wu and Zhaohui Wu},
issn = {21622388},
volume = {28},
year = {2016},
isbn = {2162-2388 (Electronic)\r2162-237X (Linking)},
pages = {1164--1177},
pmid = {26915135},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
doi = {10.1109/TNNLS.2016.2514368},
title = {On Deep Learning for Trust-Aware Recommendations in Social Networks},
number = {February},
abstract = {With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user's trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users' interests and their trusted friends' interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.},
keywords = {social recommendations},
mendeley-tags = {social recommendations},
}

@article{Lee2015,
author = {Chen-Yu Lee and Patrick W. Gallagher and Zhuowen Tu},
doi = {10.1109/TPAMI.2017.2703082},
abstract = {We seek to improve deep neural networks by generalizing the pooling operations that play a central role in current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures. These benefits come with only a light increase in computational overhead during training and a very modest increase in the number of model parameters.},
pmid = {67101},
volume = {51},
issn = {0162-8828},
year = {2015},
journal = {Artificial Intelligence and Statistics},
archiveprefix = {arXiv},
eprint = {1509.08985},
title = {Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree},
pages = {464--472},
arxivid = {1509.08985},
url = {http://arxiv.org/abs/1509.08985},
keywords = {optimization},
mendeley-tags = {optimization},
}

@article{Sarroff,
author = {Andy M. Sarroff and Michael Casey},
year = {2014},
isbn = {9789604661374},
title = {Musical audio synthesis using autoencoding neural nets},
number = {September},
volume = {1},
abstract = {With an optimal network topology and tuning of hyperpa-rameters, artificial neural networks (ANNs) may be trained to learn a mapping from low level audio features to one or more higher-level representations. Such artificial neural networks are commonly used in classification and regression settings to perform arbitrary tasks. In this work we suggest repurposing autoencoding neural networks as musical audio synthesizers. We offer an interactive musical audio synthesis system that uses feedforward artificial neural networks for musical audio synthesis, rather than discriminative or regression tasks. In our system an ANN is trained on frames of low-level features. A high level representation of the musical audio is learned though an autoencoding neural net. Our real-time synthesis system allows one to interact directly with the parameters of the model and generate musical audio in real time. This work therefore proposes the exploitation of neural networks for creative musical applications. Copyright:},
journal = {Proceedings - 40th International Computer Music Conference, ICMC 2014 and 11th Sound and Music Computing Conference, SMC 2014 - Music Technology Meets Philosophy: From Digital Echos to Virtual Ethos},
pages = {14--20},
}

@article{wang2017tacotron,
author = {Yuxuan Wang and RJ J. Skerry-Ryan and Daisy Stanton and Yonghui Wu and Ron J. Weiss and Navdeep Jaitly and Zongheng Yang and Ying Xiao and Zhifeng Chen and Samy Bengio and Quoc Le and Yannis Agiomyrgiannakis and Rob Clark and Rif A. Saurous},
volume = {2017-Augus},
eprint = {1703.10135},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
title = {Tacotron: Towards end-To-end speech synthesis},
doi = {10.21437/Interspeech.2017-1452},
issn = {19909772},
url = {http://arxiv.org/abs/1703.10135},
abstract = {A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods.},
archiveprefix = {arXiv},
year = {2017},
arxivid = {1703.10135},
pages = {4006--4010},
keywords = {speech synthesis,state of the art},
mendeley-tags = {speech synthesis,state of the art},
}

@article{Arik2017,
author = {Sercan O. Arik and Mike Chrzanowski and Adam Coates and Gregory Diamos and Andrew Gibiansky and Yongguo Kang and Xian Li and John Miller and Andrew Ng and Jonathan Raiman and Shubho Sengupta and Mohammad Shoeybi and  Others and Andrew Ng and Jonathan Raiman and Shubho Sengupta and Mohammad Shoeybi and  Others},
arxivid = {1702.07825},
year = {2017},
abstract = {We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For the segmentation model, we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component, our system is simpler and more flexible than traditional text-to-speech systems, where each component requires laborious feature engineering and extensive domain expertise. Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.},
journal = {arXiv preprint arXiv:1702.07825},
url = {http://arxiv.org/abs/1702.07825},
eprint = {1702.07825},
archiveprefix = {arXiv},
number = {Icml},
issn = {1938-7228},
title = {Deep Voice: Real-time Neural Text-to-Speech},
keywords = {speech synthesis,state of the art},
mendeley-tags = {speech synthesis,state of the art},
}

@article{Toderici2016a,
author = {George Toderici and Damien Vincent and Nick Johnston and Sung Jin Hwang and David Minnen and Joel Shor and Michele Covell},
archiveprefix = {arXiv},
issn = {08936080},
isbn = {9780761914402},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
arxivid = {1608.05148},
eprint = {1608.05148},
volume = {2017-Janua},
year = {2016},
url = {http://arxiv.org/abs/1608.05148},
title = {Full Resolution Image Compression with Recurrent Neural Networks},
doi = {10.4135/9781412985277},
abstract = {This paper presents a set of full-resolution lossy image compression methods based on neural networks. Each of the architectures we describe can provide variable compression rates during deployment without requiring retraining of the network: each network need only be trained once. All of our architectures consist of a recurrent neural network (RNN)-based encoder and decoder, a binarizer, and a neural network for entropy coding. We compare RNN types (LSTM, associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study "one-shot" versus additive reconstruction architectures and introduce a new scaled-additive framework. We compare to previous work, showing improvements of 4.3%-8.8% AUC (area under the rate-distortion curve), depending on the perceptual metric used. As far as we know, this is the first neural network architecture that is able to outperform JPEG at image compression across most bitrates on the rate-distortion curve on the Kodak dataset images, with and without the aid of entropy coding.},
pmid = {21655600},
pages = {5435--5443},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Ding2016,
author = {Hui Ding and Shaohua Kevin Zhou and Rama Chellappa},
institution = {IEEE},
title = {FaceNet2ExpNet: Regularizing a Deep Face Recognition Net for Expression Recognition},
eprint = {1609.06591},
journal = {Automatic Face & Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
arxivid = {1609.06591},
issn = {2160-7508},
pages = {118--126},
abstract = {Relatively small data sets available for expression recognition research make the training of deep networks for expression recognition very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redun- dant information from the pre-trained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully- connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization shows that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu-CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art.},
archiveprefix = {arXiv},
doi = {10.1109/FG.2017.23},
url = {http://arxiv.org/abs/1609.06591},
year = {2016},
isbn = {9781509040230},
keywords = {facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
}

@article{Park2017a,
author = {Sungheon Park and Nojun Kwak},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year = {2017},
title = {Analysis on the dropout effect in convolutional neural networks},
doi = {10.1007/978-3-319-54184-6_12},
institution = {Springer},
isbn = {9783319541839},
pages = {189--204},
issn = {16113349},
volume = {10112 LNCS},
keywords = {optimization},
mendeley-tags = {optimization},
}

@article{stanley2007compositional,
author = {Kenneth O. Stanley},
year = {2007},
doi = {10.1007/s10710-007-9028-8},
pages = {131--162},
isbn = {1389-2576},
volume = {8},
number = {2},
issn = {13892576},
title = {Compositional pattern producing networks: A novel abstraction of development},
publisher = {Springer},
abstract = {Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed.},
journal = {Genetic programming and evolvable machines},
keywords = {artificial embryogeny,complexity,developmental encoding,evolutionary computation,generative systems,indirect encoding,representation},
mendeley-tags = {artificial embryogeny,complexity,developmental encoding,evolutionary computation,generative systems,indirect encoding,representation},
}

@article{Larsson2016,
author = {Gustav Larsson and Michael Maire and Gregory Shakhnarovich},
institution = {Springer},
isbn = {9783319464923},
address = {Anais�},
year = {2016},
doi = {10.1007/978-3-319-46493-0_35},
edition = {European C},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
title = {Learning representations for automatic colorization},
archiveprefix = {arXiv},
abstract = {We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.},
volume = {9908 LNCS},
eprint = {1603.06668},
pages = {577--593},
publisher = {Springer},
arxivid = {1603.06668},
issn = {16113349},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Tsai2006,
author = {Jinn-Tsong Tsong Tsai and Jyh-Horng Horng Chou and Tung-Kuan Kuan Liu},
doi = {10.1109/TNN.2005.860885},
isbn = {1045-9227 (Print)\r1045-9227 (Linking)},
journal = {IEEE Transactions on Neural Networks},
volume = {17},
number = {1},
pmid = {16526477},
publisher = {IEEE},
pages = {69--80},
year = {2006},
issn = {10459227},
abstract = {In this paper, a hybrid Taguchi-genetic algorithm (HTGA) is applied to solve the problem of tuning both network structure and parameters of a feedforward neural network. The HTGA approach is a method of combining the traditional genetic algorithm (TGA), which has a powerful global exploration capability, with the Taguchi method, which can exploit the optimum offspring. The Taguchi method is inserted between crossover and mutation operations of a TGA. Then, the systematic reasoning ability of the Taguchi method is incorporated in the crossover operations to select the better genes to achieve crossover, and consequently enhance the genetic algorithms. Therefore, the HTGA approach can be more robust, statistically sound, and quickly convergent. First, the authors evaluate the performance of the presented HTGA approach by studying some global numerical optimization problems. Then, the presented HTGA approach is effectively applied to solve three examples on forecasting the sunspot numbers, tuning the associative memory, and solving the XOR problem. The numbers of hidden nodes and the links of the feedforward neural network are chosen by increasing them from small numbers until the learning performance is good enough. As a result, a partially connected feedforward neural network can be obtained after tuning. This implies that the cost of implementation of the neural network can be reduced. In these studied problems of tuning both network structure and parameters of a feedforward neural network, there are many parameters and numerous local optima so that these studied problems are challenging enough for evaluating the performances of any proposed GA-based approaches. The computational experiments show that the presented HTGA approach can obtain better results than the existing method reported recently in the literature.},
title = {Tuning the structure and parameters of a neural network by using hybrid Taguchi-genetic algorithm},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Hou2015,
author = {Weilong Hou and Xinbo Gao and Dacheng Tao and Xuelong Li and Senior Member and Dacheng Tao and Senior Member},
volume = {26},
year = {2015},
publisher = {IEEE},
title = {Blind Image Quality Assessment via Deep Learning},
number = {6},
journal = {IEEE transactions on neural networks and learning systems},
pages = {1275--1286},
keywords = {image classification,sentiment analysis},
mendeley-tags = {image classification,sentiment analysis},
}

@article{Hopfield1982,
author = {John J. Hopfield},
volume = {79},
title = {Neural networks and physical systems with emergent collective computational abilities.},
eprint = {arXiv:1411.3159v1},
archiveprefix = {arXiv},
pmid = {6953413},
arxivid = {arXiv:1411.3159v1},
abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
publisher = {National Acad Sciences},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {8},
isbn = {0027-8424},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
year = {1982},
doi = {10.1073/pnas.79.8.2554},
pages = {2554--2558},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Yadav2007,
author = {Ram N. Yadav and Prem Kumar Kalra and Joseph John},
doi = {10.1016/j.asoc.2006.01.003},
title = {Time series prediction with single multiplicative neuron model},
year = {2007},
volume = {7},
pages = {1157--1163},
number = {4},
journal = {Applied Soft Computing Journal},
publisher = {Elsevier},
abstract = {Single neuron models are typical functional replica of the biological neuron that are derived using their individual and group responses in networks. In recent past, a lot of work in this area has produced advanced neuron models for both analog and binary data patterns. Popular among these are the higher-order neurons, fuzzy neurons and other polynomial neurons. In this paper, we propose a new neuron model based on a polynomial architecture. Instead of considering all the higher-order terms, a simple aggregation function is used. The aggregation function is considered as a product of linear functions in different dimensions of the space. The functional mapping capability of the proposed neuron model is demonstrated through some well known time series prediction problems and is compared with the standard multilayer neural network. ?? 2006 Elsevier B.V. All rights reserved.},
issn = {15684946},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Sigtia2016b,
author = {Siddharth Sigtia and Emmanouil Benetos and Simon DIxon},
pages = {927--939},
title = {An end-to-end neural network for polyphonic piano music transcription},
volume = {24},
arxivid = {1508.01774},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
doi = {10.1109/TASLP.2016.2533858},
number = {5},
publisher = {IEEE Press},
year = {2016},
archiveprefix = {arXiv},
url = {https://arxiv.org/abs/1508.01774},
abstract = {We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yields the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.},
issn = {23299290},
eprint = {1508.01774},
keywords = {music transcription,state of the art},
mendeley-tags = {music transcription,state of the art},
}

@article{Hutchings2017,
author = {P. Hutchings},
archiveprefix = {arXiv},
arxivid = {1706.09558},
pages = {43--47},
journal = {arXiv},
year = {2017},
abstract = {Presented is a method of generating a full drum kit part for a provided kick-drum sequence. A sequence to sequence neural network model used in natural language translation was adopted to encode multiple musical styles and an online survey was developed to test different techniques for sampling the output of the softmax function. The strongest results were found using a sampling technique that drew from the three most probable outputs at each subdivision of the drum pattern but the consistency of output was found to be heavily dependent on style.},
issn = {23318422},
annote = {From Duplicate 2 (Talking Drums: Generating drum grooves with neural networks. - Hutchings, P)preprint},
eprint = {1706.09558},
number = {1},
title = {Talking Drums: Generating drum grooves with neural networks},
url = {http://arxiv.org/abs/1706.09558},
volume = {1},
keywords = {music generation,state of the art},
mendeley-tags = {music generation,state of the art},
}

@article{Omar2017,
author = {Normah Omar and Zulaikha 'Amirah Amirah Johari and Malcolm Smith},
url = {http://dx.doi.org/10.1108/eb025814%5Cnhttp://},
volume = {24},
year = {2017},
pages = {362--387},
isbn = {1359079051062},
doi = {10.1108/13590791011082797},
title = {Predicting fraudulent financial reporting using artificial neural network},
abstract = {This study explores the effectiveness of an Artificial Neural Network (ANN) in predicting fraudulent financial reporting in small market capitalization companies in Malaysia. Design/methodology/approach Based on the concepts of ANN, a mathematical model is developed to compare non-fraud and fraud companies selected from among small market capitalization companies in Malaysia; the fraud companies had already been charged by the Securities Commission for the falsification of financial statements. Ten financial ratios are used as fraud risk indicators to predict fraudulent financial reporting using ANN. Findings Indicate that the proposed ANN methodology outperforms other statistical techniques widely used for predicting fraudulent financial reporting. Originality/value The study is one of few to adopt the ANN approach to the prediction of financial reporting fraud.},
number = {2},
issn = {1359-0790},
journal = {Journal of Financial Crime Iss},
keywords = {security},
mendeley-tags = {security},
}

@article{rdd13,
author = {Fran\ccois Rigaud and Bertr David and   and Laurent Daudet},
number = {5},
pages = {3107--3118},
pmid = {23654413},
title = {A parametric model and estimation techniques for the inharmonicity and tuning of the piano},
year = {2013},
abstract = {Inharmonicity of piano tones is an essential property of their timbre that strongly influences the tuning, leading to the so-called octave stretching. It is proposed in this paper to jointly model the inharmonicity and tuning of pianos on the whole compass. While using a small number of parameters, these models are able to reflect both the specificities of instrument design and tuner's practice. An estimation algorithm is derived that can run either on a set of isolated note recordings, but also on chord recordings, assuming that the played notes are known. It is applied to extract parameters highlighting some tuner's choices on different piano types and to propose tuning curves for out-of-tune pianos or piano synthesizers.},
doi = {10.1121/1.4799806},
volume = {133},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
}

@article{Goldberg2015,
author = {Yoav Goldberg},
journal = {J. Artif. Intell. Res.(JAIR)},
doi = {10.1613/jair.4992},
eprint = {1510.00726},
title = {A Primer on Neural Network Models for Natural Language Processing},
arxivid = {1510.00726},
volume = {57},
archiveprefix = {arXiv},
year = {2015},
abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
issn = {1076-9757},
url = {http://arxiv.org/abs/1510.00726},
pages = {1--76},
keywords = {review,speech recognition,speech synthesis},
mendeley-tags = {review,speech recognition,speech synthesis},
}

@article{Boulanger-lewandowski2014,
author = { Boulanger-Lew and Nicolas owski and Jasha Droppo and Mike Seltzer and Dong Yu},
year = {2014},
title = {Phone sequence modeling with recurrent neural networks},
issn = {15206149},
isbn = {9781479928927},
doi = {10.1109/ICASSP.2014.6854638},
pages = {5454--5458},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
number = {2},
abstract = {In this paper, we investigate phone sequence modeling with recurrent neural networks in the context of speech recognition. We introduce a hybrid architecture that combines a phonetic model with an arbitrary frame-level acoustic model and we propose efficient algorithms for training, decoding and sequence alignment. We evaluate the advantage of our phonetic model on the TIMIT and Switchboard-mini datasets in complementarity to a powerful context-dependent deep neural network (DNN) acoustic classifier and a higher-level 3-gram language model. Consistent improvements of 2-10% in phone accuracy and 3% in word error rate suggest that our approach can readily replace HMMs in current state-of-the-art systems. \textcopyright 2014 IEEE.},
institution = {IEEE},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Zhao2016,
author = {Xiangyun Zhao and Xiaodan Liang and Luoqi Liu and Teng Li and Yugang Han and Nuno Vasconcelos and Shuicheng Yan},
url = {http://arxiv.org/abs/1607.06997},
pmid = {4520227},
year = {2016},
volume = {9906 LNCS},
archiveprefix = {arXiv},
arxivid = {1607.06997},
isbn = {9783319464749},
doi = {10.1007/978-3-319-46475-6_27},
abstract = {Objective functions for training of deep networks for face-related recognition tasks, such as facial expression recognition (FER), usually consider each sample independently. In this work, we present a novel peak-piloted deep network (PPDN) that uses a sample with peak expression (easy sample) to supervise the intermediate feature responses for a sample of non-peak expression (hard sample) of the same type and from the same subject. The expression evolving process from non-peak expression to peak expression can thus be implicitly embedded in the network to achieve the invariance to expression intensities. A special purpose back-propagation procedure, peak gradient suppression (PGS), is proposed for network training. It drives the intermediate-layer feature responses of non-peak expression samples towards those of the corresponding peak expression samples, while avoiding the inverse. This avoids degrading the recognition capability for samples of peak expression due to interference from their non-peak expression counterparts. Extensive comparisons on two popular FER datasets, Oulu-CASIA and CK+, demonstrate the superiority of the PPDN over state-ofthe-art FER methods, as well as the advantages of both the network structure and the optimization strategy. Moreover, it is shown that PPDN is a general architecture, extensible to other tasks by proper definition of peak and non-peak samples. This is validated by experiments that show state-of-the-art performance on pose-invariant face recognition, using the Multi-PIE dataset.},
eprint = {1607.06997},
pages = {425--442},
institution = {Springer},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
issn = {16113349},
title = {Peak-piloted deep network for facial expression recognition},
keywords = {facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
}

@article{Boulanger-Lewandowski2013,
author = { Boulanger-Lew and Nicolas owski and Yoshua Bengio and Pascal Vincent},
publisher = {Anais�IEEE},
eprint = {1212.1936},
pages = {3178--3182},
arxivid = {1212.1936},
year = {2013},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
number = {5},
archiveprefix = {arXiv},
doi = {10.1109/ICASSP.2013.6638244},
institution = {IEEE},
isbn = {9781479903566},
issn = {15206149},
title = {High-dimensional sequence transduction},
abstract = {We investigate the problem of transforming an input sequence into a high-dimensional output sequence in order to transcribe polyphonic audio music into symbolic notation. We introduce a probabilistic model based on a recurrent neural network that is able to learn realistic output distributions given the input and we devise an efficient algorithm to search for the global mode of that distribution. The resulting method produces musically plausible transcriptions even under high levels of noise and drastically outperforms previous state-of-the-art approaches on five datasets of synthesized sounds and real recordings, approximately halving the test error rate.},
keywords = {music transcription},
mendeley-tags = {music transcription},
}

@article{Xu2015,
author = {Wenduan Xu and Michael Auli and Stephen Clark},
abstract = {Recent work on supertagging using a feed-forward neural network achieved signifi-cant improvements for CCG supertagging and parsing (Lewis and Steedman, 2014). However, their architecture is limited to considering local contexts and does not naturally model sequences of arbitrary length. In this paper, we show how di-rectly capturing sequence information us-ing a recurrent neural network leads to fur-ther accuracy improvements for both su-pertagging (up to 1.9%) and parsing (up to 1% FI), on CCGBank, Wikipedia and biomedical text.},
isbn = {9781941643730},
pages = {250--255},
title = {CCG Supertagging with a Recurrent Neural Network},
journal = {Acl-2015},
year = {2015},
publisher = {Association for Computational Linguistics},
number = {2014},
url = {https://doi.org/10.3115/v1/p15-2041},
volume = {2},
doi = {10.3115/v1/p15-2041},
keywords = {sentence classification},
mendeley-tags = {sentence classification},
}

@article{Shin2016,
author = {Hoo-Chang Chang Shin and Holger R. Roth and Mingchen Gao and Le Lu and Ziyue Xu and Isabella Nogues and Jianhua Yao and Daniel Mollura and Ronald M. Summers},
abstract = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and the revival of deep CNN. CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
issn = {1558254X},
publisher = {IEEE},
year = {2016},
title = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},
volume = {35},
number = {5},
eprint = {1602.03409},
arxivid = {1602.03409},
doi = {10.1109/TMI.2016.2528162},
pages = {1285--1298},
pmid = {26886976},
isbn = {0278-0062 VO - 35},
archiveprefix = {arXiv},
journal = {IEEE Transactions on Medical Imaging},
keywords = {image classification,optimization},
mendeley-tags = {image classification,optimization},
}

@article{Collobert2004,
author = {Ronan Collobert and Samy Bengio},
abstract = {We propose to study links between three important classification algorithms: Perceptrons, Multi-Layer Perceptrons (MLPs) and Support Vector Machines (SVMs). We first study ways to control the capacity of Perceptrons (mainly regularization parameters and early stopping), using the margin idea introduced with SVMs. After showing that under simple conditions a Perceptron is equivalent to an SVM, we show it can be computationally expensive in time to train an SVM (and thus a Perceptron) with stochastic gradient descent, mainly because of the margin maximization term in the cost function. We then show that if we remove this margin maximization term, the learning rate or the use of early stopping can still control the margin. These ideas are extended afterward to the case of MLPs. Moreover, under some assumptions it also appears that MLPs are a kind of mixture of SVMs, maximizing the margin in the hidden layer space. Finally, we present a very simple MLP based on the previous findings, which yields better performances in generalization and speed than the other models.},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015415},
pages = {23},
doi = {10.1145/1015330.1015415},
institution = {ACM},
issn = {1581138385},
year = {2004},
journal = {Twenty-first international conference on Machine learning - ICML '04},
isbn = {1581138285},
title = {Links between perceptrons, MLPs and SVMs},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Araque2017a,
author = {Oscar Araque and Ignacio Corcuera-Platas and J. Fern S\'anchez-Rada and  o and Carlos A. Iglesias},
issn = {09574174},
isbn = {0957-4174},
journal = {Expert Systems with Applications},
abstract = {Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on F1-Score.},
publisher = {Elsevier Ltd},
title = {Enhancing deep learning sentiment analysis with ensemble techniques in social applications},
doi = {10.1016/j.eswa.2017.02.002},
volume = {77},
pages = {236--246},
year = {2017},
keywords = {sentiment analysis},
mendeley-tags = {sentiment analysis},
}

@article{Zhang2016b,
author = {Yu Zhang and William Chan and Navdeep Jaitly},
eprint = {1610.03022},
doi = {10.1109/ICASSP.2017.7953077},
issn = {15206149},
institution = {IEEE},
isbn = {9781509041176},
url = {http://arxiv.org/abs/1610.03022},
archiveprefix = {arXiv},
abstract = {Sequence-to-sequence models have shown success in end-to-end speech recognition. However these models have only used shallow acoustic encoder networks. In our work, we successively train very deep convolutional networks to add more expressive power and better generalization for end-to-end ASR models. We apply network-in-network principles, batch normalization, residual connections and convolutional LSTMs to build very deep recurrent and convolutional structures. Our models exploit the spectral structure in the feature space and add computational depth without overfitting issues. We experiment with the WSJ ASR task and achieve 10.5\% word error rate without any dictionary or language using a 15 layer deep network.},
arxivid = {1610.03022},
title = {Very Deep Convolutional Networks for End-to-End Speech Recognition},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on},
year = {2016},
pages = {10--14},
keywords = {speech recognition,state of the art},
mendeley-tags = {speech recognition,state of the art},
}

@article{Zhang2016a,
author = {Richard Zhang and Phillip Isola and Alexei A. Efros},
pages = {649--666},
pmid = {10463930},
arxivid = {1603.08511},
isbn = {9783319464862},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {9907 LNCS},
abstract = {Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test," asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.},
eprint = {1603.08511},
institution = {Springer},
issn = {16113349},
publisher = {Springer},
year = {2016},
edition = {European C},
title = {Colorful image colorization},
archiveprefix = {arXiv},
doi = {10.1007/978-3-319-46487-9_40},
address = {Anais�},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Wu2016,
author = {Zhizheng Wu and Simon King},
issn = {15206149},
volume = {2016-May},
doi = {10.1109/ICASSP.2016.7472657},
archiveprefix = {arXiv},
pages = {5140--5144},
abstract = {Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feed-forward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.},
arxivid = {1601.02539},
year = {2016},
isbn = {9781479999880},
institution = {IEEE},
eprint = {1601.02539},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
title = {Investigating gated recurrent networks for speech synthesis},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
}

@article{Tu2016,
author = {Enmei Tu and Nikola Kasabov and Jie Yang},
pages = {1--14},
publisher = {IEEE},
volume = {28},
eprint = {1603.05594},
doi = {10.1109/TNNLS.2016.2536742},
abstract = {This paper proposes a new method for an optimized mapping of temporal variables, describing a temporal stream data, into the recently proposed NeuCube spiking neural network architecture. This optimized mapping extends the use of the NeuCube, which was initially designed for spatiotemporal brain data, to work on arbitrary stream data and to achieve a better accuracy of temporal pattern recognition, a better and earlier event prediction and a better understanding of complex temporal stream data through visualization of the NeuCube connectivity. The effect of the new mapping is demonstrated on three bench mark problems. The first one is early prediction of patient sleep stage event from temporal physiological data. The second one is pattern recognition of dynamic temporal patterns of traffic in the Bay Area of California and the last one is the Challenge 2012 contest data set. In all cases the use of the proposed mapping leads to an improved accuracy of pattern recognition and event prediction and a better understanding of the data when compared to traditional machine learning techniques or spiking neural network reservoirs with arbitrary mapping of the variables.},
number = {6},
year = {2016},
issn = {21622388},
pmid = {26992179},
title = {Mapping Temporal Variables Into the NeuCube for Improved Pattern Recognition, Predictive Modeling, and Understanding of Stream Data},
archiveprefix = {arXiv},
arxivid = {1603.05594},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {forecasting,state of the art},
mendeley-tags = {forecasting,state of the art},
}

@article{s07,
author = {Xavier Serra},
isbn = {1424412749},
year = {2007},
pages = {9--12},
volume = {2007},
abstract = {Sound synthesis and processing has been the most active research topic in the field of Sound and Music Computing for more than 40 years. Quite a number of the early research results are now standard components of many audio and music devices and new technologies are continuously being developed and integrated into new products. Through the years there have been important changes. For example, most of the abstract algorithms that were the focus of work in the 70s and 80s are considered obsolete. Then the 1990s saw the emergence of computational approaches that aimed either at capturing the characteristics of a sound source, known as physical models, or at capturing the perceptual characteristics of the sound signal, generally referred to as spectral or signal models. More recent trends include the combination of physical and spectral models and the corpus-based concatenative methods. But the field faces major challenges that might revolutionize the standard paradigms and applications of sound synthesis. In this article we will first place the sound synthesis topic within its research context, then we will highlight some of the current trends, and finally we will attempt to identify some challenges for the future. \textcopyright 2007 IEEE.},
journal = {2007 IEEE 9Th International Workshop on Multimedia Signal Processing, MMSP 2007 - Proceedings},
title = {State of the art and future directions in musical sound synthesis},
doi = {10.1109/MMSP.2007.4412805},
keywords = {and music composition,experimental psychology and neurosciences,including,most smc research is,psychoacoustics,psychology,quite applied,signal processing and electronics,sound and music computing,sound and music computing,sound synthesis,sound synthesis},
mendeley-tags = {and music composition,experimental psychology and neurosciences,including,most smc research is,psychoacoustics,psychology,quite applied,signal processing and electronics,sound and music computing,sound and music computing,sound synthesis,sound synthesis},
}

@article{Bock2012,
author = {Sebastian Bock and Markus Schedl},
title = {Polyphonic piano note transcription with recurrent neural networks},
abstract = {In this paper a new approach for polyphonic piano note onset transcription is presented. It is based on a recurrent neural network to simultaneously detect the onsets and the pitches of the notes from spectral features. Long Short-Term Memory units are used in a bidirectional neural network to model the context of the notes. The use of a single regression output layer instead of the often used one-versus-all classification approach enables the system to significantly lower the number of erroneous note detections. Evaluation is based on common test sets and shows exceptional temporal precision combined with a significant boost in note transcription performance compared to current state-of-the-art approaches. The system is trained jointly with various synthesized piano instruments and real piano recordings and thus generalizes much better than existing systems. \textcopyright 2012 IEEE.},
issn = {15206149},
institution = {IEEE},
publisher = {Anais�IEEE},
year = {2012},
pages = {121--124},
doi = {10.1109/ICASSP.2012.6287832},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
isbn = {9781467300469},
keywords = {music transcription},
mendeley-tags = {music transcription},
}

@unpublished{r16,
author = {Sebastian Ruder},
pages = {1--14},
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
eprint = {1609.04747},
url = {http://arxiv.org/abs/1609.04747},
arxivid = {1609.04747},
archiveprefix = {arXiv},
year = {2016},
title = {An overview of gradient descent optimization algorithms},
annote = {From Duplicate 1 (An overview of gradient descent optimization algorithms - Ruder, Sebastian)preprint},
}

@article{Choi2016,
author = {Keunwoo Choi and George Gy\"orgy Fazekas and  S and Mark ler and Kyunghyun Cho},
title = {Convolutional Recurrent Neural Networks for Music Classification},
pages = {1--5},
archiveprefix = {arXiv},
abstract = {We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features. We compare CRNN with three CNN structures that have been used for music tagging while controlling the number of parameters with respect to their performance and training time per sample. Overall, we found that CRNNs show a strong performance with respect to the number of parameter and training time, indicating the effectiveness of its hybrid structure in music feature extraction and feature summarisation.},
arxivid = {1609.04243},
doi = {10.1.1.302.7795},
eprint = {1609.04243},
issn = {15209210},
journal = {Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on},
year = {2016},
url = {http://arxiv.org/abs/1609.04243},
isbn = {9789881701282},
institution = {IEEE},
keywords = {music classification},
mendeley-tags = {music classification},
}

@book{l11,
author = {Richard G. Lyons},
address = {Traducao. [s.l.]},
isbn = {9780201634679},
issn = {1053-5888},
pmid = {13458011},
publisher = {Springer},
abstract = {Digital Signal Processing (DSP) is the process of taking any kind of analog signal (such as voice) and converting it into digital form so that it can be sent over a telephone line, the Internet, a wireless network, or other communication vehicle. Understanding Digital Signal Processing presents both the theory and application of DSP in an approachable manner.},
doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
pages = {552},
url = {http://books.google.co.uk/books?id=8osoAQAAMAAJ},
year = {2004},
title = {Understanding digital signal processing},
}

@article{Karpathy2014a,
author = {Andrej Karpathy and George Toderici and Sachin Sanketh Sachin Shetty and Tommy Thomas Leung and Rahul Sukthankar and Li Fei-Fei},
pages = {1725--1732},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909619%0Apapers3://publication/doi/10.1109/CVPR.2014.223},
doi = {10.1109/CVPR.2014.223},
archiveprefix = {arXiv},
abstract = {Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a new...},
journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Large-Scale Video Classification with Convolutional Neural Networks},
year = {2014},
isbn = {978-1-4799-5118-5},
arxivid = {1412.0767},
eprint = {1412.0767},
issn = {978-1-4799-5118-5},
keywords = {video classification},
mendeley-tags = {video classification},
}

@article{Deng2013,
author = {Li Deng and Geoffrey E. Hinton and Brian Kingsbury},
pages = {8599--8603},
journal = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
issn = {1520-6149},
eprint = {arXiv:1303.5778v1},
pmid = {23127789},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6639344},
year = {2013},
doi = {10.1109/ICASSP.2013.6639344},
isbn = {978-1-4799-0356-6},
title = {New types of deep neural network learning for speech recognition and related applications: An overview},
archiveprefix = {arXiv},
arxivid = {arXiv:1303.5778v1},
institution = {IEEE},
abstract = {In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled "New Types of Deep Neural Network Learning for Speech Recognition and Related Applications," as organized by the authors. We also describe the historical context in which acoustic models based on deep neural networks have been developed. The technical overview of the papers presented in our special session is organized into five ways of improving deep learning methods: (1) better optimization; (2) better types of neural activation function and better network architectures; (3) better ways to determine the myriad hyper-parameters of deep neural networks; (4) more appropriate ways to preprocess speech for deep neural networks; and (5) ways of leveraging multiple languages or dialects that are more easily achieved with deep neural networks than with Gaussian mixture models.},
keywords = {review,speech recognition},
mendeley-tags = {review,speech recognition},
}

@article{Salama2015,
author = {Khalid M. Salama and Ashraf M. Abdelbar},
number = {4},
title = {Learning neural network structures with ant colony algorithms},
volume = {9},
journal = {Swarm Intelligence},
year = {2015},
publisher = {Springer US},
issn = {19353820},
abstract = {Ant colony optimization (ACO) has been successfully applied to classification, where the aim is to build a model that captures the relationships between the input attributes and the target class in a given domain's dataset. The constructed classification model can then be used to predict the unknown class of a new pattern. While artificial neural networks are one of the most widely used models for pattern classification, their application is commonly restricted to fully connected three-layer topologies. In this paper, we present a new algorithm, ANN-Miner, which uses ACO to learn the structure of feed-forward neural networks. We report computational results on 40 benchmark datasets for several variations of the algorithm. Performance is compared to the standard three-layer structure trained with two different weight-learning algorithms (back propagation, and the ACOℝ algorithm), and also to a greedy algorithm for learning NN structures. A nonparametric Friedman test is used to determine statistical significance. In addition, we compare our proposed algorithm with NEAT, a prominent evolutionary algorithm for evolving neural networks, as well as three different well-known state-of-the-art classifiers, namely the C4.5 decision tree induction algorithm, the Ripper classification rule induction algorithm, and support vector machines.},
doi = {10.1007/s11721-015-0112-z},
pages = {229--265},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{aa16,
author = {Abdullah Aljumah and Tariq Ahamad},
pages = {132},
number = {12},
volume = {16},
abstract = {DDoS attacks are the perfect planned attacks with the aim to stop the legitimate users from accessing the system or the service by consuming the bandwidth or by making the system or service unavailable. The attackers do not attack to steal or access any information but they decline the performance of the network and the system. DDoS attack at application layers are difficult to detect because they imitate the legitimate traffic. We used Lyapunav coefficient to check the traffic and patter for being attack traffic or legitimate traffic and a six step technique is designed using chaos theory to secure networks from DDoS attack traffic. In this research article we have proposed a novel approach of detecting DDoS attack using artificial neural network and theory of chaos.},
year = {2016},
title = {A Novel Approach for Detecting DDoS using Artificial Neural Networks.},
journal = {Ijcsns},
keywords = {security},
mendeley-tags = {security},
}

@article{Benardos2007,
author = {P. G. Benardos and G-C C. Vosniakos},
issn = {09521976},
doi = {10.1016/j.engappai.2006.06.005},
number = {3},
publisher = {Elsevier},
isbn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
volume = {20},
pages = {365--382},
year = {2007},
abstract = {Despite the fact that feedforward artificial neural networks (ANNs) have been a hot topic of research for many years there still are certain issues regarding the development of an ANN model, resulting in a lack of absolute guarantee that the model will perform well for the problem at hand. The multitude of different approaches that have been adopted in order to deal with this problem have investigated all aspects of the ANN modelling procedure, from training data collection and pre/post-processing to elaborate training schemes and algorithms. Increased attention is especially directed to proposing a systematic way to establish an appropriate architecture in contrast to the current common practice that calls for a repetitive trial-and-error process, which is time-consuming and produces uncertain results. This paper proposes such a methodology for determining the best architecture and is based on the use of a genetic algorithm (GA) and the development of novel criteria that quantify an ANN's performance (both training and generalization) as well as its complexity. This approach is implemented in software and tested based on experimental data capturing workpiece elastic deflection in turning. The intention is to present simultaneously the approach's theoretical background and its practical application in real-life engineering problems. Results show that the approach performs better than a human expert, at the same time offering many advantages in comparison to similar approaches found in literature. \textcopyright 2006 Elsevier Ltd. All rights reserved.},
title = {Optimizing feedforward artificial neural network architecture},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Sotelo2017b,
author = {Jose Sotelo and Soroush Mehri and Kundan Kumar and Kyle Kastner},
number = {2015},
year = {2017},
pages = {1--6},
title = {C Har 2W Av : E Nd - To -E Nd S Peech S Ynthesis},
}

@article{Deng2015,
author = {ChenWei Deng and GuangBin Huang and Jia Xu and JieXiong Tang},
number = {2},
abstract = {Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that "random hidden neurons" capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.},
volume = {58},
issn = {1674-733X},
title = {Extreme learning machines: new trends and applications},
year = {2015},
pages = {1--16},
doi = {10.1007/s11432-014-5269-3},
url = {http://link.springer.com/10.1007/s11432-014-5269-3},
journal = {Science China Information Sciences},
keywords = {elm,review},
mendeley-tags = {elm,review},
}

@article{Hoover2012,
author = {Amy K Hoover and Paul A Szerlip and Marie E Norton and Trevor A Brindle and Zachary Merritt and Kenneth O Stanley},
isbn = {9781905254668},
year = {2012},
journal = {International Conference on Computational Creativity},
title = {Generating a complete multipart musical composition from a single monophonic melody with functional scaffolding},
pages = {111},
keywords = {music generation},
mendeley-tags = {music generation},
}

@book{s16,
author = {Pascal Staudt},
year = {2016},
title = {Development of a Digital Musical Instrument with Embedded Sound Synthesis},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016StaudtDevelopment Development of a Digital Musical Instrument with Embedded Sound Synthesis.pdf\:pdf},
}

@article{Tang2015,
author = {Jiexiong Tang and  ChenweiDeng and Guang-Bin Huang},
pages = {1--13},
doi = {10.1109/TNNLS.2015.2424995},
abstract = {— Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parame-ters are randomly generated and the output weights are analyti-cally computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via 1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme. Index Terms— Deep learning (DL), deep neural network (DNN), extreme learning machine (ELM), multilayer perceptron (MLP), random feature mapping.},
issn = {2162-237X},
year = {2015},
isbn = {2162-2388 (Electronic) 2162-237X (Linking)},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
pmid = {25966483},
title = {Extreme Learning Machine for Multilayer Perceptron},
keywords = {elm},
mendeley-tags = {elm},
}

@article{Fritzke1994,
author = {Bernd Fritzke},
issn = {08936080},
number = {9},
doi = {10.1016/0893-6080(94)90091-4},
journal = {Neural Networks},
pages = {1441--1460},
title = {Growing cell structures—A self-organizing network for unsupervised and supervised learning},
isbn = {0893-6080},
abstract = {We present a new self-organizing neural network model that has two variants. The first variant performs unsupervised learning and can be used for data visualization, clustering, and vector quantization. The main advantage over existing approaches (e.g., the Kohonen feature map) is the ability of the model to automatically find a suitable network structure and size. This is achieved through a controlled growth process that also includes occasional removal of units. The second variant of the model is a supervised learning method that results from the combination of the above-mentioned self-organizing network with the radial basis function (RBF) approach. In this model it is possible—in contrast to earlier approaches—to perform the positioning of the RBF units and the supervised training of the weights in parallel. Therefore, the current classification error can be used to determine where to insert new RBF units. This leads to small networks that generalize very well. Results on the two-spirals benchmark and a vowel classification problem are presented that are better than any results previously published.},
publisher = {Elsevier},
url = {http://linkinghub.elsevier.com/retrieve/pii/0893608094900914},
volume = {7},
year = {1994},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
}

@article{Balle2016,
author = {Johannes Ball\'e and Valero Laparra and Eero P. Simoncelli},
archiveprefix = {arXiv},
issn = {01973975},
arxivid = {1611.01704},
abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.},
journal = {arXiv preprint arXiv:1611.01704},
year = {2016},
isbn = {0197-3975},
title = {End-to-end Optimized Image Compression},
eprint = {1611.01704},
url = {http://arxiv.org/abs/1611.01704},
doi = {10.1016/S0197-3975(03)00059-6},
pmid = {16508805},
keywords = {image compression,image compression- lossy},
mendeley-tags = {image compression,image compression- lossy},
}

@article{Kulkarni2015a,
author = { Err and D. onea and O. Gomis and D. Santamar\'ia-Perez and B. Garc\'ia-Domene and A. Mu\~noz and  Rodr\'iguez-Hern\' and P. ez and S. N. Achary and A. K. Tyagi and C. Popescu},
abstract = {We have studied the structural behavior of bismuth phosphate under compression. We performed x-ray powder diffraction measurements up to 31.5 GPa and ab initio calculations. Experiments were carried out on different polymorphs: trigonal (phase I) and monoclinic (phases II and III). Phases I and III, at low pressure (P < 0.2-0.8 GPa), transform into phase II, which has a monazite-type structure. At room temperature, this polymorph is stable up to 31.5 GPa. Calculations support these findings and predict the occurrence of an additional transition from the monoclinic monazite-type to a tetragonal scheelite-type structure (phase IV). This transition was experimentally found after the simultaneous application of pressure (28 GPa) and temperature (1500 K), suggesting that at room temperature the transition might by hindered by kinetic barriers. Calculations also predict an additional phase transition at 52 GPa, which exceeds the maximum pressure achieved in the experiments. This transition is from phase IV to an orthorhombic barite-type structure (phase V). We also studied the axial and bulk compressibility of BiPO4. Room-temperature pressure-volume equations of state are reported. BiPO4 was found to be more compressible than isomorphic rare-earth phosphates. The discovered phase IV was determined to be the less compressible polymorph of BiPO4. On the other hand, the theoretically predicted phase V has a bulk modulus comparable with that of monazite-type BiPO4. Finally, the isothermal compressibility tensor for the monazite-type structure is reported at 2.4 GPa showing that the direction of maximum compressibility is in the (0 1 0) plane at approximately 15° (21°) to the a axis for the case of our experimental (theoretical) study.},
url = {http://arxiv.org/abs/1503.03167},
archiveprefix = {arXiv},
issn = {10897550},
journal = {Journal of Applied Physics},
number = {10},
doi = {10.1063/1.4914407},
title = {Exploring the high-pressure behavior of the three known polymorphs of BiPO4: Discovery of a new polymorph},
pages = {1--10},
volume = {117},
arxivid = {1503.03167},
eprint = {1503.03167},
year = {2015},
keywords = {image synthesis,tesis},
mendeley-tags = {image synthesis,tesis},
}

@article{Sato2015,
author = {Ikuro Sato and Hiroki Nishimura and Kensuke Yokoi},
year = {2015},
abstract = {Deep neural networks have been exhibiting splendid accuracies in many of visual pattern classification problems. Many of the state-of-the-art methods employ a technique known as data augmentation at the training stage. This paper addresses an issue of decision rule for classifiers trained with augmented data. Our method is named as APAC: the Augmented PAttern Classification, which is a way of classification using the optimal decision rule for augmented data learning. Discussion of methods of data augmentation is not our primary focus. We show clear evidences that APAC gives far better generalization performance than the traditional way of class prediction in several experiments. Our convolutional neural network model with APAC achieved a state-of-the-art accuracy on the MNIST dataset among non-ensemble classifiers. Even our multilayer perceptron model beats some of the convolutional models with recently invented stochastic regularization techniques on the CIFAR-10 dataset.},
eprint = {1505.03229},
archiveprefix = {arXiv},
title = {APAC: Augmented PAttern Classification with Neural Networks},
journal = {arXiv preprint arXiv:1505.03229},
arxivid = {1505.03229},
url = {http://arxiv.org/abs/1505.03229},
keywords = {image classification,optimization},
mendeley-tags = {image classification,optimization},
}

@article{Yao1999,
author = {Xin Yao},
journal = {Proceedings of the IEEE},
eprint = {1108.1530},
abstract = {Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANNs) in recent years. This paper: 1) reviews different combinations between ANNs and evolutionary algorithms (EAs), including using EAs to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EAs; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANNs and EAs can lead to significantly better intelligent systems than relying on ANNs or EAs alone},
pmid = {9821520},
title = {Evolving artificial neural networks},
archiveprefix = {arXiv},
arxivid = {1108.1530},
publisher = {IEEE},
volume = {87},
doi = {10.1109/5.784219},
number = {9},
pages = {1423--1447},
isbn = {9780470287194},
year = {1999},
issn = {00189219},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
}

@article{Zweig2016,
author = {Geoffrey Zweig and Chengzhu Yu and Jasha Droppo and Andreas Stolcke},
eprint = {1609.05935},
issn = {15206149},
publisher = {Anais�IEEE},
isbn = {9781509041176},
edition = {Acoustics,},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
archiveprefix = {arXiv},
year = {2017},
url = {http://arxiv.org/abs/1609.05935},
arxivid = {1609.05935},
pages = {4805--4809},
doi = {10.1109/ICASSP.2017.7953069},
title = {Advances in all-neural speech recognition},
institution = {IEEE},
abstract = {This paper advances the design of CTC-based all-neural (or end-to-end) speech recognizers. We propose a novel symbol inventory, and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner version. We present a number of stabilization and initialization methods we have found useful in training these networks. We evaluate our system on the commonly used NIST 2000 conversational telephony test set, and significantly exceed the previously published performance of similar systems, both with and without the use of an external language model and decoding technology.},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@book{18,
year = {2018},
publisher = {<},
address = {Intel AI Dispon�vel em},
title = {Neon},
url = {https://ai.intel.com/neon/%3E},
}

@article{Ludermir2006,
author = {Teresa B. Ludermir and Akio Yamazaki and Cleber Zanchettin},
doi = {10.1109/TNN.2006.881047},
number = {6},
publisher = {IEEE},
pages = {1452--1459},
journal = {IEEE Transactions on Neural Networks},
title = {An optimization methodology for neural network weights and architectures},
pmid = {17131660},
issn = {10459227},
abstract = {This paper introduces a methodology for neural network global optimization. The aim is the simultaneous optimization of multilayer perceptron (MLP) network weights and architectures, in order to generate topologies with few connections and high classification performance for any data sets. The approach combines the advantages of simulated annealing, tabu search and the backpropagation training algorithm in order to generate an automatic process for producing networks with high classification performance and low complexity. Experimental results obtained with four classification problems and one prediction problem has shown to be better than those obtained by the most commonly used optimization techniques.},
volume = {17},
year = {2006},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{JeffHwang2016,
author = {Sudesh Pahal and Preeti Sehrawat},
journal = {Lecture Notes in Electrical Engineering},
title = {Image Colorization with Deep Convolutional Neural Networks},
year = {2021},
abstract = {Colorization, a task of coloring monochrome images or videos, plays an important role in the human perception of visual information, to black and white pictures or videos. Colorizing, when done manually in Photoshop, a single picture might take months to get exactly correct. Understanding the tediousness of the task and inspired by the benefits of artificial intelligence, we propose a mechanism to automate the coloring process with the help of convolutional neural networks (CNNs). Firstly, an Alpha version is developed which successfully works on trained images but fails to colorize images, and the network has never seen before. Subsequently, a Beta version is implemented which is able to overcome the limitations of Alpha version and works well for untrained images. To further enhance the network, we fused the deep CNN with a classifier called Inception ResNet V2 which is a pre-trained model. Finally, the training results are observed for all the versions followed by a comparative analysis for trained and untrained images.},
issn = {18761119},
isbn = {9789811553400},
pages = {45--56},
doi = {10.1007/978-981-15-5341-7_4},
volume = {668},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Wu2015a,
author = {Chih Wei Wu and Alex Lerch and  er},
doi = {10.1109/EUSIPCO.2015.7362590},
abstract = {In this paper, a drum transcription algorithm using partially fixed non-negative matrix factorization is presented. The proposed method allows users to identify percussive events in complex mixtures with a minimal training set. The algorithm decomposes the music signal into two parts: percussive part with pre-defined drum templates and harmonic part with undefined entries. The harmonic part is able to adapt to the music content, allowing the algorithm to work in polyphonic mixtures. Drum event times can be simply picked from the percussive activation matrix with onset detection. The system is efficient and robust even with a minimal training set. The recognition rates for the ENST dataset vary from 56.7 to 78.9% for three percussive instruments extracted from polyphonic music.},
pages = {1281--1285},
isbn = {9780992862633},
title = {Drum transcription using partially fixed non-negative matrix factorization},
year = {2015},
journal = {2015 23rd European Signal Processing Conference, EUSIPCO 2015},
keywords = {music transcription,tesis},
mendeley-tags = {music transcription,tesis},
}

@article{Wang2015,
author = {Bo Wang and Yubin Gao},
volume = {13},
journal = {TELKOMNIKA (Telecommunication Computing Electronics and Control)},
abstract = {Image compression technology is to compress the redundancy between the pixels to reduce the transmission broadband and storage space by using the correlation of the image pixels. Fuzzy neural network effectively integrates neural network technology and fuzzy technology; combines learning, self- adaptivity, imagination and identity and uses rule-based reasoning and fuzzy information processing in the nodes; thus greatly improving the transparency of fuzzy neural network. This paper mainly investigates the applications of fuzzy neural network in image compression and realizes the image compression and reconstruction of fuzzy neural network. It is demonstrated in the simulation experiment that the image compression algorithm based on fuzzy neural network has significant advantages in training speed, compression quality and robustness.},
doi = {10.12928/telkomnika.v13i1.1270},
year = {2015},
number = {1},
issn = {2302-9293},
url = {http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/1270},
title = {An Image Compression Scheme Based on Fuzzy Neural Network},
pages = {137},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@unpublished{b15,
author = {Soheil Bahrampour and Naveen Ramakrishnan and Lukas Schott and Mohak Shah},
abstract = {Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.},
annote = {From Duplicate 2 (Comparative Study of Deep Learning Software Frameworks - Bahrampour, Soheil; Ramakrishnan, Naveen; Schott, Lukas; Shah, Mohak)preprint},
year = {2015},
arxivid = {1511.06435},
eprint = {1511.06435},
url = {http://arxiv.org/abs/1511.06435},
title = {Comparative Study of Deep Learning Software Frameworks},
archiveprefix = {arXiv},
}

@unpublished{,
url = {http://torch.ch/%3E},
title = {Torch},
}

@article{DiPersio2016,
author = {Luca Di Persio and Oleks Honchar and  r},
issn = {19984464},
journal = {International Journal of Circuits, Systems and Signal Processing},
abstract = {? 2016, North Atlantic University Union. All rights reserved.We present an Artificial Neural Network (ANN) approach to predict stock market indices, particularly with respect to the forecast of their trend movements up or down. Exploiting different Neural Networks architectures, we provide numerical analysis of concrete financial time series. In particular, after a brief r?esum?e of the existing literature on the subject, we consider the Multi-layer Perceptron (MLP), the Convolutional Neural Networks (CNN), and the Long Short-Term Memory (LSTM) recurrent neural networks techniques. We focus on the importance of choosing the correct input features, along with their preprocessing, for the specific learning algorithm one wants to use. Eventually, we consider the S&P500 historical time series, predicting trend on the basis of data from the past days, and proposing a novel approach based on combination of wavelets and CNN, which outperforms the basic neural networks ones. We show, that neural networks are able to predict financial time series movements even trained only on plain time series data and propose more ways to improve results.},
volume = {10},
pages = {403--413},
year = {2016},
title = {Artificial neural networks architectures for stock price prediction: Comparisons and applications},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Saxena2016,
author = {Shreyas Saxena and Jakob Verbeek},
journal = {Advances in Neural Information Processing Systems},
year = {2016},
abstract = {Despite the success of CNNs, selecting the optimal architecture for a given task remains an open problem. Instead of aiming to select a single optimal architecture, we propose a "fabric" that embeds an exponentially large number of architectures. The fabric consists of a 3D trellis that connects response maps at different layers, scales, and channels with a sparse homogeneous local connectivity pattern. The only hyper-parameters of a fabric are the number of channels and layers. While individual architectures can be recovered as paths, the fabric can in addition ensemble all embedded architectures together, sharing their weights where their paths overlap. Parameters can be learned using standard methods based on back-propagation, at a cost that scales linearly in the fabric size. We present benchmark results competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset.},
eprint = {1606.02492},
issn = {10495258},
title = {Convolutional Neural Fabrics},
arxivid = {1606.02492},
url = {http://arxiv.org/abs/1606.02492},
archiveprefix = {arXiv},
pages = {4060--4068},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Zagoruyko2016,
author = {Sergey Zagoruyko and Nikos Komodakis},
arxivid = {1605.07146},
journal = {arXiv preprint arXiv:1605.07146},
url = {http://arxiv.org/abs/1605.07146},
archiveprefix = {arXiv},
abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https://github.com/szagoruyko/wide-residual-networks},
year = {2016},
title = {Wide Residual Networks},
eprint = {1605.07146},
keywords = {image classification,object detection,state of the art},
mendeley-tags = {image classification,object detection,state of the art},
}

@article{Southall2016a,
author = {Carl Southall and Ryan Stables and Jason Hockman},
abstract = {Automatic drum transcription (ADT) systems attempt to generate a symbolic music notation for percussive in-struments in audio recordings. Neural networks have al-ready been shown to perform well in fields related to ADT such as source separation and onset detection due to their utilisation of time-series data in classification. We pro-pose the use of neural networks for ADT in order to ex-ploit their ability to capture a complex configuration of fea-tures associated with individual or combined drum classes. In this paper we present a bi-directional recurrent neu-ral network for offline detection of percussive onsets from specified drum classes and a recurrent neural network suit-able for online operation. In both systems, a separate net-work is trained to identify onsets for each drum class under observation—that is, kick drum, snare drum, hi-hats, and combinations thereof. We perform four evaluations utilis-ing the IDMT-SMT-Drums and ENST minus one datasets, which cover solo percussion and polyphonic audio respec-tively. The results demonstrate the effectiveness of the pre-sented methods for solo percussion and a capacity for iden-tifying snare drums, which are historically the most diffi-cult drum class to detect.},
title = {Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks},
year = {2016},
isbn = {978-0-692-75506-8},
pages = {591--597},
journal = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
keywords = {music transcription,tesis},
mendeley-tags = {music transcription,tesis},
}

@article{l,
author = {Joel Augustus Laird},
year = {2001},
title = {the Physical Modelling of Drums Using Digital},
number = {November},
abstract = {In this thesis the physical modelling of percussive drums was approached using\ndigital waveguides. The constituent components of a drum were considered individually before connecting them together to complete the model.\nTo model the drumskin techniques were created to incorporate smooth curved\nboundaries, calculate the impedance of a 2D waveguide mesh and include the\neffect of the bearing edge. The accuracy of the curved boundary model, which\nutilised ‘rimguides', was demonstrated with a good reproduction of the first\nseven resonant modes of a circular membrane. The impedance was used in a\nkettledrum model where it correctly controlled the exchange of energy between\nthe drumskin and interior air. Simulations of different bearing edge sizes revealed that a blunt edge takes energy from low frequencies and redistributes\nit into higher frequencies. These decay faster and so the result is a decrease in\nsustain.\nFor the interior air it was necessary to correctly model 3D wave propagation\nand incorporate diffuse reflections, which occur at rough surfaces. Unlike 3D\nmeshes used in previous studies, the new dodecahedral mesh proposed here\nwas found to exhibit near direction independent dispersion error. The effect\nof diffusion was adequately simulated with a technique that was shown to be\ncontrollable, enabling different types of surface to be modelled.\nTo complete the drum model a way of connecting different waveguide meshes\ntogether was found and a new procedure for modelling a mallet exciter was\nproposed. The interfacing method enabled a lossless interconnection between\ntwo 2D meshes and also 2D and 3D meshes. The procedure used for the mallet exciter incorporated non-linear stiffness and the mallet's contact area. Its\nbehaviour was shown to be almost identical to that of a real mallet.\nFinally, a digital waveguide model of a kettledrum was constructed to demonstrate the techniques and the results were promising; the resonant modes were\nreproduced with good accuracy and their decay was sufficient to give the impression of realism, whilst not exactly matching that found through measurement.},
journal = {Control},
volume = {2001},
}

@article{Ojha2017,
author = {Varun Kumar Ojha and Ajith Abraham and V\'aclav Sn\'a\vsel},
pages = {97--116},
archiveprefix = {arXiv},
journal = {Engineering Applications of Artificial Intelligence},
number = {2017},
title = {Metaheuristic design of feedforward neural networks: A review of two decades of research},
issn = {09521976},
publisher = {Elsevier},
volume = {60},
arxivid = {arXiv:1705.05584v1},
abstract = {Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN's generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN's application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era.},
doi = {10.1016/j.engappai.2017.01.013},
eprint = {arXiv:1705.05584v1},
year = {2017},
keywords = {evolutive,review},
mendeley-tags = {evolutive,review},
}

@article{Theis2017,
author = {Lucas Theis and Wenzhe Shi and Andrew Cunningham and Ferenc Husz\'ar},
year = {2017},
pages = {1--19},
arxivid = {1703.00395},
archiveprefix = {arXiv},
eprint = {1703.00395},
abstract = {We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.},
title = {Lossy Image Compression with Compressive Autoencoders},
url = {http://arxiv.org/abs/1703.00395},
journal = {arXiv preprint arXiv:1703.00395},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@book{18,
url = {https://nsynthsuper.withgoogle.com/%3E},
publisher = {<},
address = {GoogleGoogle Dispon�vel em},
title = {NSynthSuper},
year = {2018},
}

@article{a,
author = {Ivy Audio},
title = {Ivy Audio},
url = {http://www.ivyaudio.com/%3E},
volume = {2018},
}

@article{Graves2014,
author = {Alex Graves and Greg Wayne and Ivo Danihelka},
issn = {2041-1723},
pmid = {18958277},
year = {2014},
doi = {10.3389/neuro.12.006.2007},
eprint = {1410.5401},
isbn = {0028-0836},
pages = {1--26},
archiveprefix = {arXiv},
arxivid = {1410.5401},
abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
title = {Neural Turing Machines},
url = {http://arxiv.org/abs/1410.5401},
keywords = {other},
mendeley-tags = {other},
}

@article{Chen2017a,
author = {Tao Chen and Ruifeng Xu and Yulan He and Xuan Wang},
pages = {221--230},
pmid = {19932002},
year = {2017},
volume = {72},
doi = {10.1016/j.eswa.2016.10.065},
abstract = {Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.},
title = {Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN},
journal = {Expert Systems with Applications},
eprint = {1404.7828},
issn = {09574174},
arxivid = {1404.7828},
isbn = {0925-2312},
url = {http://dx.doi.org/10.1016/j.eswa.2016.10.065},
archiveprefix = {arXiv},
publisher = {Elsevier Ltd},
keywords = {sentence classification,state of the art},
mendeley-tags = {sentence classification,state of the art},
}

@article{Egmont-Petersen2002,
author = {M. Egmont-Petersen and D. De Ridder and  H and H. els},
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments. ?? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
volume = {35},
year = {2002},
isbn = {0031-3203},
pages = {2279--2301},
title = {Image processing with neural networks- A review},
doi = {10.1016/S0031-3203(01)00178-9},
issn = {00313203},
journal = {Pattern Recognition},
number = {10},
keywords = {image classification,object detection,review},
mendeley-tags = {image classification,object detection,review},
}

@book{18,
publisher = {<},
title = {TensorFlow},
url = {https://www.tensorflow.org/%3E},
address = {TensorFlow Dispon�vel em},
year = {2018},
}

@book{Rosenblatt1957,
author = {F. Rosenblatt},
abstract = {First publication about the perceptron},
booktitle = {Report 85, Cornell Aeronautical Laboratory},
pages = {460--1},
publisher = {Cornell Aeronautical Laboratory},
year = {1957},
doi = {85-460-1},
title = {The Perceptron - A Perceiving and Recognizing Automaton},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{18,
year = {2018},
journal = {Multilayer Perceptron - DeepLearning 0.},
volume = {1},
title = {Theano},
url = {http://deeplearning.net/software/theano/%3E},
}

@article{Fini2010,
author = {Riccardo Fini and Nicola Lacetera and Scott Shane},
doi = {10.1016/j.respol.2010.05.014},
isbn = {0048-7333},
number = {8},
pages = {1060--1069},
volume = {39},
abstract = {Research and public policy on academic entrepreneurship are largely based on the assumption that faculty members start businesses to commercialize inventions that have been disclosed to university administrators and have been patented. In this paper, we analyze a sample of 11,572 professors and find that much academic entrepreneurship occurs outside the university intellectual property system. Specifically, about 2/3 of businesses started by academics are not based on disclosed and patented inventions. Moreover, we show that individual characteristics, departmental and organizational affiliations, and time allocation of academics that have started business outside the IP system are different from those of academics that have started businesses to exploit disclosed and patented inventions. We discuss the implications for research on and the practice of academic entrepreneurship. \textcopyright 2010 Elsevier B.V. All rights reserved.},
year = {2010},
month = {oct},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0048733310001381},
title = {Inside or outside the IP system? Business creation in academia},
journal = {Research Policy},
issn = {00487333},
keywords = {academic entrepreneurship,business creation,knowledge transfer},
mendeley-tags = {academic entrepreneurship,business creation,knowledge transfer},
}

@misc{Edmunds2000,
author = {Angela Edmunds and Anne Morris},
booktitle = {International Journal of Information Management},
isbn = {0268-4012},
pmid = {10272},
title = {The problem of information overload in business organisations: a review of the literature},
url = {http://www.sciencedirect.com/science/article/pii/S0268401299000511},
volume = {20},
abstract = {This paper reviews the literature on the problem of information overload, with particular reference to business organisations. The literature reveals that although the problem of information overload has existed for many years, in recent years the problem has become more widely recognised and experienced. Both perceptions and the actual effects of information overload have been exacerbated by the rapid advances made in information and communication technology, although it is not clear cut as to whether the Internet has worsened or improved the situation. A theme stressed in the literature is the paradoxical situation that, although there is an abundance of information available, it is often difficult to obtain useful, relevant information when it is needed. Some solutions put forward to reduce information overload are: a reduction in the duplication of information found in the professional literature; the adoption of personal information management strategies, together with the integration of software solutions such as push technology and intelligent agents; and the provision of value-added information (filtered by software or information specialists). An emphasis is placed on technology as a tool and not the driver, while increased information literacy may provide the key to reducing information overload.},
issn = {02684012},
year = {2000},
number = {1},
pages = {17--28},
doi = {10.1016/S0268-4012(99)00051-1},
keywords = {infoglut,information fatigue syndrome,information overload},
mendeley-tags = {infoglut,information fatigue syndrome,information overload},
}

@article{Frans2017a,
author = {Kevin Frans},
url = {http://arxiv.org/abs/1704.08834},
abstract = {When creating digital art, coloring and shading are often time consuming tasks that follow the same general patterns. A solution to automatically colorize raw line art would have many practical applications. We propose a setup utilizing two networks in tandem: a color prediction network based only on outlines, and a shading network conditioned on both outlines and a color scheme. We present processing methods to limit information passed in the color scheme, improving generalization. Finally, we demonstrate natural-looking results when colorizing outlines from scratch, as well as from a messy, user-defined color scheme. 834v1 [cs.CV]},
journal = {arXiv},
year = {2017},
arxivid = {1704.08834},
issn = {23318422},
eprint = {1704.08834},
archiveprefix = {arXiv},
title = {Outline colorization through tande adversarial networks. 2017},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@misc{Moscaritolo,
author = {Autores Moscaritolo and Angela Angelamoscaritolopcmagcom},
title = {Pebble Smartwatch Sells Out , Collects $ 10 Million on Kickstarter},
}

@misc{,
title = {Poverty and profits in the information age.pdf},
}

@article{Liao2016,
author = {Zhibin Liao and Gustavo Carneiro},
arxivid = {1508.00330},
journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
title = {On the importance of normalisation layers in deep learning with piecewise linear activation units},
eprint = {1508.00330},
abstract = {Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets. The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.},
doi = {10.1109/WACV.2016.7477624},
pages = {1--8},
institution = {IEEE},
archiveprefix = {arXiv},
isbn = {9781509006410},
year = {2016},
keywords = {image classification,optimization,theory},
mendeley-tags = {image classification,optimization,theory},
}

@article{Xu2017,
author = {Lamei Xu and Jin Lin and Lina Wang and Chunyong Yin and Jin Wang},
volume = {143},
year = {2017},
title = {Deep Convolutional Neural Network based Approach for Aspect-based Sentiment Analysis},
pages = {199--204},
journal = {Advanced Science and Technology Letters},
number = {Ast},
keywords = {sentiment analysis},
mendeley-tags = {sentiment analysis},
}

@article{Kim2014,
author = {Yoon Kim},
journal = {arXiv preprint arXiv:1408.5882},
year = {2014},
arxivid = {1408.5882},
title = {Convolutional Neural Networks for Sentence Classification},
issn = {10709908},
eprint = {1408.5882},
pmid = {10463930},
url = {http://arxiv.org/abs/1408.5882},
abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
archiveprefix = {arXiv},
doi = {10.3115/v1/D14-1181},
isbn = {9781937284961},
keywords = {sentence classification,sentiment analysis},
mendeley-tags = {sentence classification,sentiment analysis},
}

@article{Barrow2016,
author = {Devon K. Barrow and Sven F. Crone},
abstract = {This paper evaluates k-fold and Monte Carlo cross-validation and aggregation (crogging) for combining neural network autoregressive forecasts. We introduce Monte Carlo crogging which combines bootstrapping and cross-validation (CV) in a single approach through repeated random splitting of the original time series into mutually exclusive datasets for training. As the training/validation split is independent of the number of folds, the algorithm offers more flexibility in the size, and number of training samples compared to k-fold cross-validation. The study also provides for crogging and bagging: (1) the first systematic evaluation across time series length and combination size, (2) a bias and variance decomposition of the forecast errors to understand improvement gains, and (3) a comparison to established benchmarks of model averaging and selection. Crogging can easily be extended to other autoregressive models. Results on real and simulated series demonstrate significant improvements in forecasting accuracy especially for short time series and long forecast horizons.},
pages = {1120--1137},
issn = {01692070},
number = {4},
journal = {International Journal of Forecasting},
doi = {10.1016/j.ijforecast.2015.12.011},
publisher = {Elsevier B.V.},
title = {Cross-validation aggregation for combining autoregressive neural network forecasts},
year = {2016},
volume = {32},
url = {http://dx.doi.org/10.1016/j.ijforecast.2015.12.011},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Hinton2012,
author = {Geoffrey Hinton and Li Deng and Dong Yu and George E Dahl and Abdel-rahman Mohamed and Navdeep Jaitly and Andrew Senior and Vincent Vanhoucke and Patrick Nguyen and Tara N Sainath and Brian Kingsbury},
doi = {10.1109/MSP.2012.2205597},
year = {2012},
eprint = {1207.0580},
arxivid = {1207.0580},
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
isbn = {1053-5888},
issn = {1053-5888},
archiveprefix = {arXiv},
journal = {IEEE Signal Processing Magazine},
pages = {82--97},
pmid = {13057166},
title = {Deep Neural Networks for Acoustic Modeling in Speech Recognition},
number = {November},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@book{s16,
author = {Shaohuai Shi and Qiang Wang and Pengfei Xu and Xiaowen Chu},
abstract = {Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools coming to public. Training a deep network is usually a very time-consuming process. To address the huge computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training and inference time. However, different tools exhibit different features and running performance when they train different types of deep networks on different hardware platforms, making it difficult for end users to select an appropriate pair of software and hardware. In this paper, we present our attempt to benchmark several state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, TensorFlow, and Torch. We focus on evaluating the running time performance (i.e., speed) of these tools with three popular types of neural networks on two representative CPU platforms and three representative GPU platforms. Our contribution is two-fold. First, for end users of deep learning software tools, our benchmarking results can serve as a reference to selecting appropriate hardware platforms and software tools. Second, for developers of deep learning software tools, our in-depth analysis points out possible future directions to further optimize the running performance.},
doi = {10.1109/CCBD.2016.029},
year = {2017},
title = {Benchmarking state-of-the-art deep learning software tools},
booktitle = {Proceedings - 2016 7th International Conference on Cloud Computing and Big Data, CCBD 2016},
pages = {99--104},
arxivid = {1608.07249},
isbn = {9781509035557},
publisher = {Anais�IEEE},
eprint = {1608.07249},
archiveprefix = {arXiv},
edition = {Cloud Comp},
keywords = {convolutional neural networks,deep learning,feed-forward neural networks,gpu,recurrent neural networks},
mendeley-tags = {convolutional neural networks,deep learning,feed-forward neural networks,gpu,recurrent neural networks},
}

@book{18,
publisher = {<},
url = {http://caffe.berkeleyvision.org/%3E},
year = {2018},
title = {Caffe},
address = {Caffe | Model Zoo Dispon�vel em},
}

@inproceedings{g17,
author = {Amelia J. Gully and Takenori Yoshimura and Damian T. Murphy and Kei Hashimoto and Yoshihiko Nankaku and Keiichi Tokuda},
title = {Articulatory text-to-speech synthesis using the digital waveguide mesh driven by a deep neural network},
publisher = {p. 234�238},
doi = {10.21437/Interspeech.2017-900},
abstract = {Following recent advances in direct modeling of the speech waveform using a deep neural network, we propose a novel method that directly estimates a physical model of the vocal tract from the speech waveform, rather than magnetic resonance imaging data. This provides a clear relationship between the model and the size and shape of the vocal tract, offering considerable flexibility in terms of speech characteristics such as age and gender. Initial tests indicate that despite a highly simplified physical model, intelligible synthesized speech is obtained. This illustrates the potential of the combined technique for the control of physical models in general, and hence the generation of more natural-sounding synthetic speech.},
year = {2017},
issn = {19909772},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
volume = {2017-Augus},
pages = {234--238},
keywords = {deep neural network,digital waveguide mesh,electronic manuscript,speech synthesis},
mendeley-tags = {deep neural network,digital waveguide mesh,electronic manuscript,speech synthesis},
}

@book{18,
year = {2018},
url = {https://magenta.tensorflow.org/%3E},
address = {Magenta Dispon�vel em},
title = {Magenta},
publisher = {<},
}

@article{Boser1992,
author = {Bernhard E. Boser and Isabelle M. Guyon and Vladimir N. Vapnik},
doi = {10.1145/130385.130401},
year = {1992},
url = {http://portal.acm.org/citation.cfm?doid=130385.130401},
eprint = {arXiv:1011.1669v3},
institution = {ACM},
abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of classifiaction functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms. 1 INTRODUCTION Good generalization performance of pattern classifiers is achieved when the capacity of the classification function is matched to the size of the training set. Classifiers with a large numb...},
archiveprefix = {arXiv},
isbn = {089791497X},
pages = {144--152},
pmid = {25246403},
title = {A training algorithm for optimal margin classifiers},
arxivid = {arXiv:1011.1669v3},
journal = {Proceedings of the fifth annual workshop on Computational learning theory  - COLT '92},
issn = {0-89791-497-X},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Lin2013,
author = {Min Lin and Qiang Chen and Shuicheng Yan},
abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
arxivid = {1312.4400},
pages = {1--10},
eprint = {1312.4400},
journal = {arXiv preprint arXiv:1312.4400},
pmid = {24356345},
title = {Network In Network},
doi = {10.1109/ASRU.2015.7404828},
url = {http://arxiv.org/abs/1312.4400},
issn = {03029743},
year = {2013},
isbn = {9781479972913},
archiveprefix = {arXiv},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Janai2017,
author = {Joel Janai and Fatma G\"uney and Aseem Behl and Andreas Geiger},
archiveprefix = {arXiv},
journal = {arXiv preprint arXiv:1704.05519},
year = {2017},
abstract = {Recent years have witnessed amazing progress in AI related fields such as computer vision, machine learning and autonomous vehicles. As with any rapidly growing field, however, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several topic specific survey papers have been written, to date no general survey on problems, datasets and methods in computer vision for autonomous vehicles exists. This paper attempts to narrow this gap by providing a state-of-the-art survey on this topic. Our survey includes both the historically most relevant literature as well as the current state-of-the-art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning. Towards this goal, we first provide a taxonomy to classify each approach and then analyze the performance of the state-of-the-art on several challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we will also provide an interactive platform which allows to navigate topics and methods, and provides additional information and project links for each paper.},
title = {Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art},
eprint = {1704.05519},
url = {http://arxiv.org/abs/1704.05519},
arxivid = {1704.05519},
keywords = {image classification,object detection,review},
mendeley-tags = {image classification,object detection,review},
}

@article{Stanley2002a,
author = {Kenneth O. Stanley and Risto Miikkulainen},
issn = {1063-6560},
title = {Evolving Neural Networks through Augmenting Topologies},
volume = {10},
isbn = {1063-6560},
archiveprefix = {arXiv},
year = {2002},
url = {http://www.mitpressjournals.org/doi/10.1162/106365602320169811},
pmid = {12180173},
eprint = {1407.0576},
number = {2},
doi = {10.1162/106365602320169811},
journal = {Evolutionary Computation},
publisher = {MIT Press},
arxivid = {1407.0576},
pages = {99--127},
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Shi2016,
author = {Weiwei Shi and Yihong Gong and Jinjun Wang},
doi = {10.1109/TNNLS.2017.2705682},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
abstract = {In this paper, we propose a novel method to im-prove object recognition accuracies of convolu-tional neural networks (CNNs) by embedding the proposed Min-Max objective into a high layer of the models during the training process. The Min-Max objective explicitly enforces the learned object feature maps to have the minimum compactness for each object manifold and the maximum margin be-tween different object manifolds. The Min-Max objective can be universally applied to different CNN models with negligible additional computa-tion cost. Experiments with shallow and deep mod-els on four benchmark datasets including CIFAR-10, CIFAR-100, SVHN and MNIST demonstrate that CNN models trained with the Min-Max ob-jective achieve remarkable performance improve-ments compared to the corresponding baseline models.},
title = {Improving CNN performance with min-max objective},
volume = {2016-Janua},
issn = {10450823},
year = {2016},
pages = {2004--2010},
keywords = {object detection},
mendeley-tags = {object detection},
}

@article{Palmes2005,
author = {Paulito P. Palmes and Taichi Hayasaka and Shiro Usui},
title = {Mutation-based genetic neural network},
volume = {16},
publisher = {IEEE},
year = {2005},
isbn = {1045-9227},
abstract = {Evolving gradient-learning artificial neural networks (ANNs) using an evolutionary algorithm (EA) is a popular approach to address the local optima and design problems of ANN. The typical approach is to combine the strength of backpropagation (BP) in weight learning and EA's capability of searching the architecture space. However, the BP's "gradient descent" approach requires a highly computer-intensive operation that relatively restricts the search coverage of EA by compelling it to use a small population size. To address this problem, we utilized mutation-based genetic neural network (MGNN) to replace BP by using the mutation strategy of local adaptation of evolutionary programming (EP) to effect weight learning. The MGNN's mutation enables the network to dynamically evolve its structure and adapt its weights at the same time. Moreover, MGNN's EP-based encoding scheme allows for a flexible and less restricted formulation of the fitness function and makes fitness computation fast and efficient. This makes it feasible to use larger population sizes and allows MGNN to have a relatively wide search coverage of the architecture space. MGNN implements a stopping criterion where overfitness occurrences are monitored through "sliding-windows" to avoid premature learning and overlearning. Statistical analysis of its performance to some well-known classification problems demonstrate its good generalization capability. It also reveals that locally adapting or scheduling the strategy parameters embedded in each individual network may provide a proper balance between the local and global searching capabilities of MGNN.},
pmid = {15940989},
issn = {10459227},
doi = {10.1109/TNN.2005.844858},
pages = {587--600},
journal = {IEEE Transactions on Neural Networks},
number = {3},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Balle2015,
author = {Johannes Ball\'e and Valero Laparra and Eero P. Simoncelli},
title = {Density Modeling of Images using a Generalized Normalization Transformation},
url = {http://arxiv.org/abs/1511.06281},
eprint = {1511.06281},
archiveprefix = {arXiv},
pages = {1--14},
arxivid = {1511.06281},
journal = {arXiv preprint arXiv:1511.06281},
year = {2015},
abstract = {We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. The data are linearly transformed, and each component is then normalized by a pooled activity measure, computed by exponentiating a weighted sum of rectified and exponentiated components and a constant. We optimize the parameters of the full transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. The optimized transformation substantially Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than alternative methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We demonstrate the use of the model as a prior probability density that can be used to remove additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized using the same Gaussianization objective, thus offering an unsupervised method of optimizing a deep network architecture.},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Krishna2016,
author = {Tushar Krishna and Joel Emer and Vivienne Sze and International Solid-state Circuits Conference and San Francisco and Yu-hsin Chen and Tushar Krishna and Joel Emer and Vivienne Sze},
year = {2016},
title = {Eyeriss : An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks The MIT Faculty has made this article openly available . Please share Citation " Eyeriss : An Energy-Efficient Reconfigurable Accelerator for Publisher Version},
keywords = {hardware},
mendeley-tags = {hardware},
}

@article{Rehman2014,
author = {Mehwish Rehman and Muhammad Sharif and Mudassar Raza},
number = {4},
journal = {Research Journal of Applied Sciences, Engineering and Technology},
pages = {656--672},
isbn = {9233351788872},
abstract = {Image Compression is a demanding field in this era of communication. There is a need to study and analyze the literature for image compression, as the demand for images, video sequences and computer animation has increased at very high rate so that the increment is drastically over the years. Multimedia data whether graphics, audio, video data which is uncompress requires considerable transmission bandwidth and storage capacity. So this leads to the need of compression of images and all multimedia applications to save storage and transmission time. In this study we discuss different compression algorithms used to reduce size of images without quality reduction. \textcopyright Maxwell Scientific Organization, 2014.},
publisher = {Maxwell Science Publishing},
year = {2014},
issn = {20407459},
title = {Image compression: A survey},
volume = {7},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@book{Tarjano2019,
author = {Carlos Tarjano and Valdecy Pereira},
abstract = {Two main approaches are currently prevalent in the digital emulation of musical instruments: manipulation of pre-recorded samples and techniques of real-time synthesis, generally based on physical models with varying degrees of accuracy. Concerning the first, while the processing power of present-day computers enables their use in real-time, many restrictions arising from this sample-based design persist; the huge on disk space requirements and the stiffness of musical articulations being the most prominent. On the other side of the spectrum, pure synthesis approaches, while offering greater flexibility, fail to capture and reproduce certain nuances central to the verisimilitude of the generated sound, offering a dry, synthetic output, at a high computational cost. We propose a method where ensembles of lightweight neural networks working in parallel are learned, from crafted frequency-domain features of an instrument sound spectra, an arbitrary instrument's voice and articulations realistically and efficiently. We find that our method, while retaining perceptual sound quality on par with sampled approaches, exhibits 1/10 of latency times of industry standard real-time synthesis algorithms, and 1/100 of the disk space requirements of industry standard sample-based digital musical instruments. This method can, therefore, serve as a basis for more efficient implementations in dedicated devices, such as keyboards and electronic drumkits and in general purpose platforms, like desktops and tablets or open-source hardware like Arduino and Raspberry Pi. From a conceptual point of view, this work highlights the advantages of a closer integration of machine learning with other subjects, especially in the endeavor of new product development. Exploiting the synergy between neural networks, digital signal processing techniques and physical modelling, we illustrate the proposed method via the implementation of two virtual instruments: a conventional grand piano and a hibrid stringed instrument.},
doi = {10.1007/978-3-030-30490-4_30},
pages = {362--375},
volume = {11730 LNCS},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year = {2019},
title = {Neuro-Spectral Audio Synthesis: Exploiting Characteristics of the Discrete Fourier Transform in the Real-Time Simulation of Musical Instruments Using Parallel Neural Networks},
issn = {16113349},
isbn = {9783030304898},
keywords = {acoustic modeling,digital musical instruments,neural networks,real-time audio synthesis},
mendeley-tags = {acoustic modeling,digital musical instruments,neural networks,real-time audio synthesis},
}

@article{ISI:000183263200010,
author = {L Williams and A Cockburn},
number = {6},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
pages = {39--43},
issn = {0018-9162},
journal = {COMPUTER},
publisher = {IEEE COMPUTER SOC},
type = {Editorial Material},
year = {2003},
doi = {10.1109/MC.2003.1204373},
month = {jun},
title = {Agile software development: It's about feedback and change},
volume = {36},
}

@article{ISI:000268944000023,
author = {M Tavani and G Barbiellini and A Argan and F Boffelli and A Bulgarelli and P Caraveo and P W Cattaneo and A W Chen and V Cocco and E Costa and  D'Amm and F o and E Del Monte and G De Paris and G Di Cocco and G Di Persio and I Donnarumma and Y Evangelista and M Feroci and A Ferrari and M Fiorini and F Fornari and F Fuschino and  Froysl and T  and M Frutti and M Galli and F Gianotti and A Giuliani and C Labanti and I Lapshov and F Lazzarotto and F Liello and P Lipari and F Longo and E Mattaini and M Marisaldi and M Mastropietro and A Mauri and F Mauri and S Mereghetti and E Morelli and A Morselli and L Pacciani and A Pellizzoni and F Perotti and G Piano and P Picozza and C Pontoni and G Porrovecchio and M Prest and G Pucella and M Rapisarda and A Rappoldi and E Rossi and A Rubini and P Soffitta and A Traci and M Trifoglio and A Trois and E Vallazza and S Vercellone and V Vittorini and A Zambra and D Zanello and C Pittori and B Preger and P Santolamazza and F Verrecchia and P Giommi and S Colafrancesco and A Antonelli and S Cutini and D Gasparrini and S Stellato and G Fanari and R Primavera and F Tamburelli and F Viola and G Guarrera and L Salotti and F D'Amico and E Marchetti and M Crisconio and P Sabatini and G Annoni and S Alia and A Longoni and R Sanquerin and M Battilana and P Concari and E Dessimone and R Grossi and A Parise and F Monzani and E Artina and R Pavesi and G Marseguerra and L Nicolini and  Sc and L elli and L Soli and V Vettorello and E Zardetto and A Bonati and L Maltecca and E D'Alba and M Patane and G Babini and F Onorati and L Acquaroli and M Angelucci and B Morelli and C Agostara and M Cerone and A Michetti and P Tempesta and S D'Eramo and F Rocca and F Giannini and G Borghi and B Garavelli and M Conte and M Balasini and I Ferrario and M Vanotti and E Collavo and M Giacomazzo},
year = {2009},
doi = {10.1051/0004-6361/200810527},
abstract = {Context. AGILE is an Italian Space Agency mission dedicated to observingthe gamma-ray Universe. The AGILE's very innovative instrumentation forthe first time combines a gamma-ray imager (sensitive in the energyrange 30 MeV-50 GeV), a hard X-ray imager (sensitive in the range 18-60keV), a calorimeter (sensitive in the range 350 keV-100 MeV), and ananticoincidence system. AGILE was successfully launched on 2007 April 23from the Indian base of Sriharikota and was inserted in an equatorialorbit with very low particle background.Aims. AGILE provides crucial data for the study of active galacticnuclei, gamma-ray bursts, pulsars, unidentified gamma-ray sources,galactic compact objects, supernova remnants, TeV sources, andfundamental physics by microsecond timing.Methods. An optimal sky angular positioning (reaching 0.1 degrees ingamma- rays and 1-2 arcmin in hard X-rays) and very large fields of view(2.5 sr and 1 sr, respectively) are obtained by the use of Silicondetectors integrated in a very compact instrument.Results. AGILE surveyed the gamma- ray sky and detected many Galacticand extragalactic sources during the first months of observations.Particular emphasis is given to multifrequency observation programs ofextragalactic and galactic objects.Conclusions. AGILE is a successful high-energy gamma-ray mission thatreached its nominal scientific performance. The AGILE Cycle-1 pointingprogram started on 2007 December 1, and is open to the internationalcommunity through a Guest Observer Program.},
number = {3},
type = {Article},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
title = {The AGILE Mission},
publisher = {EDP SCIENCES S A},
month = {aug},
volume = {502},
issn = {1432-0746},
journal = {ASTRONOMY & ASTROPHYSICS},
pages = {995--1013},
keywords = {instrumentation: detectors,techniques: high angul},
mendeley-tags = {instrumentation: detectors,techniques: high angul},
}

@article{ISI:000238141400003,
author = {Helena Holmstrom and Brian Fitzgerald and Par J Agerfalk and Eoin O Conchuir},
doi = {10.1201/1078.10580530/46108.23.3.20060601/93703.2},
volume = {23},
number = {3},
title = {Agile practices reduce distance in global software development},
year = {2006},
journal = {INFORMATION SYSTEMS MANAGEMENT},
type = {Article},
address = {C/O CRC PRESS L L C, 2000 CORPORATE BLVD NW, BOCA RATON, FL 33431 USA},
pages = {7--18},
abstract = {This article explores how agile practices can reduce three kinds of``distance'' - temporal, geographical, and sociocultural - in globalsoftware development (GSD). On the basis of two in-depth case studies,specific Scrum and eXtreme Programming (XP) practices are found to beuseful for reducing communication, coordination, and control problemsthat have been associated with GSD.},
issn = {1058-0530},
publisher = {AUERBACH PUBLICATIONS},
}

@article{ISI:000298773100005,
author = {Chong Wu and David Barnes},
type = {Review},
number = {4},
doi = {10.1016/j.pursup.2011.09.002},
issn = {1478-4092},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
abstract = {The paper reviews the literature on supply partner decision-makingpublished between 2001 and 2011, a period that has seen a significantincrease in work published in this field. The progress made indeveloping new models and methods that can be applied to this task isassessed in the context of the previous literature. Particular attentionis given to those methods that are especially relevant for use in agilesupply chains. The paper uses a classification framework that enablesmodels intended for similar purposes to be compared and tracked overtime. It is also used to identify a number of gaps in the literature.The findings highlight an on-going need to develop methods that are ableto meet the combination of qualitative and quantitative objectives thatare typically found in partner selection problems in practice. (C) 2011Elsevier Ltd. All rights reserved.},
month = {dec},
journal = {JOURNAL OF PURCHASING AND SUPPLY MANAGEMENT},
pages = {256--274},
publisher = {ELSEVIER SCI LTD},
title = {A literature review of decision-making models and approaches for partner selection in agile supply chains},
volume = {17},
year = {2011},
keywords = {agile supply,literature review,partner selection},
mendeley-tags = {agile supply,literature review,partner selection},
}

@article{ISI:000233567300021,
author = {S Augustine and B Payne and F Sencindiver and S Woodcock},
volume = {48},
number = {12},
month = {dec},
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
pages = {85--89},
doi = {10.1145/1101779.1101781},
journal = {COMMUNICATIONS OF THE ACM},
issn = {0001-0782},
publisher = {ASSOC COMPUTING MACHINERY},
title = {Agile project management: Steering from the edges},
type = {Article},
year = {2005},
}

@article{ISI:000277107200002,
author = {Nils Brede Moe and Torgeir Dingsoyr and Tore Dyba},
type = {Article},
publisher = {ELSEVIER SCIENCE BV},
pages = {480--491},
year = {2010},
number = {5, SI},
volume = {52},
journal = {INFORMATION AND SOFTWARE TECHNOLOGY},
doi = {10.1016/j.infsof.2009.11.004},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
issn = {0950-5849},
month = {may},
abstract = {Context Software development depends significantly on team performance,as does any process that involves human interactionObjective Most current development methods argue that teams shouldself-manage Our objective is thus to provide a better understanding ofthe nature of self-managing agile teams, and the teamwork challengesthat arise when introducing such teamsMethod We conducted extensive fieldwork for 0 months in a softwaredevelopment company that introduced Scrum. We focused on the humansensemaking, on how mechanisms of teamwork were understood by the peopleinvolvedResults We describe a project through Dickinson and McIntyre's teamworkmodel, focusing on the interrelations between essential teamworkcomponents Problems with team orientation, team leadership andcoordination in addition to highly specialized skills and correspondingdivision of work were important barriers for achieving teameffectivenessConclusion Transitioning from individual work to self-managing teamsrequires a reorientation not only by developers but also by managementThis transition takes time and resources, but should not be neglected Inaddition to Dickinson and McIntyre's teamwork components, we found trustand shared mental models to be of fundamental importance (C) 2009Elsevier B V All rights reserved},
title = {A teamwork model for understanding an agile team: A case study of a Scrum project},
keywords = {agile software development,scrum,software engine},
mendeley-tags = {agile software development,scrum,software engine},
}

@article{ISI:000084793700002,
author = { Bh and M P arkar and R Nagi},
issn = {0166-3615},
pages = {3--24},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
publisher = {ELSEVIER SCIENCE BV},
journal = {COMPUTERS IN INDUSTRY},
number = {1},
type = {Article},
volume = {41},
year = {2000},
doi = {10.1016/S0166-3615(99)00040-8},
abstract = {Feature recognition, from low level geometric entities of product designrepresentations within a CAD model to facilitate process planning andmanufacturing activities, has been of significant importance in computerintegrated manufacturing (CIM). However, the emerging paradigm of AgileManufacturing has imposed additional requirements of `'neutralformat'' so that form-feature information can be readily shared amongmultiple partners of a virtual enterprise. Recently, the STandard forthe Exchange of Product model data (STEP) has emerged as the means forneutral form exchange of product related data. The ``STEP efforts''have broken down the domain of manufacturing related activities in theform of application protocols (APs) target for specific functions whichinclude drafting, configuration control and feature-based processplanning to mention a few. Efforts are still on to increase theacceptance and use of this international standard (IS). This paperfocuses on our efforts to support the STEP standard with the developmentof a standards-oriented form-feature extraction system. The developedfeature extraction system takes as a input a STEP file defining thegeometry and topology of a part and generates as output a STEP file withform-feature information in AP224 format for form feature-based processplanning. The system can also be interfaced with a recent IGES to AP202translator [M.P. Bhandarkar, B. Downie, M. Hardwick, R. Nagi,Migration from ICES to STEP: one-to-one translation of IGES drawing toSTEP drafting data, accepted by Computers in Industry, July, 1999; M.P.Bhandarkar, Satisfying information needs in Agile Manufacturing throughtranslation and feature extraction into STEP product data models, MSThesis, State University of New York at Buffalo, 1997.] to allowconversion of legacy data. The feature recognition algorithm isboundary-representation (B-Rep) based and follows a sequential approachthrough an existing classification of features. Properties of eachfeature class are exploited to enable their extraction. The algorithm iscurrently developed for prismatic solids produced by milling operationsand that contain elementary shapes such as plane and cylindricalsurfaces (possibly using non-uniform rational B-splines (NURBS)).Special attention has been paid to implementation issues. We demonstratethe efficacy of the system using representative parts. (C) 2000Published by Elsevier Science B.V. All rights reserved.},
month = {jan},
title = {STEP-based feature extraction from STEP geometry for agile manufacturing},
keywords = {feature extraction,form feature,step},
mendeley-tags = {feature extraction,form feature,step},
}

@article{ISI:000225756200019,
author = {M Lindvall and D Muthig and A Dagnino and C Wallin and M Stupperick and D Kiefer and J May and T Kahkonen},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
pages = {26+},
volume = {37},
issn = {0018-9162},
doi = {10.1109/MC.2004.231},
number = {12},
month = {dec},
title = {Agile software development in large organizations},
journal = {COMPUTER},
year = {2004},
publisher = {IEEE COMPUTER SOC},
abstract = {Developers need evidence that a new technology works in a certaincontext before they promote and deploy it on a larger scale. This needlooms greater in large organizations because of their complexity and theneed to integrate new technologies and processes with existing ones.To further evaluate agile methods and their underlying softwaredevelopment practices, several Software Experience Center membercompanies initiated a series of activities to discover if agilepractices match their organizations' needs. Based on the experiences ofthese organizations, researchers concluded that agile practices matchthe needs of large organizations, but integrating new practices withexisting processes and quality systems that govern the conduct ofsoftware development requires further tailoring. The challenge here liesnot in applying agile practices to a project, but in efficientlyintegrating the agile project into its environment.},
type = {Article},
}

@article{ISI:000309058000012,
author = {Ivana Palunko and Patricio Cruz and Rafael Fierro},
volume = {19},
year = {2012},
doi = {10.1109/MRA.2012.2205617},
pages = {69--79},
type = {Article},
month = {sep},
issn = {1070-9932},
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
journal = {IEEE ROBOTICS & AUTOMATION MAGAZINE},
number = {3},
title = {Agile Load Transportation Safe and Efficient Load Manipulation with Aerial Robots},
}

@article{ISI:000272058100007,
author = {Feng Pan and Rakesh Nagi},
volume = {37},
year = {2010},
issn = {0305-0548},
journal = {COMPUTERS & OPERATIONS RESEARCH},
doi = {10.1016/j.cor.2009.06.017},
pages = {668--683},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
abstract = {This paper considers a supply chain design problem for a new marketopportunity with uncertain demand in an agile manufacturing setting. Weconsider the integrated optimization of logistics and production costsassociated with the supply chain members. These problems routinely occurin a wide variety of industries including semiconductor manufacturing,multi-tier automotive supply chains, and consumer appliances to name afew. There are two types of decision variables: binary variables forselection of companies to form the supply chain and continuous variablesassociated with production planning. A scenario approach is used tohandle the uncertainty of demand. The formulation is a robustoptimization model with three components in the objective function:expected total costs, cost variability due to demand uncertainty, andexpected penalty for demand unmet at the end of the planning horizon.The increase of computational time with the numbers of echelons andmembers per echelon necessitates a heuristic. A heuristic based on ak-shortest path algorithm is developed by using a surrogate distance todenote the effectiveness of each member in the supply chain. Theheuristic can find an optimal solution very quickly in some small- andmedium-size cases. For large problems, a ``good'' solution with asmall gap relative to our lower bound is obtained in a shortcomputational time. (C) 2009 Elsevier Ltd. All rights reserved.},
month = {apr},
number = {4},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
title = {Robust supply chain design under uncertain demand in agile manufacturing},
type = {Article},
keywords = {integrated costs,supply chain formation,uncertai},
mendeley-tags = {integrated costs,supply chain formation,uncertai},
}

@article{ISI:000165846400007,
author = {R Mason-Jones and B Naylor and D R Towill},
issn = {0020-7543},
month = {nov},
abstract = {Many enterprises have pursued the lean thinking paradigm to improve theefficiency of their business processes. More recently, the agilemanufacturing paradigm has been highlighted as an alternative to, andpossibly an improvement on, leanness. In pursuing such arguments inisolation, the power of each paradigm may be lost, which is basicallythat agile manufacturing is adopted where demand is volatile, and leanmanufacturing adopted where there is a stable demand. However, in somesituations it is advisable to utilize a different paradigm on eitherside of the material flow de-coupling point to enable a total supplychain strategy. This approach we have termed the Leagile Paradigm. Thispaper therefore considers the effect of the marketplace environment onstrategy selection to ensure optimal supply chain performance.Real-world case studies in the mechanical precision products, carpetmaking, and electronic products market sectors demonstrate the newapproach to matching supply chain design to the actual needs of themarketplace.},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
number = {17},
pages = {4061--4070},
year = {2000},
type = {Article; Proceedings Paper},
address = {11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND},
title = {Lean, agile or leagile? Matching your supply chain to the marketplace},
publisher = {TAYLOR & FRANCIS LTD},
annote = {15th International Conference of Production Research(ICPR-15), UNIVLIMERICK, LIMERICK, IRELAND, AUG, 1999},
doi = {10.1080/00207540050204920},
volume = {38},
}

@article{ISI:000170758100024,
author = {J Highsmith and A Cockburn},
year = {2001},
publisher = {IEEE COMPUTER SOC},
type = {Article},
pages = {120--122},
number = {9},
title = {Agile software development: The business of innovation},
journal = {COMPUTER},
volume = {34},
issn = {0018-9162},
doi = {10.1109/2.947100},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
month = {sep},
}

@article{ISI:000254515800002,
author = {M Villata and C M Raiteri and V M Larionov and O M Kurtanidze and K Nilsson and M F Aller and M Tornikoski and A Volvach and H D Aller and A A Arkharov and U Bach and P Beltrame and G Bhatta and C S Buemi and M Boettcher and P Calcidese and D Carosati and A J Castro-Tirado and D Da Rio and A Di Paola and M Dolci and E Forne and A Frasca and V A Hagen-Thorn and J Heidt and D Hiriart and M Jelinek and G N Kimeridze and T S Konstantinova and E N Kopatskaya and L Lanteri and P Leto and R Ligustri and E Lindfors and A Lahteenmaki and E Marilli and E Nieppola and M G Nikolashvili and M Pasanen and B Ragozzine and J A Ros and L A Sigua and R L Smart and M Sorcia and L O Takalo and M Tavani and C Trigilio and R Turchetti and K Uckert and G Umana and S Vercellone and J R Webb},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
journal = {ASTRONOMY & ASTROPHYSICS},
type = {Article},
title = {Multifrequency monitoring of the blazar 0716+714 during the GASP-WEBT-AGILE campaign of 2007},
pages = {L79--L82},
volume = {481},
year = {2008},
month = {apr},
abstract = {Aims. Since the CGRO operation in 1991-2000, one of the primaryunresolved questions about the blazar gamma-ray emission has been itspossible correlation with the low-energy (in particular optical)emission. To help answer this problem, the Whole Earth Blazar Telescope(WEBT) consortium has organized the GLAST-AGILE Support Program (GASP)to provide the optical-to-radio monitoring data to be compared with thegamma-ray detections by the AGILE and GLAST satellites. This new WEBTproject started in early September 2007, just before a strong gamma-raydetection of 0716+714 by AGILE.Methods. We present the GASP-WEBT optical and radio light curves of thisblazar obtained in July-November 2007, about various AGILE pointings atthe source. We construct NIR-to-UV spectral energy distributions (SEDs),by assembling GASP-WEBT data together with UV data from the Swift ToOobservations of late October.Results. We observe a contemporaneous optical-radio outburst, which is arare and interesting phenomenon in blazars. The shape of the SEDs duringthe outburst appears peculiarly wavy because of an optical excess and aUV drop- and-rise. The optical light curve is well sampled during theAGILE pointings, showing prominent and sharp flares. A futurecross-correlation analysis of the optical and AGILE data will shed lighton the expected relationship between these flares and the gamma-rayevents.},
publisher = {EDP SCIENCES S A},
number = {2},
doi = {10.1051/0004-6361:200809552},
issn = {0004-6361},
keywords = {galaxies : active,galaxies : bl lacertae objects},
mendeley-tags = {galaxies : active,galaxies : bl lacertae objects},
}

@article{ISI:000303626300001,
author = {Torgeir Dingsoyr and Sridhar Nerur and VenuGopal Balijepally and Nils Brede Moe},
issn = {0164-1212},
abstract = {Ever since the agile manifesto was created in 2001, the researchcommunity has devoted a great deal of attention to agile softwaredevelopment. This article examines publications and citations toillustrate how the research on agile has progressed in the 10 yearsfollowing the articulation of the manifesto. Specifically, we delineatethe conceptual structure underlying agile scholarship by performing ananalysis of authors who have made notable contributions to the field.Further, we summarize prior research and introduce contributions in thisspecial issue on agile software development. We conclude by discussingdirections for future research and urging agile researchers to embrace atheory-based approach in their scholarship. (C) 2012 Elsevier Inc. Allrights reserved.},
doi = {10.1016/j.jss.2012.02.033},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
type = {Article},
volume = {85},
month = {jun},
number = {6},
title = {A decade of agile methodologies: Towards explaining agile software development},
pages = {1213--1221},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
year = {2012},
publisher = {ELSEVIER SCIENCE INC},
keywords = {agile software development,crystal met,lean software development,scrum,software engin,theory,xp},
mendeley-tags = {agile software development,crystal met,lean software development,scrum,software engin,theory,xp},
}

@article{ISI:000223955900002,
author = {W J Hopp and M P Van Oyen},
abstract = {This paper outlines approaches for assessing and classifyingmanufacturing and service operations in terms of their suitability foruse of cross-trained (flexible) workers. We refer to our overallframework as agile workforce evaluation. The primary contributions ofthis paper are: (i) a strategic assessment framework that structures thekey mechanisms by which cross-training can support organizationalstrategy; (ii) a tactical framework that identifies key factors to guidethe selection of an architecture and worker coordination policy forimplementing workforce agility; (iii) a classification of workforceagility architectures; (iv) a survey of a broad range of archetypicalclasses of worker coordination policies; (v) a survey of the literaturewith an operational perspective on workforce agility; and (vi)identification of opportunities for research and development ofarchitectures for specific production environments.},
issn = {0740-817X},
month = {oct},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
pages = {919--940},
number = {10},
volume = {36},
type = {Review},
journal = {IIE TRANSACTIONS},
publisher = {TAYLOR & FRANCIS LTD},
title = {Agile workforce evaluation: a framework for cross-training and coordination},
year = {2004},
doi = {10.1080/07408170490487759},
}

@article{ISI:000167124500008,
author = {R I van Hoek and A Harrison and M Christopher},
abstract = {Agility is increasingly mentioned as one of the coming challenges to theinternational business world, given volatile markets and increasinglydynamic performance requirements. Existing literature, however, mainlypresents agility as a general management or a strongly manufacturingbiased concept, but does not explicitly relate the concept to the supplychain as a whole. Research also shows a bias towards the USA. This paperpresents an attempt to establish an audit of agility in the supplychain. The audit is used in an empirical investigation of agilecapabilities in Europe. Using existing streams of supply chain researchas building blocks, a preliminary framework is introduced for creatingan agile supply chain. Based on a survey of agile efforts in the UK andthe Benelux the agile capabilities of companies are assessed andapproaches to outscore the benchmark are suggested.},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
issn = {0144-3577},
number = {1-2},
publisher = {MCB UNIV PRESS LTD},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
pages = {126--147},
title = {Measuring agile capabilities in the supply chain},
year = {2001},
type = {Article},
volume = {21},
keywords = {agility,audit,supply chain},
mendeley-tags = {agility,audit,supply chain},
}

@article{ISI:000256077900014,
author = {Hou-Tong Chen and John F O'Hara and Abul K Azad and Antoinette J Taylor and Richard D Averitt and David B Shrekenhamer and Willie J Padilla},
pages = {295--298},
number = {5},
type = {Article},
volume = {2},
address = {MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND},
issn = {1749-4885},
year = {2008},
month = {may},
title = {Experimental demonstration of frequency-agile terahertz metamaterials},
doi = {10.1038/nphoton.2008.52},
publisher = {NATURE PUBLISHING GROUP},
journal = {NATURE PHOTONICS},
abstract = {Metamaterials exhibit numerous novel effects(1-5) and operate over alarge portion of the electromagnetic spectrum(6-10). Metamaterialdevices based on these effects include gradient-index lenses(11,12),modulators for terahertz radiation(13-15) and compact waveguides(16).The resonant nature of metamaterials results in frequency dispersion andnarrow bandwidth operation where the centre frequency is fixed by thegeometry and dimensions of the elements comprising the metamaterialcomposite. The creation of frequency-agile metamaterials would extendthe spectral range over which devices function and, further, enable themanufacture of new devices such as dynamically tunable notch filters.Here, we demonstrate such frequency-agile metamaterials operating in thefar-infrared by incorporating semiconductors in critical regions ofmetallic split-ring resonators. For this first-generation device,external optical control results in tuning of the metamaterial resonancefrequency by similar to 20%. Our approach is integrable with currentsemiconductor technologies and can be implemented in other regions ofthe electromagnetic spectrum.},
}

@article{ISI:000171519800001,
author = {L M Sanchez and R Nagi},
publisher = {TAYLOR & FRANCIS LTD},
title = {A review of agile manufacturing systems},
year = {2001},
volume = {39},
number = {16},
type = {Review},
issn = {0020-7543},
doi = {10.1080/00207540110068790},
pages = {3561--3600},
address = {11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
abstract = {About a decade ago, the agile manufacturing paradigm was formulated inresponse to the constantly changing `new economy' and as a basis forreturning to global competitiveness. While agility means differentthings to different enterprises under different contexts, the followingelements capture its essential concept: agility is characterized bycooperativeness and synergism (possibly resulting in virtualcorporations), by a strategic vision that enables thriving in face ofcontinuous and unpredictable change, by the responsive creation anddelivery of customer-valued, high quality and mass customizedgoods/services, by nimble organization structures of a knowledgeable andempowered workforce, and facilitated by an information infrastructurethat links constituent partners in a unified electronic network. Duringthis period, a significant amount of attention from both the academicand industrial communities has produced a large body of results inresearch and development related to this topic. Each contribution hastackled a different aspect of this large field. In this paper, we reviewa wide range of recent literature on agile manufacturing. About 73papers from premier scientific journals and conferences have beenreviewed, and a classification scheme to organize these is proposed. Wecritique these bodies of work and suggest directions for additionalresearch and identify topics where fruitful opportunities exist.},
month = {nov},
}

@article{ISI:000185086300001,
author = {S Brown and J Bessant},
volume = {23},
abstract = {This paper is based on longitudinal case studies of research intostrategy formulation within six plants from large firms - three in thecar industry and three from the computer industry - that have embarkedon mass customisation. The core theme of this paper is that, in spite ofthe increasing attention given to manufacturing strategy from theseminal work of Skinner through to the plethora of articles in recenttimes, little is mentioned about its application to paradigms of agilityor mass customisation. As a consequence firms attempt to become agileand to pursue mass customisation without appreciating the contributionof plant-specific manufacturing strategies that might enable them toachieve these aspirations. We examine the enablers and strategicblockages in pursuing mass customisation, via a mapping process, andreveal reasons why some firms remain unable to devise and implementmanufacturing strategies.},
pages = {707--730},
doi = {10.1108/01443570310481522},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
number = {7-8},
issn = {0144-3577},
publisher = {EMERALD GROUP PUBLISHING LTD},
title = {The manufacturing strategy-capabilities links in mass customisation and agile manufacturing - an exploratory study},
year = {2003},
type = {Article},
keywords = {agile prod,mass customization,strategic planning},
mendeley-tags = {agile prod,mass customization,strategic planning},
}

@article{ISI:000323654900005,
author = {Alex Kushleyev and Daniel Mellinger and Caitlin Powers and Vijay Kumar},
journal = {AUTONOMOUS ROBOTS},
number = {4, SI},
year = {2013},
pages = {287--300},
title = {Towards a swarm of agile micro quadrotors},
abstract = {We describe a prototype 75 g micro quadrotor with onboard attitudeestimation and control that operates autonomously with an externallocalization system. The motivation for designing quadrotors at thisscale comes from two observations. First, the agility of the robotincreases with a reduction in size, a fact that is supported byexperimental results in this paper. Second, smaller robots are able tooperate in tight formations in constrained, indoor environments. Wedescribe the hardware and software used to operate the vehicle as wellour dynamic model. We also discuss the aerodynamics of vertical flightand the contribution of ground effect to the vehicle performance.Finally, we discuss architecture and algorithms to coordinate a team ofthese quadrotors, and provide experimental results for a team of 20micro quadrotors.},
doi = {10.1007/s10514-013-9349-9},
address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
type = {Article},
issn = {0929-5593},
volume = {35},
publisher = {SPRINGER},
month = {nov},
keywords = {micro aerial vehicles,quadrotors,trajectory gene},
mendeley-tags = {micro aerial vehicles,quadrotors,trajectory gene},
}

@article{ISI:000183263200013,
author = {B Boehm and R Turner},
pages = {57+},
abstract = {Both agile and plan-driven approaches have situation-dependentshortcomings that, if not addressed, can lead to project failure. Thechallenge is to balance the two approaches to take advantage of theirstrengths in a given situation while compensating for their weaknesses.The authors present a risk-based approach for structuring projects toincorporate both agile and plan-driven approaches in proportion to aproject's needs.},
journal = {COMPUTER},
number = {6},
title = {Using risk to balance agile and plan-driven methods},
type = {Article},
month = {jun},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
issn = {0018-9162},
doi = {10.1109/MC.2003.1204376},
publisher = {IEEE COMPUTER SOC},
year = {2003},
volume = {36},
}

@article{ISI:000175277300004,
author = {A Gunasekaran and Y Y Yusuf},
type = {Article},
year = {2002},
publisher = {TAYLOR & FRANCIS LTD},
abstract = {Agile Manufacturing (AM) is a relatively new operations concept that isintended to improve the competitiveness of firms. Manufacturing/serviceprocesses based on AM are characterized by customer-supplier integratedprocesses for product design, manufacturing, marketing, and supportservices. Agile manufacturing requires enriching of the customer;cooperating with competitors; organizing to manage change, uncertaintyand complexity; and leveraging people and information. In recent years,a number of research papers have been published in the area of AM. Theterm `agile' was coined in 1991. However, there are still some seriousconcerns that prevent companies from taking an entirely differentdirection from AM. Considering the potential importance of agilemanufacturing in 21st century manufacturing competitiveness, an attempthas been made in this paper to re-examine the scope, definitions andstrategies of AM. In addition, a framework has been presented as a basisfor understanding the major strategies and relevant technologies of AM.},
pages = {1357--1385},
volume = {40},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
address = {4 PARK SQUARE, MILTON PARK,, ABINGDON OX14 4RN, OXON, ENGLAND},
doi = {10.1080/00207540110118370},
month = {apr},
title = {Agile manufacturing: a taxonomy of strategic and technological imperatives},
number = {6},
issn = {0020-7543},
}

@article{ISI:000085104500005,
author = {M Christopher},
type = {Article},
pages = {37--44},
address = {655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010 USA},
month = {jan},
year = {2000},
volume = {29},
journal = {INDUSTRIAL MARKETING MANAGEMENT},
number = {1},
issn = {0019-8501},
publisher = {ELSEVIER SCIENCE INC},
title = {The agile supply chain - Competing in volatile markets},
doi = {10.1016/S0019-8501(99)00110-8},
abstract = {Turbulent and volatile markets are becoming the norm as life cyclesshorten and global economic and competitive forces create additionaluncertainty. The risk attached to lengthy and slow-moving logistics``pipelines'' has become unsustainable, forcing organizations to lookagain at how their supply chains are structured and managed. This papersuggests that the key to survival in these changed conditions is through``agility,'' in particular by the creation of responsive supplychains. A distinction is drawn between the philosophies of``leanness'' and ``agility, `` and the appropriate application ofthese ideas is (C) 2000 Elsevier Science Inc. All rights reserved.},
}

@article{ISI:000247547600012,
author = {Michael P Murphy and Metin Sitti},
doi = {10.1109/TMECH.2007.897277},
number = {3},
year = {2007},
month = {jun},
abstract = {This paper proposes a small-scale agile wall-climbing robot, which isable to climb on smooth vertical surfaces using flat adhesive elastomermaterials for attachment. Using two actuated legs with rotary motion andtwo passive revolute joints at each foot, this robot can climb and steerin any orientation. Due to its compact design, a high degree ofminiaturization is possible. It has onboard power, computing, andwireless communication, which allow for semiautonomous operation.Various aspects of a functioning prototype design and performance arediscussed in detail, including leg and foot design and gait dynamics. Amodel for the adhesion requirements and performance is developed andverified through experiments. Using an adhesive elastomer (Vytaflex 10),the current prototype can climb 90 slopes at a speed of up to 6 cm/s andsteer to any angle reliably on a,smooth acrylic surface as well astransition from floor walking to wall climbing. This robot is intendedfor inspection and surveillance applications, and ultimately, for spacemissions.},
type = {Article},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
pages = {330--338},
journal = {IEEE-ASME TRANSACTIONS ON MECHATRONICS},
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
issn = {1083-4435},
title = {Waalbot: An agile small-scale wall-climbing robot utilizing dry elastomer adhesives},
volume = {12},
keywords = {dry adhesives,m,mechatronics,miniature robotics},
mendeley-tags = {dry adhesives,m,mechatronics,miniature robotics},
}

@article{ISI:000251148000017,
author = {M Feroci and E Costa and P Soffitta and E Del Monte and G Di Persio and I Donnarumma and Y Evangelista and M Frutti and I Lapshov and F Lazzarotto and M Mastropietro and E Morelli and L Pacciani and G Porrovecchio and M Rapisarda and A Rubini and M Tavani and A Argan},
volume = {581},
month = {nov},
issn = {0168-9002},
abstract = {SuperAGILE is a coded mask experiment based on silicon microstripdetectors. It operates in the 15-45 keV nominal energy range, providingcrossed one-dimensional images of the X-ray sky with an on-axis angularresolution of 6 arcmin, over a field of view in excess of 1 sr. It wasdesigned as the hard X-ray monitor of the AGILE space mission, a smallsatellite of the Italian Space Agency devoted to image the gamma-ray skyin the 30 MeV-50 GeV energy band. The AGILE mission was launched in alow-earth orbit on 23rd April 2007. In this paper we describe theSuperAGILE experiment, its construction and test processes, and itsperformance before flight, based on the on-ground test and calibrations.(c) 2007 Elsevier B.V. All rights reserved.},
pages = {728--754},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
year = {2007},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
number = {3},
doi = {10.1016/j.nima.2007.07.147},
publisher = {ELSEVIER SCIENCE BV},
title = {SuperAGILE: The hard X-ray imager for the AGILE space mission},
type = {Article},
keywords = {high energy astrophysics,microst,x-ray detectors},
mendeley-tags = {high energy astrophysics,microst,x-ray detectors},
}

@article{ISI:000269983900004,
author = {Likoebe M Maruping and Viswanath Venkatesh and Ritu Agarwal},
pages = {377--399},
journal = {INFORMATION SYSTEMS RESEARCH},
abstract = {In this paper, we draw on control theory to understand the conditionsunder which the use of agile practices is most effective in improvingsoftware project quality. Although agile development methodologies offerthe potential of improving software development outcomes, limitedresearch has examined how project managers can structure the softwaredevelopment environment to maximize the benefits of agile methodologyuse during a project. As a result, project managers have little guidanceon how to manage teams who are using agile methodologies. Arguing thatthe most effective control modes are those that provide teams withautonomy in determining the methods for achieving project objectives, wepropose hypotheses related to the interaction between control modes,agile methodology use, and requirements change. We test the model in afield study of 862 software developers in 110 teams. The model explainssubstantial variance in four objective measures of project quality-bugseverity, component complexity, coordinative complexity, and dynamiccomplexity. Results largely support our hypotheses, highlighting theinterplay between project control, agile methodology use, andrequirements change. The findings contribute to extant literature byintegrating control theory into the growing literature on agilemethodology use and by identifying specific contingencies affecting theefficacy of different control modes. We discuss the theoretical andpractical implications of our results.},
doi = {10.1287/isre.1090.0238},
year = {2009},
type = {Article},
publisher = {INFORMS},
volume = {20},
month = {sep},
issn = {1047-7047},
title = {A Control Theory Perspective on Agile Methodology Use and Changing User Requirements},
address = {5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA},
number = {3},
keywords = {agile methodologies,agility,control theory,requ},
mendeley-tags = {agile methodologies,agility,control theory,requ},
}

@article{ISI:A1996VZ99700005,
author = {C M Gosselin and E StPierre and M Gagne},
year = {1996},
address = {345 E 47TH ST, NEW YORK, NY 10017-2394},
issn = {1070-9932},
number = {4},
month = {dec},
journal = {IEEE ROBOTICS & AUTOMATION MAGAZINE},
pages = {29--37},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {On the development of the Agile Eye},
volume = {3},
abstract = {The `'Agile Eye'' is a high-performance mechanism capable of orienting acamera within a workspace larger than that of a human eye and withvelocities and accelerations larger than those of the human eye. Themechanical design, control issues, and experimental results arepresented.},
doi = {10.1109/100.556480},
type = {Article},
keywords = {camera-orien,dynamic control,parallel mechanisms},
mendeley-tags = {camera-orien,dynamic control,parallel mechanisms},
}

@article{ISI:000269428600001,
author = {Pekka Abrahamsson and Kieran Conboy and Xiaofeng Wang},
number = {4},
doi = {10.1057/ejis.2009.27},
pages = {281--284},
title = {`Lots done, more to do': the current state of agile systems development research},
publisher = {PALGRAVE MACMILLAN LTD},
issn = {0960-085X},
month = {aug},
journal = {EUROPEAN JOURNAL OF INFORMATION SYSTEMS},
volume = {18},
address = {BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND},
type = {Editorial Material},
year = {2009},
}

@article{ISI:000180587100029,
author = { S and S T ers},
address = {175 FIFTH AVE, NEW YORK, NY 10010 USA},
number = {6-7},
pages = {799--802},
year = {2002},
journal = {APPLIED PHYSICS B-LASERS AND OPTICS},
issn = {0946-2171},
title = {Wavelength-agile fiber laser using group-velocity dispersion of pulsed super-continua and application to broadband absorption spectroscopy},
month = {nov},
type = {Article},
volume = {75},
abstract = {A swept-wavelength source is created by connecting four elements inseries: a femtosecond fiber laser at 1.56 mum, a non-linear fiber, adispersive fiber and a tunable spectral bandpass filter. The 1.56-mumpulses are converted to supercontinuum (1.1-2.2 mum) pulses by thenon-linear fiber, and these broadband pulses are stretched and arrangedinto wavelength scans by the dispersive fiber. The tunable bandpassfilter is used to select a portion of the super-continuum as ascan-wavelength output. A variety of scan characteristics are possibleusing this approach. As an example, an output with an effectivelinewidth of approximately 1 cm(-1) is scanned from 1350-1550 nm every20 us. Compared to previous scanning benchmarks of approximately 1nm/mus, such broad, rapid scans offer new capabilities: a gas sensingapplication is demonstrated by monitoring absorption bands of H2O, CO2,C2H2 and C2H6O at a pressure of 10 bar.},
publisher = {SPRINGER-VERLAG},
doi = {10.1007/s00340-002-1044-z},
}

@article{ISI:000235093400003,
author = {P Leitao and F Restivo},
volume = {57},
month = {feb},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
journal = {COMPUTERS IN INDUSTRY},
year = {2006},
issn = {0166-3615},
number = {2},
abstract = {In the last decades significant changes in the manufacturing environmenthave been noticed: moving from a local economy towards a global economy,with markets asking for products with higher quality at lower costs,highly customised and with short life cycle. In these circumstances, thechallenge is to develop manufacturing control systems with intelligencecapabilities, fast adaptation to the environment changes and morerobustness against the occurrence of disturbances. This paper presentsan agile and adaptive manufacturing control architecture that addressesthe need for the fast reaction to disturbances at the shop floor level,increasing the agility and flexibility of the enterprise, when it worksin volatile environments. The proposed architecture introduces anadaptive control that balances dynamically between a more centralisedstructure and a more decentralised one, allowing combining the globalproduction optimisation with agile reaction to unexpected disturbances.(c) 2005 Elsevier B.V. All rights reserved.},
doi = {10.1016/j.compind.2005.05.005},
publisher = {ELSEVIER SCIENCE BV},
title = {ADACOR: A holonic architecture for agile and adaptive manufacturing control},
type = {Article},
pages = {121--130},
keywords = {holonic manufac,intelligent manufacturing control},
mendeley-tags = {holonic manufac,intelligent manufacturing control},
}

@article{ISI:000184714000004,
author = {J Prince and J M Kay},
pages = {305--318},
abstract = {The paper presents the background to why some manufacturingorganisations require a combination of agile and lean characteristics intheir manufacturing organisations. The paper also describes thedevelopment of the virtual group (VG) concept, which is the applicationof virtual cells to functional layouts. VGs enable the appropriateapplication of lean and agile concepts to different stages of productionwithin a factory. The identification of VGs is achieved through the useof a methodology called enhanced production flow analysis (EPFA), whichis described together with how it differs from Burbidge's PFA. Finallythe results of two case studies are presented which tested the abilityof EFPA to identify VGs, and assess its usability. (C) 2003 ElsevierB.V. All rights reserved.},
issn = {0925-5273},
institution = {Czech Assoc Sci & Tech Soc},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
number = {3},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
publisher = {ELSEVIER SCIENCE BV},
year = {2003},
annote = {16th International Conference on Production Research (ICPR), CZECH TECHUNIV, PRAGUE, CZECH REPUBLIC, AUG, 2001},
month = {sep},
title = {Combining lean and agile characteristics: Creation of virtual groups by enhanced production flow analysis},
type = {Article; Proceedings Paper},
volume = {85},
doi = {10.1016/S0925-5273(03)0118-X},
keywords = {agile,functional layout,lean,virtual groups},
mendeley-tags = {agile,functional layout,lean,virtual groups},
}

@article{ISI:000255490900012,
author = {M Tavani and G Barbiellini and A Argan and A Bulgarelli and P Caraveo and A Chen and V Cocco and E Costa and G De Paris and E Del Monte and G Di Cocco and I Donnarumma and M Feroci and M Florini and  Froysl and T  and F Fuschino and M Galli and F Gianotti and A Giuliani and Y Evangelista and C Labanti and I Lapshov and F Lazzarotto and P Lipari and F Longo and M Marisaldi and M Mastropietro and F Mauri and S Mereghetti and E Morelli and A Morselli and L Pacciani and A Pellizzoni and F Perotti and P Picozza and C Pontoni and G Porrovecchio and M Prest and G Pucella and M Rapisarda and E Rossi and A Rubini and P Soffitta and M Trifoglio and A Trois and E Vallazza and S Vercellone and A Zarnbra and D Zanello and P Giommi and A Antonelli and C Pittori},
pages = {52--62},
type = {Article; Proceedings Paper},
volume = {588},
abstract = {AGILE is an Italian Space Agency mission dedicated to the exploration ofthe gamma-ray Universe. The AGILE, very innovative instrument, combinesfor the first time a gamma-ray imager (sensitive in the range 30 MeV-50GeV) and a hard X-ray imager (sensitive in the range 18-60 keV). Anoptimal angular resolution and very large fields of view are obtained bythe use of state-of-the-art Silicon detectors integrated in a verycompact instrument. AGILE was successfully launched on April 23, 2007from the Indian base of Sriharikota and was inserted in an optimallow-particle background equatorial orbit. AGILE will provide crucialdata for the study of Active Galactic Nuclei, Gamma-Ray Bursts,unidentified gamma-ray sources, galactic compact objects, supernovaremnants, TeV sources, and fundamental physics by microsecond timing.The AGILE Cycle-1 pointing program started on 2007 December 1, and isopen to the international community through a Guest Observer Program.(c) 2008 Elsevier B.V. All rights reserved.},
year = {2008},
doi = {10.1016/j.nima.2008.01.023},
publisher = {ELSEVIER SCIENCE BV},
issn = {0168-9002},
number = {1-2},
title = {The AGILE space mission},
month = {apr},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
annote = {1st Roma International Conference on Astroparticle Physics, Rome, ITALY,JUN 20-22, 2007},
keywords = {a,astronomical and space-research instrumentation},
mendeley-tags = {a,astronomical and space-research instrumentation},
}

@article{ISI:000080462600004,
author = {Y Y Yusuf and M Sarhadi and A Gunasekaran},
doi = {10.1016/S0925-5273(98)00219-9},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
pages = {33--43},
type = {Article},
month = {may},
volume = {62},
year = {1999},
title = {Agile manufacturing: The drivers, concepts and attributes},
number = {1-2},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
abstract = {Agile manufacturing, a recently popularised concept, has been advocatedas the 21st century manufacturing paradigm. It is seen as the winningstrategy to be adopted by manufacturers bracing. themselves for dramaticperformance enhancements to become national and international leaders inan increasingly competitive market of fast changing customerrequirements. This paper identifies the drivers of agility and discussesthe portfolio of competitive advantages that have emerged over time as aresult of the changing requirements of manufacturing. The need toachieve the competitive advantages of manufacturing in synergy andwithout trade-offs is fundamental to the agile paradigm. To further theunderstanding of agility, this paper reviews the meaning of agility fromdifferent perspectives and suggests a comprehensive definition which canbe adopted as a working definition by practitioners. Four underliningconcepts of agility has emerged from the working definition and thepaper presents a representation of these concepts and theirinteractions. Finally, the paper highlights some of the key enablers ofagility and identifies potential future research directions. (C) 1999Elsevier Science B.V. All rights reserved.},
issn = {0925-5273},
publisher = {ELSEVIER SCIENCE BV},
keywords = {agility,attributes,concepts,drivers,enablers},
mendeley-tags = {agility,attributes,concepts,drivers,enablers},
}

@article{ISI:000241037900009,
author = {Balasubramaniam Ramesh and Lan Cao and Kannan Mohan and Peng Xu},
volume = {49},
journal = {COMMUNICATIONS OF THE ACM},
year = {2006},
month = {oct},
publisher = {ASSOC COMPUTING MACHINERY},
number = {10},
pages = {41--46},
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
title = {Can distributed software development be agile?},
type = {Article},
doi = {10.1145/1164394.1164418},
issn = {0001-0782},
}

@inproceedings{ISI:000183140900022,
author = {P Abrahamsson and J Warsta and M T Siponen and J Ronkainen},
organization = {IEEE; IEEE Comp Soc, Tech Council Software Engn; ACM; ACM SIGSOFT; IBM; NORTHROP GRUMMAN Space Technol; BMW; NOKIA; SUN Microsyst; DaimlerChrysler; Microsoft Res},
title = {New directions on agile methods: A comparative analysis},
year = {2003},
annote = {25th International Conference on Software Engineering (ICSE 2003),PORTLAND, OR, MAY 03-10, 2003},
publisher = {IEEE COMPUTER SOC},
type = {Proceedings Paper},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
doi = {10.1109/ICSE.2003.1201204},
pages = {244--254},
isbn = {0-7695-1877-X},
issn = {0270-5257},
abstract = {Agile software development methods have caught the attention of softwareengineers and researchers worldwide. Scientific research is yet scarce.This paper reports results from a study, which aims to organize, analyzeand make sense out of the dispersed field of agile software developmentmethods. The comparative analysis is performed using the method'slife-cycle coverage, project management support, type of practicalguidance, fitness-for-use and empirical evidence as the analyticallenses. The results show that agile software development methods,without rationalization, cover certain/different phases of the softwaredevelopment life-cycle and most of them do not offer adequate supportfor project management. Yet, many methods still attempt to strive foruniversal solutions (as opposed to situation appropriate) and theempirical evidence is still very limited. Based on the results, newdirections are suggested In principal, it is suggested to place emphasison methodological quality - not method quantity.},
booktitle = {25TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, PROCEEDINGS},
series = {International Conference on Software Engineering},
}

@article{ISI:000251595500020,
author = {D S Zrnic and J F Kimpel and D E Forsyth and A Shapiro and G Crain and R Ferek and J Heimmer and W Benner and T J McNellis and R J Vogt},
abstract = {Weather radars with conventional antenna cannot provide desired volumescan updates at intervals of one minute or less, which is essential forsignificant improvement in warning lead time of impending storm hazards.The agile-beam multimission phased array radar (MPAR) discussed hereinis one potential candidate that can provide faster scanning. It alsooffers a unique potential for multipurpose use to not only sampleweather, but support air traffic needs and track noncooperativeairplanes, thus making it an affordable option. After introducing thebasic idea behind electronic beam steering, the needs for frequentobservations of convective weather are explained. Then, advantages ofthe phased array radar (PAR) for weather monitoring and improving dataquality are examined. To explore and develop weather-relatedapplications of the PAR, a National Weather Radar Testbed (NWRT) hasbeen established in Norman, Oklahoma. The NWRT's main purpose is toaddress the advanced capabilities anticipated within the next decade sothat these could be projected to a possible network of future weatherradars. Examples of data illustrating advantages of this advanced radarare shown, and forthcoming plans are discussed.},
journal = {BULLETIN OF THE AMERICAN METEOROLOGICAL SOCIETY},
volume = {88},
type = {Article},
year = {2007},
address = {45 BEACON ST, BOSTON, MA 02108-3693 USA},
pages = {1753+},
publisher = {AMER METEOROLOGICAL SOC},
doi = {10.1175/BAMS-88-11-1753},
issn = {0003-0007},
number = {11},
title = {Agile-beam phased array radar for weather observations},
month = {nov},
}

@article{ISI:000173405800012,
author = {B Wie and D Bailey and C Heiberg},
volume = {25},
issn = {0731-5090},
doi = {10.2514/2.4854},
type = {Article},
year = {2002},
address = {1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091 USA},
pages = {96--104},
publisher = {AMER INST AERONAUT ASTRONAUT},
number = {1},
title = {Rapid multitarget acquisition and pointing control of agile spacecraft},
abstract = {Study results of developing an attitude control system for agilespacecraft that require rapid retargeting and fast transient settlingare presented. In particular, a nonlinear feedback control logic isdeveloped for large-angle, rapid multitarget acquisition and pointingmaneuvers subject to various physical constraints, including actuatorsaturation, slew rate limit, and control bandwidth limit. The rapidmultitarget acquisition and pointing capability of the proposed attitudecontrol system is demonstrated for an agile spacecraft equipped withredundant single-gimbal control moment gyros. A realistic case ofpointing the line of sight of an imaging satellite in low Earth orbittoward multiple targets on the ground is also briefly discussed.},
journal = {JOURNAL OF GUIDANCE CONTROL AND DYNAMICS},
}

@article{ISI:000080462600013,
author = {J M Sharp and Z Irani and S Desai},
type = {Article},
volume = {62},
pages = {155--169},
number = {1-2},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
abstract = {The business environment is one which is ever more demanding oncompanies, due to its sheer dynamism, which means that they areconstantly having to improve their manufacturing performance.Organisations are continuously having to cope with changing markets thatare unpredictable and more diversified, increasing global competitionand ever changing customer demands. Companies now have to be able to notonly predict variations and changes within the market and socio-economicand political environments but must also be able to adapt and change inaccordance with these environments. As a result, this demands that anorganisation develops and sustains an inherent ability to continuouslychange. Such a demand can be met by adopting the management philosophyof agile manufacturing. Tn embracing such an approach, there are a lotof key concepts and enabling technologies that are required to be ableto implement agile manufacturing and many companies do not know how fardown the path they are towards becoming agile manufacturingorganisations. Hence, in providing a deeper understanding, this paperproposes a conceptual model, based on joint research, which has beendeveloped to identify where UK's best practice companies are in theirquest to become agile manufacturing organisations. In support of this, aquestionnaire has been developed and completed by best practitioners ofmanufacturing, to assess the model, and establish whether they aremaking progress to becoming agile manufacturing organisations. (C) 1999Elsevier Science B.V. All rights reserved.},
publisher = {ELSEVIER SCIENCE BV},
doi = {10.1016/S0925-5273(98)00228-X},
year = {1999},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
issn = {0925-5273},
month = {may},
title = {Working towards agile manufacturing in the UK industry},
keywords = {agility,conceptual model,manufacturing},
mendeley-tags = {agility,conceptual model,manufacturing},
}

@article{ISI:000173128600021,
author = {B Boehm},
doi = {10.1109/2.976920},
journal = {COMPUTER},
abstract = {Although many of their advocates consider the agile and plan-drivensoftware development methods polar opposites, synthesizing the two canprovide developers with a comprehensive spectrum of tools and options.},
year = {2002},
number = {1},
issn = {0018-9162},
publisher = {IEEE COMPUTER SOC},
title = {Get ready for agile methods, with care},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
month = {jan},
pages = {64+},
type = {Article},
volume = {35},
}

@article{ISI:000222980400008,
author = {Y Y Yusuf and A Gunasekaran and E O Adeleye and K Sivayoganathan},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
publisher = {ELSEVIER SCIENCE BV},
year = {2004},
month = {dec},
number = {2},
journal = {EUROPEAN JOURNAL OF OPERATIONAL RESEARCH},
title = {Agile supply chain capabilities: Determinants of competitive objectives},
doi = {10.1016/j.ejor.2003.08.022},
issn = {0377-2217},
abstract = {Changing customer and technological requirements force manufacturers todevelop agile supply chain capabilities in order to be competitive.Therefore, several companies are stressing flexibility and agility inorder to respond, real time, to the unique needs of customers andmarkets. However, the resource competencies required are often difficultto mobilise and retain by single companies. It is therefore imperativefor companies to co-operate and leverage complementary competencies. Tothis end, legally separate and spatially distributed companies arebecoming integrated through Internet-based technologies. The paperreviews emerging patterns in supply chain integration. It also exploresthe relationship between the emerging patterns and attainment ofcompetitive objectives. The results reported in the paper are based onthe data collected from a survey using the standard questionnaire. Thesurvey involved 600 companies in the UK, as part of a larger study ofagile manufacturing. The study was driven by a conceptual model, whichrelates supply chain practices to competitive objectives. The studyinvolves the use of factor analysis to reduce research variables to afew principal components. Subsequently, multiple regression wasconducted to study the relationship amongst the selected variables. Theresults validate the proposed conceptual model and lend credence tocurrent thinking that supply chain integration is a vital tool forcompetitive advantage. (C) 2003 Elsevier B.V. All rights reserved.},
pages = {379--392},
type = {Article},
volume = {159},
keywords = {agile manufacturing,agile supply chains,enterpri},
mendeley-tags = {agile manufacturing,agile supply chains,enterpri},
}

@article{ISI:000245954500003,
author = {Hector M Olague and Letha H Etzkorn and Sampson Gholston and Stephen Quattlebaum},
pages = {402--419},
year = {2007},
month = {jun},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
title = {Empirical validation of three software metrics suites to predict fault-proneness of object-oriented classes developed using highly iterative or agile software development processes},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
publisher = {IEEE COMPUTER SOC},
abstract = {Empirical validation of software metrics suites to predict faultproneness in object-oriented (OO) components is essential to ensuretheir practical use in industrial settings. In this paper, weempirically validate three OO metrics suites for their ability topredict software quality in terms of fault-proneness: the Chidamber andKemerer (CK) metrics, Abreu's Metrics for Object-Oriented Design (MOOD), and Bansiya and Davis' Quality Metrics for Object-Oriented Design(QMOOD). Some CK class metrics have previously been shown to be goodpredictors of initial OO software quality. However, the other two suiteshave not been heavily validated except by their original proposers.Here, we explore the ability of these three metrics suites to predictfault-prone classes using defect data for six versions of Rhino, anopen-source implementation of JavaScript written in Java. We concludethat the CK and QMOOD suites contain similar components and producestatistical models that are effective in detecting error-prone classes.We also conclude that the class components in the MOOD metrics suite arenot good class fault-proneness predictors. Analyzing multivariate binarylogistic regression models across six Rhino versions indicates thesemodels may be useful in assessing quality in OO classes produced usingmodern highly iterative or agile software development processes.},
number = {6},
volume = {33},
doi = {10.1109/TSE.2007.1015},
type = {Article},
issn = {0098-5589},
keywords = {object-oriented,object-oriented software metrics},
mendeley-tags = {object-oriented,object-oriented software metrics},
}

@article{ISI:000173405800014,
author = {E Frazzoli and M A Dahleh and E Feron},
address = {1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091-4344 USA},
volume = {25},
issn = {0731-5090},
pages = {116--129},
number = {1},
doi = {10.2514/2.4856},
publisher = {AMER INST AERONAUT ASTRONAUT},
year = {2002},
journal = {JOURNAL OF GUIDANCE CONTROL AND DYNAMICS},
type = {Article},
abstract = {Planning the path of an autonomous, agile vehicle in a dynamicenvironment is a very complex problem, especially when the vehicle isrequired to use its full maneuvering capabilities. Recent efforts aimedat using randomized algorithms for planning the path of kinematic anddynamic vehicles have demonstrated considerable potential forimplementation on future autonomous platforms. This paper builds uponthese efforts by proposing a randomized path planning architecture fordynamical systems in the presence of fixed and moving obstacles. Thisarchitecture addresses the dynamic constraints on the vehicle's motion,and it provides at the same time a consistent decoupling betweenlow-level control and motion planning. The path planning algorithmretains the convergence properties of its kinematic counterparts. Systemsafety is also addressed in the face of finite computation times byanalyzing the behavior of the algorithm when the available onboardcomputation resources are limited, and the planning must be performed inreal time. The proposed algorithm can be applied to vehicles whosedynamics are described either by ordinary differential equations or byhigher-level, hybrid representations. Simulation examples involving aground robot and a small autonomous helicopter are presented anddiscussed.},
title = {Real-time motion planning for agile autonomous vehicles},
}

@article{ISI:000243915300010,
author = {Tsung-Hsien Lin and Yu-Jen Lai},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
pages = {340--349},
title = {An agile VCO frequency-calibration technique for a 10-GHz CMOS PLL},
type = {Article},
journal = {IEEE JOURNAL OF SOLID-STATE CIRCUITS},
abstract = {This paper reports an agile VCO frequency calibration technique and itsapplication on a 10-GHz CMOS integer-N phase-locked loop. The proposedcalibration method accomplishes efficient search for an optimum VCOdiscrete tuning curve among a group of frequency sub-bands. The agilityis attributed to a proposed frequency comparison technique which isbased on measuring the period difference between two signals. Othermixed-signal circuits are also developed to facilitate this approach.The PLL incorporating the proposed calibration technique is implementedin a 0.18-mu m CMOS process. The measured PLL phase noise at 10 GHz is-102 dBc/Hz at 1-MHz offset frequency and the reference spurs are lowerthan -48 dBc. The PLL consumes 44 mW in the low-current mode. Thecalibration time is less than 4 mu s.},
volume = {42},
issn = {0018-9200},
doi = {10.1109/JSSC.2006.889360},
number = {2},
year = {2007},
month = {feb},
keywords = {calibration,cmos integrated circuits,frequency s},
mendeley-tags = {calibration,cmos integrated circuits,frequency s},
}

@article{ISI:000182753200046,
author = {M Prest and G Barbiellini and G Bordignon and G Fedel and F Liello and F Longo and C Pontoni and E Vallazza},
abstract = {AGILE (Light Imager for Gamma-ray Astrophysics) is the first smallscientific mission of ASI, the Italian Space Agency. It is a light (100kg for the scientific instrument) satellite for the detection ofgamma-ray sources in the energy range 30 MeV-50 GeV within a large fieldof view (1 of the sky). It is planned to be operational in the years2003-2006, a period in which no other gamma-ray mission in the sameenergy range is foreseen.AGILE is made of a silicon tungsten tracker, a CsI(Tl) minicalorimeter(1.5X(0)), an anticoincidence system of segmented plastic scintillatorsand a X-ray imaging detector sensitive in the 10-40 keV range. Thetracker consists of 14 planes, each of them made of two layers of 16single-sided, AC coupled, 410 mum thick, 9.5 x 9.5 cm(2) silicondetectors with a readout pitch of 242 mum and a floating strip. Thereadout ASIC is the TAA1, an analog-digital, low noise, self-triggeringASIC used in a very low power configuration (<400 &mu;W/channel) withfull analog readout. The trigger of the satellite is given by thetracker. The total number of readout channels is around 43 000.We present a detailed description of the tracker, its trigger andreadout logic, its assembly procedures and the prototype performance inseveral testbeam periods at the CERN PS. (C) 2002 Elsevier Science B.V.All rights reserved.},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
number = {1},
title = {The AGILE silicon tracker: an innovative gamma-ray instrument for space},
issn = {0168-9002},
type = {Article; Proceedings Paper},
pages = {280--287},
publisher = {ELSEVIER SCIENCE BV},
annote = {10th International Workshop on Vertex Detectors, BRUNNEN, SWITZERLAND,SEP 23-28, 2001},
year = {2003},
month = {mar},
volume = {501},
doi = {10.1016/S0168-9002(02)02047-8},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
keywords = {floa,satellite,self-triggering,silicon detector},
mendeley-tags = {floa,satellite,self-triggering,silicon detector},
}

@article{ISI:000283606800005,
author = {Xinxing Luo and Chong Wu and Duska Rosenberg and David Barnes},
title = {Supplier selection in agile supply chains: An information-processing model and an illustration},
pages = {249--262},
volume = {15},
year = {2009},
type = {Article},
number = {4},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
month = {dec},
publisher = {ELSEVIER SCI LTD},
issn = {1478-4092},
abstract = {Agile supply chains need to be highly flexible in order to reconfigurequickly in response to changes in their environment. An effectivesupplier selection process is essential for this. This paper develops amodel that helps overcome the information-processing difficultiesinherent in screening a large number of potential suppliers in the earlystages of the selection process. Based on radial basis functionartificial neural network (RBF-ANN), the model enables potentialsuppliers to be assessed against multiple criteria using bothquantitative and qualitative measures. Its efficacy is illustrated usingempirical data from the Chinese electrical appliance and equipmentmanufacturing industries. (C) 2009 Elsevier Ltd. All rights reserved.},
doi = {10.1016/j.pursup.2009.05.004},
journal = {JOURNAL OF PURCHASING AND SUPPLY MANAGEMENT},
keywords = {agile supply chain,artificial,supplier selection},
mendeley-tags = {agile supply chain,artificial,supplier selection},
}

@article{ISI:000367200400009,
author = {Guy Millot and Stephane Pitois and Ming Yan and Tatevik Hovhannisyan and Abdelkrim Bendahmane and Theodor W Haensch and Nathalie Picque},
year = {2016},
abstract = {Spectroscopic gas sensing and its applications to, for example, tracedetection or chemical kinetics, require ever more demanding measurementtimes, acquisition rates, sensitivities, precisions and broad tuningranges. Here, we propose a new approach to near-infrared molecularspectroscopy, utilizing advanced concepts of optical telecommunicationsand supercontinuum photonics. We generate, without mode-locked lasers,two frequency combs of slightly different repetition frequencies andmoderate, but rapidly tunable, spectral span. The output of afrequency-agile continuous-wave laser is split and sent into twoelectro-optic intensity modulators. Flat-top low-noise frequency combsare produced by wave-breaking in a nonlinear optical fibre of normaldispersion. With a dual-comb spectrometer, we record Doppler-limitedspectra spanning 60 GHz within 13 mu s and an 80 kHz refresh rate, at atuning speed of 10 nm s(-1). The sensitivity for weak absorption isenhanced by a long gas-filled hollow-core fibre. New opportunities forreal-time diagnostics may be opened up, even outside the laboratory.},
doi = {10.1038/NPHOTON.2015.250},
address = {MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND},
title = {Frequency-agile dual-comb spectroscopy},
pages = {27--U37},
type = {Article},
issn = {1749-4885},
number = {1},
journal = {NATURE PHOTONICS},
publisher = {NATURE PUBLISHING GROUP},
month = {jan},
volume = {10},
}

@article{ISI:000077216500002,
author = {S Thomke and D Reinertsen},
publisher = {UNIV CALIF},
pages = {8+},
type = {Article},
year = {1998},
number = {1},
doi = {10.2307/41165973},
abstract = {As product complexity and the rate of market change have dramaticallyincreased over the last years, firms find it increasingly difficult toforecast product requirements in their development processes. Thisarticle redefines the problem from one of improving forecasting to oneof increasing product development agility and thus reducing the need foraccurate long-term forecasts. It introduces the notion of developmentflexibility, shows how it can be measured, and presents results from alarge empirical study on integrated systems development, which foundthat projects using flexible technologies outperformed projects usinginflexible technologies by a factor of 2.2 (in person-months). Finally,the article proposes three major strategies for introducing flexibilityinto organizations. These strategies can help firms increase theiragility and position themselves to succeed in accelerating and moreturbulent markets.},
volume = {41},
title = {Agile product development: Managing development flexibility in uncertain environments},
issn = {0008-1256},
journal = {CALIFORNIA MANAGEMENT REVIEW},
address = {GRAD SCH BUSINESS ADMIN, BERKELEY, CA 94720 USA},
}

@article{ISI:000256966600004,
author = {M Pikkarainen and J Haikara and O Salo and P Abrahamsson and J Still},
type = {Article},
number = {3},
volume = {13},
publisher = {SPRINGER},
title = {The impact of agile practices on communication in software development},
year = {2008},
month = {jun},
pages = {303--337},
address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
issn = {1382-3256},
journal = {EMPIRICAL SOFTWARE ENGINEERING},
abstract = {Agile software development practices such as eXtreme Programming (XP)and SCRUM have increasingly been adopted to respond to the challenges ofvolatile business environments, where the markets and technologiesevolve rapidly and present the unexpected. In spite of the encouragingresults so far, little is known about how agile practices affectcommunication. This article presents the results from a study whichexamined the impact of XP and SCRUM practices on communication withinsoftware development teams and within the focal organization. Theresearch was carried out as a case study in F-Secure where two agilesoftware development projects were compared from the communicationperspective. The goal of the study is to increase the understanding ofcommunication in the context of agile software development: internallyamong the developers and project leaders and in the interface betweenthe development team and stakeholders (i.e. customers, testers, otherdevelopment teams). The study shows that agile practices improve bothinformal and formal communication. However, it further indicates that,in larger development situations involving multiple externalstakeholders, a mismatch of adequate communication mechanisms cansometimes even hinder the communication. The study highlights the factthat hurdles and improvements in the communication process can bothaffect the feature requirements and task subtask dependencies asdescribed in coordination theory. While the use of SCRUM and some XPpractices facilitate team and organizational communication of thedependencies between product features and working tasks, the use ofagile practices requires that the team and organization use alsoadditional plan-driven practices to ensure the efficiency of externalcommunication between all the actors of software development.},
doi = {10.1007/s10664-008-9065-9},
keywords = {agile software development practices,communicatio},
mendeley-tags = {agile software development practices,communicatio},
}

@article{ISI:000245650200061,
author = {Carlos Prieto and Javier De Las Rivas},
doi = {10.1093/nar/gkl128},
issn = {0305-1048},
publisher = {OXFORD UNIV PRESS},
title = {APID: Agile Protein Interaction DataAnalyzer},
type = {Article},
volume = {34},
year = {2006},
abstract = {Agile Protein Interaction DataAnalyzer (APID) is an interactivebioinformatics web tool developed to integrate and analyze in a unifiedand comparative platform main currently known information aboutprotein-protein interactions demonstrated by specific small-scale orlarge-scale experimental methods. At present, the application includesinformation coming from five main source databases enclosing an unifiedsever to explore > 35 000 different proteins and 111 000 differentproven interactions. The web includes search tools to query and browseupon the data, allowing selection of the interaction pairs based incalculated parameters that weight and qualify the reliability of eachgiven protein interaction. Such parameters are for the `proteins':connectivity, cluster coefficient, Gene Ontology ( GO) functionalenvironment, GO environment enrichment; and for the `interactions':number of methods, GO overlapping, iPfam domain-domain interaction. APIDalso includes a graphic interactive tool to visualize selectedsub-networks and to navigate on them or along the whole interactionnetwork. The application is available open access athttp://bioinfow.dep.usal.es/apid/.},
pages = {W298--W302},
address = {GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND},
month = {jul},
number = {SI},
journal = {NUCLEIC ACIDS RESEARCH},
}

@article{ISI:000229359800020,
author = {S Nerur and R Mahapatra and G Mangalaraj},
pages = {72--78},
journal = {COMMUNICATIONS OF THE ACM},
type = {Article},
volume = {48},
doi = {10.1145/1060710.1060712},
number = {5},
title = {Challenges of emigrating to agile methodologies},
issn = {0001-0782},
publisher = {ASSOC COMPUTING MACHINERY},
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
month = {may},
year = {2005},
}

@article{ISI:000071490100010,
author = {C R Duguay and  L and S ry and F Pasin},
abstract = {In industrial management, the 1980s marked the end of the twentiethcentury, an epoch dominated by US manufacturers, the alleged masters ofmass production. This system has now been outstripped in several dynamicsectors by flexible/agile production. Increases in the pace oftechnological progress, training and aspirations have made the moderncontext so dynamic that firms which manage to harness the creativity andinitiative of a good part of their workforce have an advantage overthose that can only count on the input of their experts and managers. Insectors undergoing relatively broad and rapid change, twenty-firstcentury firms must adopt a more flexible and innovative type oforganization to achieve manufacturing excellence.},
pages = {1183+},
number = {11-12},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
issn = {0144-3577},
type = {Article},
volume = {17},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
year = {1997},
doi = {10.1108/01443579710182936},
title = {From mass production to flexible/agile production},
keywords = {agile production,flexible manufacturing systems},
mendeley-tags = {agile production,flexible manufacturing systems},
}

@article{ISI:000235785800021,
author = {C S Ruf and S M Gross and S Misra},
month = {mar},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
number = {3},
pages = {694--706},
type = {Article},
year = {2006},
journal = {IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
volume = {44},
abstract = {A new type of microwave radiometer detector has been developed that iscapable of identifying high and low levels of radio-frequencyinterference (RFI) and of reducing or eliminating its effect on themeasured brightness temperatures. High-level, localized RFI can beeasily identified by its unnatural appearance in brightness temperatureimagery. Low-level or persistent RFI can be much more difficult toidentify and filter out. The agile digital detector (ADD) candiscriminate between RFI and natural thermal emission signals bydirectly measuring higher order moments of the signal than the variancethat is traditionally measured. After detection, the ADD then usesspectral filtering methods to selectively remove the RFI. ADDperformance is experimentally verified in controlled laboratory testsand in the field near a commercial air traffic control radar. High-levelRFI is easily identified and removed. Very low level RFI contamination,with power levels as low as the radiometric measurement uncertainty ofthe radiometer, is also shown to be reliably detected and removed.},
issn = {0196-2892},
title = {RFI detection and mitigation for microwave radiometry with an agile digital detector},
doi = {10.1109/TGRS.2005.861411},
keywords = {microwave radiometry,radio spectrum management},
mendeley-tags = {microwave radiometry,radio spectrum management},
}

@article{ISI:000080462600009,
author = {J B Naylor and M M Naim and D Berry},
number = {1-2},
abstract = {As the lean thinking and agile manufacturing paradigms have beendeveloped there has been a tendency to view them in a progression and inisolation. This article shows that this is too simplistic a view. Theuse of either paradigm has to be combined with a total supply chainstrategy particularly considering market knowledge and positioning ofthe decoupling point as agile manufacturing is best suited to satisfyinga fluctuating demand and lean manufacturing requires a level schedule.This view is supported by consideration of a PC supply chain case study.(C) 1999 Elsevier Science B.V. All rights reserved.},
pages = {107--118},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
volume = {62},
issn = {0925-5273},
publisher = {ELSEVIER SCIENCE BV},
title = {Leagility: Integrating the lean and agile manufacturing paradigms in the total supply chain},
type = {Article},
month = {may},
year = {1999},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
keywords = {agile manufacturing,lean thinking,supply chain m},
mendeley-tags = {agile manufacturing,lean thinking,supply chain m},
}

@article{ISI:000231943500006,
author = {J Erickson and K Lyytinen and K Siau},
doi = {10.4018/jdm.2005100105},
address = {701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA},
pages = {88--100},
abstract = {While there are many claims for the successful use of extremeprogramming (XP) and agile modeling (AM), and the proponents can oftenbe vocal in the extreme regarding their supposed benefits, researchevidence supporting proponents' claims is somewhat lacking. Currently,the only research appearing to investigate the phenomena consists of twoprominent streams. A small number of case studies and experience reportsthat generally promote the success of XP in various developmentenvironments, and a well-established stream of research into pairprogramming has generated results that in part support the idea of XPResearch into AM appears to be even more sparse than that for XP Casestudies, comparative analyses, and experience reports comprise themajority of the research in the area, while very few empirical researchefforts have been conducted. This article reviews the state of researchin XP and AM, and recommends areas that could benefit from furtherstudy. Since nearly all empirical XP research relates to pairprogramming, a closer look into the unstudied XP core practices would bebeneficial, although interaction between related core practice areascould confound such efforts. It might also be possible to group relatedcore XP concepts and study the groups individually. Finally, there arethose who claim that XP and AM, or even agility in general, are reallynothing more than a repackaging of old concepts. This claim needs to beinvestigated.},
journal = {JOURNAL OF DATABASE MANAGEMENT},
year = {2005},
issn = {1063-8016},
type = {Review},
title = {Agile modeling, agile software development, and extreme programming: The state of research},
publisher = {IGI PUBL},
volume = {16},
number = {4},
keywords = {agile modelin,agile software development,agility},
mendeley-tags = {agile modelin,agile software development,agility},
}

@article{ISI:000255824100022,
author = {Juan M Herrerias and Jonathan A Leighton and Guido Costamagna and Anthony Infantolino and Rami Eliakim and Doron Fischer and David T Rubin and Howard D Manten and Eitan Scapa and Douglas R Morgan and Ari J Bergwerk and Binyamin Koslowsky and Samuel N Adler},
number = {6},
title = {Agile patency system eliminates risk of capsule retention in patients with known intestinal strictures who undergo capsule endoscopy},
type = {Article; Proceedings Paper},
month = {may},
pages = {902--909},
address = {360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA},
volume = {67},
year = {2008},
doi = {10.1016/j.gie.2007.10.063},
annote = {3rd International Symposium on Natural Orifice Translumenal EndoscopicSurgery, San Francisco, CA, JUL 10, 2008},
issn = {0016-5107},
publisher = {MOSBY-ELSEVIER},
abstract = {Background: Capsule endoscopy (CE) of the small bowel has become astandard diagnostic tool, but there have been concerns regarding therisk of capsule retention in certain high-risk groups. The Agile patencysystem, an ingestible and dissolvable capsule with an external scanner,was developed to allow physicians to perform CE with greater confidencethat the capsule will be safely excreted in patients at risk for capsuleretention.Objective: Our purpose was to assess the ability of the device to helpphysicians identify which patients with known strictures may safelyundergo CE.Design: Patients with known strictures ingested the new patency capsuleand under-went periodic scanning until it was excreted. The intestinaltract was considered to be sufficiently patent if the capsule wasexcreted intact or if the capsule was not detected by the scanner at 30hours after ingestion. if patency was established, then standard CE wasperformed.Setting: International multicenter study.Patients: A total of 106 patients with known strictures.Intervention: Agile patency system.Main Outcome Measurements: Performance and safety of Agile patencysystem.Results: A total of 106 patients ingested the patency capsule.Fifty-nine (56%) excreted it intact and subsequently underwent CE.There were no cases of capsule retention. Significant findings on CEwere found in 24 (41%). There were 3 severe adverse events.Conclusions: These results suggest that the Agile patency system is auseful tool for physicians to use before CE in patients with stricturesto avoid retention. This group of patients may have a high yield ofclinically significant findings at CE. This capsule may determinewhether patients who have a contraindication to CE may safely undergo CEand obtain useful diagnostic information.},
journal = {GASTROINTESTINAL ENDOSCOPY},
}

@article{ISI:000073433700004,
author = {A Gunasekaran},
issn = {0020-7543},
address = {ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND},
type = {Article},
publisher = {TAYLOR & FRANCIS LTD},
year = {1998},
number = {5},
doi = {10.1080/002075498193291},
abstract = {Tougher competitive situations have led to increasing attention beingpaid to customer satisfaction, of which timely and customized servicesare the key concepts. As the product life cycle becomes shortened, highproduct quality becomes necessary for survival. Markets become highlydiversified and global, and continuous and unexpected change become thekey factors for success. The need for a method of rapidly andcost-effectively developing products, production facilities andsupporting software, including design, process planning and shop floorcontrol system has led to the concept of agile manufacturing.Agile manufacturing can be defined as the capability to survive andprosper in a competitive environment of continuous and unpredictablechange by reacting quickly and effectively to changing markets, drivenby customer-designed products and services. This article details the keyconcepts and enablers of agile manufacturing. The key enablers of agilemanufacturing include: (i) virtual enterprise formation tools/metrics;(ii) physically distributed manufacturing architecture and teams; (iii)rapid partnership formation tools/metrics; (iv) concurrent engineering;(v) integrated product/production/business information system; (vi)rapid prototyping tools; and (vii) electronic commerce. A conceptualframework for the development of an agile manufacturing system andfuture research directions are presented in this paper. This frameworktakes into account the customization and system integration with thehelp of business process redesign, legal issues, concurrent engineering,computer-integrated manufacturing, cost management, total qualitymanagement and information technology.},
pages = {1223--1247},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
title = {Agile manufacturing: enablers and an implementation framework},
volume = {36},
month = {may},
}

@article{ISI:000238914800019,
author = {Neil R Smith and Don C Abeysinghe and Joseph W Haus and Jason Heikenfeld},
number = {14},
volume = {14},
year = {2006},
journal = {OPTICS EXPRESS},
issn = {1094-4087},
doi = {10.1364/OE.14.006557},
address = {2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA},
abstract = {A novel basis for beam steering with electrowetting microprisms (EMPs)is reported. EMPs utilize electrowetting modulation of liquid contactangle in order to mimic the refractive behavior for various classicalprism geometries. Continuous beam steering through an angle of 14degrees (+/- 7 degrees) has been demonstrated with a liquid index of},
month = {jul},
pages = {6557--6563},
title = {Agile wide-angle beam steering with electrowetting microprisms},
n = {1.359. Experimental results are well-matched to theoretical behaviorup to the point of electrowetting contact-angle saturation. Projectionsshow that use of higher index liquids (n similar to 1.6) will result insteering through similar to 30 degrees(+/- 15 degrees). Fundamentalfactors defining achievable deflection range, and issues for Ladar use,are reviewed. This approach is capable of good switching speed (similarto ms), polarization independent operation, modulation of beamfield-of-view (lensing), and high steering efficiency that isindependent of deflection angle. (c) 2006 Optical Society of America.},
publisher = {OPTICAL SOC AMER},
type = {Article},
}

@article{ISI:000228020200008,
author = {P B Pearman and T W J Garner},
address = {9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND},
number = {4},
month = {apr},
issn = {1461-023X},
type = {Article},
publisher = {BLACKWELL PUBLISHING LTD},
title = {Susceptibility of Italian agile frog populations to an emerging strain of Ranavirus parallels population genetic diversity},
pages = {401--408},
abstract = {Western populations of the Italian agile frog (Rana latastei) experiencewidespread genetic depletion. Based on population genetic theory,molecular models of immunity and previous empirical studies, populationgenetic depletion predicts increased susceptibility of populations toemergent pathogens. We experimentally compared susceptibility of R.latastei populations upon exposure to an emerging strain of Ranavirus,frog virus 3 (FV3), using six populations spanning the geographicalrange and range of population genetic diversity found in nature. Ourfindings confirm this prediction, suggesting that the loss of geneticdiversity accompanying range expansion and population isolation iscoincident with increased mortality risk from an emergent pathogen. Lossof heterozygosity and escape from selection imposed by immunologicallycross-reactive pathogens may potentially generate range-wide variationin disease resistance.},
doi = {10.1111/j.1461-0248.2005.00735.x},
journal = {ECOLOGY LETTERS},
volume = {8},
year = {2005},
keywords = {amphibian declines,disease emergence,frog virus},
mendeley-tags = {amphibian declines,disease emergence,frog virus},
}

@article{ISI:000308110200009,
author = {Izunildo Cabral and Antonio Grilo and Virgilio Cruz-Machado},
volume = {50},
number = {17, SI},
doi = {10.1080/00207543.2012.657970},
title = {A decision-making model for Lean, Agile, Resilient and Green supply chain management},
year = {2012},
publisher = {TAYLOR & FRANCIS LTD},
type = {Article},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
abstract = {In modern business environments, an effective supply chain management(SCM) is crucial to business continuity. Competition between supplychains (SC) has replaced the traditional competition between companies.Lean, Agile, Resilient and Green (LARG) paradigms are advocated as thefoundation of a competitive SCM. To make a supply chain morecompetitive, capable of responding to the demands of customers withagility and capable of responding effectively to unexpected disturbance,in conjugation with environmental responsibilities and the necessity toeliminate processes that add no value, companies must implement a set ofLARG SCM practices and key performance indicators (KPI) to measure theirinfluence on the SC performance. However, the selection of the best LARGSCM practices and KPIs is a complex problem, involving dependencies andfeedbacks. This paper proposes an integrated LARG analytic networkprocess (ANP) model to support decision-making in choosing the mostappropriate practices and KPIs to be implemented by companies in an SC.To validate the model in an exploratory approach, a case study in anautomaker supply chain is presented.},
issn = {0020-7543},
pages = {4830--4845},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
keywords = {agile,anp,green,lean,resilient,scm},
mendeley-tags = {agile,anp,green,lean,resilient,scm},
}

@article{ISI:000275321000002,
author = {M Marisaldi and F Fuschino and C Labanti and M Galli and F Longo and E Del Monte and G Barbiellini and M Tavani and A Giuliani and E Moretti and S Vercellone and E Costa and S Cutini and I Donnarumma and Y Evangelista and M Feroci and I Lapshov and F Lazzarotto and P Lipari and S Mereghetti and L Pacciani and M Rapisarda and P Soffitta and M Trifoglio and A Argan and F Boffelli and A Bulgarelli and P Caraveo and P W Cattaneo and A Chen and V Cocco and  D'Amm and F o and G De Paris and G Di Cocco and G Di Persio and A Ferrari and M Fiorini and  Froysl and T  and F Gianotti and A Morselli and A Pellizzoni and F Perotti and P Picozza and G Piano and M Pilia and M Prest and G Pucella and A Rappoldi and A Rubini and S Sabatini and E Striani and A Trois and E Vallazza and V Vittorini and A Zambra and D Zanello and L A Antonelli and S Colafrancesco and D Gasparrini and P Giommi and C Pittori and B Preger and P Santolamazza and F Verrecchia and L Salotti},
journal = {JOURNAL OF GEOPHYSICAL RESEARCH-SPACE PHYSICS},
volume = {115},
doi = {10.1029/2009JA014502},
publisher = {AMER GEOPHYSICAL UNION},
address = {2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA},
month = {mar},
type = {Article},
title = {Detection of terrestrial gamma ray flashes up to 40 MeV by the AGILE satellite},
abstract = {We report the detection by the Astrorivelatore Gamma a Immagini Leggero(AGILE) satellite of terrestrial gamma ray flashes (TGFs) obtained withthe minicalorimeter (MCAL) detector operating in the energy range0.3-100 MeV. We select events typically lasting a few milliseconds withspectral and directional selections consistent with the TGFcharacteristics previously reported by other space missions. During theperiod 1 June 2008 to 31 March 2009 we detect 34 high-confidence eventsshowing millisecond durations and a geographical distribution peakedover continental Africa and Southeast Asia. For the first time,AGILE-MCAL detects photons associated with TGF events up to 40 MeV. Wedetermine the cumulative spectral properties of the spectrum in therange 0.5-40 MeV, which can be effectively described by a Bremsstrahlungspectrum. We find that both the TGF cumulative spectral properties andtheir geographical distribution are in good agreement with the ReuvenRamaty High Energy Solar Spectroscopic Imager (RHESSI) results.},
year = {2010},
issn = {0148-0227},
}

@article{ISI:000271681800011,
author = {Subhas Ch Misra and  ra and Vinod Kumar and Uma Kumar},
month = {nov},
doi = {10.1016/j.jss.2009.05.052},
publisher = {ELSEVIER SCIENCE INC},
type = {Article},
volume = {82},
abstract = {Agile software development (ASD) is an emerging approach in softwareengineering, initially advocated by a group of 17 software professionalswho practice a set of ``lightweight'' methods, and share a common setof values of software development. In this paper, we advance thestate-of-the-art of the research in this area by conducting asurvey-based ex-post-facto study for identifying factors from theperspective of the ASD practitioners that will influence the success ofprojects that adopt ASD practices. In this paper, we describe ahypothetical success factors framework we developed to address ourresearch question, the hypotheses we conjectured, the researchmethodology, the data analysis techniques we used to validate thehypotheses, and the results we obtained from data analysis. The studywas conducted using an unprecedentedly large-scale survey-basedmethodology, consisting of respondents who practice ASD and who hadexperience practicing plan-driven software development in the past. Thestudy indicates that nine of the 14 hypothesized factors havestatistically significant relationship with ``Success''. The importantsuccess factors that were found are: customer satisfaction, customercollaboration, customer commitment, decision time, corporate culture,control, personal characteristics, societal culture, and training andlearning. (C) 2009 Elsevier Inc. All rights reserved.},
pages = {1869--1890},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
year = {2009},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
number = {11},
title = {Identifying some important success factors in adopting agile software development practices},
issn = {0164-1212},
keywords = {agile software,success factors},
mendeley-tags = {agile software,success factors},
}

@article{ISI:A1997YE58900002,
author = {R DeVor and R Graves and J J Mills},
publisher = {CHAPMAN HALL LTD},
pages = {813--823},
address = {2-6 BOUNDARY ROW, LONDON, ENGLAND SE1 8HN},
issn = {0740-817X},
title = {Agile manufacturing research: accomplishments and opportunities},
abstract = {Agile manufacturing is a new expression that is used to represent theability of a producer of goods and services to thrive in the face ofcontinuous change. These changes can occur in markets, in technologies,in business relationships and in all facets of the business enterprise.This paper discusses the genesis of several of the Agile ManufacturingResearch Institutes (AMRIs) and their on-going activities and results todale. A vision for agile manufacturing research is articulated andinitial accomplishments identified. Additional research needs are alsodiscussed.},
volume = {29},
journal = {IIE TRANSACTIONS},
year = {1997},
number = {10},
type = {Article},
month = {oct},
}

@article{ISI:000231388800019,
author = {B Boehm and R Turner},
abstract = {Agile software development processes have shown positive impacts oncost, schedule, and customer satisfaction. However, most implementationsof agile processes have been in smaller-scale, software-onlyenvironments. In March 2004, a group of researchers and practitionersaddressed the implementation of agile processes in largesystems-engineering projects that rely on traditional developmentprocesses and artifacts. They identified three management challengeareas. Here, the authors discuss numerous ways in which to address them.},
publisher = {IEEE COMPUTER SOC},
title = {Management challanges to implementing Agile Processes in traditional development organizations},
number = {5},
pages = {30+},
type = {Article},
year = {2005},
volume = {22},
doi = {10.1109/MS.2005.129},
issn = {0740-7459},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
journal = {IEEE SOFTWARE},
}

@article{ISI:000078667300001,
author = {L M Meade and J Sarkis},
abstract = {The objective of this paper is to introduce a decision methodology andstructure for manufacturing land organizational) agility improvement.The methodology allows for the evaluation of alternatives (e.g.projects) to help organizations become more agile, with a specificobjective of improving the manufacturing business processes. An agileenterprise is one whose processes are designed to respond effectively tounanticipated change. One of the difficulties in designing and analysingbusiness processes, in general, is that they are operational designsthat need to incorporate strategic attributes. In order to evaluatealternatives that impact the business processes, a networkedhierarchical analysis model based on the various characteristics ofagility, is proposed. This evaluation model will be based on theanalytic network process methodology for solving complex and systemicdecisions. An actual example of a small manufacturing enterpriseprovides some managerial insights into the methodology.},
issn = {0020-7543},
address = {ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
doi = {10.1080/002075499191751},
type = {Article},
pages = {241--261},
month = {jan},
year = {1999},
number = {2},
title = {Analyzing organizational project alternatives for agile manufacturing processes: an analytical network approach},
publisher = {TAYLOR & FRANCIS LTD},
volume = {37},
}

@article{ISI:000180224400015,
author = {Y Y Yusuf and E O Adeleye},
type = {Article},
volume = {40},
year = {2002},
issn = {0020-7543},
pages = {4545--4562},
abstract = {In response to changing success factors and environmental pressures,companies are aspiring to break out of mass production and become leanor agile. Whereas performance enhancements of lean practices have beendemonstrated, it is now the case that markets have become increasinglycharacterized by turbulence, a situation in which reliance on leanpractices is insufficient, and that survival requires adoption of agilepractices. As a result, a comparative study of lean and agilemanufacturing with a related survey of current practices in the UK wascarried out, the results of which is presented in this paper. The paperexplored the threats to lean and the drivers of agile manufacturing.Using data from a questionnaire survey, four hypotheses were tested,which was indicative of the benefits of agile manufacturing. In contrastto their lean counterparts, agile companies paid attention to a widerrange of competitive capabilities. They therefore had a lower range ofmean scores on competitive capabilities. Independent sample tests ofsignificant difference in business performance measures revealed thatthe agile companies consistently outperformed their lean competitors onall business performance measures studied. In addition, a wider range ofcompetitive capabilities and performance measures of the agile companiescorrelated significantly and positively whilst such correlation wasobserved for only a narrow range of capabilities and performancemeasures for lean companies. The results suggest that competingsimultaneously on multiple competitive capabilities enhance performancebetter than a rather narrow focus on cost and quality.},
doi = {10.1080/00207540210157141},
address = {4 PARK SQUARE, MILTON PARK,, ABINGDON OX14 4RN, OXON, ENGLAND},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
month = {nov},
publisher = {TAYLOR & FRANCIS LTD},
title = {A comparative study of lean and agile manufacturing with a related survey of current practices in the UK},
number = {17},
}

@article{ISI:000080462600008,
author = {A Gunasekaran},
number = {1-2},
publisher = {ELSEVIER SCIENCE BV},
pages = {87--105},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
abstract = {Agile manufacturing (AM) is a new concept in manufacturing intended toimprove the competitiveness of firms. Manufacturing processes based onAM are characterized by customer-supplier integrated process for productdesign, manufacturing, marketing, and support services. This needsdecision-making at functional knowledge levels, stable unit costs,flexible manufacturing, easy access to integrated data, and modularproduction facilities. Agile manufacturing requires enriching of thecustomer, co-operating with competitors, organizing to manage change,uncertainty and complexity, and leveraging people and information. Inthe recent years, a number of research papers have been published in thearea of AM. However, a framework for the development of AM has notreceived due attention from both researchers and practitioners.Realizing the importance of agile manufacturing in the 21st centurymanufacturing competitiveness, an attempt has been made in this paper toreview the literature available on AM with the objective to: (i)identify key strategies and techniques of AM,(ii) suggest some futureresearch directions and (iii) develop a framework for the development ofagile manufacturing systems (AMSs) along four key dimensions whichinclude strategies, technologies, systems and people. (C) 1999 ElsevierScience B.V. All rights reserved.},
title = {Agile manufacturing: A framework for research and development},
month = {may},
type = {Article},
doi = {10.1016/S0925-5273(98)00222-9},
volume = {62},
year = {1999},
issn = {0925-5273},
keywords = {agile manufacturing,deve,future research,review},
mendeley-tags = {agile manufacturing,deve,future research,review},
}

@article{ISI:000265879200001,
author = {Bhuvan Urgaonkar and Prashant Shenoy and  Ch and Abhishek ra and Pawan Goyal and Timothy Wood},
doi = {10.1145/1342171.1342172},
annote = {2nd International Conference on Autonomic Computing (ICAC 2005),Seattle, WA, JUN 13-16, 2005},
journal = {ACM TRANSACTIONS ON AUTONOMOUS AND ADAPTIVE SYSTEMS},
title = {Agile Dynamic Provisioning of Multi-Tier Internet Applications},
institution = {IEEE Comp Soc; Natl Sci Fdn},
address = {2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA},
volume = {3},
abstract = {Dynamic capacity provisioning is a useful technique for handling themulti-time-scale variations seen in Internet workloads. In this article,we propose a novel dynamic provisioning technique for multi-tierInternet applications that employs (1) a flexible queuing model todetermine how much of the resources to allocate to each tier of theapplication, and (2) a combination of predictive and reactive methodsthat determine when to provision these resources, both at large andsmall time scales. We propose a novel data center architecture based onvirtual machine monitors to reduce provisioning overheads. Ourexperiments on a forty-machine Xen/Linux-based hosting platformdemonstrate the responsiveness of our technique in handling dynamicworkloads. In one scenario where a flash crowd caused the workload of athree-tier application to double, our technique was able to double theapplication capacity within five minutes, thus maintaining response-timetargets. Our technique also reduced the overhead of switching serversacross applications from several minutes to less than a second, whilemeeting the performance targets of residual sessions.},
month = {mar},
year = {2008},
publisher = {ASSOC COMPUTING MACHINERY},
issn = {1556-4665},
number = {1},
type = {Article},
keywords = {design,experimentation,internet app,performance},
mendeley-tags = {design,experimentation,internet app,performance},
}

@article{ISI:000184713800006,
author = {R Stratton and R D H Warburton},
number = {2},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
volume = {85},
institution = {Czech Assoc Sci & Tech Soc},
annote = {16th International Conference on Production Research (ICPR), CZECH TECHUNIV, PRAGUE, CZECH REPUBLIC, AUG, 2001},
doi = {10.1016/S0925-5273(03)00109-9},
abstract = {Lean supply is closely associated with enabling flow and the eliminationof wasteful variation within the supply chain. However, lean operationsdepend on level scheduling and the growing need to accommodate varietyand demand uncertainty has resulted in the emergence of the concept ofagility. This paper explores the role of inventory and capacity inaccommodating such variation and identifies how TRIZ separationprinciples and TOC tools may be combined in the integrated developmentof responsive and efficient supply chains. A detailed apparel industrycase study is used to illustrate the application of these concepts andtools. (C) 2003 Elsevier Science B.V. All rights reserved.},
issn = {0925-5273},
month = {aug},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
type = {Article; Proceedings Paper},
year = {2003},
publisher = {ELSEVIER SCIENCE BV},
title = {The strategic integration of agile and lean supply},
pages = {183--198},
keywords = {agile,lean,quick response,trade-offs},
mendeley-tags = {agile,lean,quick response,trade-offs},
}

@article{ISI:000080462600006,
author = {R Mason-Jones and D R Towill},
publisher = {ELSEVIER SCIENCE BV},
type = {Article},
volume = {62},
pages = {61--73},
year = {1999},
title = {Total cycle time compression and the agile supply chain},
abstract = {Agility is herein interpreted as using market knowledge and a virtualcorporation to exploit profitable opportunities in a volatile marketplace. This requires the slashing of process lead times throughout thechain. However, as we demonstrate in the paper such action is simply notenough to enable agility. Similar steps must also be taken to reduceinformation lead times, resulting in the concept of the ``informationenriched'' supply chain. Simulation results obtained on realisticmodels of fashion trade supply chains confirm the superior agilityresulting from information enrichment. The paper concludes with aRoute-Map indicating the steps to be taken in achieving supply chainagility in real world scenarios. (C) 1999 Elsevier Science B.V. Allrights reserved.},
month = {may},
number = {1-2},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
doi = {10.1016/S0925-5273(98)00221-7},
journal = {INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS},
issn = {0925-5273},
keywords = {agile,competitive adva,information,supply chain},
mendeley-tags = {agile,competitive adva,information,supply chain},
}

@article{ISI:000171886500026,
author = {A Cockburn and J Highsmith},
year = {2001},
title = {Agile software development: The people factor},
pages = {131--133},
type = {Editorial Material},
month = {nov},
issn = {0018-9162},
journal = {COMPUTER},
publisher = {IEEE COMPUTER SOC},
volume = {34},
number = {11},
doi = {10.1109/2.963450},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
}

@article{ISI:000234695300029,
author = {F Perotti and M Fiorini and S Incorvaia and E Mattaini and E Sant'Ambrogio},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
number = {1},
pages = {228--236},
title = {The AGILE anticoincidence detector},
abstract = {AGILE is a gamma-ray astrophysics space mission which will operate,starting from 2006, in the 30 MeV-50 GeV energy range with imagingcapability also in the 15-45 keV energy band. In order to achieve therequired detection sensitivity, all AGILE detectors are surrounded by ananticoincidence detector aimed at charged particle background rejectionwith an inefficiency as low as 10(-4). In this work, the design and thestructure of this anticoincidence detector are presented, as well as itsperformances in terms of charged particles detection inefficiency asderived from extensive calibrations performed at CERN PS. (c) 2005Elsevier B.V. All rights reserved.},
journal = {NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT},
doi = {10.1016/j.nima.2005.10.016},
publisher = {ELSEVIER SCIENCE BV},
issn = {0168-9002},
type = {Article},
month = {jan},
volume = {556},
year = {2006},
keywords = {charged particles detector,scintillation detector},
mendeley-tags = {charged particles detector,scintillation detector},
}

@article{ISI:000178571700015,
author = {E J Skogen and J S Barton and S P Denbaars and L A Coldren},
number = {4},
journal = {IEEE JOURNAL OF SELECTED TOPICS IN QUANTUM ELECTRONICS},
doi = {10.1109/JSTQE.2002.800849},
issn = {1077-260X},
pages = {863--869},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
volume = {8},
year = {2002},
address = {345 E 47TH ST, NEW YORK, NY 10017-2394 USA},
abstract = {Wavelength-agile photonic integrated circuits are fabricated using aone-step ion implantation quantum-well intermixing process. In thispaper, we discuss the issues in processing optimized widely tunablemultisection lasers using this technique and present the resultsachieved using this process. This quantum-well intermixing process isgeneral in its application and can be used to monolithically integrate awide variety of optoelectronic components with widely tunable lasers.},
type = {Article},
title = {A quantum-well-intermixing process for wavelength-agile photonic integrated circuits},
keywords = {ion implantation,laser tuning,semiconductor lase},
mendeley-tags = {ion implantation,laser tuning,semiconductor lase},
}

@article{ISI:000300611700007,
author = {David J Deming and Claudia Goldin and Lawrence F Katz},
abstract = {Private for-profit institutions have been the fastest-growing part ofthe U.S. higher education sector. For-profit enrollment increased from0.2 percent to 9.1 percent of total enrollment in degree-grantingschools from 1970 to 2009, and for-profit institutions account for themajority of enrollments in non-degree-granting postsecondary schools. Wedescribe the schools, students, and programs in the for-profit highereducation sector, its phenomenal recent growth, and its relationship tothe federal and state governments. Using the 2004 to 2009 BeginningPostsecondary Students (BPS) longitudinal survey, we assess outcomes ofa recent cohort of first-time undergraduates who attended for-profitsrelative to comparable students who attended community colleges or otherpublic or private non-profit institutions. We find that relative tothese other institutions, for-profits educate a larger fraction ofminority, disadvantaged, and older students, and they have greatersuccess at retaining students in their first year and getting them tocomplete short programs at the certificate and AA levels. But we alsofind that for-profit students end up with higher unemployment and``idleness'' rates and lower earnings six years after enteringprograms than do comparable students from other schools and that, notsurprisingly, they have far greater default rates on their loans.},
issn = {0895-3309},
journal = {JOURNAL OF ECONOMIC PERSPECTIVES},
volume = {26},
year = {2012},
pages = {139--163},
address = {2014 BROADWAY, STE 305, NASHVILLE, TN 37203 USA},
number = {1},
publisher = {AMER ECONOMIC ASSOC},
doi = {10.1257/jep.26.1.139},
title = {The For-Profit Postsecondary School Sector: Nimble Critters or Agile Predators?},
type = {Article},
}

@article{ISI:A1956WD31400011,
author = {S E GUNTER and H I KOHN},
pages = {571--581},
publisher = {AMER SOC MICROBIOLOGY},
issn = {0021-9193},
address = {1325 MASSACHUSETTS AVENUE, NW, WASHINGTON, DC 20005-4171},
type = {Article},
title = {THE EFFECT OF X-RAYS ON THE SURVIVAL OF BACTERIA AND YEAST .1. A COMPARATIVE STUDY OF THE DOSE-SURVIVAL CURVES OF AZOTOBACTER-AGILE, ESCHERICHIA-COLI, PSEUDOMONAS-FLUORESCENS, RHODOPSEUDOMONAS-SPHEROIDES, AND SACCHAROMYCES-CEREVISIAE IRRADIATED IN THE RES},
journal = {JOURNAL OF BACTERIOLOGY},
number = {5},
volume = {71},
year = {1956},
}

@article{ISI:000342721500040,
author = {Auke J Ijspeert},
address = {1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA},
pages = {196--203},
title = {Biorobotics: Using robots to emulate and investigate agile locomotion},
number = {6206},
publisher = {AMER ASSOC ADVANCEMENT SCIENCE},
doi = {10.1126/science.1254486},
type = {Review},
year = {2014},
abstract = {The graceful and agile movements of animals are difficult to analyze andemulate because locomotion is the result of a complex interplay of manycomponents: the central and peripheral nervous systems, themusculoskeletal system, and the environment. The goals of bioroboticsare to take inspiration from biological principles to design robots thatmatch the agility of animals, and to use robots as scientific tools toinvestigate animal adaptive behavior. Used as physical models, biorobotscontribute to hypothesis testing in fields such as hydrodynamics,biomechanics, neuroscience, and prosthetics. Their use may contribute tothe design of prosthetic devices that more closely take human locomotionprinciples into account.},
journal = {SCIENCE},
month = {oct},
issn = {0036-8075},
volume = {346},
}

@article{ISI:000271206100001,
author = {Mattias Hallgren and Jan Olhager},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
issn = {0144-3577},
volume = {29},
year = {2009},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
type = {Article},
abstract = {Purpose - Lean and agile manufacturing are two initiatives that are usedby manufacturing plant managers to improve operations capabilities. Thepurpose of this paper is to investigate internal and external factorsthat drive the choice of lean and agile operations capabilities andtheir respective impact on operational performance.Design/methodology/approach - Lean and agile manufacturing are eachconceptualized as a second-order factor and measured through a bundle ofdistinct practices. The competitive intensity of industry and thecompetitive strategy are modeled as potential external and internaldrivers, respectively, and the impact on quality, delivery, cost, andflexibility performance is analyzed using structural equations modeling.The model is tested with data from the high performance manufacturingproject comprising a total of 211 plants from three industries and sevencountries.Findings - The results indicate that lean and agile manufacturing differin terms of drivers and outcomes. The choice of a cost-leadershipstrategy fully mediates the impact of the competitive intensity ofindustry as a driver of lean manufacturing, while agile manufacturing isdirectly affected by both internal and external drivers, i.e. adifferentiation strategy as well as the competitive intensity ofindustry. Agile manufacturing is found to be negatively associated witha cost-leadership strategy, emphasizing the difference between lean andagile manufacturing. The major differences in performance outcomes arerelated to cost and flexibility, such that lean manufacturing has asignificant impact on cost performance (whereas agile manufacturing hasnot), and that agile manufacturing has a stronger relationship withvolume as well as product mix flexibility than does lean manufacturing.Research limitations/implications - Cross-sectional data from threeindustries and seven countries are used, and it would be interesting totest this model for more industries and countries.Practical implications - The results provide insights into the factorsthat influence the choice of lean or agile manufacturing for improvingoperations, and the results that can be obtained.Originality/value - To the authors' knowledge, this is the firstlarge-scale empirical survey of leanness and agility simultaneously,using data from manufacturing firms in Europe, Asia, and North America.The model incorporates a wide perspective on factors related to lean andagile manufacturing, to be able to identify similarities anddifferences.},
number = {10},
pages = {976--999},
title = {Lean and agile manufacturing: external and internal drivers and performance outcomes},
doi = {10.1108/01443570910993456},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
keywords = {agile production,lean production,operations mana},
mendeley-tags = {agile production,lean production,operations mana},
}

@article{ISI:000245226000011,
author = {Yiping Xing and  Ch and R ramouli and Carlos Cordeiro},
abstract = {We explore the price dynamics in a competitive market consisting ofspectrum agile network service providers and users. Here, multipleself,interested spectrum providers operating with different technologiesand costs compete for potential customers. Different buyers or consumersmay evaluate the same seller differently depending on theirapplications, operating technologies and locations. Two different buyerpopulations, the quality-sensitive and the price-sensitive areinvestigated, and the resulting collective price dynamics are studiedusing a combination of analysis and simulations. Various scenarios areconsidered regarding the nature and accuracy of information available tothe sellers. A myopically optimal strategy is studied when fullinformation is available, while a stochastic learning based strategy isconsidered when the information is limited. Cooperating groups may beformed among the sellers which will in-turn influence the group profitfor those participants. Free riding phenomenon is observed under certaincircumstances.},
number = {3},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
address = {445 HOES LANE, PISCATAWAY, NJ 08855 USA},
journal = {IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS},
type = {Article},
title = {Price dynamics in competitive agile spectrum access markets},
doi = {10.1109/JSAC.2007.07041},
pages = {613--621},
volume = {25},
year = {2007},
issn = {0733-8716},
month = {apr},
keywords = {radio spectrum management,wireless communication},
mendeley-tags = {radio spectrum management,wireless communication},
}

@article{ISI:000251876200013,
author = {Lan Cao and Balasubramaniam Ramesh},
type = {Article},
publisher = {IEEE COMPUTER SOC},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
number = {1},
title = {Agile requirements engineering practices: An emprical study},
pages = {60--67},
year = {2008},
issn = {0740-7459},
doi = {10.1109/MS.2008.1},
journal = {IEEE SOFTWARE},
volume = {25},
}

@article{ISI:000237770500016,
author = {A Agarwal and R Shankar and M K Tiwari},
type = {Article},
pages = {211--225},
doi = {10.1016/j.ejor.2004.12.005},
month = {aug},
number = {1},
volume = {173},
journal = {EUROPEAN JOURNAL OF OPERATIONAL RESEARCH},
year = {2006},
issn = {0377-2217},
publisher = {ELSEVIER SCIENCE BV},
title = {Modeling the metrics of lean, agile and leagile supply chain: An ANP-based approach},
abstract = {With the emergence of a business era that embraces `change' as one ofits major characteristics, manufacturing success and survival arebecoming more and more difficult to ensure. The emphasis is onadaptability to changes in the business environment and on addressingmarket and customer needs proactively. Changes in the businessenvironment due to varying needs of the customers lead to uncertainty inthe decision parameters. Flexibility is needed in the supply chain tocounter the uncertainty in the decision parameters. A supply chainadapts the changes if it is flexible and agile in nature. A framework ispresented in this paper, which encapsulates the market sensitiveness,process integration, information driver and flexibility measures ofsupply chain performance. The paper explores the relationship amonglead-time, cost, quality, and service level and the leanness and agilityof a case supply chain in fast moving consumer goods business. The paperconcludes with the justification of the framework, which analyses theeffect of market winning criteria and market qualifying criteria on thethree types of supply chains: lean, agile and leagile. (c) 2005 ElsevierB.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
keywords = {agility,analytic netwo,flexibility,supply chain},
mendeley-tags = {agility,analytic netwo,flexibility,supply chain},
}

@article{ISI:000271514900043,
author = {C Pittori and F Verrecchia and A W Chen and A Bulgarelli and A Pellizzoni and A Giuliani and S Vercellone and F Longo and M Tavani and P Giommi and G Barbiellini and M Trifoglio and F Gianotti and A Argan and A Antonelli and F Boffelli and P Caraveo and P W Cattaneo and V Cocco and S Colafrancesco and T Contessi and E Costa and S Cutini and  D'Amm and F o and E Del Monte and G De Paris and G Di Cocco and G Di Persio and I Donnarumma and Y Evangelista and G Fanari and M Feroci and A Ferrari and M Fiorini and F Fornari and F Fuschino and  Froysl and T  and M Frutti and M Galli and D Gasparrini and C Labanti and I Lapshov and F Lazzarotto and F Liello and P Lipari and E Mattaini and M Marisaldi and M Mastropietro and A Mauri and F Mauri and S Mereghetti and E Morelli and E Moretti and A Morselli and L Pacciani and F Perotti and G Piano and P Picozza and M Pilia and C Pontoni and G Porrovecchio and B Preger and M Prest and R Primavera and G Pucella and M Rapisarda and A Rappoldi and E Rossi and A Rubini and S Sabatini and P Santolamazza and E Scalise and P Soffitta and S Stellato and E Striani and F Tamburelli and A Traci and A Trois and E Vallazza and V Vittorini and A Zambra and D Zanello and L Salotti},
type = {Article},
journal = {ASTRONOMY & ASTROPHYSICS},
pages = {1563--1574},
volume = {506},
address = {17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE},
month = {nov},
publisher = {EDP SCIENCES S A},
issn = {0004-6361},
doi = {10.1051/0004-6361/200911783},
number = {3},
abstract = {We present the first catalog of high-confidence gamma-ray sourcesdetected by the AGILE satellite during observations performed from July9, 2007 to June 30, 2008. Cataloged sources were detected by merging allthe available data over the entire time period. AGILE, launched in April2007, is an ASI mission devoted to gamma-ray observations in the 30MeV-50 GeV energy range, with simultaneous X-ray imaging capability inthe 18-60 keV band. This catalog is based on Gamma-Ray Imaging Detector(GRID) data for energies greater than 100 MeV. For the first AGILEcatalog, we adopted a conservative analysis, with a high-quality eventfilter optimized to select gamma-ray events within the central zone ofthe instrument field of view (radius of 40 degrees). This is asignificance-limited (4 sigma) catalog, and it is not a completeflux-limited sample due to the non-uniform first-year AGILE skycoverage. The catalog includes 47 sources, 21 of which are associatedwith confirmed or candidate pulsars, 13 with blazars (7 FSRQ, 4 BL Lacs,2 unknown type), 2 with HMXRBs, 2 with SNRs, 1 with a colliding-windbinary system, and 8 with unidentified sources.},
title = {First AGILE catalog of high-confidence gamma-ray sources},
year = {2009},
keywords = {catalogs,gamma rays: observations},
mendeley-tags = {catalogs,gamma rays: observations},
}

@article{ISI:000231943500005,
author = {D Turk and R France and B Rumpe},
publisher = {IGI PUBL},
abstract = {Agile processes focus on the early facilitation and fast production ofworking code, and are based on software-development process models thatsupport iterative, incremental development of software. Although agilemethods have existed for a number of years now, answers to questionsconcerning the suitability of agile processes to particularsoftware-development environments are still often based on anecdotalaccounts of experiences. An appreciation of the (often unstated)assumptions underlying agile processes can lead to a betterunderstanding of the applicability of agile processes to particularsituations. Agile processes are less likely to be applicable insituations in which core assumptions do not hold. This article examinesthe principles and advocated practices of agile processes to identifyunderlying assumptions. It also identifies limitations that may arisefrom these assumptions and outlines how the limitations can be addressedby incorporating other software-development techniques and practicesinto agile development environments.},
title = {Assumptions underlying agile software-development processes},
pages = {62--87},
issn = {1063-8016},
number = {4},
doi = {10.4018/jdm.2005100104},
type = {Review},
volume = {16},
address = {701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA},
year = {2005},
journal = {JOURNAL OF DATABASE MANAGEMENT},
keywords = {agile development,assumptions,extreme programmin},
mendeley-tags = {agile development,assumptions,extreme programmin},
}

@article{ISI:000319705100015,
author = {Xijun Wang and Aihua Zhang and Ping Wang and Hui Sun and Gelin Wu and Wenjun Sun and Haitao Lv and Guozheng Jiao and Hongying Xu and Ye Yuan and Lian Liu and Dixin Zou and Zeming Wu and Ying Han and Guangli Yan and Wei Dong and Fangfang Wu and Tianwei Dong and Yang Yu and Shuxiang Zhang and Xiuhong Wu and Xin Tong and Xiangcai Meng},
address = {9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA},
abstract = {To enhance the therapeutic efficacy and reduce the adverse effects oftraditional Chinese medicine, practitioners often prescribe combinationsof plant species and/or minerals, called formulae. Unfortunately, theworking mechanisms of most of these compounds are difficult to determineand thus remain unknown. In an attempt to address the benefits offormulae based on current biomedical approaches, we analyzed thecomponents of Yinchenhao Tang, a classical formula that has been shownto be clinically effective for treating hepatic injury syndrome. Thethree principal components of Yinchenhao Tang are Artemisia annua L.,Gardenia jasminoids Ellis, and Rheum Palmatum L., whose major activeingredients are 6,7-dimethylesculetin (D), geniposide (G), and rhein(R), respectively. To determine the mechanisms underlying the efficacyof this formula, we conducted a systematic analysis of the therapeuticeffects of the DGR compound using immunohistochemistry, biochemistry,metabolomics, and proteomics. Here, we report that the DGR combinationexerts a more robust therapeutic effect than any one or two of the threeindividual compounds by hitting multiple targets in a rat model ofhepatic injury. Thus, DGR synergistically causes intensified dynamicchanges in metabolic biomarkers, regulates molecular networks throughtarget proteins, has a synergistic/additive effect, and activates bothintrinsic and extrinsic pathways.},
month = {may},
publisher = {AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC},
year = {2013},
pages = {1226--1238},
journal = {MOLECULAR & CELLULAR PROTEOMICS},
volume = {12},
doi = {10.1074/mcp.M112.021683},
issn = {1535-9476},
number = {5},
type = {Article},
title = {Metabolomics Coupled with Proteomics Advancing Drug Discovery toward More Agile Development of Targeted Combination Therapies},
}

@article{ISI:000269983900003,
author = {Richard Vidgen and Xiaofeng Wang},
type = {Article},
publisher = {INFORMS},
volume = {20},
year = {2009},
issn = {1047-7047},
doi = {10.1287/isre.1090.0237},
month = {sep},
address = {7240 PARKWAY DR, STE 310, HANOVER, MD 21076-1344 USA},
journal = {INFORMATION SYSTEMS RESEARCH},
number = {3},
abstract = {Despite the popularity of agile methods in software development andincreasing adoption by organizations there is debate about what agilityis and how it is achieved. The debate suffers from a lack ofunderstanding of agile concepts and how agile software development ispracticed. This paper develops a framework for the organization of agilesoftware development that identifies enablers and inhibitors of agilityand the emergent capabilities of agile teams. The work is grounded incomplex adaptive systems (CAS) and draws on three principles ofcoevolving systems: match coevolutionary change rate, maximizeself-organizing, and synchronize exploitation and exploration. Theseprinciples are used to study the processes of two software developmentteams, one a team using eXtreme Programming (XP) and the other a teamusing a more traditional, waterfall-based development cycle. From thecases a framework for the organization of agile software development isdeveloped. Time pacing, self-management with discipline androutinization of exploration are among the agile enablers found in thecases studies while event pacing, centralized management, and lack ofresources allocated to exploration are found to be inhibitors toagility. Emergent capabilities of agile teams that are identified fromthe research include coevolution of business value, sustainable workingwith rhythm, sharing and team learning, and collective mindfulness.},
pages = {355--376},
title = {Coevolving Systems and the Organization of Agile Software Development},
keywords = {agile software development,co,coevolving systems},
mendeley-tags = {agile software development,co,coevolving systems},
}

@article{ISI:000171242900006,
author = {P K Menon and E J Ohlmeyer},
doi = {10.1016/S0967-0661(01)00082-X},
type = {Article},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
pages = {1095--1106},
issn = {0967-0661},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
title = {Integrated design of agile missile guidance and autopilot systems},
volume = {9},
journal = {CONTROL ENGINEERING PRACTICE},
year = {2001},
abstract = {Traditional approach for the design of missile guidance and autopilotsystems has been to design these subsystems separately and then tointegrate them. Such an approach does not exploit any beneficialrelationships between these and other subsystems. A technique forintegrated design of missile guidance and autopilot systems using thefeedback linearization technique is discussed. Numerical results using asix degree-of-freedom missile simulation are given. Integratedguidance-autopilot systems are expected to result in significantimprovements in missile performance, leading to lower weight andenhanced lethality. These design methods have extensive applications inhigh performance aircraft autopilot and guidance system design. (C) 2001Elsevier Science Ltd. All rights reserved.},
number = {10},
month = {oct},
keywords = {autopilot,feedback lineariz,guidance,integrated},
mendeley-tags = {autopilot,feedback lineariz,guidance,integrated},
}

@article{ISI:000275074600005,
author = {Gwanhoo Lee and Weidong Xia},
volume = {34},
pages = {87--114},
title = {TOWARD AGILE: AN INTEGRATED ANALYSIS OF QUANTITATIVE AND QUALITATIVE FIELD DATA ON SOFTWARE DEVELOPMENT AGILITY},
journal = {MIS QUARTERLY},
abstract = {As business and technology environments change at an unprecedented rate,software development agility to respond to changing user requirementshas become increasingly critical for software development performance.Agile software development approaches, which emphasizesense-and-respond, self-organization, cross-functional teams, andcontinuous adaptation, have been adopted by an increasing number oforganizations to improve their software development agility. However,the agile development literature is largely anecdotal and prescriptive,lacking empirical evidence and theoretical foundation to support theprinciples and practices of agile development. Little research hasempirically examined the software development agility construct in termsof its dimensions, determinants, and effects on software developmentperformance. As a result, there is a lack of understanding about howorganizations can effectively implement an agile development approach.Using an integrated research approach that combines quantitative andqualitative data analyses, this research opens the black box of agiledevelopment by empirically examining the relationships among twodimensions of software development agility (software team responseextensiveness and software team response efficiency), two antecedentsthat can be con trolled (team autonomy and team diversity), and threeaspects of software development performance (on-time completion,on-budget completion, and software functionality). Our PLS results ofsurvey, responses of 399 software project managers suggest that therelationships among these variables are more complex than what has beenperceived by the literature. The results suggest a tradeoff relationshipbetween response extensiveness and response efficiency. These twoagility dimensions impact software development performance differently:response efficiency positively affects all of on-time completion,on-budget completion, and software functionality, whereas responseextensiveness positively affects only software functionality. Theresults also suggest that team autonomy has a positive effect onresponse efficiency and a negative effect on response extensiveness, andthat team diversity has a positive effect on response extensiveness, Weconducted 10 post hoc case studies to qualitatively cross-validate ourPLS results and provide rich, additional insights regarding the complex,dynamic interplays between autonomy, diversity, agility, andperformance. The qualitative analysis also provides explanations forboth supported and unsupported hypotheses. We discuss these qualitativeanalysis results and conclude with the theoretical and practicalimplications of our research findings for agile development approaches.},
month = {mar},
type = {Article},
number = {1},
issn = {0276-7783},
year = {2010},
publisher = {SOC INFORM MANAGE-MIS RES CENT},
address = {UNIV MINNESOTA-SCH MANAGEMENT 271 19TH AVE SOUTH, MINNEAPOLIS, MN 55455 USA},
keywords = {agile software devel,software development agility},
mendeley-tags = {agile software devel,software development agility},
}

@article{ISI:000251845500002,
author = {Daniel Vazquez-Bustelo and Lucia Avella and  Fern and Esteban ez},
volume = {27},
year = {2007},
pages = {1303--1332},
title = {Agility drivers, enablers and outcomes - Empirical test of an integrated agile manufacturing model},
type = {Article},
abstract = {Purpose - Despite the fact that agile manufacturing has been frequentlypromoted as a means of improving business competitiveness, littleempirical evidence exists in the literature validating its positive linkwith business performance. The purpose of this research paper is toanalyse agile manufacturing in Spain and study whether it is a criticalfactor for success in different industries.Design/methodology/approach - A conceptual model is drawn up, based onthe literature and a previous case study, to relate turbulence in theenvironment with agile manufacturing practices and business performance.The model is tested on a large sample of Spanish manufacturers using asurvey methodology to obtain information and a structural equation modelto analyse the data.Findings - The results obtained show that, in turbulent environments,the integrated use of agile manufacturing practices promotesmanufacturing competitive strength, leading to better operational,market and financial performance.Research limitations/implications - This study has two main limitations.First, it is difficult to determine the most suitable unit of analysiswhen studying agile manufacturing. Second, single respondent bias may beconsidered a limitation.Practical implications - Managers should consider the integratedimplementation of agile manufacturing practices in order to developmanufacturing strength and to outperform competitors in turbulentbusiness environments.Originality/value - This study adopts a systematic approach to theanalysis of agile manufacturing, considering various agility practicesor enablers in an integrated way and relating them not only toenvironmental characteristics but also to business performance. Thisapproach is especially interesting because most of the literature onagile manufacturing deals with agility strategies or techniques in anisolated way. The study also tests the suitability of agilemanufacturing in real organisations - for the first time in the Spanishcontext.},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
doi = {10.1108/01443570710835633},
issn = {0144-3577},
number = {12},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
keywords = {agile production,operations and production manage},
mendeley-tags = {agile production,operations and production manage},
}

@article{ISI:000244664800021,
author = {Sridhar Nerur and VanuGopal Balijepally},
journal = {COMMUNICATIONS OF THE ACM},
month = {mar},
pages = {79--83},
volume = {50},
title = {Theoretical reflections on agile development methodologies - The traditional goal of optimization and control is making way for learning and innovation.},
year = {2007},
number = {3},
issn = {0001-0782},
doi = {10.1145/1226736.1226739},
publisher = {ASSOC COMPUTING MACHINERY},
address = {1515 BROADWAY, NEW YORK, NY 10036 USA},
type = {Article},
}

@article{ISI:000251845300005,
author = {Joseph Sarkis and Srinivas Talluri and A Gunasekaran},
doi = {10.1108/01443570710830601},
issn = {0144-3577},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
year = {2007},
number = {11},
abstract = {Purpose - This paper aims to provide a practical model usable byorganizations to help form agile virtual enterprises. The model helps tointegrate a variety of factors, tangible and intangible, strategic andoperational, for decision-making purposes.Design/methodology/approach - A comprehensive development of factors isdetermined from the literature and an analytical network process (ANP)methodology is introduced for decision model development. Anillustrative example is presented.Findings - The results provide a robust model that will aid decisionmakers and agile virtual enterprise brokers form partnerships withinthese organizational structures.Research limitations/implications - The paper introduces a conceptualmodel with an illustrative validating example. A practical applicationand reapplication of the model are required to further validate themodel. ANP can require significant managerial input for its application,potentially causing fatigue for decision makers.Practical implications - Practical implications include a partnerselection tool and framework for decision makers. The model may beeasily tweaked by the elimination or addition of decision factors andtheir relationships.Originality/value - The paper is useful to practitioners andorganizations seeking to manage partnership formation of agile virtualenterprises, an emerging organizational form. This work expands thenumber of factors and interrelationships among these factors that noother model has explicitly addressed for the agile virtual enterpriseformation situation.},
pages = {1213--1234},
type = {Article},
volume = {27},
title = {A strategic model for agile virtual enterprise partner selection},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
keywords = {agile production,partnership,virtual organizatio},
mendeley-tags = {agile production,partnership,virtual organizatio},
}

@article{ISI:000237552000009,
author = {Brian Fitzgerald and Gerard Hartnett and Kieran Conboy},
journal = {EUROPEAN JOURNAL OF INFORMATION SYSTEMS},
issn = {0960-085X},
number = {2},
address = {BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND},
title = {Customising agile methods to software practices at Intel Shannon},
type = {Article},
volume = {15},
year = {2006},
month = {apr},
publisher = {PALGRAVE MACMILLAN LTD},
doi = {10.1027/palgrave.ejis.300605},
pages = {200--213},
abstract = {Tailoring of methods is commonplace in the vast majority of softwaredevelopment projects and organisations. However, there is not much knownabout the tailoring and engineering of agile methods, or about how thesemethods can be used to complement each other. This study investigatedtailoring of the agile methods, eXtreme programming (XP) and Scrum, atIntel Shannon, and involved experienced software engineers whocontinuously monitored and reflected on these methods over a 3- yearperiod. The study shows that agile methods may individually beincomplete in supporting the overall development process, but XP andScrum complement each other well, with XP providing support fortechnical aspects and Scrum providing support for project planning andtracking. The principles of XP and Scrum were carefully selected (onlysix of the 12 XP key practices were implemented, for example) andtailored to suit the needs of the development environment at IntelShannon. Thus, the study refutes the suggestion that agile methods arenot divisible or individually selectable but achieve their benefitsthrough the synergistic combination of individual agile practices;rather, this study shows that an a la carte selection and tailoring ofpractices can work very well. In the case of Scrum, some local tailoringhas led to a very committed usage by developers, in contrast to manydevelopment methods whose usage is limited despite being decreedmandatory by management. The agile practices that were applied did leadto significant benefits, including reductions in code defect density bya factor of 7. Projects of 6-month and 1-year duration have beendelivered ahead of schedule, which bodes well for future ability toaccurately plan development projects.},
keywords = {agile methods,me,scrum,software development,xp},
mendeley-tags = {agile methods,me,scrum,software development,xp},
}

@article{ISI:000257529900001,
author = {Tore Dyba and Torgeir Dingsoyr},
publisher = {ELSEVIER SCIENCE BV},
pages = {833--859},
title = {Empirical studies of agile software development: A systematic review},
volume = {50},
year = {2008},
type = {Review},
issn = {0950-5849},
month = {aug},
abstract = {Agile software development represents a major departure fromtraditional, plan-based approaches to software engineering. A systematicreview of empirical studies of agile software development up to andincluding 2005 was conducted. The search strategy identified 1996studies, of which 36 were identified as empirical studies. The studieswere grouped into four themes: introduction and adoption, human andsocial factors, perceptions on agile methods, and comparative studies.The review investigates what is currently known about the benefits andlimitations of, and the strength of evidence for, agile methods.Implications for research and practice are presented. The mainimplication for research is a need for more and better empirical studiesof agile software development within a common research agenda. For theindustrial readership, the review provides a map of findings, accordingto topic, that can be compared for relevance to their own settings andsituations. (C) 2008 Elsevier B.V. All rights reserved.},
journal = {INFORMATION AND SOFTWARE TECHNOLOGY},
doi = {10.1016/j.infsof.2008.01.006},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
number = {9-10},
keywords = {empirical software engineering,evidence-based sof},
mendeley-tags = {empirical software engineering,evidence-based sof},
}

@article{ISI:000296592600022,
author = {Henry Arguello and Gonzalo R Arce},
type = {Article},
month = {nov},
number = {11},
doi = {10.1364/JOSAA.28.002400},
title = {Code aperture optimization for spectrally agile compressive imaging},
abstract = {Coded aperture snapshot spectral imaging (CASSI) provides a mechanismfor capturing a 3D spectral cube with a single shot 2D measurement. Inmany applications selective spectral imaging is sought since relevantinformation often lies within a subset of spectral bands. Capturing andreconstructing all the spectral bands in the observed image cube, tothen throw away a large portion of this data, is inefficient. To thisend, this paper extends the concept of CASSI to a system admittingmultiple shot measurements, which leads not only to higher quality ofreconstruction but also to spectrally selective imaging when thesequence of code aperture patterns is optimized. The aperture codeoptimization problem is shown to be analogous to the optimization of aconstrained multichannel filter bank. The optimal code apertures allowthe decomposition of the CASSI measurement into several subsets, eachhaving information from only a few selected spectral bands. The richtheory of compressive sensing is used to effectively reconstruct thespectral bands of interest from the measurements. A number ofsimulations are developed to illustrate the spectral imagingcharacteristics attained by optimal aperture codes. (C) 2011 OpticalSociety of America},
address = {2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA},
volume = {28},
pages = {2400--2413},
year = {2011},
issn = {1084-7529},
journal = {JOURNAL OF THE OPTICAL SOCIETY OF AMERICA A-OPTICS IMAGE SCIENCE AND VISION},
publisher = {OPTICAL SOC AMER},
}

@article{ISI:000256391400011,
author = {Tsun Chow and Dac-Buu Cao},
issn = {0164-1212},
number = {6},
pages = {961--971},
title = {A survey study of critical success factors in agile software projects},
doi = {10.1016/j.jss.2007.08.020},
type = {Article},
month = {jun},
abstract = {While software is so important for all facets of the modern world,software development itself is not a perfect process. Agile softwareengineering methods have recently emerged as a new and different way ofdeveloping software as compared to the traditional methodologies.However, their success has mostly been anecdotal, and research in thissubject is still scant in the academic circles. This research study wasa survey study on the critical success factors of Agile softwaredevelopment projects using quantitative approach.Based on existing literature, a preliminary list of potential criticalsuccess factors of Agile projects were identified and compiled.Subsequently, reliability analysis and factor analysis were conducted toconsolidate this preliminary list into a final set of 12 possiblecritical success factors for each of the four project success categories- Quality, Scope, Time, and Cost.A survey was conducted among Agile professionals, gathering survey datafrom 109 Agile projects from 25 countries across the world. Multipleregression techniques were used, both at the full regression model andat the optimized regression model via the stepwise screening procedure.The results revealed that only 10 out of 48 hypotheses were supported,identifying three critical success factors for Agile softwaredevelopment projects: (a) Delivery Strategy, (b) Agile SoftwareEngineering Techniques, and (c) Team Capability.Limitations of the study are discussed together with interpretations forpractitioners. To ensure success of their projects, managers are urgedto focus on choosing a high-caliber team, practicing Agile engineeringtechniques and following Agile-style delivery strategy. (C) 2007Elsevier Inc. All rights reserved.},
volume = {81},
year = {2008},
address = {360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
publisher = {ELSEVIER SCIENCE INC},
journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
keywords = {agile methods,critical succ,software development},
mendeley-tags = {agile methods,critical succ,software development},
}

@article{ISI:000178991000007,
author = {M Lemaitre and G Verfaillie and F Jouhaud and J M Lachiver and N Bataille},
publisher = {ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER},
volume = {6},
year = {2002},
address = {23 RUE LINOIS, 75724 PARIS, FRANCE},
pages = {367--381},
issn = {1270-9638},
type = {Article},
journal = {AEROSPACE SCIENCE AND TECHNOLOGY},
abstract = {This article concerns the problem of managing the new generation ofAgile Earth Observing Satellites (AEOS). This kind of satellites ispresently studied by the French Centre National d'Etudes Spatiales(PLEIADES project). The mission of an Earth Observing Satellite is toacquire images of specified areas on the Earth surface, in response toobservation requests from customers. Whereas non-agile satellites suchas SPOT5 have only one degree of freedom for acquiring images, the newgeneration satellites have three, giving opportunities for a moreefficient use of the satellite imaging capabilities. Counterwise to thisadvantage, the selection and scheduling of observations becomessignificantly more difficult, due to the larger search space forpotential solutions. Hence, selecting and scheduling observations ofagile satellites is a highly combinatorial problem. This article setsout the overall problem and analyses its difficulties. Then it presentsdifferent methods which have been investigated in order to solve asimplified version of the complete problem: a greedy algorithm, adynamic programming algorithm, a constraint programming approach and alocal search method. (C) 2002 Editions scientifiques et medicalesElsevier SAS. All rights reserved.},
number = {5},
month = {sep},
title = {Selecting and scheduling observations of agile satellites},
doi = {10.1016/S1270-9638(02)01173-2},
keywords = {agile satellite,earth observing satellite,missio},
mendeley-tags = {agile satellite,earth observing satellite,missio},
}

@article{ISI:000086196000001,
author = {S Halpain},
doi = {10.1016/S0166-2236(00)01576-9},
publisher = {ELSEVIER SCIENCE LONDON},
pages = {141--146},
issn = {0166-2236},
type = {Editorial Material},
volume = {23},
year = {2000},
abstract = {Since early anatomical descriptions, the existence of dendritic spineshas stimulated intense curiosity and speculation about their regulationand function. Research over the past three decades has described animpressive mutability in dendritic-spine number and morphology under avariety of physiological circumstances. Current evidence favors aproposed model in which two pools of actin filaments, one stable and theother dynamic, support both persistent spine structure and rapid spinemotility. Potential functions of spine motility and dynamic actininclude regulated protein scaffolding, retrograde signaling and synapsestabilization.},
number = {4},
month = {apr},
title = {Actin and the agile spine: how and why do dendritic spines dance?},
address = {84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND},
journal = {TRENDS IN NEUROSCIENCES},
}

@article{ISI:A1996UU40400002,
author = {H Cho and M Y Jung and M Kim},
journal = {COMPUTERS & INDUSTRIAL ENGINEERING},
address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB},
volume = {30},
issn = {0360-8352},
year = {1996},
month = {jul},
publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
doi = {10.1016/0360-8352(96)00001-0},
type = {Article},
abstract = {As product life cycle becomes shortened, high product quality becomesnecessary for survival, markets become highly diversified and global,and continuous and unexpected change becomes the key factor for success.The need for a method of rapidly and cost-effectively developingproducts, production facilities and supporting software includingdesign, process planning, shop door control systems is becoming urgent.The essence of this concept of manufacturing would be characterized byintroducing a new term agility or rapidity. When compared with computerintegrated manufacturing, agile manufacturing can be defined as thecapability of surviving and prospering in a competitive environment ofcontinuous and unpredictable change by reacting quickly and effectivelyto changing markets, driven by customer-designed products and services.Critical to successfully accomplishing agile manufacturing are a fewenabling technologies such as the standard for the exchange of products(STEP), concurrent engineering, virtual manufacturing, component-basedheterarchical shop floor control system, information and communicationinfrastructure, etc. This article details key concepts of those enablingtechnologies and presents various activities related to agilemanufacturing under development in Korea, especially an agilemanufacturing test-bed at Pohang University of Science and Technologyand a prototype of the life cycle engineering study of a product modelmade in a consumer electronic industry. Copyright (C) 1996 ElsevierScience Ltd.},
number = {3},
pages = {323--334},
title = {Enabling technologies of agile manufacturing and its related activities in Korea},
}

@article{ISI:000169462700014,
author = {H Sharifi and Z Zhang},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
number = {5-6},
title = {Agile manufacturing in practice - Application of a methodology},
abstract = {A evolutionary transformation of the business environment, with changeas a main characteristic, is taking place. Manufacturing companies, eventhose operating in relatively stable conditions with good marketpositions, are facing rapid and often unanticipated changes in theirbusiness environment. Agile manufacturing is proposed in response to thecircumstances as a solution and is perceived as a vital characteristicthat manufacturing companies need to have in order to maintain theircompetitive advantages in the new order of world business, Each companywill respond in a specific and different way to the changingcircumstances by deploying its own agile characteristics. Agility inmanufacturing may be achieved through the implementation and integrationof appropriate practices which provide the required abilities for acompany to respond properly to changes. Based on this concept, amethodology is applied in two manufacturing companies and data collectedfrom the applications are used to validate the methodology. This paperprovides a brief summary of the methodology and details itsimplementation and validation in the two case study companies. Practicesare proposed to support the achievement of agility in the twoorganisations.},
year = {2001},
pages = {772--794},
type = {Article},
volume = {21},
doi = {10.1108/01443570110390462},
issn = {0144-3577},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
publisher = {MCB U P LIMITED},
keywords = {agile production,manufacturing,methodology},
mendeley-tags = {agile production,manufacturing,methodology},
}

@article{ISI:000288926200006,
author = {R Anthony Inman and R Samuel Sale and Kenneth W Green Jr. and Dwayne Whitten},
doi = {10.1016/j.jom.2010.06.001},
type = {Article},
publisher = {ELSEVIER SCIENCE BV},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
abstract = {A structural model incorporating agile manufacturing as the focalconstruct is theorized and tested. The model includes the primarycomponents of JIT (JIT-purchasing and JIT-production) as antecedents andoperational performance and firm performance as consequences to agilemanufacturing. Using data collected from production and operationsmanagers working for large U.S. manufacturers, the model is assessedfollowing a structural equation modeling methodology. The resultsindicate that JIT-purchasing has a direct positive relationship withagile manufacturing while the positive relationship betweenJIT-production and agile manufacturing is mediated by JIT-purchasing.The results also indicate that agile manufacturing has a direct positiverelationship with the operational performance of the firm, that theoperational performance of the firm has a direct positive relationshipwith the marketing performance of the firm, and that the positiverelationship between the operational performance of the firm and thefinancial performance of the firm is mediated by the marketingperformance of the firm. (C) 2010 Elsevier B.V. All rights reserved.},
journal = {JOURNAL OF OPERATIONS MANAGEMENT},
pages = {343--355},
volume = {29},
year = {2011},
month = {may},
issn = {0272-6963},
title = {Agile manufacturing: Relation to JIT, operational performance and firm performance},
number = {4},
keywords = {agile manufacturing,jit systems,organizational p},
mendeley-tags = {agile manufacturing,jit systems,organizational p},
}

@article{ISI:000236672000004,
author = {R Oloruntoba and R Gray},
year = {2006},
pages = {115--120},
journal = {SUPPLY CHAIN MANAGEMENT-AN INTERNATIONAL JOURNAL},
number = {2},
abstract = {Purpose - The purpose of this article is to investigate the nature ofthe humanitarian aid supply chain and discuss the extent to whichcertain business supply chain concepts, particularly supply chainagility, are relevant to humanitarian aid.Design/methodology/approach - The paper identifies elements of goodpractice in conventional business supply chains and applies them to thehumanitarian aid supply chain, making use of published practice-basedliterature and web sites associated with humanitarian aid. Particularemphasis is placed on the concept of ``agility'' in supply chainmanagement. A model of an agile supply chain for humanitarian aid isdeveloped.Findings - Humanitarian supply chains have similarities with businesssupply chains, but there are significant differences. Many humanitariansupply chains have a short and unstable existence with an inadequatelink between emergency aid and longer-term developmental aid. Unlikemany business supply chains, typical emergency aid appeals assigninventory to a particular destination at the supply chain source.Practical implications - This research note is a starting-point forempirical studies to test the agile humanitarian supply chain model.Originality/value - This paper seeks to integrate humanitarian aidpractice with concepts in the academic supply chain literature. Inparticular, proposes that humanitarian donors need convincing of thevalue of supply chain processes.},
title = {Humanitarian aid: an agile supply chain?},
volume = {11},
type = {Article},
doi = {10.1108/13598540610652492},
issn = {1359-8546},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
keywords = {aid agencies,supply chain management},
mendeley-tags = {aid agencies,supply chain management},
}

@article{ISI:000256780400001,
author = {Bechir Hamdaoui and Kang G Shin},
pages = {915--930},
issn = {1536-1233},
doi = {10.1109/TMC.2007.70758},
abstract = {Wireless networks and devices have rapidly been gaining popularity overtheir wired counterparts. This popularity, in turn, has been generatingan explosive and ever-increasing demand for, and hence creating ashortage of, the radio spectrum. The reason for this foreseen spectrumshortage is reported not to be the scarcity of the radio spectrum butthe inefficiency of current spectrum access methods, thus leavingspectrum opportunities along both the time and frequency dimensions thatwireless devices can exploit. Fortunately, recent technological advanceshave made it possible to build software-defined radios (SDRs), which,unlike traditional radios, can switch from one frequency band to anotherat little or no cost. We propose a MAC protocol, called OpportunisticSpectrum MAC (OS-MAC), for wireless networks equipped with cognitiveradios like SDRs. OS-MAC 1) adaptively and dynamically seeks andexploits opportunities in both licensed and unlicensed spectra and alongboth the time and frequency dimensions, 2) accesses and shares spectrumamong different unlicensed and licensed users, and 3) coordinates withother unlicensed users for better spectrum utilization. Using extensivesimulation, OS-MAC is shown to be far more effective than current accessprotocols from both the network's and the user's perspectives. Bycomparing its performance with an Ideal-MAC protocol, OS-MAC is alsoshown to not only outperform current access protocols, but also achieveperformance very close to that obtainable under the Ideal-MAC protocol.},
journal = {IEEE TRANSACTIONS ON MOBILE COMPUTING},
title = {OS-MAC: An efficient MAC protocol for spectrum-agile wireless networks},
volume = {7},
publisher = {IEEE COMPUTER SOC},
type = {Article},
year = {2008},
number = {8},
month = {aug},
address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
keywords = {opportunistic mac protocols,sof,spectrum agility},
mendeley-tags = {opportunistic mac protocols,sof,spectrum agility},
}

@article{ISI:000220125400007,
author = {M Bruce and L Daly and N Towers},
title = {Lean or agile - A solution for supply chain management in the textiles and clothing industry?},
journal = {INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT},
address = {60/62 TOLLER LANE, BRADFORD BD8 9BY, W YORKSHIRE, ENGLAND},
volume = {24},
year = {2004},
abstract = {The textiles and apparel industry has been neglected in terms of supplychain management research. Recently, the industry has undergone a greatdeal of change, particularly with global sourcing and high levels ofprice competition. In addition, textiles and clothing has marketcharacteristics, such as short product lifecycle, high volatility, lowpredictability, and a high level of impulse purchase, making such issuesas quick response of Paramount importance. This article discussescharacteristics of the textiles and apparel industry and identifies theperspectives of lean, agile and leagility (a combination of these)within existing supply chain literature, which have been proffered assolutions to achieving quick response and reduced lead times. Throughcase studies of textile and apparel companies, different approaches tosupply chain management are illustrated.},
pages = {151--170},
type = {Article},
issn = {0144-3577},
number = {1-2},
doi = {10.1108/01443570410514867},
publisher = {EMERALD GROUP PUBLISHING LIMITED},
keywords = {supply chain management,textile industry},
mendeley-tags = {supply chain management,textile industry},
}

@book{sa97,
author = {Steven W Smith},
abstract = {Markets have always influenced the central thrust of the semiconductor industry. Beginning in the early eighties, the personal computer (PC) market has been the dominant market influencing the semiconductor industry. Single-chip microprocessors (MPUs) enabled what became the huge PC market, which ultimately overshadowed the earlier minicomputer and mainframe computer markets. The popularity of PCs led to investments in increasingly more powerful MPUs and memory chips of ever-growing capacity. MPUs and DRAMs became the semiconductor industry technology drivers for the data processing needs of the PC. But now, DSP, as opposed to conventional data processing, has become the major technology driver for the semiconductor industry as evidenced by its market growth and the fervour of chip vendors to provide new products based on DSP technology. The increasing need to digitally process analog information signals, like audio and video, is causing a major shift in the semiconductor business. Since DSP is the mathematical manipulation of those digitized information signals, specialized math circuitry is required for efficient signal processing-circuitry that was previously confined to classical DSP chips},
title = {The scientist and engineer's guide to digital signal processing},
isbn = {0966017633 9780966017632},
year = {1997},
keywords = {file},
mendeley-tags = {file},
}

@article{r,
author = {F Rosenblatt},
title = {The perceptron a perceiving and recognizing automaton Project Para.},
volume = {1957},
journal = {Traducao. [s.l.] Cornell Aeronautical Laboratory},
}

@unpublished{g17,
author = {Eric Grinstein and Ngoc Q.K. Duong and Alexey Ozerov and Patrick Perez},
title = {Audio Style Transfer},
archiveprefix = {arXiv},
doi = {10.1109/ICASSP.2018.8461711},
eprint = {1710.11385},
isbn = {9781538646588},
arxivid = {1710.11385},
year = {2018},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
abstract = {'Style transfer' among images has recently emerged as a very active research topic, fuelled by the power of convolution neural networks (CNNs), and has become fast a very popular technology in social media. This paper investigates the analogous problem in the audio domain: How to transfer the style of a reference audio signal to a target audio content? We propose a flexible framework for the task, which uses a sound texture model to extract statistics characterizing the reference audio style, followed by an optimization-based audio texture synthesis to modify the target content. In contrast to mainstream optimization-based visual transfer method, the proposed process is initialized by the target content instead of random noise and the optimized loss is only about texture, not structure. These differences proved key for audio style transfer in our experiments. In order to extract features of interest, we investigate different architectures, whether pre-trained on other tasks, as done in image style transfer, or engineered based on the human auditory system. Experimental results on different types of audio signal confirm the potential of the proposed approach.},
annote = {preprint},
pages = {586--590},
issn = {15206149},
volume = {2018-April},
keywords = {audio style transfer,auditory system,deep neural network,sound texture model,texture synthesis},
mendeley-tags = {audio style transfer,auditory system,deep neural network,sound texture model,texture synthesis},
}

@article{s,
author = {Sound Samples},
journal = {The Grants Register 2019},
doi = {10.1007/978-1-349-95810-8_954},
volume = {2018},
pages = {595--596},
year = {2019},
url = {http://www.philharmonia.co.uk/explore/sound_samples%3E},
title = {Philharmonia Orchestra},
}

@book{t,
author = {Keras: The},
url = {https://keras.io/%3E},
publisher = {<},
title = {Python Deep Learning library},
address = {Keras Documentation, [s.d.]. Dispon�vel em},
}

@article{f08,
author = {Marie Forgeard and Ellen Winner and Andrea Norton and Gottfried Schlaug},
journal = {PLoS ONE},
abstract = {Background: In this study we investigated the association between instrumental music training in childhood and outcomes closely related to music training as well as those more distantly related. Methodology/Principal Findings: Children who received at least three years (M=4.6 years) of instrumental music training outperformed their control counterparts on two outcomes closely related to music (auditory discrimination abilities and fine motor skills) and on two outcomes distantly related to music (vocabulary and nonverbal reasoning skills). Duration of training also predicted these outcomes. Contrary to previous research, instrumental music training was not associated with heightened spatial skills, phonemic awareness, or mathematical abilities. Conclusions/Significance: While these results are correlational only, the strong predictive effect of training duration suggests that instrumental music training may enhance auditory discrimination, fine motor skills, vocabulary, and nonverbal reasoning. Alternative explanations for these results are discussed. \textcopyright 2008 Forgeard et al.},
doi = {10.1371/journal.pone.0003566},
pmid = {18958177},
issn = {19326203},
title = {Practicing a musical instrument in childhood is associated with enhanced verbal ability and nonverbal reasoning},
volume = {3},
year = {2008},
number = {10},
}

@article{03,
journal = {The simulation of piano string vibration: From physical models to finite difference schemes and digital waveguides},
title = {___},
year = {2003},
volume = {114},
}

@book{ha17,
author = {David M. Howard and Jamie A. S. Angus},
booktitle = {Acoustics and Psychoacoustics},
year = {2017},
publisher = {Traducao. [s.l.] Focal press},
doi = {10.4324/9781315716879},
title = {Acoustics and Psychoacoustics},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
}

@article{s,
author = {Ilya Sutskever and James Martens and George Dahl and Geoffrey Hinton},
title = {On the importance of initialization and momentum in deep learning},
year = {2013},
volume = {2013},
journal = {30th International Conference on Machine Learning, ICML 2013},
number = {PART 3},
pages = {2176--2184},
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods. Copyright 2013 by the author(s).},
}

@book{mp69,
author = {J. Nievergelt},
issn = {00189340},
title = {R69-13 Perceptrons: An Introduction to Computational Geometry},
booktitle = {IEEE Transactions on Computers},
abstract = {Perceptrons were invented in the fifties when "learning machine" was an exciting new concept. For a decade thereafter, there has been much describing, experimenting, and speculating about what perceptrons can and cannot do. Discussions of this topic were typically lively and vague, because the underlying model and the concepts used were rarely completely defined. Copyright \textcopyright 1969 by The Institute of Electrical and Electronics Engineers, Inc.},
publisher = {MIT Press, Cambridge},
address = {MA},
doi = {10.1109/T-C.1969.222718},
volume = {C-18},
year = {1969},
pages = {572},
number = {6},
}

@book{das93,
author = {SA Van Duyne},
edition = {Proceeding},
publisher = {Anais�INTERNATIONAL COMPUTER MUSIC ACCOCIATION},
year = {1993},
abstract = {An extremely efficient method for modeling wave propagation in a membrane is provided by the multidimensional extension of the digital waveguide. The 2-D digital waveguide mesh is constructed out of bidirectional delay units and scattering junctions. We show that it coincides with the standard finite difference approximation scheme for the 2-D wave equation, and we derive the dispersion error. Applications may be found in physical models of drums, soundboards, cymbals, gongs, small-box reverberators, and other acoustic constructs where a one-dimensional model is less desirable.},
issn = {1026-1087},
title = {Physical modeling with the 2-D digital waveguide mesh},
booktitle = {Proceedings of the International Computer Music Conference (ICMC)},
isbn = {1026-1087},
pages = {40--47},
url = {http://people.ece.cornell.edu/land/courses/ece5760/LABS/f2011/vanduyne93physical.pdf},
}

@article{rhw,
author = {D. E. Rumelhart and G. E. Hinton and R. J. Williams},
journal = {Readings in Cognitive Science: A Perspective from Psychology and Artificial Intelligence},
title = {Learning Internal Representations by Error Propagation},
doi = {10.1016/B978-1-4832-1446-7.50035-2},
pages = {399--421},
volume = {1985},
isbn = {1558600132},
year = {2013},
}

@book{yyk15,
author = {Neha Yadav and Anupam Yadav and Manoj Kumar},
address = {Traducao. [s.l.]},
volume = {16},
pages = {13--15},
publisher = {Springer},
title = {An Introduction to Neural Network Methods for Differential Equations},
year = {2015},
abstract = {Here we are presenting a brief history of neural networks, given in Haykin (Neural networks: a comprehensive foundation, 2002) [7], Zurada (Introduction to artificial neural systems, 2001) [8], Nielsen (Neurocomputing, 1990 [9] in terms of the development of architectures and algorithms that are widely used today. The history of neural networks has been divided in four stages: Beginning of neural networks, First golden age, Quiet Years and Renewed enthusiasm which shows the interplay among biological experimentation, modeling and computer simulation, hardware implementation.},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84924190922&partnerID=tZOtx3y1},
issn = {21915318},
isbn = {978-94-017-9815-0},
booktitle = {SpringerBriefs in Applied Sciences and Technology},
keywords = {adaline,biological modeling,neurocomputing,pattern recognition,perceptron,signal processing},
mendeley-tags = {adaline,biological modeling,neurocomputing,pattern recognition,perceptron,signal processing},
}

@unpublished{,
title = {No Title},
url = {https://github.com/tesserato/tesserato.github.io%3E},
}

@unpublished{p85,
author = {Stephen Plowright},
abstract = {Early, extensive studies of feed-forward connectionist networks of analog units with sigmoid activation function. Independently derives a generalization of the Perceptron (delta) learning rule that is similar to the formulation of Rumelhart, Hinton & Williams (1986). [AL 3/1/2004, 3/3/2004].},
year = {2017},
doi = {10.20850/9781329443068},
title = {Learning Logic},
booktitle = {Learning Logic},
}

@article{th12,
author = {Tijmen Tieleman and G Hinton},
number = {2},
volume = {6},
year = {2012},
journal = {Mach. Learn},
title = {Divide the gradient by a running average of its recent magnitude. COURSERA Neural Netw},
}

@book{s16,
author = {S Salsa},
address = {Traducao. [s.l.] v. 99},
pages = {53--1824--53--1824},
doi = {10.5860/choice.193386},
issn = {0009-4978},
abstract = {applicability for this approach.},
publisher = {Springer},
number = {04},
title = {Partial differential equations in action: from modelling to theory},
booktitle = {Choice Reviews Online},
volume = {53},
year = {2015},
}

@article{b05,
author = {Julien Bensa and Stefan Bilbao and  Kronl and Richard -Martinet and Julius O. Smith and Thierry Voinier},
title = {Computational modeling of stiff piano strings using digital waveguides and finite differences},
abstract = {As is well-known, digital waveguides offer a computationally efficient, and physically motivated means of simulating wave propagation in strings. The method is based on sampling the traveling wave solution to the ideal wave equation and linearly filtering this solution to simulate dispersive effects due to stiffness and frequency-dependent loss; such digital filters may terminate the waveguide or be embedded along its length. For strings of high stiffness, however, dispersion filters can be difficult to design and expensive to implement. In this article, we show how high-quality time-domain terminating filters may be derived from given frequency-domain specifications which depend on the model parameters. Particular attention is paid to the problem of phase approximation, which, in the case of high stiffness, is strongly nonlinear. Finally, in the interest of determining the limits of applicability of digital waveguide techniques, we make a comparison with more conventional finite difference schemes, in terms of computational cost and numerical dispersion, for a set of string stiffness parameters. \textcopyright S. Hirzel Verlag.},
journal = {Acta Acustica united with Acustica},
number = {2},
volume = {91},
pages = {289--298},
issn = {16101928},
year = {2005},
}

@book{d16,
author = {Timothy Dozat},
pages = {2013--2016},
number = {1},
booktitle = {ICLR Workshop},
title = {Incorporating Nesterov Momentum into Adam},
abstract = {This work aims to improve upon the recently proposed and rapidly popular-ized optimization algorithm Adam (Kingma & Ba, 2014). Adam has two main components—a momentum component and an adaptive learning rate component. However, regular momentum can be shown conceptually and empirically to be in-ferior to a similar algorithm known as Nesterov's accelerated gradient (NAG). We show how to modify Adam's momentum component to take advantage of insights from NAG, and then we present preliminary evidence suggesting that making this substitution improves the speed of convergence and the quality of the learned mod-els.},
year = {2016},
}

@article{58,
volume = {65},
title = {___},
year = {1958},
journal = {The perceptron: a probabilistic model for information storage and organization in the brain},
}

@book{b09,
author = {Stefan Bilbao},
year = {2009},
abstract = {Digital sound synthesis has long been approached using standard digital filtering techniques. Newer synthesis strategies, however, make use of physical descriptions of musical instruments, and allow for much more realistic and complex sound production and thereby synthesis becomes a problem of simulation. This book has a special focus on time domain finite difference methods presented within an audio framework. It covers time series and difference operators, and basic tools for the construction and analysis of finite difference schemes, including frequency-domain and energy-based methods, with special attention paid to problems inherent to sound synthesis. Various basic lumped systems and excitation mechanisms are covered, followed by a look at the 1D wave equation, linear bar and string vibration, acoustic tube modelling, and linear membrane and plate vibration. Various advanced topics, such as the nonlinear vibration of strings and plates, are given an elaborate treatment. Key features: Includes a historical overview of digital sound synthesis techniques, highlighting the links between the various physical modelling methodologies. A pedagogical presentation containing over 150 problems and programming exercises, and numerous figures and diagrams, and code fragments in the MATLAB\textregistered programming language helps the reader with limited experience of numerical methods reach an understanding of this subject. Offers a complete treatment of all of the major families of musical instruments, including certain audio effects. Numerical Sound Synthesis is suitable for audio and software engineers, and researchers in digital audio, sound synthesis and more general musical acoustics. Graduate students in electrical engineering, mechanical engineering or computer science, working on the more technical side of digital audio and sound synthesis, will also find this book of interest. \textcopyright 2009 John Wiley & Sons, Ltd.},
address = {Traducao. [s.l.] John & Sons},
booktitle = {Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics},
doi = {10.1002/9780470749012},
isbn = {9780470510469},
title = {Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics},
publisher = {Wiley},
pages = {1--441},
}

@article{95,
author = {S.A. Van Duyne and J.O. Smith},
doi = {10.1109/aspaa.1995.482998},
abstract = {The 2D digital waveguide mesh has proven to be effective and efficient in the modeling of musical membranes and plates, particularly in combination with recent simplifications in modeling stiffness, nonlinearities, and felt mallet excitations. The rectilinear 3D extension to the mesh had been suggested, and has been applied to the case of room acoustics. However, it requires the use of 6-port scattering junctions, which make a multiply-free implementation impossible in the isotropic case. The 4-port scattering junctions of the 2D mesh required only an internal divide by 2, which could be implemented as a right shift in binary arithmetic. However, the 6-port junction requires a divide by 3. The multiply-free cases occur for N-port junctions in which N is a power of two. We propose here a tetrahedral distribution of multiply-free 4-port scattering junctions filling space much like the molecular structure of the diamond crystal, where the placement of the scattering junctions corresponds to the placement of the carbon nuclei, and the bi-directional delay units correspond to the four tetrahedrally spaced single bonds between each pair of nuclei. We show that the tetrahedral mesh is mathematically equivalent to a finite difference scheme (FDS) which approximates the 3D lossless wave equation. We further compute the frequency- and direction-dependent plane wave propagation speed dispersion error},
pages = {234--237},
title = {The tetrahedral digital waveguide mesh},
volume = {1995},
year = {2002},
journal = {Applications of Signal Processing to Audio and Acoustics},
}

@article{fra,
author = {Federico Fontana and Davide Rocchesso and Enzo Apollonio},
volume = {2000},
journal = {Proceedings of the COST G-6 Conference on Digital Audio Effects (DAFX-00)},
pages = {7--10},
title = {Using the Waveguide Mesh in Modelling 3D Resonators},
url = {http://ftp.funet.fi/index/Science/audio/dafx/2000/profs.sci.univr.it/%257Edafx/Final-Papers/pdf/Fontana_paper.pdf},
year = {2000},
}

@article{k,
author = {Bh SravyaPranati and D. Suma and Ch ManjuLatha and Sudhakar Putheti},
doi = {10.1007/978-981-15-7062-9_69},
pages = {689--695},
volume = {196},
isbn = {9789811570612},
abstract = {Convolutional neural networks have been established as an unbelievable class of models for picture confirmation issues. Enabled by these results, we give CNN's extensive trial evaluation a large degree of video-action syllabus using another dataset of 8M YouTube accounts. To get the Chronicles and its effects, we've used a YouTube video specification framework, which gives the names of the accounts they focus on. While the names are machine-generated, they are high-precision and are derived from a group of human-based icons, including metadata and question click signals. We have filtered the video names (Knowledge Graph Components) using both modern and manual curation strategies, including curiosity regarding whether the print is clearly indisputable. After that, we decode each video at one-layout per-second and use the deep CNN adjusted to ImageNet to remove the cover depicted immediately before the course of the action layer. Finally, we've stuffed the packaging features and made available both features and video level names for download. We train unique (ambiguous) game plan models on the dataset, survey them using significant evaluation estimates, and report them as baseline. Regardless of the size of the dataset, a portion of our models train the connection in less than a day on a singular machine using VGG. CNN our course release code for setting up model deals and generating predictions.},
journal = {Smart Innovation, Systems and Technologies},
year = {2021},
issn = {21903026},
title = {Large-Scale Video Classification with Convolutional Neural Networks},
keywords = {convolutional neural networks,dataset,labels,video classification},
mendeley-tags = {convolutional neural networks,dataset,labels,video classification},
}

@article{xac,
author = {W Xu and M Auli and S Ccg Clark},
journal = {CL (},
title = {Supertagging with a Recurrent Neural Network},
volume = {2},
}

@unpublished{Pse2010,
author = {C L I Pse and E Serv Ed},
url = {https://github.com/crabacus/the-open-source-drumkit%3E},
title = {the Open Source},
year = {2010},
booktitle = {Source},
pages = {2--5},
}

@article{o,
author = {A\"aron Van Den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
eprint = {1606.05328},
title = {Conditional image generation with PixelCNN decoders},
year = {2016},
archiveprefix = {arXiv},
issn = {10495258},
volume = {2016},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
pages = {4797--4805},
arxivid = {1606.05328},
journal = {Advances in Neural Information Processing Systems},
}

@article{k,
author = {G Klambauer and  Others},
title = {Self-normalizing neural networksAdvances in Neural Information Processing Systems},
volume = {2017},
journal = {Anais�},
}

@article{w,
author = {DrumGizmo Wiki},
volume = {2018},
url = {https://www.drumgizmo.org/wiki/doku.php%3E},
title = {DrumGizmo Wiki},
}

@book{e,
author = { Google},
address = {Dispon�vel em},
abstract = {NSynth Super is an open source experimental instrument. It gives musicians the ability to explore completely new sounds generated by the NSynth machine learning algorithm.},
publisher = {<},
title = {Making music using new sounds generated with machine learning},
url = {https://www.youtube.com/watch?v=iTXU9Z0NYoU},
year = {2018},
keywords = {creation,creativity},
mendeley-tags = {creation,creativity},
}

@book{b16,
author = {T Bovermann and  Others},
publisher = {Springer},
title = {Musical Instruments in the 21st Century},
address = {Traducao. [s.l.]},
year = {2017},
abstract = {The great importance of music in Etruscan civilization is attested by several ancient Greek and Latin authors, who place a strong emphasis on the aerophones such as auloi, conches, horns, and trumpets of various kinds-namely the Latin cornu, lituus, and tuba. This assertion has been confirmed in recent times by various scholars, who also take into account the large number of musical instruments and the wide range of iconographic evidence that have been found at Etruscan sites, which span from the beginning of the seventh century to the first century BCE. While the only specimens that survive are, of course, those made of nonperishable materials like metal or clay, the iconographic evidence-such as the tomb paintings and other kinds of representations-clearly show that almost all of the musical instruments that were widespread in the Mediterranean at the time were also used in Etruria on many different occasions, including public and private ceremonies, rituals, and daily life. Tantalizing glimpses of the earlier presence of perishable instruments-such as wooden pipes and string instruments-are provided by the surviving parts made of ivory or bone, including a few pipes, joints between pipe and reed, and plectra. One notable feature in the Etruscan context seems to be the complete lack of membranophones-in particular the frame drum-which had still not appeared by the turn of the fifth century, and by which time all of the other musical instruments were already firmly established in the area.},
booktitle = {Musical Instruments in the 21st Century},
doi = {10.1007/978-981-10-2951-6},
}

@book{ck16,
author = {Antoine Chaigne and Jean Kergomard},
abstract = {This book, the first English-language translation of Acoustique des instruments de musique, Second Edition, presents the necessary foundations for understanding the complex physical phenomena involved in musical instruments. What is the function of the labium in a flute? Which features of an instrument allow us to make a clear audible distinction between a clarinet and a trumpet? With the help of numerous examples, these questions are addressed in detail. The authors focus in particular on the significant results obtained in the field during the last fifteen years. Their goal is to show that elementary physical models can be used with benefit for various applications in sound synthesis, instrument making, and sound recording. The book is primarily addressed to graduate students and researchers; however it could also be of interest for engineers, musicians, craftsmen, and music lovers who wish to learn about the basics of musical acoustics.},
title = {Acoustics of Musical Instruments},
year = {2016},
isbn = {978-1-4939-3679-3},
address = {Traducao. [s.l.]},
pages = {XXV, 844},
publisher = {Springer},
}

@article{bff09,
author = {E. S. Brunette and R. C. Flemmer and C. L. Flemmer},
journal = {ICARA 2009 - Proceedings of the 4th International Conference on Autonomous Robots and Agents},
isbn = {9781424427130},
pages = {385--392},
year = {2009},
volume = {2009},
doi = {10.1109/ICARA.2000.4804025},
abstract = {This paper reviews the field of artificial intelligence focusing on embodied artificial intelligence. It also considers models of artificial consciousness, agent-based artificial intelligence and the philosophical commentary on artificial intelligence. It concludes that there is almost no consensus nor formalism in the field and that the achievements of the field are meager. \textcopyright2009 IEEE.},
title = {A review of artificial intelligence},
keywords = {artificial intelligence,consciouness,embodied intelligence,machine intelligence},
mendeley-tags = {artificial intelligence,consciouness,embodied intelligence,machine intelligence},
}

@book{16,
author = {Soheil Bahrampour and Naveen Ramakrishnan and Lukas Schott and Mohak Shah},
url = {http://search.proquest.com/docview/1626785137?accountid=10755%5Cnhttp://sfx.bib-bvb.de/sfx_uben?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=unknown&sid=ProQ:ProQ:abiglobal&atitle=BEHAVIOUR+OF+ELDERLY+USERS+ON+FACEBOOK+TOWARD+VIRAL+M},
archiveprefix = {arXiv},
number = {1},
arxivid = {1511.06435},
issn = {19494912},
publisher = {Comparative study of caffe},
address = {neon, theano, and torch for deep learning},
pages = {1--14},
year = {2015},
booktitle = {ArXiv},
isbn = {9150617397},
eprint = {1511.06435},
volume = {2},
abstract = {Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.},
title = {Comparative Study of Caffe, Neon, Theano, and Torch for Deep Learning},
keywords = {business and economics--marketing and purchasing,comparative studies,discount coupons,europe,experiment/theoretical treatment,internet services industry,lotteries,marketing,older people,social networks,united states,united states--us,viral marketing,western europe},
mendeley-tags = {business and economics--marketing and purchasing,comparative studies,discount coupons,europe,experiment/theoretical treatment,internet services industry,lotteries,marketing,older people,social networks,united states,united states--us,viral marketing,western europe},
}

@article{s87,
author = {Henrik V. Sorensen and Douglas L. Jones and Michael T. Heideman and C. Sidney Burrus},
doi = {10.1109/TASSP.1987.1165220},
number = {6},
pages = {849--863},
abstract = {This tutorial paper describes the methods for constructing fast algorithms for the computation of the discrete Fourier transform (DFT) of a real-valued series. The application of these ideas to all the major fast Fourier transform (FFT) algorithms is discussed, and the various algorithms are compared. We present a new implementation of the real-valued split-radix FFT, an algorithm that uses fewer operations than any other real-valued power-of-2-length FFT. We also compare the performance of inherently real-valued transform algorithms such as the fast Hartley transform (FHT) and the fast cosine transform (FCT) to real-valued FFT algorithms for the computation of power spectra and cyclic convolutions. Comparisons of these techniques reveal that the alternative techniques always require more additions than a method based on a real-valued FFT algorithm and result in computer code of equal or greater length and complexity. Copyright \textcopyright 1987 by The Institute of Electrical and Electronics Engineers, Inc.},
issn = {00963518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
year = {1987},
volume = {35},
title = {Real-Valued Fast Fourier Transform Algorithms},
}

@article{sc,
author = {A M Sarroff and M A Casey},
title = {Musical audio synthesis using autoencoding neural nets},
volume = {2014},
journal = {ICMC},
}

@article{rn,
author = {S J Russell and P Norvig},
volume = {2016},
title = {Artificial intelligence: a modern approach},
}

@article{s,
author = {Lawrence Fritts},
url = {http://theremin.music.uiowa.edu/MIS-Pitches-2012/MISTenorTrombone2012.html%0Ahttp://theremin.music.uiowa.edu/MIS.html},
year = {1997},
journal = {University of Iowa},
title = {University of Iowa Electronic Music Studios},
volume = {2018},
abstract = {The University of Iowa Musical Instrument Samples (MIS) are created by Lawrence Fritts, Director of the Electronic Music Studios and Associate Professor of Composition at the University of Iowa. Since 1997, these recordings have been freely available on this website and may be downloaded and used for any projects, without restrictions. These are used by musicians, application developers, teachers, students, and researchers. These have been used in over 270 published research articles and books.},
}

@article{l,
author = {Earlence Fern Ivan Evtimov, Kevin Eykholt and  es and Bo Li},
volume = {2018},
abstract = {The BAIR Blog},
title = {The Berkeley Artificial Intelligence Research Blog},
url = {http://bair.berkeley.edu/blog/},
year = {2017},
journal = {Bair},
}

@article{dhs11,
author = {John Duchi and Elad Hazan and Yoram Singer},
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. The adaptation, in essence, allows us to find needles in haystacks in the form of very predictive yet rarely observed features. Our paradigm stems from recent advances in online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies the task of setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We corroborate our theoretical results with experiments on a text classification task, showing substantial improvements for classification with sparse datasets.},
title = {Adaptive subgradient methods for online learning and stochastic optimization},
year = {2010},
pages = {257--269},
isbn = {9780982252925},
journal = {COLT 2010 - The 23rd Conference on Learning Theory},
volume = {12},
}

@article{v00,
author = {Kathryn Vaughn},
title = {Music and Mathematics: Modest Support for the Oft-Claimed Relationship},
year = {2000},
number = {3/4},
volume = {34},
abstract = {Explores three meta-analyses investigating the relationship between music and mathematics on: (1) correlational studies (n=20); (2) experimental training studies (n=6) instructing students in music performance, then testing them on mathematics skills; and (3) experimental studies (n=15) investigating whether listening to background music during a mathematics test elevated test scores. (CMK)},
issn = {00218510},
doi = {10.2307/3333641},
journal = {Journal of Aesthetic Education},
pages = {149},
}

@unpublished{z12,
author = {Matthew D. Zeiler},
url = {http://arxiv.org/abs/1212.5701},
annote = {preprint},
abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
arxivid = {1212.5701},
eprint = {1212.5701},
archiveprefix = {arXiv},
year = {2012},
title = {ADADELTA: An Adaptive Learning Rate Method},
}

@article{oa,
author = {Tim Olson},
title = {Applied Fourier Analysis},
abstract = {The subject of Fourier Analysis is at the center of many modern sciences. Physics and engineering depend so heavily on the subject, it is hard to imag- ine even mentioning them without thinking immediately about frequency- dependent phenomena: light, sound, orbits, and vibrations to name a few. Many other scientific fields also are highly dependent upon Fourier Analy- sis for understanding even the most basic of phenomena, such as population dynamics in biology. Fourier Analysis is also essential in understanding what are some of the most common occurrences in everyday life. The various peri- odic phenomena of the sun, the moon, the tides, and the seasons are yet to be completely understood. We know the sun and moon will rise with certainty, and their secondary seasonal effect on wind and tide-related phenomena such as el Nino are still somewhat of a mystery. These periodic effects are drastic and life altering, and are naturally studied with Fourier Analysis.},
year = {2017},
journal = {Applied Fourier Analysis},
doi = {10.1007/978-1-4939-7393-4},
volume = {2017},
}

@book{p17,
author = {A Parvat and  Others},
title = {A survey of deep-learning frameworks},
year = {2017},
edition = {Inventive },
publisher = {Anais�IEEE},
}

@article{dsf14,
author = {Mat Dalgleish and Chris Foster and Steve Spencer},
title = {Blurring the Lines : an Integrated Compositional Model for Digital Music Instrument Design},
journal = {CIM},
year = {2014},
volume = {14},
}

@book{dv16,
author = {Vincent Dumoulin and Francesco Visin},
arxivid = {1603.07285},
year = {2016},
eprint = {1603.07285},
title = {A guide to convolution arithmetic for deep learning},
url = {http://arxiv.org/abs/1603.07285},
publisher = {ArXiv e-prints},
abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
address = {mar},
archiveprefix = {arXiv},
}

@article{ssh,
author = {C Southall and R Stables and J Hockman},
title = {Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks},
journal = {SMIR},
volume = {2016},
}

@article{r06,
author = {Tim Reiffenstein},
number = {3},
issn = {00083658},
year = {2006},
title = {Codification, patents and the geography of knowledge transfer in the electronic musical instrument industry},
doi = {10.1111/j.1541-0064.2006.00143.x},
journal = {Canadian Geographer},
abstract = {Recent research in economic geography has emphasized tacit knowledge as the basis of industrial learning. In contrast, codification and the practices of industrial writing have received little attention for the roles they play in mobilizing knowledge across space. This paper offers insight into the geographies of codification through an examination of technology transfer in the electronic musical instrument industry between 1965 and 1995. The research draws on a variety of primary and secondary data that include interviews with inventors, biographical accounts and patent analysis. These sources offer perspective on the career trajectories of three U.S. inventors who transferred knowledge from various contexts in California's high-tech industry to the Japanese firm, Yamaha. Conceptually, the paper draws on the actor-network theory and Latour's idea of translation to highlight the detours inventors must take to register novelty. The analysis reveals the problematic nature of codified knowledge and its transfer; in this case codified knowledge was mobile internationally but not locally, at least until it reached Japan. The paper argues for the need to understand how texts such as patents are produced-the context of their authorship, the geographies of their circulation and their efficacy for shaping further innovative practice. \textcopyright 2006 Canadian Association of Geographers/L'Association canadienne des g\'eographes.},
pages = {298--318},
volume = {50},
}

@article{r,
author = {Wei‐Meng Lee},
volume = {2015},
year = {2019},
doi = {10.1002/9781119557500},
title = {Python\textregistered Machine Learning},
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
journal = {Python\textregistered Machine Learning},
}

@article{pw,
author = {M C Pereyra and L A Ward},
title = {Harmonic analysis:from Fourier to wavelets.},
journal = {Traducao. [s.l.] American Mathematical Soc},
volume = {2012},
}

@inproceedings{nyc15,
author = {Anh Nguyen and Jason Yosinski and Jeff Clune},
archiveprefix = {arXiv},
pages = {427--436},
title = {Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
year = {2015},
volume = {07-12-June},
arxivid = {1412.1897},
doi = {10.1109/CVPR.2015.7298640},
eprint = {1412.1897},
abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call 'fooling images' (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
isbn = {9781467369640},
issn = {10636919},
}

@article{zf,
author = {E Zwicker and H Fastl},
volume = {2013},
journal = {Traducao. [s.l.] Springer Science & Business Media},
title = {Psychoacoustics: Facts and models.},
}

@article{c,
author = {Ben Coppin},
journal = {Expert Systems},
year = {2004},
abstract = {This book is intended for students of computer science at the college level, or students of other subjects that cover Artificial Intelligence. It also is intended to be an interesting and relevant introduction to the subject for other students or individuals who simply have an interest in the subject.},
issn = {02650096},
volume = {2004},
title = {Artificial Intelligence Illuminated},
pages = {768},
isbn = {0763732303},
}

@book{v,
author = {Robert J. Merlo},
url = {http://www.asimovinstitute.org/neural-network-zoo/%3E},
year = {1999},
booktitle = {Energy (Norwalk, Connecticut)},
address = {Dispon�vel em},
abstract = {Artificial intelligence computing offers lower cost and greater efficiency.},
title = {The neural network},
issn = {01499386},
volume = {24},
pages = {33},
edition = {The Asimov},
publisher = {<},
number = {2},
}

@article{ss,
author = {Elias M Stein and Lillian Pierce},
number = {May},
volume = {2003},
issn = {0002-9920},
isbn = {9780691113845},
title = {Princeton Lectures in Analysis},
journal = {Review},
pages = {641--647},
year = {2012},
}

@book{haks18,
author = {M C Horowitz and Gregory C. Allen and Elsa B. Kania and Paul Scharre},
abstract = {This report is part of the Center for a New American Security's series on Artificial Intelligence and International Security. The series examines the potential consequences of advances in artificial intelligence for the national security community. Nearly every aspect of national security could be transformed by artificial intelligence. AI has applications for defense, intelligence, homeland security, diplomacy, surveillance, cybersecurity, information, and economic tools of statecraft. The United States must not only anticipate these developments, but act decisively to prepare for uses by competitors and take advantage of the opportunities AI presents. ALSO},
year = {2018},
url = {https://www.cnas.org/publications/reports/strategic-competition-in-an-era-of-artificial-intelligence},
number = {July},
title = {Strategic Competition in an Era of Artificial Intelligence | Center for a New American Security},
}

@article{wh,
author = {Bernard Widrow and Marcian E. Hoff},
title = {Adaptive switching circuits},
year = {1989},
journal = {Wescon Conference Record},
pages = {709--717},
abstract = {Use of switching theory for system design is considered. An approach is taken in this paper which does not require an explicit use of the truth table. The design objective is the minimization of the average number of errors, rather than a minimization of the number of logical components used. The nature of the logical elements is quite unconventional. The system design procedure is adaptive, and is based upon an iterative search process. Performance feedback is used to achieve automatic system synthesis, i.e., the selection of the 'best' system from a restricted but useful class of possibilities. The designer 'trains' the system to give the correct responses by 'showing' it examples of inputs and respective desired outputs. The more examples 'seen', the better is the system performance.},
volume = {1960},
}

@book{r18,
author = {Adam Roberts and Jesse Engel and Sageev Oore and Douglas Eck},
issn = {16130073},
booktitle = {CEUR Workshop Proceedings},
title = {Learning latent representations of music to generate interactive musical palettes},
year = {2018},
volume = {2068},
abstract = {Advances in machine learning have the potential to radically reshape interactions between humans and computers. Deep learning makes it possible to discover powerful representations that are capable of capturing the latent structure of highdimensional data such as music. By creating interactive latent space "palettes" of musical sequences and timbres, we demonstrate interfaces for musical creation made possible by machine learning. We introduce an interface to the intuitive, low-dimensional control spaces for high-dimensional note sequences, allowing users to explore a compositional space of melodies or drum beats in a simple 2-D grid. Furthermore, users can define 1-D trajectories in the 2-D space for autonomous, continuous morphing during improvisation. Similarly for timbre, our interface to a learned latent space of audio provides an intuitive and smooth search space for morphing between the timbres of different instruments. We remove technical and computational barriers by embedding pre-trained networks into a browser-based GPU-accelerated framework, making the systems accessible to a wide range of users while maintaining potential for creative flexibility and personalization.},
keywords = {deep learning,latent space,musical interface,variational autoencoder},
mendeley-tags = {deep learning,latent space,musical interface,variational autoencoder},
}

@unpublished{kb14,
author = {Diederik P. Kingma and Jimmy Lei Ba},
archiveprefix = {arXiv},
annote = {preprint},
title = {Adam: A method for stochastic optimization},
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
arxivid = {1412.6980},
eprint = {1412.6980},
year = {2015},
}

@unpublished{dmp18,
author = {Chris Donahue and Julian McAuley and Miller Puckette},
title = {Adversarial audio synthesis},
abstract = {Audio signals are sampled at high temporal resolutions, and learning to synthesize audio requires capturing structure across a range of timescales. Generative adversarial networks (GANs) have seen wide success at generating images that are both locally and globally coherent, but they have seen little application to audio generation. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. WaveGAN is capable of synthesizing one second slices of audio waveforms with global coherence, suitable for sound effect generation. Our experiments demonstrate that-without labels-WaveGAN learns to produce intelligible words when trained on a smallvocabulary speech dataset, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. We compare WaveGAN to a method which applies GANs designed for image generation on image-like audio feature representations, finding both approaches to be promising.},
booktitle = {arXiv},
issn = {23318422},
annote = {preprint},
archiveprefix = {arXiv},
year = {2018},
eprint = {1802.04208},
arxivid = {1802.04208},
}

@book{rkk18,
author = {Risheng Liu and Pan Mu and Jin Zhang},
arxivid = {1909.10819},
booktitle = {arXiv},
archiveprefix = {arXiv},
eprint = {1909.10819},
abstract = {Along with the development of learning and vision, Alternating Direction Method of Multiplier (ADMM) has become a popular algorithm for separable optimization model with linear constraint. However, the ADMM and its numerical variants (e.g., inexact, proximal or linearized) are awkward to obtain state-of-The-Art performance when dealing with complex learning and vision tasks due to their weak task-Adaption ability. Recently, there has been an increasing interest in incorporating task-specific computational modules (e.g., designed filters or learned architectures) into ADMM iterations. Unfortunately, these task-related modules introduce uncontrolled and unstable iterative flows, they also break the structures of the original optimization model. Therefore, existing theoretical investigations are invalid for these resulted task-specific iterations. In this paper, we develop a simple and generic proximal ADMM framework to incorporate flexible task-specific module for learning and vision problems. We rigorously prove the convergence both in objective function values and the constraint violation and provide the worst-case convergence rate measured by the iteration complexity. Our investigations not only develop new perspectives for analyzing task-Adaptive ADMM but also supply meaningful guidelines on designing practical optimization methods for real-world applications. Numerical experiments are conducted to verify the theoretical results and demonstrate the efficiency of our algorithmic framework.},
year = {2019},
title = {On the convergence of ADMM with task adaption and beyond},
issn = {23318422},
keywords = {computer vision,global convergence,proximal admm,task-adapted optimization},
mendeley-tags = {computer vision,global convergence,proximal admm,task-adapted optimization},
}

@article{pg,
author = {Josh Patterson and Adam Gibson},
volume = {2017},
title = {Deep Learning: A Practitioner's Approach. " O'Reilly Media, Inc."},
}

@unpublished{s16,
author = {Patsorn Sangkloy and Jingwan Lu and Chen Fang and Fisher Yu and James Hays},
doi = {10.1109/CVPR.2017.723},
annote = {preprint},
year = {2017},
arxivid = {1612.00835},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
title = {Scribbler: Controlling deep image synthesis with sketch and color},
abstract = {Several recent works have used deep convolutional networks to generate realistic imagery. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach generates more realistic, diverse, and controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.},
eprint = {1612.00835},
isbn = {9781538604571},
archiveprefix = {arXiv},
pages = {6836--6845},
volume = {2017-Janua},
}

@book{p18,
author = {A Pfalz},
title = {Generating Audio Using Recurrent Neural Networks},
year = {2018},
}

@article{m,
author = {Scott a Van Duyne and Iii Smith Julius O},
journal = {Area},
abstract = {Acoustical physical modelling synthesis uses mathematical algorithms to describe a real-world sound production process or propagational environ-ment. Digital waveguides can be used to form a 1D model of the vocal tract, simplistically represented as a series of cylindrical tubes of varying radius along a straight axis. This 1D signal propagating element can also be extended to create a digital waveguide mesh (DWM), giving acoustical synthesis of a higher dimensional structure, such as a 2D surface or 3D space. The work contained in this thesis is an investigation into the effects of increased dimensionality in the 1D waveguide vocal tract paradigm. A 2D DWM is configured as a model of the tract, such that shape characteristics are set within the width of the mesh. Wave propagation and reflection is simulated along the tract from the glottis to the lips, as well as across it, between the two inner walls, thereby removing plane-wave limitations inherent in the 1D model. The 2D tract is found to give accurate formant synthesis, producing vowels that give a good match to real-world targets. However, problems associated with high sampling frequency limitations and discontinuous dynamic operation are identified. Movements readily occurring in speech, such as diphthongs, are not easily accommodated by the static mesh structure. A novel alternative approach is also presented which maintains a rect-angular mesh, but maps the changing tract shapes onto the waveguide impedances. This allows for stable dynamic manipulation of the modelled space. Furthermore, sampling frequency limitations are removed, such that real-time operation and interaction with the 2D tract model is achieved. i Contents Abstract i Acknowledgments xi Declaration xii},
title = {Physical modelling of the vocal tract with the 2D digital waveguide mesh},
year = {2006},
pages = {40--47},
number = {April},
volume = {2006},
url = {http://www-users.york.ac.uk/$\sim$dtm3/Download/JackThesis.pdf},
}

@article{mhn,
author = {A L Maas and A Y Hannun and A Y Ng},
volume = {2013},
title = {Rectifier nonlinearities improve neural network acoustic models},
journal = {ICML. Anais�},
}

@article{Poczos1993,
author = {Lecturer Barnabas Poczos},
abstract = {The history of artificial neural networks is like a roller-coaster ride. There were times when it was popular(up), and there were times when it wasn't. We are now in one of its very big time. • Progression (1943-1960)-First Mathematical model of neurons * Pitts & McCulloch (1943) [MP43]-Beginning of artificial neural networks-Perceptron, Rosenblatt (1958) [R58] * A single neuron for classification * Perceptron learning rule * Perceptron convergence theorem [N62] • Degression (1960-1980)-Perceptron can't even learn the XOR function [MP69]-We don't know how to train MLP-1963 Backpropagation (Bryson et al.) * But not much attention • Progression (1980-)-1986 Backpropagation reinvented: * Learning representations by back-propagation errors. Rumilhart et al. Nature [RHW88]-Successful applications in * Character recognition, autonomous cars, ..., etc.-But there were still some open questions in * Overfitting? Network structure? Neuron number? Layer number? Bad local minimum points? When to stop training?-Hopfield nets (1982) [H82], Boltzmann machines [AHS85], ..., etc. • Degression (1993-) 1},
number = {1982},
year = {1993},
pages = {1--10},
url = {http://www.cs.cmu.edu/$\sim$10701/slides/Perceptron_Reading_Material.pdf},
title = {Perceptron History of Artificial Neural Networks The Neuron},
}

@article{,
title = {UNCLASSIFIED LIMITATION CHANGES TO : FROM :},
year = {1995},
}

@book{Papert,
author = {Seymour A Papert},
isbn = {9780262130431},
title = {Perceptrons},
}

@article{Diego1985,
author = {S A N Diego},
number = {V},
title = {862 18 120,},
year = {1985},
}

@article{,
title = {No Title},
}

@article{Harrison2015,
author = {Reginald L. Harrison and Stefan Bilbao and James Perry},
year = {2015},
abstract = {This paper presents a physical modelling sound synthesis environment for the production of valved brass instrument sounds. The governing equations of the system are solved using finite-difference time-domain (FDTD) methods and the environment is implemented in the C programming language. Users of the environment can create their own custom instruments and are able to control player parameters such as lip frequency, mouth pressure and valve openings through the use of instrument and score files. The algorithm for sound synthesis is presented in detail along with a discussion of optimisation methods used to reduce run time. Binaries for the environment are available for download online for multiple platforms.},
title = {An algorithm for a valved brass instrument synthesis environment using finite-difference time-domain methods with performance optimisation},
journal = {DAFx 2015 - Proceedings of the 18th International Conference on Digital Audio Effects},
}

@article{Sound1990,
author = {Xavier Serra and Julius O. Smith},
issn = {01489267},
title = {Spectral modeling synthesis. A sound analysis/synthesis system based on a deterministic plus stochastic decomposition},
volume = {14},
abstract = {Spectral modeling synthesis is an analysis-based technique capable of capturing the perceptual characteristics of a wide variety of sounds. The representation that results from the analysis is intuitive and is easily mapped to useful musical parameters. The analysis part is central to the system. It is a complex algorithm that requires the manual setting of a few control parameters. Further work may automate the analysis process, particularly if there is a specialization for a group of sounds. Some aspects of the analysis are also open to further research, in particular the peak-continuation algorithm. The synthesis from the deterministic plus stochastic representation is simple and can be performed in real time with current technology. A real-time implementation of this system would allow the use of this technnique in performance.},
doi = {10.2307/3680788},
year = {1990},
pages = {12--24},
number = {4},
journal = {Computer Music Journal},
}

@article{Serra2000,
author = {Xavier Serra and Jordi Bonada},
year = {1998},
abstract = {<!-- .Normal font-size 10.0pt; font-family "Times New Roman"; --> <p> <span>The basic Spectral Modeling Synthesis (SMS) technique models sounds as the sum of sinusoids plus a residual. Though this analysis/synthesis system has proved to be successful in transforming sounds, more powerful and intuitive musical transformations can be achieved by moving into the SMS high-level attribute plane. In this paper we describe how to extract high level sound attributes from the basic representation, modify them, and add them back before the synthesis stage. In this process new problems come up for which we propose some initial solutions.</span> </p>},
journal = {International Conference on Digital Audio Effects},
number = {February 2013},
url = {http://mtg.upf.edu/files/publications/dafx98-1.pdf},
title = {Sound Transformations Based on the SMS High Level Attributes},
}

@article{,
title = {Percussion Instrument Modelling In 3D : Sound Synthesis Through Time Domain Numerical Simulation University of Edinburgh},
}

@article{Hahn2017,
author = {Henrik Hahn},
title = {Expressive Sampling Synthesis - Learning Extended Source-Filter Models from Instrument Sound Databases for Expressive Sample Manipulations},
abstract = {This thesis addresses imitative digital sound synthesis of acoustically viable instruments with support of expressive, high-level control parameters. A general model is provided for quasi-harmonic instruments that reacts coherently with its acoustical equivalent when control parameters are varied. The approach builds upon recording-based methods and uses signal transformation techniques to manipulate instrument sound signals in a manner that resembles the behavior of their acoustical equivalents using the fundamental control parameters intensity and pitch. The method preserves the inherent quality of discretized recordings of a sound of acoustic instruments and introduces a transformation method that retains the coherency with its timbral variations when control parameters are modified. It is thus meant to introduce parametric control for sampling sound synthesis. The objective of this thesis is to introduce a new general model representing the timbre variations of quasi-harmonic music instruments regarding a parameter space determined by the control parameters pitch as well as global and instantaneous intensity. The model independently represents the deterministic and non-deterministic components of an instrument's signal and an extended source-filter model will be introduced for the former to represent the excitation and resonance characteristics of a music instrument by individual parametric filter functions. The latter component will be represented using a classic source-filter approach using filters with similar parameterization. All filter functions are represented using tensor-product B-splines to support for multivariate control variables. An algorithm will be presented for the estimation of the model's parameters that allows for the joint estimation of the filter functions of either component in a multivariate surface-fitting approach using a data-driven optimization strategy. This procedure also includes smoothness constraints and solutions for missing or sparse data and requires suitable data sets of single note recordings of a particular musical instrument. Another original contribution of the present thesis is an algorithm for the calibration of a note's intensity by means of an analysis of crescendo and decrescendo signals using the presented instrument model. The method enables the adjustment of the note intensity of an instrument sound coherent with the relative differences between varied values of its note intensity. A subjective evaluation procedure is presented to assess the quality of the transformations obtained using a calibrated instrument model and independently varied control parameters pitch and note intensity. Several extends of sound signal manipulations will be presented therein. For the support of inharmonic sounds as present in signals produced by the piano, a new algorithm for the joint estimation of a signal's fundamental frequency and inharmonicity coefficient is presented to extend the range of possible instruments to be manageable by the system. The synthesis system will be evaluated in various ways for sound signals of a trumpet, a clarinet, a violin and a piano.},
url = {https://hal.archives-ouvertes.fr/tel-01263656},
year = {2015},
}

@article{Serafin1996,
author = {Tsuyoshi Tasaki and Tetsuya Ogata and Hiroshi G Okuno and The Iteraction and Multiple People},
year = {2013},
doi = {10.1162/COMJ},
pages = {1--8},
number = {12},
title = {( B ) 有査読学術雑誌論文},
volume = {52},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 The Hands The Making of a Digital Musical Instrument - Torre et al..pdf\:pdf},
}

@article{Bonada2016,
author = {Jordi Bonada and Mart\'i Umbert and Merlijn Blaauw},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
abstract = {Sample and statistically based singing synthesizers typically require a large amount of data for automatically generating expressive synthetic performances. In this paper we present a singing synthesizer that using two rather small databases is able to generate expressive synthesis from an input consisting of notes and lyrics. The system is based on unit selection and uses the Wide-Band Harmonic Sinusoidal Model for transforming samples. The first database focuses on expression and consists of less than 2 minutes of free expressive singing using solely vowels. The second one is the timbre database which for the English case consists of roughly 35 minutes of monotonic singing of a set of sentences, one syllable per beat. The synthesis is divided in two steps. First, an expressive vowel singing performance of the target song is generated using the expression database. Next, this performance is used as input control of the synthesis using the timbre database and the target lyrics. A selection of synthetic performances have been submitted to the Interspeech Singing Synthesis Challenge 2016, in which they are compared to other competing systems.},
issn = {19909772},
year = {2016},
doi = {10.21437/Interspeech.2016-872},
title = {Expressive singing synthesis based on unit selection for the singing synthesis challenge 2016},
volume = {08-12-Sept},
pages = {1230--1234},
keywords = {expression control,singing voice synthesis,unitselection},
mendeley-tags = {expression control,singing voice synthesis,unitselection},
}

@article{Selfridge,
author = {Rod Selfridge and David J. Moffat and Joshua D. Reiss and Eldad J. Avital},
journal = {24th International Congress on Sound and Vibration, ICSV 2017},
pages = {1--8},
abstract = {A real-time physical sound synthesis model of an Aeolian harp is presented. The model uses semiempirical fluid dynamics equations to inform its operation, providing suitable parameters for users to interact. A basic wind model is included as well as an interface allowing user adjustable parameters. Sounds generated by the model were subject to objective measurements against real-world recordings, which showed that many of the physical properties of the harp were replicated in our model, but a possible link between harmonics and vibration amplitude was not. A perceptual test was performed, where participants were asked to rate sounds in terms of how plausible they were in comparison with spectral modelling synthesis and recorded Aeolian Harp samples. Evaluation showed that our model performed as well as an alternative non-physical synthesis method, but was not as authentic as actual recorded samples.},
title = {Real-time physical model of an Aeolian harp},
year = {2017},
keywords = {aeolian harp,physical model,real-time,sound synthesis},
mendeley-tags = {aeolian harp,physical model,real-time,sound synthesis},
}

@article{Blaauw2010,
author = {Merlijn Blaauw and Jordi Bonada and Music Technology Group and Universitat Pompeu Fabra},
title = {A n p s s},
year = {2010},
arxivid = {arXiv:1704.03809v3},
archiveprefix = {arXiv},
eprint = {arXiv:1704.03809v3},
pages = {1--9},
}

@article{Zappi2017,
author = {Victor Zappi and Andrew Allen and Sidney Fels},
url = {http://www.nime.org/proceedings/2017/nime2017_paper0028.pdf},
year = {2017},
journal = {NIME 2017 Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {145--150},
title = {Shader-based Physical Modelling for the Design of Massive Digital Musical Instruments},
abstract = {Physical modelling is a sophisticated synthesis technique, often used in the design of Digital Musical Instruments (DMIs). Some of the most precise physical simulations of sound propagation are based on Finite-Difference Time-Domain (FDTD) methods, which are stable, highly parameterizable but characterized by an extremely heavy computational load. This drawback hinders the spread of FDTD from the domain of off-line simulations to the one of DMIs. With this paper, we present a novel approach to real-time physical modelling synthesis, which implements a 2D FDTD solver as a shader program running on the GPU directly within the graphics pipeline. The result is a system capable of running fully interactive, massively sized simulation domains, suitable for novel DMI design. With the help of diagrams and code snippets, we provide the implementation details of a first interactive application, a drum head simulator whose source code is available online. Finally, we evaluate the proposed system, showing how this new approach can work as a valuable alternative to classic GPGPU modelling.},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/Shader-based Physical Modelling for the Design of Massive Digital Musical Instruments - Zappi et al..pdf\:pdf},
}

@article{Unterthiner2017,
author = {Thomas Unterthiner and L G Sep and Sepp Hochreiter},
eprint = {arXiv:1706.02515v5},
year = {2017},
title = {Self-Normalizing Neural Networks},
archiveprefix = {arXiv},
arxivid = {arXiv:1706.02515v5},
}

@article{Lokki2018,
author = {Tapio Lokki and Meinard M\"uller and Stefania Serafin and Vesa V\"alim\"aki},
title = {Special issue on "Sound and music computing"},
pages = {1--5},
journal = {Applied Sciences (Switzerland)},
issn = {20763417},
year = {2018},
doi = {10.3390/app8040518},
volume = {8},
number = {4},
}

@article{Morse,
author = {Bryan Morse},
title = {Magnitude and Phase The Fourier Transform : Examples , Properties , Common Pairs CS 450 : Introduction to Digital Signal and Image Processing Example : Fourier Transform of a Cosine Example : Fourier Transform of a Cosine Odd and Even Functions Sinusoids },
journal = {Image Processing},
}

@article{Karplus1983,
author = {Kevin Karplus and Alex Strong},
volume = {7},
journal = {Computer Music Journal},
year = {1983},
abstract = {There are many techniques currently used for digital music synthesis, including frequency modulation (FM) synthesis, waveshaping, additive synthesis, and subtractive synthesis. To achieve rich, natural sounds, all of them require fast arithmetic capability, such as is found on expensive computers or digital synthesizers. For musicians and experimenters without access to these machines, musically interesting digital synthesis has been almost impossible. The techniques described in this paper can be implemented quite cheaply on almost any computer. Real-time synthesis implementations have been done for Intel 8080A (by Alex Strong), Texas Instruments TMS9900 (by Kevin Karplus), and SC/MP (by Mike Plass) microprocessors. David Jaffe and Julius Smith have programmed the Systems Concept Digital Synthesizer at the Center for Computer Research in Music and Acoustics (CCRMA) to perform several variants of the algorithms (Jaffe and Smith 1983).},
pages = {43--55},
title = {Digital Synthesis of and Plucked-String Timbres},
number = {2},
}

@article{Chaigne1994,
author = {Antoine Chaigne and Anders Askenfelt},
doi = {10.1121/1.408459},
volume = {95},
issn = {NA},
number = {2},
year = {1994},
pages = {1112--1118},
abstract = {The first attempt to generate musical sounds by solving the equations of vibrating strings by means of finite difference methods (FDM) was made by Hiller and Ruiz [J. Audio Eng. Soc. 19, 462–472 (1971)]. It is shown here how this numerical approach and the underlying physical model can be improved in order to simulate the motion of the piano string with a high degree of realism. Starting from the fundamental equations of a damped, stiff string interacting with a nonlinear hammer, a numerical finite difference scheme is derived, from which the time histories of string displacement and velocity for each point of the string are computed in the time domain. The interacting force between hammer and string, as well as the force acting on the bridge, are given by the same scheme. The performance of the model is illustrated by a few examples of simulated string waveforms. A brief discussion of the aspects of numerical stability and dispersion with reference to the proper choice of sampling parameters is also included. \textcopyright 1994, Acoustical Society of America. All rights reserved.},
journal = {Journal of the Acoustical Society of America},
title = {Numerical simulations of piano strings. I. A physical model for a struck string using finite difference methods},
}

@article{Corporation1959,
author = {Westinghouse Electric Corporation and East Pittsburgh and Ann Arbor},
title = {L : L :  L : L :  L : L :},
volume = {31},
pages = {978--986},
number = {4},
year = {1959},
}

@misc{,
title = {1983 Extensions of the Karplus-Strong Plucked String Algorithm.pdf},
}

@article{Jarvelainen2001,
author = {Hanna J\"arvel\"ainen and Vesa V\"alim\"aki and Matti Karjalainen},
title = {Audibility of the timbral effects of inharmonicity in stringed instrument tones},
number = {April},
abstract = {Listening tests were conducted to find the audibility of inharmonicity in musical sounds produced by stringed instruments, such as the piano or the guitar. The audibility threshold of inharmonicity was measured at five fundamental frequencies. Results show that the detection of inharmonicity is strongly dependent on the fundamental frequency f0. A simple model is presented for estimating the threshold as a function of f0. The need to implement inharmonicity in digital sound synthesis is discussed. \textcopyright2001 Acoustical Society of America.},
journal = {Acoustic Research Letters Online},
issn = {15297853},
volume = {2},
year = {2001},
pages = {79--84},
doi = {10.1121/1.1374756},
}

@article{Masri,
author = {P Masri},
number = {0},
title = {Using Digital Waveguides},
volume = {44},
}

@article{Molteno2004,
author = {Timothy C. Molteno and Nicholas B. Tufillaro},
number = {9},
doi = {10.1119/1.1764557},
year = {2004},
journal = {American Journal of Physics},
issn = {0002-9505},
abstract = {We describe a detailed experimental investigation into the dynamics of a sinusoidally forced string. We find qualitative agreement with the predictions of the averaged equations of motion for a string in the high damping regime. At low damping we observe more complex phenomena not present in the averaged equations. (C) 2004 American Association of Physics Teachers.},
volume = {72},
title = {An experimental investigation into the dynamics of a string},
pages = {1157--1169},
}

@article{Oø,
author = {\^O \"O \`O\o and \"O \O Ð\textordmasculine \"O \~N \^U\'o\"o and \`O \O \`O \'O \`O \^U \'O \"O \O\"o and \O \`O \O\"o\`u\~n \`O\o and Ð \O \O\'y\textordmasculine \`I \~N\'o and Ð \"O \`O\o\"o\'o \`U \`O \O \'O\"o and \"O \'O \~N \O \'O \`U \O \'O \`O \'U Ð \'O \O and \`O \`O \"E\o\"o and \'A\`o\o\"o\'o \`U \O \'O\`o and Ð \`O \O \'A\`o and \O Ð \'O\"o\~n\`uð \O \'O\`o and \O \'O\`oð\'y \"O \O\'o\"o and \`I \^O \^O \"O \'U \`O \O \'O \'U \O \'O \`O \`O \`O\o\"o\'o \`U \`O\`u},
title = {\`I\'o\^u \"o × \aa \o \"o ð \aa\'o ðð \`o \`o \`e \'y× ð \aa\'o ð× \'i× \`o \"i \'u \`u ×},
}

@article{Garder2005,
author = {Anders G\"arder},
title = {Physical modeling of percussion instruments},
abstract = {This report contains an overview of a typical modern rock drum set and the acoustics describing them. Explanations of the modeling methods Digital Waveguides and Digital Waveguide Networks are given and then applied to simulating a tom tom drum. The results are compared to recordings of real tom tom drums made in an anechoic environment. Although clearly distinguishable from real drum sounds, basic acoustic properties are accurately modeled and the model can be used as a basis for more detailed physical modeling.},
year = {2005},
}

@article{Arts2008,
author = {Sonic Arts},
number = {September},
year = {2008},
title = {Physical modelling of the piano : An investigation into the e ff ect of string sti ff ness on the hammer-string interaction},
}

@article{Huang2008,
author = {Norden E Huang and Zhaohua Wu},
issn = {87551209},
number = {2007},
isbn = {1944-9208},
abstract = {Data analysis has been one of the core activities in scientific research, but limited by the availability of analysis methods in the past, data analysis was often relegated to data processing. To accommodate the variety of data generated by nonlinear and nonstationary processes in nature, the analysis method would have to be adaptive. Hilbert-Huang transform, consisting of empirical mode decomposition and Hilbert spectral analysis, is a newly developed adaptive data analysis method, which has been used extensively in geophysical research. In this review, we will briefly introduce the method, list some recent developments, demonstrate the usefulness of the method, summarize some applications in various geophysical research areas, and finally, discuss the outstanding open problems. We hope this review will serve as an introduction of the method for those new to the concepts, as well as a summary of the present frontiers of its applications for experienced research scientists.},
url = {http://rcada.ncu.edu.tw/reference010.pdf},
volume = {46},
pages = {1--23},
journal = {Reviews of Geophysics},
title = {a Review on Hilbert-Huang Transform : Method and Its Applications},
year = {2008},
doi = {10.1029/2007RG000228.1.INTRODUCTION},
keywords = {doi,empirical mode decomposition,hil,http://dx.doi.org/10.1029/2007rg,huang transform},
mendeley-tags = {doi,empirical mode decomposition,hil,http://dx.doi.org/10.1029/2007rg,huang transform},
}

@article{Duda2011,
author = {Krzysztof Duda and Leszek B. Magalas and Mariusz Majewski and Tomasz P. Zieli\'nski},
title = {DFT-based estimation of damped oscillation parameters in low-frequency mechanical spectroscopy},
doi = {10.1109/TIM.2011.2113124},
number = {11},
pages = {3608--3618},
year = {2011},
journal = {IEEE Transactions on Instrumentation and Measurement},
volume = {60},
issn = {00189456},
abstract = {In this paper, we analyze and compare the properties of different well-known and also new nonparametric discrete Fourier transform (DFT)-based methods for resonant frequency and logarithmic decrement estimation in application to mechanical spectroscopy. We derive a new DFT interpolation algorithm for a signal analyzed with Rife-Vincent class-I windows and also propose new formulas that extend Bertocco and Yoshida methods. We study errors of the resonant frequency and logarithmic decrement estimation in realistic conditions that include measurement noise and a zero-point drift. We also investigate the systematic errors of the estimation methods of interest. A nonlinear least squares time-domain parametric signal fitting is used to determine the boundaries of statistical efficiency in all tests. \textcopyright 2011 IEEE.},
keywords = {damping estimation,discrete fourier transform (dft,frequency estimation,interpolated dft,logarithmic decrement,mechanical spectroscopy,signal processing},
mendeley-tags = {damping estimation,discrete fourier transform (dft,frequency estimation,interpolated dft,logarithmic decrement,mechanical spectroscopy,signal processing},
}

@article{Bensa2006,
author = {Julien Bensa and Stefan Bilbao and  Kronl and Richard -martinet and Julius Smith and Julien Bensa and Stefan Bilbao and  Kronl and Richard -martinet and Julius Smith and Thierry Voinier Computa- and Julien Bensa and Stefan Bilbao and  Kronl and Richard -martinet and Julius O Smith Iii and Thierry Voinier},
pages = {0--10},
title = {Computational modeling of stiff piano strings using digital waveguides and finite difference To cite this version : HAL Id : hal-00088061 Computational Modeling of Stiff Piano Strings Using Digital Waveguides and Finite Differences},
year = {2006},
}

@article{Jos2009,
author = {Thomas D. Rossing},
journal = {American Journal of Physics},
issn = {0002-9505},
title = {                            Acoustics of the Piano                          },
year = {1991},
number = {1},
doi = {10.1119/1.16713},
pages = {94--95},
volume = {59},
}

@article{David2012,
author = {MDA Speed},
url = {http://core.kmi.open.ac.uk/download/pdf/9554518.pdf},
year = {2012},
title = {Voice synthesis using the three-dimensional digital waveguide mesh},
}

@article{Society2012,
author = {Stefan Bilbao},
number = {1},
abstract = {The snare drum is a complex system, relying on the interaction of multiple components: the drumheads, or membranes, a set of snares, the surrounding acoustic field and an internal cavity. Because these components are multidimensional, and due to a strong distributed non-linearity (the snare interaction), many techniques used frequently in physical modeling synthesis applications, such as digital waveguides and modal methods are difficult to apply. In this article, finite difference time domain techniques are applied to a full 3D system, and various features of interest, such as the coupling between membranes, and the interaction between the membranes and the snares, are examined in detail. Also discussed are various numerical features, such as spurious splitting of degenerate modes and bandwidth limitation, and estimates of computational complexity are provided. Sound examples are presented.},
year = {2012},
title = {Time domain simulation and sound synthesis for the snare drum},
doi = {10.1121/1.3651240},
issn = {0001-4966},
volume = {131},
journal = {The Journal of the Acoustical Society of America},
pages = {914--925},
}

@article{Ptb2015,
author = {Leonard Klaus},
journal = {XXI IMEKO World Congress "Measurement in Research and Industry"},
volume = {1},
year = {2015},
title = {Comparison of hilbert transform and sine fit approaches for the determination of damping parameters},
abstract = {For the analysis of rotational damping measurements in the time domain, two different identification procedures are compared. The first procedure investigated incorporates a Hilbert transform of the data, which enables an analysis by a linear regression calculation. The second approach is a direct nonlinear regression calculation of a damped sine function. The two approaches are compared using both simulated data and measurement data. The results of the comparison are presented.},
number = {4},
keywords = {damping coefficient,decay rate,rotational damping,torsional damping},
mendeley-tags = {damping coefficient,decay rate,rotational damping,torsional damping},
}

@article{Kartofelev,
author = {Dmitri Kartofelev and Anatoli Stulov and Heidi-Maria Lehtonen and Vesa V\"alim\"aki},
journal = {Proc. Stockholm Musical Acoust. Conf},
year = {2013},
url = {http://cs.ioc.ee/$\sim$stulov/smac13.pdf},
title = {Modeling a vibrating string terminated against a bridge with arbitrary geometry},
abstract = {This paper considers dynamic string motion in which the displacement is unilaterally constrained by the termination condition with an arbitrarily chosen geometry. A digital waveguide model is proposed for simulating the nonlin- earity inducing interactions between the vibrating string and the contact condition at the point of string termina- tion. The current work analyzes the resulting string mo- tion influenced by the contact conditions with mostly flat but slightly curved geometries. The effect of a minute im- perfection of the termination condition on the string vibra- tion is investigated. It is shown that the lossless string vi- brates in two distinct vibration regimes. In the beginning the string starts to interact in a nonlinear fashion with the bridge, and the resulting string motion is nonperiodic. The duration of that vibration regime depends on the geome- try of the bridge. After some time of nonperiodic vibra- tion, the string vibration settles in a periodic regime. Pre- sented results are applicable for example in the physics- based sound synthesis of stringed musical instruments, such as the shamisen, biwa, sitar, tambura, veena or even the bray harp and the grand piano.},
}

@article{,
volume = {1},
pages = {594--598},
title = {MODELLING THE DECAY OF PIANO SOUNDS Tian Cheng , Simon Dixon , Matthias Mauch Centre for Digital Music , Queen Mary University of London , London , United Kingdom},
year = {2015},
isbn = {9781467369978},
}

@article{Serra2014,
author = {Xavier Serra},
url = {http://138.37.35.209/dafx03/pdfs/XSerra-Presentation.pdf},
number = {February},
title = {Spectral modeling synthesis: Past and present},
year = {1993},
journal = {Proceedings of DAFX London},
}

@article{Berdahl,
author = {Edgar J Berdahl and Julius O Smith Iii},
title = {Plucked String Digital Waveguide Model},
journal = {Electrical Engineering},
pages = {1--14},
}

@article{Deserio,
author = {Robert DeSerio},
year = {2013},
abstract = {How duplicate genes provide genetic robustness remains an unresolved question. We have examined the duplicated histone deacetylases Sir2p and Hst1p in Saccharomyces cerevisiae and find that these paralogs with non-overlapping functions can provide genetic robustness against null mutations through a substitution mechanism. Hst1p is an NAD(+)-dependent histone deacetylase that acts with Sum1p to repress a subset of midsporulation genes. However, hst1Delta mutants show much weaker derepression of target loci than sum1Delta mutants. We show that this modest derepression of target loci in hst1Delta strains occurs in part because Sir2p substitutes for Hst1p. Sir2p contributes to repression of the midsporulation genes only in the absence of Hst1p and is recruited to target promoters by a physical interaction with the Sum1 complex. Furthermore, when Sir2p associates with the Sum1 complex, the complex continues to repress in a promoter-specific manner and does not spread. Our results imply that after the duplication, SIR2 and HST1 subfunctionalized. The single SIR2/HST1 gene from Kluyveromyces lactis, a closely related species that diverged prior to the duplication, can suppress an hst1Delta mutation in S. cerevisiae as well as interact with Sir4p in S. cerevisiae. In addition, the existence of two distinct protein interaction domains for the Sir and Sum1 complexes was revealed through the analysis of a chimeric Sir2-Hst1 molecule. Therefore, the ability of Sir2p to substitute for Hst1p probably results from a retained but reduced affinity for the Sum1 complex that is a consequence of subfunctionalization via the duplication, degeneration, and complementation mechanism. These results suggest that the evolutionary path of duplicate gene preservation may be an important indicator for the ability of duplicated genes to contribute to genetic robustness.},
title = {Addendum: The Fourier transform of decaying oscillations (Ilidio Notes)},
issn = {1553-7404},
number = {6},
}

@article{Ði,
author = {\O \'U \`U Ð\"i},
title = {\AA\`u× ð \'a\`o×\o\"o\`u\~n \`o\o \aa\'o ðð \`o \'i× \`o \o ð\"i \'u \`u ×},
}

@article{Bank2010,
author = {Bal\'azs Bank and Stefano Zambon and Federico Fontana},
abstract = {This paper presents a real-time piano synthesizer where both the transverse and longitudinal motion of the string is modeled by modal synthesis, resulting in a coherent and highly parallel model structure. The paper applies recent developments in piano modeling and focuses on the issues related to practical implementation (e.g., numerical stability, aliasing, and efficiency). A strong emphasis is given to modeling nonlinear string vibrations, and a new variation of earlier synthesis techniques is proposed which is particularly well suited for modal synthesis. For soundboard modeling, the possibilities of using fast Fourier transform-based fast convolution and parallel second-order filters are discussed. Additionally, the paper describes the details of the software implementation and discusses the computational complexity of each model block. The piano model runs on current computer hardware with full polyphony in real time. \textcopyright 2010 IEEE.},
issn = {15587916},
number = {4},
year = {2010},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
volume = {18},
pages = {809--821},
title = {A modal-based real-time piano synthesizer},
doi = {10.1109/TASL.2010.2040524},
keywords = {modal synthesis,physics-based sound synthesis,piano},
mendeley-tags = {modal synthesis,physics-based sound synthesis,piano},
}

@article{Salih2016,
author = {A Salih},
year = {2016},
title = {Second-Order Wave Equation d ' Alembert ' s Solution in Infinite Domain},
pages = {1--24},
number = {December},
}

@article{Feldman2000,
author = {David R. Bergman},
title = {Derivation of the Wave Equation},
year = {2018},
pages = {19--48},
abstract = {We shall formulate the postulates, from which the wave equation can be obtained. In the end it will be understandable, that it is the most natural law describing the motion of a system. The postulates themselves are simple and apparent: the first and the fifth postulate set the definition of the coordinate and the definition of its evolution. The second and the fourth postulate define the momentum and define its evolution. The third postulate sets the superposition principle. On the basis of these statements it is possible to obtain the wave equation.},
doi = {10.1002/9781119277323.ch3},
journal = {Computational Acoustics},
}

@article{h96,
author = {Martin Hagan and Howard Demuth},
title = {Neural Network Design},
isbn = {978-0971732117},
url = {http://scholar.google.com/scholar?hl=en&sugexp=gsih&pq=badminton+training&xhr=t&q=neural+network+design&cp=16&qe=bmV1cmFsIG5ldHdvcmsgZA&qesig=k9_6OUSCnOMtzbLRV7Bxag&pkc=AFgZ2tnXZWxdMzsRdm7bQlAZ9Ouzahw-8F-Iap-NFqR9QR-QaxLC0MI5wrX4F_gMeseaytVjRLbReEMmERZgMf},
journal = {Neural Networks in a Softcomputing Framework},
abstract = {Introductory textbook on neural networks that uses MATLAB as a simulator and has a nice annotated bibliography for every chapter.},
year = {2014},
pages = {1--1012},
volume = {20},
}

@incollection{l12,
author = {Yann A. LeCun and L\'eon Bottou and Genevieve B. Orr and Klaus-Robert M\"uller},
publisher = {Springer},
address = {Traducao. [s.l.] p. 9�48},
pages = {9--48},
year = {2012},
booktitle = {Neural networks: Tricks of the trade},
abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most "classical" second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
doi = {10.1007/978-3-642-35289-8_3},
title = {Efficient BackProp},
}

@unpublished{18,
author = {Adam Roberts and Jesse Engel and Colin Raffel and Curtis Hawthorne and Douglas Eck},
abstract = {The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the "posterior collapse" problem which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a "flat" baseline model. An implementation of our "MusicVAE" is available online.2.},
annote = {arXiv preprint},
arxivid = {1803.05428},
title = {A hierarchical latent vector model for learning long-term structure in music},
booktitle = {35th International Conference on Machine Learning, ICML 2018},
year = {2018},
pages = {6939--6954},
volume = {10},
archiveprefix = {arXiv},
isbn = {9781510867963},
eprint = {1803.05428},
}

@article{Valin2017,
author = {Jean Marc Valin},
eprint = {1709.08243},
arxivid = {1709.08243},
title = {A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement},
journal = {arXiv},
archiveprefix = {arXiv},
year = {2017},
issn = {23318422},
abstract = {—Despite noise suppression being a mature area in signal processing, it remains highly dependent on fine tuning of estimator algorithms and parameters. In this paper, we demonstrate a hybrid DSP/deep learning approach to noise suppression. We focus strongly on keeping the complexity as low as possible, while still achieving high-quality enhanced speech. A deep recurrent neural network with four hidden layers is used to estimate ideal critical band gains, while a more traditional pitch filter attenuates noise between pitch harmonics. The approach achieves significantly higher quality than a traditional minimum mean squared error spectral estimator, while keeping the complexity low enough for real-time operation at 48 kHz on a low-power CPU.},
keywords = {index terms—noise suppression,recurrent neural ne},
mendeley-tags = {index terms—noise suppression,recurrent neural ne},
}

@article{Liao,
author = {Qianli Liao and Joel Z. Leibo and Tomaso Poggio},
pages = {1837--1844},
isbn = {9781577357605},
journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
eprint = {1510.05067},
arxivid = {1510.05067},
abstract = {Gradient backpropagation (BP) requires symmetric feedforward and feedback connections-the same weights must be used for forward and backward passes. This "weight transport problem" (Grossberg 1987) is thought to be one of the main reasons to doubt BP's biologically plausibility. Using 15 different classification datasets, we systematically investigate to what extent BP really depends on weight symmetry. In a study that turned out to be surprisingly similar in spirit to Lillicrap et al.'s demonstration (Lillicrap et al. 2014) but orthogonal in its results, our experiments indicate that: (1) the magnitudes of feedback weights do not matter to performance (2) the signs of feedback weights do matter-the more concordant signs between feedforward and their corresponding feedback connections, the better (3) with feedback weights having random magnitudes and 100% concordant signs, we were able to achieve the same or even better performance than SGD. (4) some normalizations/stabilizations are indispensable for such asymmetric BP to work, namely Batch Normalization (BN) (Ioffe and Szegedy 2015) and/or a "Batch Manhattan" (BM) update rule.},
title = {How important is weight symmetry in backpropagation?},
archiveprefix = {arXiv},
year = {2016},
}

@article{Tomar2017,
author = {Shikha Tomar and Parasuraman Sumathi},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
pages = {229--237},
abstract = {An online method for amplitude and frequency estimation of exponentially decaying sinusoids is proposed with a moving-window discrete Fourier transform (MWDFT) filter and frequency-locked loop. The tuned filter characteristics of MWDFT is modified into more flat characteristic around the center frequency with negative feedback, which increases the bandwidth of the filter. An adaptive sampling pulse adjustment mechanism is incorporated in the proposed structure for online estimation of frequency. Hence, the frequency error was exploited to achieve synchronization between in-phase component of MWDFT and input signal of estimation. The amplitude is estimated in online from the in-phase and quadrature-phase components of MWDFT. The performance of the proposed method is compared with the existing techniques and experimentally validated on single-link flexible manipulator system for the online estimation of frequency and amplitude of tip deflection signal. The experimental investigation prove that the proposed online technique performs well over the existing techniques.},
volume = {67},
title = {Amplitude and frequency estimation of exponentially decaying sinusoids},
year = {2018},
doi = {10.1109/TIM.2017.2755998},
number = {1},
keywords = {exponentially decaying sinusoid,single-link flexible manipulator (slfm,sinusoidal amplitude and frequency estimation,vibration estimation},
mendeley-tags = {exponentially decaying sinusoid,single-link flexible manipulator (slfm,sinusoidal amplitude and frequency estimation,vibration estimation},
}

@article{Smith2015,
author = {Leslie N. Smith},
archiveprefix = {arXiv},
journal = {Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017},
number = {April},
pages = {464--472},
arxivid = {1506.01186},
doi = {10.1109/WACV.2017.58},
year = {2017},
isbn = {9781509048229},
title = {Cyclical learning rates for training neural networks},
eprint = {1506.01186},
abstract = {It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate 'reasonable bounds' - linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.},
}

@article{Nielsen2017,
author = {Frank Nielsen},
arxivid = {arXiv:1612.01010v2},
eprint = {arXiv:1612.01010v2},
title = {DeepBach: a Steerable Model for Bach Chorales Generation},
year = {2017},
archiveprefix = {arXiv},
}

@article{Jaderberg,
author = {Max Jaderberg and Wojciech Marian Czarnecki and Simon Osindero and Oriol Vinyals and Alex Graves and David Silver and Koray Kavukcuoglu},
eprint = {1608.05343},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
archiveprefix = {arXiv},
arxivid = {1608.05343},
pages = {2558--2577},
abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagaling error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropa-gated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which arc decoupled in both the forward and backwards pass - amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
title = {Decoupled neural interfaces using synthetic gradients},
year = {2017},
volume = {4},
}

@article{Louizos2017,
author = {Christos Louizos and Max Welling and Diederik P. Kingma},
year = {2017},
abstract = {We propose a practical method for L0norm regularization for neural networks: pruning the network during training by encouraging weights to become exactly zero. Such regularization is interesting since (1) it can greatly speed up training and inference, and (2) it can improve generalization. AIC and BIC, well-known model selection criteria, are special cases of L0regularization. However, since the L0norm of weights is non-differentiable, we cannot incorporate it directly as a regularization term in the objective function. We propose a solution through the inclusion of a collection of non-negative stochastic gates, which collectively determine which weights to set to zero. We show that, somewhat surprisingly, for certain distributions over the gates, the expected L0regularized objective is differentiable with respect to the distribution parameters. We further propose the hard concrete distribution for the gates, which is obtained by "stretching" a binary concrete distribution and then transforming its samples with a hard-sigmoid. The parameters of the distribution over the gates can then be jointly optimized with the original network parameters. As a result our method allows for straightforward and efficient learning of model structures with stochastic gradient descent and allows for conditional computation in a principled way. We perform various experiments to demonstrate the effectiveness of the resulting approach and regularizer.},
journal = {arXiv},
pages = {1--13},
arxivid = {1712.01312},
eprint = {1712.01312},
archiveprefix = {arXiv},
issn = {23318422},
title = {Learning sparse neural networks through L0regularization},
}

@article{Gabrielli2017,
author = {Leonardo Gabrielli and Stefano Tomassetti and Stefano Squartini and Carlo Zinato},
title = {Introducing deep machine learning for parameter estimation in physical modelling},
journal = {DAFx 2017 - Proceedings of the 20th International Conference on Digital Audio Effects},
abstract = {One of the most challenging tasks in physically-informed sound synthesis is the estimation of model parameters to produce a desired timbre. Automatic parameter estimation procedures have been developed in the past for some specific parameters or application scenarios but, up to now, no approach has been proved applicable to a wide variety of use cases. A general solution to parameters estimation problem is provided along this paper which is based on a supervised convolutional machine learning paradigm. The described approach can be classified as "end-to-end" and requires, thus, no specific knowledge of the model itself. Furthermore, parameters are learned from data generated by the model, requiring no effort in the preparation and labeling of the training dataset. To provide a qualitative and quantitative analysis of the performance, this method is applied to a patented digital waveguide pipe organ model, yielding very promising results.},
year = {2017},
pages = {11--16},
}

@article{Bello2017,
author = {Irwan Bello and Barret Zoph and Vijay Vasudevan and Quoc V. Le},
volume = {1},
eprint = {1709.07417},
archiveprefix = {arXiv},
journal = {34th International Conference on Machine Learning, ICML 2017},
arxivid = {1709.07417},
pages = {712--721},
number = {2002},
isbn = {9781510855144},
abstract = {We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string in a specific domain language that describes a mathematical update equation based on a list of primitive functions, such as the gradient, running average of the gradient, etc. The controller is trained with Reinforcement Learning to maximize the performance of a model after a few epochs. On CIFAR-10, our method discovers several update rules that are better than many commonly used optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet model. These optimizers can also be transferred to perform well on different neural network architectures, including Google's neural machine translation system.},
title = {Neural optimizer search with Reinforcement learning},
year = {2017},
}

@article{Kalchbrenner2016,
author = {Nal Kalchbrenner and Lasse Espeholt and Karen Simonyan and Aaron van den Oord and Alex Graves and Koray Kavukcuoglu},
archiveprefix = {arXiv},
abstract = {We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.},
arxivid = {1610.10099},
eprint = {1610.10099},
url = {http://arxiv.org/abs/1610.10099},
title = {Neural Machine Translation in Linear Time},
year = {2016},
}

@article{Peng2017,
author = {Xue Bin Peng and Pieter Abbeel and Sergey Levine and Michiel Van De Panne},
journal = {ACM Transactions on Graphics},
number = {4},
title = {DeepMimic: Example-guided deep reinforcement learning of physics-based character skills},
abstract = {A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing userspecified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the convenience and motion quality of using motion clips to define the desired style and appearance, with the flexibility and generality afforded by RL methods and physics-based animation. We further explore a number of methods for integrating multiple clips into the learning process to develop multi-skilled agents capable of performing a rich repertoire of diverse skills. We demonstrate results using multiple characters (human, Atlas robot, bipedal dinosaur, dragon) and a large variety of skills, including locomotion, acrobatics, and martial arts.},
doi = {10.1145/3197517.3201311},
eprint = {1804.02717},
year = {2018},
volume = {37},
archiveprefix = {arXiv},
arxivid = {1804.02717},
issn = {15577368},
keywords = {motion control,physics-based character animation,reinforcement learning},
mendeley-tags = {motion control,physics-based character animation,reinforcement learning},
}

@article{Eisenach2017,
author = {Forest Agostinelli and Matthew Hoffman and Peter Sadowski and Pierre Baldi},
year = {2015},
archiveprefix = {arXiv},
eprint = {arXiv:1412.6830v3},
title = {L Earning a Ctivation F Unctions},
arxivid = {arXiv:1412.6830v3},
number = {2013},
pages = {1--9},
}

@article{For2018,
author = {Taco Bell},
journal = {Health (San Francisco)},
number = {January},
title = {Earching for},
year = {2007},
pages = {1--3},
}

@article{Ephrat2017,
author = {Ariel Ephrat and The Hebrew and William T Freeman and Michael Rubinstein and Only Jon and Only Rory},
arxivid = {arXiv:1804.03619v1},
eprint = {arXiv:1804.03619v1},
archiveprefix = {arXiv},
title = {Looking to Listen at the Cocktail Party : A Speaker-Independent Audio-Visual Model for Speech Separation},
year = {2017},
}

@article{Donoso2007,
author = {Pedro Donoso and Alberto Tann and Francisco Guimar},
number = {December},
title = {A f ´ ısica do violino},
year = {2008},
volume = {2305},
keywords = {acoustics,helmholtz,musical instruments,resonance,violin},
mendeley-tags = {acoustics,helmholtz,musical instruments,resonance,violin},
}

@article{Donahue2014,
author = {Chris Donahue and Julian Mcauley and Miller Puckette},
arxivid = {arXiv:1802.04208v1},
title = {Synthesizing Audio with Generative Adversarial Networks},
year = {2014},
archiveprefix = {arXiv},
eprint = {arXiv:1802.04208v1},
}

@misc{,
title = {Parzen - 1962 - On estimation of a probability density function and mode.pdf},
}

@article{Balkema1974,
author = {a a Balkema and L De Haan},
number = {5},
journal = {Statistics},
pages = {347--370},
year = {1974},
abstract = {The asymptotic behaviour of the residual life time at time t is investigated (for t rightarrow infty). We derive weak limit laws and their domains of attraction and treat rates of convergence and moment convergence. The presentation exploits the close similarity with extreme value theory.},
issn = {0091-1798},
title = {Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Probability. \textregistered www.jstor.org},
volume = {2},
url = {http://projecteuclid.org/euclid.aop/1176996548},
}

@article{Bernroider2013,
author = {Edward Bernroider and Patrick Schm\"ollerl},
pages = {141--153},
journal = {European Journal of Operational Research},
url = {http://epub.wu.ac.at/3913/},
number = {224},
title = {ePub WU Institutional Repository A technological , organisational , and environmental analysis},
year = {2013},
}

@article{Zopounidis2002,
author = {Constantin Zopounidis and Michael Doumpos},
number = {2},
volume = {138},
year = {2002},
issn = {03772217},
doi = {10.1016/S0377-2217(01)00243-0},
journal = {European Journal of Operational Research},
pages = {229--246},
title = {Multicriteria classification and sorting methods: A literature review},
abstract = {The assignment of alternatives (observations/objects) into predefined homogenous groups is a problem of major practical and research interest. This type of problem is referred to as classification or sorting, depending on whether the groups are nominal or ordinal. Methodologies for addressing classification and sorting problems have been developed from a variety of research disciplines, including statistics/econometrics, artificial intelligent and operations research. The objective of this paper is to review the research conducted on the framework of the multicriteria decision aiding (MCDA). The review covers different forms of MCDA classification/sorting models, different aspects of the model development process, as well as real-world applications of MCDA classification/sorting techniques and their software implementations. \textcopyright 2002 Elsevier Science B.V. All rights reserved.},
keywords = {classification,decision rules,multiple criteria analysis,outranking relations,preference disaggregation,sorting,utility functions},
mendeley-tags = {classification,decision rules,multiple criteria analysis,outranking relations,preference disaggregation,sorting,utility functions},
}

@article{Ishizaka2017,
author = {Alessio Ishizaka and Sajid Siraj},
url = {http://dx.doi.org/10.1016/j.ejor.2017.05.041},
year = {2017},
doi = {10.1016/j.ejor.2017.05.041},
title = {PT},
issn = {0377-2217},
journal = {European Journal of Operational Research},
publisher = {Elsevier B.V.},
keywords = {ahp,decision analysis,experimental evaluation,macbeth,smart},
mendeley-tags = {ahp,decision analysis,experimental evaluation,macbeth,smart},
}

@article{Zamani-sabzi2016,
author = {Hamed Zamani-Sabzi and James Phillip King and Charlotte C. Gard and Shalamu Abudu},
journal = {Operations Research Perspectives},
url = {http://dx.doi.org/10.1016/j.orp.2016.11.001},
pages = {92--117},
issn = {22147160},
year = {2016},
abstract = {Different multi-criteria decision-making (MCDM) techniques require different levels of computational intensity and may produce different outputs, so selecting an appropriate technique largely determines the quality of the recommended decision and the effort required to obtain that decision. In most real environments, criteria and their constraints are not deterministic and cannot be specified precisely; therefore, those criteria are uncertain or fuzzy. To facilitate the selection of an appropriate MCDM method under a fuzzy environment, this study investigates and statistically compares the performances of ten commonly used MCDM techniques: simple additive weights (SAW), weighted product method (WPM), compromise programming (CP), technique for order preference by similarity to ideal solution (TOPSIS), four types of analytical hierarchy process (AHP), VIKOR (in Serbian: VIseKriterijumska Optimizacija I Kompromisno Resenje), and ELECTRE (in French: ELimination Et Choix Traduisant la REalit\'e). These techniques' performances were compared using fuzzy criteria and constraints, matching the conditions usually found in real applications. To conduct the comparisons, the 10 multi-criteria decision ranking methods were applied to 1250 simulated sets of decision matrices with fuzzy triangular values, and 12,500 sets of ranks were analyzed to compare the ranking methods. SAW and TOPSIS had statistically similar performances. ELECTRE was not preferable in providing full, sorted ranks among the alternatives. VIKOR considering its ranking process, for specific conditions, assigns identical ranks for several alternatives; when full, sorted ranks are required, VIKOR is unfavorable, although it is a powerful technique in introducing the closest alternative to the ideal condition. Types 1 and 3 of AHP and types 2 and 4 of AHP had close performances. Notably, no ranking method was significantly sensitive to uncertainty levels when uncertainty changed symmetrically.},
publisher = {Elsevier Ltd},
title = {Statistical and analytical comparison of multi-criteria decision-making techniques under fuzzy environment},
volume = {3},
doi = {10.1016/j.orp.2016.11.001},
keywords = {defuzzification,fuzzy environment,multi-criteria decision-making,statistical analysis of ranking methods},
mendeley-tags = {defuzzification,fuzzy environment,multi-criteria decision-making,statistical analysis of ranking methods},
}

@article{Carayannis2018,
author = {Elias G. Carayannis and Jo\~ao J.M. Ferreira and Marjan S. Jalali and Fern Ferreira and o A.F.},
journal = {Technological Forecasting and Social Change},
volume = {131},
year = {2018},
issn = {00401625},
abstract = {The importance of knowledge in creating value, driving productivity and promoting economic growth has long been recognized. Accompanying this recognition of the central role of knowledge in today's economies has been an added focus on information, technology, learning and the accelerated pace of technical and scientific advance that results therefrom. Closely connected to these developments has been the advent of big data; and as information becomes available at greater volumes and higher speed, the focus is shifting from quantity to the quality of the information collected and the manner in which it is used. In this respect, Multiple Criteria Decision Analysis (MCDA) techniques constitute valuable tools for structuring and evaluating complex decision situations, and can allow for more informed, potentially better decisions. MCDA techniques are able to build on the knowledge of expert participants in a given field, and produce assessment systems based on values and experience. Constructivist in nature, this approach has grown exponentially over the past few decades, causing a change in the decision-making arena in general, and in the field of decision support systems (DSS) in particular. The objective of this special issue is to bring together recent developments and methodological contributions within MCDA, with the challenges which characterize the knowledge-based economy, as they pertain to the themes of technological forecasting and social change.},
pages = {1--3},
number = {xxxx},
title = {MCDA in knowledge-based economies: Methodological developments and real world applications},
url = {http://dx.doi.org/10.1016/j.techfore.2018.01.028},
publisher = {Elsevier},
doi = {10.1016/j.techfore.2018.01.028},
}

@article{Marttunen2017,
author = {Mika Marttunen and Judit Lienert and Valerie Belton},
volume = {263},
title = {Structuring problems for Multi-Criteria Decision Analysis in practice: A literature review of method combinations},
issn = {03772217},
abstract = {Structuring problems for Multi-Criteria Decision Analysis (MCDA) has attracted increasing attention over the past 20 years from both a conceptual and a practical perspective. This is reflected in a significant growth in the number of published applications which use a formal approach to problem structuring in combination with an analytic method for multi-criteria analysis. The problem structuring approaches (PSMs) include general methodologies such as Checkland's Soft Systems Method (SSM), Eden and Ackermann's Strategic Options Design and Analysis (SODA) and other methods that focus on a particular aspect. We carried out a literature review that covers eight PSMs (Cognitive and Causal Maps, DPSIR, Scenario Planning, SSM, Stakeholder Analysis, Strategic Choice Approach, SODA and SWOT) and seven MCDA methods (AHP, ANP, ELECTRE, MAUT, MAVT, PROMETHEE and TOPSIS). We first identified and analysed 333 articles published during 2000-2015, then selected 68 articles covering all PSM-MCDA combinations, which were studied in detail to understand the associated processes, benefits and challenges. The three PSMs most commonly combined with MCDA are SWOT, Scenario Planning and DPSIR. AHP was by far the most commonly applied MCDA method. Combining PSMs with MCDA produces a richer view of the decision situation and enables more effective support for different phases of the decision-making process. Some limitations and challenges in combining PSMs and MCDA are also identified, most importantly relating to building a value tree and assigning criteria weights.},
pages = {1--17},
year = {2017},
url = {http://dx.doi.org/10.1016/j.ejor.2017.04.041},
publisher = {Elsevier B.V.},
number = {1},
doi = {10.1016/j.ejor.2017.04.041},
journal = {European Journal of Operational Research},
keywords = {multi-methodology,multi-stakeholder decision-making,multiple criteria decision analysis,problem structuring},
mendeley-tags = {multi-methodology,multi-stakeholder decision-making,multiple criteria decision analysis,problem structuring},
}

@article{Guitouni1998,
author = {Adel Guitouni and Jean Marc Martel},
number = {2},
doi = {10.1016/S0377-2217(98)00073-3},
year = {1998},
journal = {European Journal of Operational Research},
title = {Tentative guidelines to help choosing an appropriate MCDA method},
volume = {109},
abstract = {Despite the development of a large number of refined multicriterion decision aid (MCDA) methods, none can be considered as the 'super method' appropriate to all decision making situations. Hence, how can one choose an appropriate method to a specific decision situation? Recent experimental studies in psychology and behaviour have revealed, on the one hand, that the human thinking is not to be modelled by logical rules and calculations, and, on the other hand, that the response mode affects the preference formation as well as the use of compensatory or noncompensatory strategies. The aim of this paper is to draw a conceptual framework for articulating tentative guidelines to choose an appropriate MCDA method. This paper also presents the results of the comparison of well known multicriterion aggregation procedures (MCAP) on the basis of these guidelines. In our opinion this study can constitute a first step for proposing a methodological approach to select an appropriate MCDA method to a specific decision making situation. Such an approach should be validated and may be integrated into a decision support system. Moreover, the framework suggested is helpful to develop useful methods and to address neglected issues within the field. \textcopyright 1998 Elsevier Science B.V. All rights reserved.},
pages = {501--521},
issn = {03772217},
keywords = {behavioural considerations,comparative analysis,decision making situation,multicriteria analysis,multicriterion aggregation procedure,multicriterion decision aid method,preferences modelling},
mendeley-tags = {behavioural considerations,comparative analysis,decision making situation,multicriteria analysis,multicriterion aggregation procedure,multicriterion decision aid method,preferences modelling},
}

@article{Solomon1998,
author = {Stelios H. Zanakis and Anthony Solomon and Nicole Wishart and S Dublish and  ipa},
doi = {10.1016/S0377-2217(97)00147-1},
year = {1998},
volume = {107},
issn = {03772217},
number = {3},
pages = {507--529},
title = {Multi-attribute decision making: A simulation comparison of select methods},
abstract = {Several methods have been proposed for solving multi-attribute decision making problems (MADM). A major criticism of MADM is that different techniques may yield different results when applied to the same problem. The problem considered in this study consists of a decision matrix input of N criteria weights and ratings of L alternatives on each criterion. The comparative performance of some methods has been investigated in a few, mostly field, studies. In this simulation experiment we investigate the performance of eight methods: ELECTRE, TOPSIS, Multiplicative Exponential Weighting (MEW), Simple Additive Weighting (SAW), and four versions of AHP (original vs. geometric scale and right eigenvector vs. mean transformation solution). Simulation parameters are the number of alternatives, criteria and their distribution. The solutions are analyzed using twelve measures of similarity of performance. Similarities and differences in the behavior of these methods are investigated. Dissimilarities in weights produced by these methods become stronger in problems with few alternatives; however, the corresponding final rankings of the alternatives vary across methods more in problems with many alternatives. Although less significant, the distribution of criterion weights affects the methods differently. In general, all AHP versions behave similarly and closer to SAW than the other methods. ELECTRE is the least similar to SAW (except for closer matching the top-ranked alternative), followed by MEW. TOPSIS behaves closer to AHP and differently from ELECTRE and MEW, except for problems with few criteria. A similar rank-reversal experiment produced the following performance order of methods: SAW and MEW (best), followed by TOPSIS, AHPs and ELECTRE. It should be noted that the ELECTRE version used was adapted to the common MADM problem and therefore it did not take advantage of the method's capabilities in handling problems with ordinal or imprecise information. \textcopyright 1998 Elsevier Science B.V.},
journal = {European Journal of Operational Research},
keywords = {decision theory,multiple criteria analysis,simulation,utility theory},
mendeley-tags = {decision theory,multiple criteria analysis,simulation,utility theory},
}

@article{Jacquet-lagr2001,
author = {Eric Jacquet-Lagr\`eze and Yannis Siskos},
abstract = {The philosophy of preference disaggregation in multicriteria decision-aid system (MCDA) is to assess/infer global preference models from the given preferential structures and to address decision-aiding activities. A panorama of preference disaggregation methods is presented and the most important results and applications over the last 20 years were discussed.},
issn = {03772217},
year = {2001},
journal = {European Journal of Operational Research},
title = {Preference disaggregation: 20 Years of MCDA experience},
doi = {10.1016/S0377-2217(00)00035-7},
volume = {130},
number = {2},
pages = {233--245},
keywords = {criteria,general philosophy,goal programming,in decision-making involving multiple,introduction and background,multicriteria analysis,preference disaggregation,regression},
mendeley-tags = {criteria,general philosophy,goal programming,in decision-making involving multiple,introduction and background,multicriteria analysis,preference disaggregation,regression},
}

@article{Information2000,
author = {Background Information and Description Of and Some Mcdm},
year = {2000},
pages = {5--21},
journal = {Multi-criteria Decision Making Methods: A Comparative Study},
isbn = {978-1-4419-4838-0},
title = {Chapter 2 MULTI-CRITERIA DECISION MAKING METHODS 2.1},
}

@article{Dehe2015,
author = {Benjamin Dehe and David Bamford},
issn = {09574174},
doi = {10.1016/j.eswa.2015.04.059},
number = {19},
title = {Development, test and comparison of two Multiple Criteria Decision Analysis (MCDA) models: A case of healthcare infrastructure location},
publisher = {Elsevier Ltd},
volume = {42},
journal = {Expert Systems with Applications},
abstract = {When planning a new development, location decisions have always been a major issue. This paper examines and compares two modelling methods used to inform a healthcare infrastructure location decision. Two Multiple Criteria Decision Analysis (MCDA) models were developed to support the optimisation of this decision-making process, within a National Health Service (NHS) organisation, in the UK. The proposed model structure is based on seven criteria (environment and safety, size, total cost, accessibility, design, risks and population profile) and 28 sub-criteria. First, Evidential Reasoning (ER) was used to solve the model, then, the processes and results were compared with the Analytical Hierarchy Process (AHP). It was established that using ER or AHP led to the same solutions. However, the scores between the alternatives were significantly different; which impacted the stakeholders' decision-making. As the processes differ according to the model selected, ER or AHP, it is relevant to establish the practical and managerial implications for selecting one model or the other and providing evidence of which models best fit this specific environment. To achieve an optimum operational decision it is argued, in this study, that the most transparent and robust framework is achieved by merging ER process with the pair-wise comparison, an element of AHP. This paper makes a defined contribution by developing and examining the use of MCDA models, to rationalise new healthcare infrastructure location, with the proposed model to be used for future decision. Moreover, very few studies comparing different MCDA techniques were found, this study results enable practitioners to consider even further the modelling characteristics to ensure the development of a reliable framework, even if this means applying a hybrid approach.},
url = {http://dx.doi.org/10.1016/j.eswa.2015.04.059},
pages = {6717--6727},
year = {2015},
keywords = {analytical hierarchy process (ahp,evidential reasoning (er,location decision,multiple criteria decision analysis (mcda},
mendeley-tags = {analytical hierarchy process (ahp,evidential reasoning (er,location decision,multiple criteria decision analysis (mcda},
}

@article{Behzadian2010,
author = {Majid Behzadian and R. B. Kazemzadeh and A. Albadvi and M. Aghdasi},
issn = {03772217},
number = {1},
title = {PROMETHEE: A comprehensive literature review on methodologies and applications},
doi = {10.1016/j.ejor.2009.01.021},
publisher = {Elsevier B.V.},
abstract = {In recent decades, several Multi-Criteria Decision Aid (MCDA) methods have been proposed to help in selecting the best compromise alternatives. In the meantime, the PROMETHEE (Preference Ranking Organization Method for Enrichment Evaluations) family of outranking methods and their applications has attracted much attention from academics and practitioners. In this paper, a classification scheme and a comprehensive literature review are presented in order to uncover, classify, and interpret the current research on PROMETHEE methodologies and applications. Based on the scheme, 217 scholarly papers from 100 journals are categorized into application areas and non-application papers. The application areas include the papers on the topics of Environment Management, Hydrology and Water Management, Business and Financial Management, Chemistry, Logistics and Transportation, Manufacturing and Assembly, Energy Management, Social, and Other Topics. The last area covers the papers published in several fields: Medicine, Agriculture, Education, Design, Government and Sports. The scholarly papers are also classified by (1) year of publication, (2) journal of publication, (3) authors' nationality, (4) PROMETHEE as applied with other MCDA methods, and (5) PROMETHEE as applied with GAIA (Geometrical Analysis for Interactive Aid) plane. It is hoped that the paper can meet the needs of researchers and practitioners for easy references of PROMETHEE methodologies and applications, and hence promote the future of PROMETHEE research. \textcopyright 2009 Elsevier B.V. All rights reserved.},
url = {http://dx.doi.org/10.1016/j.ejor.2009.01.021},
year = {2010},
volume = {200},
pages = {198--215},
journal = {European Journal of Operational Research},
keywords = {application areas,gaia,literature review,mcda,outranking,promethee},
mendeley-tags = {application areas,gaia,literature review,mcda,outranking,promethee},
}

@article{Leoneti2016,
author = {Alex Leoneti and re Bevilacqua},
year = {2016},
doi = {10.1016/j.orp.2016.04.001},
journal = {Operations Research Perspectives},
pages = {21--26},
volume = {3},
title = {Utility Function for modeling Group Multicriteria Decision Making problems as games},
issn = {22147160},
publisher = {Elsevier Ltd},
url = {http://dx.doi.org/10.1016/j.orp.2016.04.001},
abstract = {To assist in the decision making process, several multicriteria methods have been proposed. However, the existing methods assume a single decision-maker and do not consider decision under risk, which is better addressed by Game Theory. Hence, the aim of this research is to propose a Utility Function that makes it possible to model Group Multicriteria Decision Making problems as games. The advantage of using Game Theory for solving Group Multicriteria Decision Making problems is to evaluate the conflicts between the decision makers using a strategical approach.},
keywords = {game theory,group multicriteria decision,maut,utility function},
mendeley-tags = {game theory,group multicriteria decision,maut,utility function},
}

@article{Govindan2015,
author = {Kannan Govindan and Martin Br Jepsen and  t},
doi = {10.1016/j.ejor.2015.07.019},
volume = {250},
pages = {1--29},
issn = {03772217},
journal = {European Journal of Operational Research},
number = {1},
title = {ELECTRE: A comprehensive literature review on methodologies and applications},
year = {2016},
abstract = {Multi-criteria decision analysis (MCDA) is a valuable resource within operations research and management science. Various MCDA methods have been developed over the years and applied to decision problems in many different areas. The outranking approach, and in particular the family of ELECTRE methods, continues to be a popular research field within MCDA, despite its more than 40 years of existence. In this paper, a comprehensive literature review of English scholarly papers on ELECTRE and ELECTRE-based methods is performed. Our aim is to investigate how ELECTRE and ELECTRE-based methods have been considered in various areas. This includes area of applications, modifications to the methods, comparisons with other methods, and general studies of the ELECTRE methods. Although a significant amount of literature on ELECTRE is in a language different from English, we focus only on English articles, because many researchers may not be able to perform a study in some of the other languages. Each paper is categorized according to its main focus with respect to ELECTRE, i.e. if it considers an application, performs a review, considers ELECTRE with respect to the problem of selecting an MCDA method or considers some methodological aspects of ELECTRE. A total of 686 papers are included in the review. The group of papers considering an application of ELECTRE consists of 544 papers, and these are further categorized into 13 application areas and a number of sub-areas. In addition, all papers are classified according to the country of author affiliation, journal of publication, and year of publication. For the group of applied papers, the distribution by ELECTRE version vs. application area and ELECTRE version vs. year of publication are provided. We believe that this paper can be a valuable source of information for researchers and practitioners in the field of MCDA and ELECTRE in particular.},
publisher = {Elsevier Ltd.},
url = {http://dx.doi.org/10.1016/j.ejor.2015.07.019},
keywords = {electre,literature review,multiple criteria decision aiding (mcda,outranking},
mendeley-tags = {electre,literature review,multiple criteria decision aiding (mcda,outranking},
}

@article{Stefano2015,
author = {Nara Medianeira Stefano and Nelson Casarotto Filho and Liz Garcia Lupi Vergara and  ra and Rodrigo Ulisses Garbin Da Rocha},
issn = {15480992},
abstract = {This paper presents a state-of-the-art literature survey on COPRAS applications and methodologies. The classification this review contains 59 papers, where if analyzed: titles and authors, cited journal, area classification, application areas, other multi-criteria methods combined with the COPRAS, authors nationality and country and most cited articles (or scientific recognition). This document provides useful insights about the COPRAS which is a new method, with many research opportunity.},
title = {COPRAS (Complex Proportional Assessment): State of the art research and its applications},
volume = {13},
journal = {IEEE Latin America Transactions},
year = {2015},
pages = {3899--3906},
doi = {10.1109/TLA.2015.7404925},
number = {12},
keywords = {literature review,mcda,mcdm,multi-criteria},
mendeley-tags = {literature review,mcda,mcdm,multi-criteria},
}

@article{Costa2016,
author = {Helder Gomes Costa},
pages = {26--42},
abstract = {Purpose – This study aims to use a graphical approach to highlight the differences between outranking and preference relationships. The outranking principle is based on a structure of non-dominance, which differs from the usual structures of preferences. Design/methodology/approach – To reach the objective, the paper makes a deep analysis of outranking and preference relationships and uses graphical representation to highlight the differences between these two concepts. Graphical interpretation is also used to support the results form ELECTRE I and to highlight misinterpretation of results, such as rank reversal in ELECTRE I. Findings – The results show that the assumption of rank reversal while using ELECTRE I is a mistake. Originality/value – It was not found in literature a previous work paper that demonstrates a result like this one.},
number = {1},
year = {2016},
doi = {10.1108/JM2-08-2013-0037},
issn = {17465672},
volume = {11},
journal = {Journal of Modelling in Management},
title = {Graphical interpretation of outranking principles: Avoiding misinterpretation results from ELECTRE I},
keywords = {decision analysis,mcda,multicriteria,outranking},
mendeley-tags = {decision analysis,mcda,multicriteria,outranking},
}

@article{Oliveira,
author = {G. A.Q.S.M. Oliveira and R. Seleme and I. C. Zattar},
abstract = {Since their conception, electric systems have not been through large modifications regarding their topology, solutions and metrics. However, the use of sensors, communications, computational capacity and control to increase and improve the power system functionalities, concept known as Smart Grid (SG), has great potential to revolutionize the electric sector. Nonetheless, many difficulties emerge when implementing SG technologies in a large scale. These difficulties may be technical, financial, environmental, regulatory and managerial. In order to aid in this process, the goal of this research is to propose a novel approach on how to assess the performance of SG implementation projects. The approach is based on the multicriteria decision aid theory, specifically using the Multicriteria Decision Aid Constructive Approach (MCDA-C), due to its logical and data treatment structures. A case study to evaluate the MCDA-C application was conducted, in partnership with a local utility SG pilot-project. With the use of this novel approach, it was possible to build a quantitative roadmap to monitor and improve the project performance. The main contribution of this work is the novel approach proposed, an adaptive model based on a multicriteria decision aid method that can comprehensively assess the performance of any SG project.},
number = {5},
journal = {IEEE Latin America Transactions},
doi = {10.1109/TLA.2016.7530428},
volume = {14},
pages = {2316--2322},
year = {2016},
title = {Smart Grid Performance Assessment Via Multicriteria Decision Aid Constructive Approach Method},
issn = {15480992},
keywords = {multicriteria decision aid,project management,roadmap,smart grids},
mendeley-tags = {multicriteria decision aid,project management,roadmap,smart grids},
}

@article{Mix2017,
author = {M. Dester},
journal = {IEEE Latin America Transactions},
number = {3},
pages = {1302--1307},
volume = {14},
abstract = {Integration of renewable sources into Brazils power mix is desirable and necessary. The main benefit from these energy sources is maintaining greenhouse gas emissions at low levels. Nevertheless, high penetration of these energy sources into the power mix can lead to many problems, for instance, intermittency in power generation. There are some mechanisms which can be implemented to mitigate intermittency and allow a higher level of participation of these energy sources in the generation mix. One such mechanism is utilizing Energy Storage Systems (ESS). The goal of this paper is to perform a study to find the best ESS options using Multi-criteria Decision Analysis. Moreover, an examination regarding Hydro Power Plants' reservoirs as an ESS is accomplished through a case study using three of Brazils significant Hydro Power Plants.},
year = {2016},
title = {Reliability of Electricity Supply Regarding the Integration of Intermittent Sources in Brazil's Power Mix},
doi = {10.1109/TLA.2016.7459613},
issn = {15480992},
keywords = {energy storage systems,intermittent sources,multi-criteria decision analysis,power mix,renewable sources},
mendeley-tags = {energy storage systems,intermittent sources,multi-criteria decision analysis,power mix,renewable sources},
}

@article{Jesus,
author = {Telmo Oliveira De Jesus and Michel Dos Santos Soares},
doi = {10.1109/TLA.2017.7910207},
abstract = {Changes in requirements occur throughout the software process from elicitation and analysis requirements through the operation of the software. Requirements traceability makes it possible to identify the origin and the dependence of the software requirements. Studies show that the tools and current requirements traceability methods are inadequate and hamper the practical use of traceability. In this paper, we carried out analysis of evaluation techniques and requirement traceability tools in order to verify if the techniques are being actually used and are being supported by software tools. As a result, we observed the lack of relationship between the techniques and tools evaluated and that some criteria, such as communication with stakeholders, difficulty, and requirement of stability were little considered in the evaluated tools.},
volume = {15},
journal = {IEEE Latin America Transactions},
year = {2017},
number = {5},
title = {A Multi-Criteria Analysis of Techniques and Tools for Tracing Software Requirements},
issn = {15480992},
pages = {922--927},
keywords = {requirements engineering,requirements management,requirements traceability},
mendeley-tags = {requirements engineering,requirements management,requirements traceability},
}

@misc{,
title = {1988 - A Theoretical Framework for Back-Propagation.pdf},
}

@article{Makin2006,
author = {J G Makin},
pages = {1--8},
title = {Backpropagation},
year = {2006},
}

@article{Introduction1996,
author = {A Systematic Introduction},
title = {Neural Networks},
year = {1996},
}

@article{,
number = {Xxx},
title = {t\~ao simples e compacta quanto poss\'ivel , adotando-se , para tanto , a nota\cc\~ao matricial . Embora matematicamente equivalente \`as deriva\cc\~oes apresentadas em ( XXX ), optou-se por uma abordagem direta com a inten\cc\~ao de tornar mais intuitivo o entendimento do},
}

@article{Sathyanarayana2014,
author = {Shashi Sathyanarayana and D Ph},
year = {2014},
title = {A Gentle Introduction to Backpropagation What is so difficult about designing a neural},
pages = {1--15},
}

@misc{,
title = {c1992backpropagationand.pdf},
}

@book{Zocca,
author = {Valentino Zocca and Daniel Slater},
isbn = {9781786464453},
title = {Python Deep Learning},
}

@misc{,
title = {Matthieu Ricard, Trinh Xuan Thuan-The quantum and the lotus_ a journey to the frontiers where science and Buddhism meet-Three Rivers Press (2004).pdf},
}

@article{Bahrampour2016,
author = {Cassius V C Reis},
pages = {294--310},
isbn = {9150617397},
number = {2},
title = {C Omparative S Tudy of C Ranial T Opographic},
journal = {Neurosurgery},
volume = {62},
abstract = {In the last decade, rapid growth in mobile applications, web technologies, social media generating unstructured data has led to the advent of various nosql data stores. Demands of web scale are in increasing trend everyday and nosql databases are evolving to meet up with stern big data requirements. The purpose of this paper is to explore nosql technologies and present a comparative study of document and column store nosql databases such as cassandra, MongoDB and Hbase in various attributes of relational and distributed database system principles. Detailed study and analysis of architecture and internal working cassandra, Mongo DB and HBase is done theoretically and core concepts are depicted. This paper also presents evaluation of cassandra for an industry specific use case and results are published.},
year = {2008},
issn = {15760162},
keywords = {cerebral localization,craniocerebral topography,neurosurgical history,neurosurgical navi},
mendeley-tags = {cerebral localization,craniocerebral topography,neurosurgical history,neurosurgical navi},
}

@article{Grinstein,
author = {Eric Grinstein and Ngoc Q K Duong and Alexey Ozerov and P Patrick},
arxivid = {arXiv:1710.11385v1},
eprint = {arXiv:1710.11385v1},
title = {No Title},
archiveprefix = {arXiv},
}

@article{Jing,
author = {Yongcheng Jing},
eprint = {arXiv:1705.04058v1},
archiveprefix = {arXiv},
title = {Neural Style Transfer: A Review},
arxivid = {arXiv:1705.04058v1},
}

@article{Abnisa2014,
author = {Faisal Abnisa and Wan Mohd Ashri Wan Daud and M Athanassiou and A Zabaniotou and a V Bridgwater and Duncan Brown and Andrew Rowe and Peter Wild and Dezhen Chen and Lijie Yin and Huan Wang and Pinjing He and Qun Chen and Ruiming Yang and Bo Zhao and Yan Li and Shujuan Shaobin Wang and Hongwei Wu and Yuqun Zhuo and Changhe Chen and Andrew Cross and Saran P. Sohi and Hong-Sheng Ding and Hong Jiang and  Francescato and Natalia G\'omez and Jos\'e Guillermo Rosas and Jorge Cara and Olegario Mart\'inez and Jos\'e Antonio Alburquerque and Marta Elena S\'anchez and E R Kaiser and Rajesh S. Kempegowda and \Oyvind Skreiberg and Khanh-quang Quang Tran and Tom Kuppens and Miet Van Dael and Kenny Vanreppelen and Theo Thewys and Jan Yperman and Robert Carleer and Sonja Schreurs and Steven Van Passel and Johannes Lehmann and Naprave Podjetja Paloma D D S and Budi Soediono and Outcome Defective Non-defective Total and Ayla Uslu and Andr\'e P.C. Faaij and P.C.A. Bergman and Hua Yang and Shinji Kudo and Hsiu Po Kuo and Koyo Norinaga and Aska Mori and Ondřej Ma\vsek and Jun Ichiro Hayashi and M Singh and G S\'et\'al\'o and X Guan and M Warren and  Toran-Aller and C D  and Peter Brownsort and Dane Dickinson and J.G. Rogers and J.G. Brammer and Saran P. Sohi and Kyle Crombie and Ondřej Ma\vsek and Naprave Podjetja Paloma D D S and Ondřej Ma\vsek and Miki Konno and Sou Hosokai and Nozomu Sonoyama and Koyo Norinaga and Jun Ichiro Hayashi and M Athanassiou and A Zabaniotou and Biomass Input and Uncondensed H O T Gases and Slow Pyrolysis and Katharina Prost and Nils Borchard and Jan Siemens and Timo Kautz and Jean-Marie S\'equaris and Andreas M\"oller and Wulf Amelung and Frederik Ronsse and Sven van Hecke and Dane Dickinson and Wolter Prins and S Abiven and N Singh and B Maestrini and Natalia Rogovska and David A. Laird and Richard Cruse and Pierce Fleming and Tim Parkin and David Meek and Kurt a Spokas and Jonathan Yoder and Suzette Galinato and David Granatstein and Manuel Garcia-P\'erez and Pietro Galgani and Ester van der Voet and Gijsbert Korevaar and G. San Miguel and M. P. Dom\'inguez and  Hern\' and M. ez and F. Sanz-P\'erez and Publishable Results and M P Bernal and Jos\'e Antonio Alburquerque and R Moral and R Bott and  Lew and Clare M. owski and New Co-investigator and  Lew and Clare M. owski and Peter a Brownsort (UKBRC/The University of Edinburgh) and Biochar Farms and Fern Preto and  o and Michaela Klinglm and Kyle Crombie and Ondřej Ma\vsek and Simon Shackley and Jim Hammond and John Gaunt and Rodrigo Ibarrola and Daren E. Daugaard and Robert C. Brown and E Krull and Bp Singh and Ms a Downie and Deliverable W P D and Ian C. Kemp and B. Christran Fyhr and Stephane Laurent and Michel a. Roques and Carda E. Groenewold and Evangelos Tsotsas and Alberto a. Sereno and Cathenne B. Bonazzi and Jean-Jacques Bimbenet and Mathhues Kind and  EBC and European Biochar Certificate and Shane M. Troy and Tereza Nolan and James J. Leahy and Peadar G. Lawlor and Mark G. Healy and Witold Kwapinski and The International Organisation and E N Iso and E N Iso and E N Iso and E N Iso and Nathan Kauffman and Jerome Dumortier and Dermot J. Hayes and Robert C. Brown and David A. Laird and Hua Yang and Shinji Kudo and Hsiu Po Kuo and Koyo Norinaga and Aska Mori and Ondřej Ma\vsek and Jun Ichiro Hayashi and J.G. Rogers and J.G. Brammer and C. Coskun and Z. Oktay and N. Ilten and Relative Energy and Fwhm $\Gamma$ $\Delta$e and Johannes Lehmann and Veronika Hansen and Dorette M\"uller-St\"over and Jesper Ahrenfeldt and Jens Kai Holm and Ulrik Birk Henriksen and Henrik Hauggaard-Nielsen and Sidney J. Rauch and Natalia G\'omez and Jos\'e Guillermo Rosas and Jorge Cara and Olegario Mart\'inez and Jos\'e Antonio Alburquerque and Marta Elena S\'anchez and Qun Chen and Ruiming Yang and Bo Zhao and Yan Li and Shujuan Shaobin Wang and Hongwei Wu and Yuqun Zhuo and Changhe Chen and K Raveendran and Product Definition and  St and Specification ards and Thayer Tomlinson and International Biochar Initiative and Bio Carbon Minerals and Inorganic C Required and Minimum Class and Required Declaration and Required Declaration and St Method and ard Test and Rapid Determination and Carbonate Content and St Method and ard Test and Chemical Analysis and Wood Charcoal and D I N E N Iso and Power Engineering Faculty and Power Engineering Faculty and Power Engineering Faculty and Power Engineering Faculty and Fang He and Weiming Yi and Xueyuan Bai and Table O F Contents and Energy Conversion and O Table and Tom Kuppens and Miet Van Dael and Kenny Vanreppelen and Robert Carleer and Leslie Miller-robbie and Bridget A Ulrich and Dotti F Ramey and Kathryn S Spencer and Skuyler P Herzog and Tzahi Y Cath and Jennifer R Stokes and Christopher P Higgins and Thiago De Paula Prot\'asio and Paulo Fern Trugilho and  o and Alfredo Napoli and Quanyuan Wei and Yongshui Qu and Tianwei Tan and R S Dhillon and George Von Wuehlisch and G A Huff and I A Vasalos and Abhishek Sharma and Vishnu Pareek and Shujuan Shaobin Wang and Zhezi Zhang and Yogesh Shinde and Vishnu Pareek and Dongke Zhang and T B Reed C D Cowdery and Crew Building and Mattias Gustafsson and Joseph M Reckamp and Rene A Garrido and Justinus A Satrio and Kyle Crombie and Dezhen Chen and Lijie Yin and Huan Wang and Pinjing He and Qun Chen and Ruiming Yang and Bo Zhao and Yan Li and Shujuan Shaobin Wang and Hongwei Wu and Yuqun Zhuo and Changhe Chen and a V Bridgwater and Kyle Crombie and Ondřej Ma\vsek and Guillermo Rosas and Jorge Cara and Olegario Mart\'inez and Saran P. Sohi and Peter Brownsort and Sarah Carter and Jason Cook and Colin Cunningham and John Gaunt and Rodrigo Ibarrola and Ondřej Ma\vsek and Kirsten Sims and Patricia Thornley and Deliverable W P D and Andrew Welfle and Paul Gilbert and Patricia Thornley and Tsz Him and Daniel Pleissner and Kin Yan and Joachim Venus and Aude Pommeret and Carol Sze and Ki Lin and Nelson Sommerfeldt and Hatef Madani and Tom Kuppens and Miet Van Dael and Kenny Vanreppelen and Theo Thewys and Jan Yperman and Robert Carleer and Sonja Schreurs and Steven Van Passel and Rajesh S. Kempegowda and \Oyvind Skreiberg and Khanh-quang Quang Tran and M J C Van Der Stelt and H Gerhauser and J H A Kiel and K J Ptasinski and Ayla Uslu and Long Beach and Won Chan Park and Forest Service and William T Simpson and Interreg Ivb},
title = {How to get published},
year = {2014},
doi = {10.1016/j.biortech.2014.03.134},
issn = {09619534},
pages = {1--10},
volume = {5},
archiveprefix = {arXiv},
arxivid = {arXiv:1011.1669v3},
journal = {Biomass and Bioenergy},
number = {1},
pmid = {15003161},
abstract = {What distinguishes a good manuscript from a bad one?},
isbn = {1757-1693},
eprint = {arXiv:1011.1669v3},
}

@article{,
abstract = {literature review},
journal = {2016},
title = {A literature review is a description of the literature relevant to a particular field or topic. It gives an overview of:},
}

@misc{Hastie2009,
author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
booktitle = {Bayesian Forecasting and Dynamic Models},
issn = {0172-7397},
isbn = {978-0-387-84857-0},
eprint = {arXiv:1011.1669v3},
doi = {10.1007/b94608},
pmid = {12377617},
title = {The Elements of Statistical Learning},
pages = {1--694},
arxivid = {arXiv:1011.1669v3},
url = {http://www.springerlink.com/index/10.1007/b94608},
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
volume = {1},
year = {2009},
archiveprefix = {arXiv},
}

@book{Petre2010,
author = {M Petre and G Rugg},
title = {The unwritten rules of PhD research},
url = {http://books.google.com/books?id=_DDwCqx6wpcC&printsec=frontcover&dq=unwritten+rules+of+phd+research&hl=&cd=1&source=gbs_api%255Cnpapers2://publication/uuid/48967E01-55F9-4397-B941-310D9C5405FA%255Cnhttp://medcontent.metapress.com/index/A65RM03P4874243N.p},
year = {2010},
booktitle = {Vasa},
pages = {320},
isbn = {9780335237029},
pmid = {1275585},
abstract = {"I feel grateful to have found this book only a year into my PhD. It has opened my eyes to the world of academia. There is more to a PhD than just research in the sense of working on a problem, getting some results and publishing your findings. This book has allowed me to open my eyes and see all the other things I should be doing to fully succeed at my endeavour of becoming a researcher myself." Dominic Hosler, University of Sheffield This bestselling book on the process of PhD research provides readers with engaging discussion and comprehensive guidance on aspects that other books don't usually mention. Covering all the key topics of the previous edition, including what a PhD is really about, how to do one well, how to decipher what your supervisor actually means by terms like 'good referencing' and 'clean research question', and how to design, report and defend your research,the authors continue to offer an accessible, down-to-earth, and insightful account of the whole PhD process. Their advice addresses how to avoid some of the pitfalls en route to a successful submission. Updated throughout, the new edition includes new material on: Critical thinking Research skills The route to research independence Different models of study The Unwritten Rules of PhD Research is essential reading for anyone considering a PhD or embarking on one. It will tell you the things many students wish someone had told them before they started.},
issn = {14724677},
doi = {10.1049/em:20040508},
}

@article{Tabei1996,
author = {Makoto Tabei and Bruce R. Musicus},
pages = {1504--1511},
year = {1996},
volume = {44},
number = {6},
title = {A simple estimator for frequency and decay rate},
issn = {1053587X},
doi = {10.1109/78.506615},
journal = {IEEE Transactions on Signal Processing},
}

@article{Robel,
author = {Axel Robel},
title = {Signals},
}

@article{Brown1991,
author = {Judith C Brown and Bin Zhang},
number = {5},
abstract = {In two recent papers, a description is given of a means of obtaining an arbitrarily narrow peak in the calculation of the autocorrelation function [J. C. Brown and M. S. Puckette, "Calculation of a narrowed autocorrelation function," J. Acoust. Soc. Am. 85, 1595?1601 (1989)] or of a narrow valley in the calculation of an inverse autocorrelation [J. C. Brown and M. S. Puckette, "Musical information from a narrowed autocorrelation function," Proceedings of the 1987 International Conference on Computer Music, Urbana, Illinois, 84?88 (1987)]. These calculations are applied to the determination of the fundamental frequency of musical signals produced by keyboard, wind, and string instruments. These results are compared to frequency tracking results obtained on these sounds with conventional autocorrelation. In so doing it is determined first whether the method of autocorrelation is well-adapted to the problem of tracking the frequency of musical signals, and, second, under what conditions "narrowed" autocorrelation is advantageous. \textcopyright1991 Acoustical Society of America.},
issn = {00014966},
journal = {J. Acoust. Soc. Am.},
pages = {2346--2354},
title = {Musical frequency tracking using the methods of conventional and "narrowed" autocorrelation},
volume = {89},
year = {1991},
doi = {10.1121/1.400923},
}

@article{Provencher1976,
author = {S. W. Provencher},
title = {A Fourier method for the analysis of exponential decay curves},
abstract = {A method based on the Fourier convolution theorem is developed for the analysis of data composed of random noise, plus an unknown constant "base line," plus a sum of (or an integral over a continuous spectrum of) exponential decay functions. The Fourier method's usual serious practical limitation of needing high accuracy data over a very wide range is eliminated by the introduction of convergence parameters and a Gaussian taper window. A computer program is described for the analysis of discrete spectra, where the data involves only a sum of exponentials. The program is completely automatic in that the only necessary inputs are the raw data (not necessarily in equal intervals of time); no potentially biased initial guesses concerning either the number or the values of the components are needed. The outputs include the number of components, the amplitudes and time constants together with their estimated errors, and a spectral plot of the solution. The limiting resolving power of the method is studied by analyzing a wide range of simulated two-, three-, and four-component data. The results seem to indicate that the method is applicable over a considerably wider range of conditions than nonlinear least squares or the method of moments. \textcopyright 1976, The Biophysical Society. All rights reserved.},
number = {1},
volume = {16},
pages = {27--41},
year = {1976},
doi = {10.1016/S0006-3495(76)85660-3},
isbn = {0006-3495},
issn = {00063495},
pmid = {1244888},
journal = {Biophysical Journal},
}

@misc{Martucci1994,
author = {Stephen A. Martucci},
volume = {42},
title = {Symmetric Convolution and the Discrete Sine and Cosine Transforms},
doi = {10.1109/78.295213},
booktitle = {IEEE Transactions on Signal Processing},
issn = {19410476},
number = {5},
year = {1994},
abstract = {This paper discusses the use of symmetric convolution and the\ndiscrete sine and cosine transforms (DSTs and DCTs) for general digital\nsignal processing. The operation of symmetric convolution is a\nformalized approach to convolving symmetrically extended sequences. The\nresult is the same as that obtained by taking an inverse discrete\ntrigonometric transform (DTT) of the product of the forward DTTs of\nthose two sequences. There are 16 members in the family of DTTs. Each\nprovides a representation for a corresponding distinct type of\nsymmetric-periodic sequence. The author defines symmetric convolution,\nrelates the DSTs and DCTs to symmetric-periodic sequences, and then use\nthese principles to develop simple but powerful\nconvolution-multiplication properties for the entire family of DSTs and\nDCTs. Symmetric convolution can be used for discrete linear filtering\nwhen the filter is symmetric or antisymmetric. The filtering will be\nefficient because fast algorithms exist for all versions of the DTTs.\nConventional linear convolution is possible if one first zero-pad the\ninput data. Symmetric convolution and its fast implementation using DTTs\nare now an alternative to circular convolution and the DFT},
pages = {1038--1051},
}

@article{Smith1999,
author = {Julius O. Smith},
abstract = {Use of a bilinear conformai map to achieve a frequency warping nearly identical to that of the Bark frequency scale is described. Because the map takes the unit circle to itself, its form is that of the transfer function of a first-order allpass filter. Since it is a first-order map, it preserves the model order of rational systems, making it a valuable frequency warping technique for use in audio filter design. A closed-form weighted-equationor method is derived that computes the optimal mapping coefficient as a function of sampling rate, and the solution is shown to be generally indistinguishable from the optimal least-squares solution. The optimal Chebyshev mapping is also found to be essentially identical to the optimal least-squares solution. The expression 0.8517 [arctan(0.06583fs)]1/2-0.916 is shown to accurately approximate the optimal allpass coefficient as a function of sampling rate fs in kHz for sampling rates greater than 1 kHz. A filter design example is included that illustrates improvements due to carrying out the design over a Bark scale. Corresponding results are also given and compared for approximating the related "equivalent rectangular bandwidth (ERB) scale≤ of Moore and Glasberg using a first-order allpass transformation. Due to the higher frequency resolution called for by the ERB scale, particularly at low frequencies, the first-order conformal map is less able to follow the desired mapping, and the error is two to three times greater than the Bark-scale case, depending on the sampling rate. \textcopyright 1999 IEEE Publisher Item Identifier S 1063-6676(99)07979-1.},
issn = {10636676},
number = {6},
pages = {697--708},
pmid = {799695},
title = {Bark and ERB Bilinear Transforms},
doi = {10.1109/89.799695},
year = {1999},
isbn = {- 1063-6676},
volume = {7},
journal = {IEEE Transactions on Speech and Audio Processing},
keywords = {bark,bilinear transform,erb,filter design,frequency warping},
mendeley-tags = {bark,bilinear transform,erb,filter design,frequency warping},
}

@article{Silvescu1999,
author = {A. Silvescu},
journal = {IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)},
pages = {488--491},
doi = {10.1109/IJCNN.1999.831544},
year = {1999},
abstract = {A new kind of neuron model that has a Fourier-like in/out function\nis introduced. The model is discussed in a general theoretical framework\nand some completeness theorems are presented. Current experimental\nresults show that the new model outperforms, by a large margin both in\nrepresentational power and convergence speed, the classical mathematical\nmodel of neuron based on weighted sum of inputs filtered by a nonlinear\nfunction. The new model is also appealing from a neurophysiological\npoint of view because it produces a more realistic representation by\nconsidering the inputs as oscillations},
issn = {1098-7576},
isbn = {0-7803-5529-6},
url = {http://ieeexplore.ieee.org/document/831544/},
title = {Fourier neural networks},
volume = {1},
}

@article{Rowland1999,
author = { Rowl and David R.  and Colin Pask},
issn = {0002-9505},
url = {http://aapt.scitation.org/doi/10.1119/1.19272},
number = {5},
abstract = {The usual suggestion for the longitudinally propagating momentum carried by a transverse wave on a string is shown to lead to paradoxes. Numerical simulations provide clues for resolving these paradoxes. The usual formula for wave momentum should be changed by a factor of 2 and the involvement of the cogenerated longitudinal waves is shown to be of crucial importance.},
doi = {10.1119/1.19272},
pages = {378--388},
journal = {American Journal of Physics},
title = {The missing wave momentum mystery},
volume = {67},
year = {1999},
}

@article{Cecotti2008,
author = {Hubert Cecotti and Axel Graeser},
isbn = {1051-4651},
pages = {1--4},
journal = {2008 19th International Conference on Pattern Recognition (ICPR)},
title = {Convolutional Neural Network with embedded Fourier Transform for EEG classification},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761638%5Cnpapers3://publication/doi/10.1109/ICPR.2008.4761638},
year = {2008},
abstract = {In BCI (brain - computer interface) systems, brain signals must be processed to identify distinct activities that convey different mental states. We propose a new technique for the classification of electroencephalographic (EEG) steady-state visual e...},
}

@article{Uncini,
author = {Aurelio Uncini},
title = {Sound Synthesis by Flexible Activation Function Recurrent Neural Networks},
}

@article{G-1999,
author = {Cost G- and Digital Audio Effects},
abstract = {This paper presents a model of the envelope of the additive parameters of isolated musical sounds, along with a new method for the estimation of the important envelope split- point times. The model consists of start, attack, sustain, release, and end segments with variable split-point amplitude and time. The estimation of the times is done using smoothed derivatives of the envelopes. The estimated split-point values can be used together with a curve-form model introduced in this paper in the analysis/synthesis of musical sounds. The envelope model can recreate noise-less musical sounds with good fidelity, and the method for the estimation of the envelope times performs significantly better than the classical percentage- based method.},
doi = {10.1109/MMSP.2001.962718},
title = {Envelope model of isolated musical sounds},
year = {1999},
journal = {Audio},
number = {1},
pages = {9--12},
}

@article{Graves2013b,
author = {Alex Graves},
title = {Generating Sequences With Recurrent Neural Networks},
url = {http://arxiv.org/abs/1308.0850},
year = {2013},
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
arxivid = {1308.0850},
doi = {10.1145/2661829.2661935},
eprint = {1308.0850},
isbn = {2000201075},
issn = {18792782},
archiveprefix = {arXiv},
pmid = {23459267},
pages = {1--43},
}

@article{Embrechts2009,
author = {Paul Embrechts and Marco Frei},
volume = {69},
year = {2009},
title = {Panjer recursion versus FFT for compound distributions},
number = {3},
abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used.We give a survey of these tools, point out the respective merits and provide some numerical examples.},
pages = {497--508},
issn = {14322994},
journal = {Mathematical Methods of Operations Research},
doi = {10.1007/s00186-008-0249-2},
keywords = {compound distributions,fast fourier transform,panjer recursion,risk management},
mendeley-tags = {compound distributions,fast fourier transform,panjer recursion,risk management},
}

@article{Merri2014,
author = {Kyunghyun Cho and Bart van Merrienboer and Dzmitry Bahdanau and Yoshua Bengio},
pages = {103--111},
arxivid = {1409.1259},
eprint = {1409.1259},
year = {2015},
abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
archiveprefix = {arXiv},
doi = {10.3115/v1/w14-4012},
title = {On the Properties of Neural Machine Translation: Encoder–Decoder Approaches},
}

@article{Lillicrap,
author = {Timothy P. Lillicrap and Daniel Cownden and Douglas B. Tweed and Colin J. Akerman},
year = {2014},
url = {http://arxiv.org/abs/1411.0247},
arxivid = {1411.0247},
archiveprefix = {arXiv},
title = {Random feedback weights support learning in deep neural networks},
pages = {1--27},
abstract = {The brain processes information through many layers of neurons. This deep architecture is representationally powerful, but it complicates learning by making it hard to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame to a neuron by computing exactly how it contributed to an error. To do this, it multiplies error signals by matrices consisting of all the synaptic weights on the neuron's axon and farther downstream. This operation requires a precisely choreographed transport of synaptic weight information, which is thought to be impossible in the brain. Here we present a surprisingly simple algorithm for deep learning, which assigns blame by multiplying error signals by random synaptic weights. We show that a network can learn to extract useful information from signals sent through these random feedback connections. In essence, the network learns to learn. We demonstrate that this new mechanism performs as quickly and accurately as backpropagation on a variety of problems and describe the principles which underlie its function. Our demonstration provides a plausible basis for how a neuron can be adapted using error signals generated at distal locations in the brain, and thus dispels long-held assumptions about the algorithmic constraints on learning in neural circuits.},
eprint = {1411.0247},
}

@article{Kopparapu,
author = {Sunil Kopparapu and M Satish},
title = {Optimal Gaussian Filter for Effective Noise Filtering},
arxivid = {arXiv:1406.3172v1},
eprint = {arXiv:1406.3172v1},
archiveprefix = {arXiv},
pages = {1--7},
number = {2},
}

@article{Courtney2015,
author = {Elya Courtney and Michael Courtney},
arxivid = {1507.01832},
title = {A More Accurate Fourier Transform},
abstract = {Fourier transform methods are used to analyze functions and data sets to provide frequencies, amplitudes, and phases of underlying oscillatory components. Fast Fourier transform (FFT) methods offer speed advantages over evaluation of explicit integrals (EI) that define Fourier transforms. This paper compares frequency, amplitude, and phase accuracy of the two methods for well resolved peaks over a wide array of data sets including cosine series with and without random noise and a variety of physical data sets, including atmospheric $\mathrmCO_2$ concentrations, tides, temperatures, sound waveforms, and atomic spectra. The FFT uses MIT's FFTW3 library. The EI method uses the rectangle method to compute the areas under the curve via complex math. Results support the hypothesis that EI methods are more accurate than FFT methods. Errors range from 5 to 10 times higher when determining peak frequency by FFT, 1.4 to 60 times higher for peak amplitude, and 6 to 10 times higher for phase under a peak. The ability to compute more accurate Fourier transforms has promise for improved data analysis in many fields, including more sensitive assessment of hypotheses in the environmental sciences related to $\mathrmCO_2$ concentrations and temperature. Other methods are available to address different weaknesses in FFTs; however, the EI method always produces the most accurate output possible for a given data set. On the 2011 Lenovo ThinkPad used in this study, an EI transform on a 10,000 point data set took 31 seconds to complete. Source code (C) and Windows executable for the EI method are available at https://sourceforge.net/projects/amoreaccuratefouriertransform/.},
url = {http://arxiv.org/abs/1507.01832},
archiveprefix = {arXiv},
eprint = {1507.01832},
year = {2015},
}

@article{Vincent,
author = {Pascal Vincent and Xavier Bouthillier},
arxivid = {arXiv:1412.7091v3},
pages = {1--15},
eprint = {arXiv:1412.7091v3},
archiveprefix = {arXiv},
title = {Efficient Exact Gradient Update for training Deep Networks with Very Large Sparse Targets [ Technical report ]},
}

@article{Baharev2015,
author = {Ali Baharev and Hermann Schichl and Arnold Neumaier},
title = {An exact method for the minimum feedback arc set problem},
year = {2015},
abstract = {Abstract Given a directed graph G, a feedback arc set of G is a subset of its edges containing at least one edge of every cycle in G. Finding a feedback arc set of minimum cardinality is the minimum feedback arc set problem. The present paper focuses on large and sparse ...},
pages = {35--60},
volume = {10},
journal = {University of Vienna},
keywords = {a directed graph g,e,edges of,graph if it has,introduction,is a pair,it is a simple,linear,maximum acyclic subgraph,minimum feedback arc set,minimum feedback vertex set,no multiple edges or,of finite sets,ordering problem,self-loops,tearing,the edges e,the vertices v and,v},
mendeley-tags = {a directed graph g,e,edges of,graph if it has,introduction,is a pair,it is a simple,linear,maximum acyclic subgraph,minimum feedback arc set,minimum feedback vertex set,no multiple edges or,of finite sets,ordering problem,self-loops,tearing,the edges e,the vertices v and,v},
}

@article{Moon2014,
author = {Il Joon Moon and Sung Hwa Hong},
number = {1},
volume = {18},
pages = {1--7},
issn = {20933797},
abstract = {Complex sound like speech can be characterized as the sum of number of amplitude-modulated signals representing the outputs of an array of narrow frequency bands. Temporal information at the output of each band can be separated into temporal fine structure (TFS), the rapid oscillations close to the center frequency and temporal envelope (ENV), slower amplitude modulations superimposed on the TFS. TFS information can be carried in the pattern of phase locking to the stimulus waveform, while ENV by the changes in firing rate over time. The relative importance of temporal ENV and TFS information in understanding speech has been studied using various sound-processing techniques. A number of studies demonstrated that ENV cues are associated with speech recognition in quiet, while TFS cues are possibly linked to melody/pitch perception and listening to speech in a competing background. However, there are evidences that recovered ENV from TFS as well as TFS itself may be partially responsible for speech recognition. Current technologies used in cochlear implants (CI) are not efficient in delivering the TFS cues, and new attempts have been made to deliver TFS information into sound-processing strategy in CI. We herein discuss the current updated findings of TFS with a literature review. \textcopyright 2014 The Korean Audiological Society.},
year = {2014},
journal = {Korean Journal of Audiology},
doi = {10.7874/kja.2014.18.1.1},
title = {What is temporal fine structure and why is it important?},
keywords = {hearing loss,speech perception,temporal envelope,temporal fine structure},
mendeley-tags = {hearing loss,speech perception,temporal envelope,temporal fine structure},
}

@article{Nayebi,
author = {Aran Nayebi and Matt Vitelli},
journal = {Deep Learning for Natural Language Processing},
pages = {1--6},
isbn = {978-3-531-94308-4},
abstract = {We compare the performance of two different types of recurrent neural networks (RNNs) for the task of algorithmic music generation, with audio waveforms as input. In particular, we focus on RNNs that have a sophisticated gating mecha-nism, namely, the Long Short-Term Memory (LSTM) network and the recently introduced Gated Recurrent Unit (GRU). Our results indicate that the generated outputs of the LSTM network were significantly more musically plausible than those of the GRU.},
url = {https://web.stanford.edu/$\sim$anayebi/projects/CS_224D_Final_Project_Writeup.pdf},
year = {2015},
title = {GRUV: Algorithmic Music Generation using Recurrent Neural Networks},
}

@article{Ioffe,
author = {Sergey Ioffe and Christian Szegedy},
archiveprefix = {arXiv},
title = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
volume = {1},
arxivid = {1502.03167},
isbn = {9781510810587},
year = {2015},
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.},
eprint = {1502.03167},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {448--456},
}

@article{Highlander2015,
author = { Highl and Tyler er},
title = {arXiv : 1601 . 06815v1 [ cs . NE ] 25 Jan 2016 Very Efficient Training of Convolutional Neural Networks using Fast Fourier},
arxivid = {arXiv:1601.06815v1},
year = {2015},
archiveprefix = {arXiv},
pages = {1--9},
eprint = {arXiv:1601.06815v1},
}

@article{Reyes2015,
author = {Marco A. Reyes and Rafael Arcos-Olalla},
title = {Supersymmetric features of the Error and Dawson's functions},
url = {http://arxiv.org/abs/1510.03735},
abstract = {Following a letter by Bassett, we show first that it is possible to find an analytical approximation to the error function in terms of a finite series of hyperbolic tangents from the supersymmetric (SUSY) solution of the Poschl-Teller eigenvalue problem in quantum mechanics (QM). Afterwards, we show that the second order differential equation for the derivatives of Dawson's function can be found in another SUSY related eigenvalue problem, where the factorization of the simple harmonic oscillator Hamiltonian renders the wrong-sign Hermite differential equation, and that Dawson's second order differential equation possess a singular SUSY type relation to this equation.},
arxivid = {1510.03735},
year = {2015},
issn = {0035-001X},
pages = {1--13},
number = {2},
archiveprefix = {arXiv},
eprint = {1510.03735},
keywords = {dawson,error function,gp,ln,mv,pacs numbers,pb,s function,supersymmetry,the error function,the integral,which is defined by},
mendeley-tags = {dawson,error function,gp,ln,mv,pacs numbers,pb,s function,supersymmetry,the error function,the integral,which is defined by},
}

@article{He2016,
author = {Lei He and Volker Dellwo},
number = {September},
abstract = {A speech signal can be viewed as a high frequency carrier signal containing the temporal fine structure (TFS) that is modulated by a low frequency envelope (ENV). A widely used method to decompose a speech signal into the TFS and ENV is the Hilbert transform. Although this method has been available for about one century and is widely applied in various kinds of speech processing tasks (e.g. speech chimeras), there are only very few speech processing packages that contain readily available functions for the Hilbert transform, and there is very little textbook type literature tailored for speech scientists to explain the processes behind the transform. With this paper we provide the code for carrying out the Hilbert operation to obtain the TFS and ENV in the widely used speech processing software Praat, and explain the basics of the procedure. To verify our code, we compare the Hilbert transform in Praat with a widely applied function for the same purpose in MATLAB ("hilbert(.)"). We can confirm that both methods arrive at identical outputs.},
doi = {10.21437/Interspeech.2016-1447},
pages = {530--534},
volume = {08-12-Sept},
year = {2016},
title = {A Praat-based algorithm to extract the amplitude envelope and temporal fine structure using the Hilbert transform},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {amplitude envelope,hilbert transform,praat,temporal fine structure},
mendeley-tags = {amplitude envelope,hilbert transform,praat,temporal fine structure},
}

@article{Esser,
author = {Steven K. Esser and Paul A. Merolla and John V. Arthur and Andrew S. Cassidy and Rathinakumar Appuswamy and Alex Andreopoulos and  er and David J. Berg and Jeffrey L. McKinstry and Timothy Melano and Davis R. Barch and Carmelo Di Nolfo and Pallab Datta and Arnon Amir and Brian Taba and Myron D. Flickner and Dharmendra S. Modha},
doi = {10.1073/pnas.1604850113},
arxivid = {1603.08270},
eprint = {1603.08270},
title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
number = {41},
year = {2016},
abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (/) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii') can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
archiveprefix = {arXiv},
pages = {11441--11446},
volume = {113},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {convolutional network,neural network,neuromorphic,truenorth},
mendeley-tags = {convolutional network,neural network,neuromorphic,truenorth},
}

@misc{Dewick2002,
author = {Paul Dewick and Ken Green and Marcela Miozzo},
number = {January},
pages = {1--31},
title = {Technological Change, Industry Structure and the Environment},
abstract = {This paper seeks to contribute towards the construction and application of a method to assess the long-term impact of the development of their technological technologies on the environment. The paper identifies the effect of three pervasive technologies – biotechnology, information technology and nanotechnology – on the production of a range of sectors and their consequent environmental effects. The sectors are selected according to taxonomies of characteristics. The technological impact is assessed qualitatively in terms of changes in production scale and resource intensity and their resulting impact on industrial greenhouse gas emissions},
year = {2002},
}

@misc{,
title = {._Sawhney, Verona e Prandelli_2005(JIM)_COLLABORATING TO CREATE- THE INTERNET AS A PLATFORM FOR CUSTOMER ENGAGEMENT IN PRODUCT INNOVATION.pdf},
}

@misc{,
title = {Unknown - Unknown - Leaps and bounds.pdf.pdf},
}

@misc{,
title = {Unknown - Unknown - Democratizing Innovation.pdf.pdf},
}

@misc{Alves1992,
author = {Alda Judith Alves},
pmid = {25246403},
abstract = {O artigo analisa o papel da revis\~ao da bibliografia em trabalhos de pesquisa e aponta as principais defici\^encias observadas em teses de mestrado e doutorado, no que se refere a esse aspecto. A primeira se\cc\~ao destaca a import\^ancia da an\'alise cr\'itica do estado atual do conhecimento na \'areade interesse do pesquisador para a problematiza\cc\~ao do temaa ser investigado. A segunda trata do referencial te\'orico e discute as dificuldades encontradas na constru\cc\~ao te\'orica no campo da educa\cc\~ao. Finalmente, a terceira se\cc\~ao apresenta os equ\'ivocos mais freq\"uentes observados em revis\~oes de bibliografia, utilizando o recurso da caricatura para tornar mais vis\'iveis certos tra\ccos.},
number = {81},
title = {A "revis\~ao da bibliografia"em teses e disserta\cc\~os: meus tipos inesquec\'iveis},
url = {http://www.fcc.org.br/pesquisa/publicacoes/cp/arquivos/916.pdf},
pages = {53--60},
year = {1992},
doi = {10.1017/CBO9781107415324.004},
isbn = {9788578110796},
arxivid = {arXiv:1011.1669v3},
eprint = {arXiv:1011.1669v3},
booktitle = {Cadernos de Pesquisa},
archiveprefix = {arXiv},
issn = {1098-6596},
}

@article{,
isbn = {9781479903566},
journal = {Computer Engineering},
pages = {3572--3576},
title = {KERNEL RECURRENT SYSTEM TRAINED BY REAL-TIME RECURRENT LEARNING ALGORITHM Pingping Zhu , Jos ´ University of Florida Electrical and Computer Engineering},
year = {2013},
}

@misc{,
title = {Wang et al. - 2011 - Rapid parametric design methods for shoe-last customization.pdf},
}

@article{Raczynski2013a,
author = {Stanis\law A. Raczy\'nski and Emmanuel Vincent and Shigeki Sagayama},
issn = {1558-7916},
title = {Dynamic Bayesian networks for symbolic polyhonic pitch modeling},
year = {2013},
doi = {10.1109/TASL.2013.2258012},
pages = {1830 -- 1840},
volume = {21},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
number = {9},
}

@article{Conference2014,
author = {Ieee International Conference and Signal Processing},
isbn = {9781479928934},
volume = {1},
year = {2014},
number = {May},
pages = {3136--3140},
title = {POLYPHONIC PIANO TRANSCRIPTION USING NON-NEGATIVE MATRIX FACTORISATION WITH GROUP SPARSITY Ken O ' Hanlon and Mark D . Plumbley Queen Mary University of London},
}

@article{Phumrattanaprapin2016a,
author = {Khanittha Phumrattanaprapin},
pages = {196--204},
volume = {10},
title = {Machine with Multilayer Perceptron},
number = {2},
year = {2016},
keywords = {chine,hierarchical extreme learning ma,hierarchical learning,multilayer perceptron},
mendeley-tags = {chine,hierarchical extreme learning ma,hierarchical learning,multilayer perceptron},
}

@article{Schaffner2017,
author = {Michael Schaffner and Student Member and Florian Scheidegger and Lukas Cavigelli and Student Member and Hubert Kaeslin and Senior Member and Luca Benini and Aljosa Smolic},
year = {2017},
title = {Ro of Ro of},
volume = {4},
}

@article{DavidA.Cacchione1997,
author = {David A. Cacchione},
doi = {10.1511/2011.89.106},
isbn = {2136240900},
issn = {0003-0996},
title = {American Scientist},
year = {1997},
volume = {85},
pages = {108--112},
number = {2},
}

@article{,
archiveprefix = {arXiv},
doi = {10.1109/5.726791},
issn = {00189219},
pmid = {15823584},
title = {Lecun-98},
arxivid = {1102.0183},
eprint = {1102.0183},
isbn = {0018-9219},
}

@article{Bengio2007a,
author = {Yoshua Bengio and Yann Lecun},
year = {2007},
journal = {New York},
number = {1},
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), reasoning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with minimal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally limited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very inefficient in terms of required number of computational elements and examples. Second, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learning) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more abstract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence.},
pages = {1--41},
title = {Scaling Learning Algorithms towards AI To appear in " Large-Scale Kernel Machines ",},
}

@article{Tang2014a,
author = {Duyu Tang and Furu Wei and Bing Qin and Li Dong and Ting Liu and Ming Zhou},
volume = {23},
isbn = {2329-9290 VO  - 23},
number = {2002},
pages = {477--487},
abstract = {In this paper, we propose a joint segmenta- tion and classification framework for sen- timent analysis. Existing sentiment clas- sification algorithms typically split a sen- tence as a word sequence, which does not effectively handle the inconsistent senti- ment polarity between a phrase and the words it contains, such as "not bad" and "a great deal of ". We address this issue by developing a joint segmentation and classification framework (JSC), which si- multaneously conducts sentence segmen- tation and sentence-level sentiment classi- fication. Specifically, we use a log-linear model to score each segmentation candi- date, and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier. A marginal log-likelihood objective function is de- vised for the segmentation model, which is optimized for enhancing the sentiment classification performance. The joint mod- el is trained only based on the annotat- ed sentiment polarity of sentences, with- out any segmentation annotations. Experi- ments on a benchmark Twitter sentimen- t classification dataset in SemEval 2013 show that, our joint model performs com- parably with the state-of-the-art methods.},
issn = {2329-9290},
journal = {Proceedings of the 2014 Conferenve on Empirical Methods in Natural Language Processing (EMNLP)},
year = {2014},
doi = {10.1109/TASLP.2015.2449071},
title = {A Joint Segmentation and Classification Framework for Sentiment Analysis},
}

@article{Boulanger-lewandowski,
author = { Boulanger-lew and Nicolas owski},
number = {2},
journal = {Ieee},
pages = {5417--5421},
title = {PHONE SEQUENCE MODELING WITH RECURRENT NEURAL NETWORKS Universit ´ e de Montr ´ Montr ´ Jasha Droppo Mike Seltzer Dong Yu One Microsoft Way},
isbn = {9781479928934},
year = {2014},
}

@misc{,
title = {Estelles-Arolas, Gonzalez-Ladron-de-Guevara - 2012 - Towards an integrated crowdsourcing definition.pdf},
}

@article{Song2016,
author = {Qing Song and Xu Zhao and Haijin Fan and Danwei Wang},
title = {Robust Recurrent Kernel Online Learning},
pages = {1068--1081},
publisher = {IEEE},
issn = {21622388},
doi = {10.1109/TNNLS.2016.2518223},
number = {5},
year = {2016},
volume = {28},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Sotelo2017,
author = {Jose Sotelo and Soroush Mehri and Kundan Kumar and Joao Felipe Santos and Kyle Kastner and Aaron Courville and Yoshua Bengio},
journal = {Iclr},
pages = {44--51},
number = {October},
abstract = {We present Char2Wav, an end-to-end model for speech synthesis. Char2Wav has two components: a reader and a neural vocoder . The reader is an encoder- decoder model with attention. The encoder is a bidirectional recurrent neural net- work that accepts text or phonemes as inputs, while the decoder is a recurrent neu- ral network (RNN) with attention that produces vocoder acoustic features. Neural vocoder refers to a conditional extension of SampleRNN which generates raw waveform samples from intermediate representations. Unlike traditional models for speech synthesis, Char2Wav learns to produce audio directly from text.},
url = {https://openreview.net/pdf?id=B1VWyySKx},
title = {Char2Wav: End-to-End Speech Synthesis},
year = {2017},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
}

@article{werbos74,
author = {Science Thesis and Ph D Appl and Math Harvard},
number = {January 1974},
title = {Beyond Regression : New Tools for Prediction and Analysis in the Behavioral},
year = {2018},
journal = {Doctoral Dissertation, Applied Mathematics, Harvard University, MA},
}

@article{Sangkloy2016,
author = {Patsorn Sangkloy and Jingwan Lu and Chen Fang and Fisher Yu and James Hays},
url = {http://arxiv.org/abs/1612.00835},
abstract = {Recently, there have been several promising methods to generate realistic imagery from deep convolutional networks. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to 'scribble' over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach can generate more realistic, more diverse, and more controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.},
arxivid = {1612.00835},
title = {Scribbler: Controlling Deep Image Synthesis with Sketch and Color},
eprint = {1612.00835},
year = {2016},
archiveprefix = {arXiv},
journal = {arXiv preprint arXiv:1612.00835},
keywords = {image synthesis,state of the art},
mendeley-tags = {image synthesis,state of the art},
}

@article{Cortes2016,
author = {Corinna Cortes and Xavi Gonzalvo and Vitaly Kuznetsov and Mehryar Mohri and Scott Yang},
journal = {arXiv preprint arXiv:1607.01097},
year = {2016},
eprint = {1607.01097},
url = {http://arxiv.org/abs/1607.01097},
arxivid = {1607.01097},
archiveprefix = {arXiv},
abstract = {We present new algorithms for adaptively learning artificial neural networks. Our algorithms (AdaNet) adaptively learn both the structure of the network and its weights. They are based on a solid theoretical analysis, including data-dependent generalization guarantees that we prove and discuss in detail. We report the results of large-scale experiments with one of our algorithms on several binary classification tasks extracted from the CIFAR-10 dataset. The results demonstrate that our algorithm can automatically learn network structures with very competitive performance accuracies when compared with those achieved for neural networks found by standard approaches.},
title = {AdaNet: Adaptive Structural Learning of Artificial Neural Networks},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Li2015,
author = {Junnan Li and Edmund Y. Lam},
doi = {10.1109/IST.2015.7294547},
title = {Facial expression recognition using deep neural networks},
issn = {1558-2809},
institution = {IEEE},
isbn = {9781479986330},
journal = {Imaging Systems and Techniques (IST), 2015 IEEE International Conference on},
pages = {1--6},
year = {2015},
keywords = {facial expression},
mendeley-tags = {facial expression},
}

@article{Bas2016,
author = {Eren Bas},
issn = {24496499},
doi = {10.1515/jaiscr-2016-0001},
journal = {Journal of Artificial Intelligence and Soft Computing Research},
pages = {5--11},
number = {1},
year = {2016},
abstract = {In recent years, artificial neural networks have been commonly used for time series forecasting by researchers from various fields. There are some types of artificial neural networks and feed forward artificial neural networks model is one of them. Although feed forward artificial neural networks gives successful forecasting results they have a basic problem. This problem is architecture selection problem. In order to eliminate this problem, Yadav et al. (2007) proposed multiplicative neuron model artificial neural network. In this study, differential evolution algorithm is proposed for the training of multiplicative neuron model for forecasting. The proposed method is applied to two well-known different real world time series data.},
volume = {6},
title = {The training of multiplicative neuron model based artificial neural networks with differential evolution algorithm for forecasting},
keywords = {evolutive,forecasting},
mendeley-tags = {evolutive,forecasting},
}

@article{PingpingZhu2013,
author = {Jos\'e Pingping Zhu and e C. Pr\'incipe and Pingping Zhu and Jos\'e C Pr\'\incipe},
title = {KERNEL RECURRENT SYSTEM TRAINED BY REAL-TIME RECURRENT LEARNING ALGORITHM},
year = {2013},
pages = {3572--3576},
isbn = {9781479903566},
journal = {Computer Engineering},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Maas2013,
author = {Andrew L Maas and Awni Y Hannun and Andrew Y Ng},
journal = {in ICML Workshop on Deep Learning for Audio, Speech and Language Processing},
url = {https://web.stanford.edu/$\sim$awni/papers/relu_hybrid_icml2013_final.pdf},
pages = {6},
year = {2013},
title = {Rectifier nonlinearities improve neural network acoustic models},
number = {1},
volume = {28},
abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@inproceedings{he2016deep,
author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
year = {2016},
pages = {770--778},
title = {Deep residual learning for image recognition},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
}

@book{bishop06,
author = {N. Abramson and D. Braverman and G. Sebestyen},
publisher = {springer},
volume = {9},
title = {Pattern recognition and machine learning},
issn = {15579654},
booktitle = {IEEE Transactions on Information Theory},
number = {4},
year = {1963},
doi = {10.1109/TIT.1963.1057854},
pages = {257--261},
}

@article{leshno93,
author = {Moshe Leshno and Vladimir Ya Lin and Allan Pinkus and Shimon Schocken},
journal = {Neural Networks},
number = {6},
abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold. \textcopyright 1993 Pergamon Press Ltd.},
title = {Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
publisher = {Elsevier},
pages = {861--867},
volume = {6},
issn = {08936080},
year = {1993},
doi = {10.1016/S0893-6080(05)80131-5},
keywords = {activation functions,lp($\mu$) approximation,multilayer feedforward networks,role of threshold,universal approximation capabilities},
mendeley-tags = {activation functions,lp($\mu$) approximation,multilayer feedforward networks,role of threshold,universal approximation capabilities},
}

@article{socher2014recursive,
author = {Richard Socher},
publisher = {Citeseer},
title = {Recursive Deep Learning for Natural Language Processing and Computer Vision},
year = {2014},
pages = {189},
abstract = {I introduced a max-margin,structure prediction framework based on Recursive Neural Networks (RNNs) for nding hierarchical structure in multiple modalities. Recursion in this case pertains to the idea that the same neural network is applied repeatedly on different components of a sentence. Since this model showed much promise for both language and image understanding, I decided to further investigate the space of recursive deep learning models. In this thesis, I explore model variations along three major axes in order to gain insights into hierarchical feature learning, building fast, practical, state of the art NLP systems and semantic compositionality, the important quality of natural language that allows speakers to determine the meaning of a longer expression based on the meanings of its words and the rules used to combine them. I explore unsupervised learning of word and sentence vectors using reconstruction errors. My my parsing work uses a simple linear scoring function and sentiment and relation classi cation use softmax classi ers to predict a label for each node and phrase in the tree. The standard RNN composition function is based on a single neural network layer that takes as input two phrase or word vectors and uses the same set of weights at every node in the parse tree to compute higher order phrase vectors. It is not expressive enough to capture all types of compositions. I explored several variants of composition functions. I have worked on constituency parsing, whose goal it is to learn the correct grammatical analysis of a sentence and produce a tree structure. Another approach allowed the actual task, such as sentiment prediction or reconstruction error, to determine the tree structure. CHANGES vs. 2011a [Dynamic pooling and unfolding recursive autoencoders for paraphrase detection], mentioned by Zhou, Troyanskaya - Deep Supervised and Convolutional Generative Stochastic Network for Protein Secondary Structure Prediction [2014] 1. For optimization of objective function, the diagonal variant of AdaGrad has much better optima in various experiments of this thesis, and converges more quickly than L-BFGS used in 2011a 2. The standard RNN composition function [used in 2011a] it is not expressive enough to capture all types of compositions. Hence, I explored several variants of composition functions.},
journal = {PhD thesis},
number = {August},
keywords = {richard socher},
mendeley-tags = {richard socher},
}

@inproceedings{choi2017convolutional,
author = {Martin Zihlmann and Dmytro Perekrestenko and Michael Tschannen},
issn = {23318422},
organization = {IEEE},
pages = {2392--2396},
booktitle = {arXiv},
year = {2017},
title = {Convolutional recurrent neural networks for electrocardiogram classification},
abstract = {We propose two deep neural network architectures for classification of arbitrary-length electrocardiogram (ECG) recordings and evaluate them on the atrial fibrillation (AF) classification data set provided by the PhysioNet/CinC Challenge 2017. The first architecture is a deep convolutional neural network (CNN) with averaging-based feature aggregation across time. The second architecture combines convolutional layers for feature extraction with long-short term memory (LSTM) layers for temporal aggregation of features. As a key ingredient of our training procedure we introduce a simple data augmentation scheme for ECG data and demonstrate its effectiveness in the AF classification task at hand. The second architecture was found to outperform the first one, obtaining an F1score of 82.1% on the hidden challenge testing set.},
}

@article{mao2000probabilistic,
author = {Ke Zhi Mao and K-C Tan and Wee Ser},
number = {4},
pages = {1009--1016},
publisher = {IEEE},
title = {Probabilistic neural-network structure determination for pattern classification},
journal = {IEEE Transactions on neural networks},
volume = {11},
year = {2000},
}

@article{egmont2002image,
author = {Michael Egmont-Petersen and Dick de Ridder and  H and Heinz els},
journal = {Pattern recognition},
year = {2002},
title = {Image processing with neural networks—a review},
pages = {2279--2301},
volume = {35},
publisher = {Elsevier},
number = {10},
}

@inproceedings{kasabov2012neucube,
author = {Nikola Kasabov},
organization = {Springer},
year = {2012},
title = {NeuCube EvoSpike Architecture for Spatio-temporal Modelling and Pattern Recognition of Brain Signals.},
booktitle = {ANNPR},
pages = {225--243},
}

@article{jiang1999image,
author = {J Jiang},
journal = {Signal Processing: Image Communication},
number = {9},
publisher = {Elsevier},
title = {Image compression with neural networks--a survey},
pages = {737--760},
volume = {14},
year = {1999},
}

@article{hinton2012deep,
author = {Geoffrey Hinton and Li Deng and Dong Yu and George Dahl and Abdel Rahman Mohamed and Navdeep Jaitly and Andrew Senior and Vincent Vanhoucke and Patrick Nguyen and Tara Sainath and Brian Kingsbury},
title = {Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
number = {6},
volume = {29},
issn = {10535888},
doi = {10.1109/MSP.2012.2205597},
journal = {IEEE Signal Processing Magazine},
pages = {82--97},
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition. \textcopyright 2012 IEEE.},
publisher = {IEEE},
year = {2012},
}

@article{ritchie2003optimizationof,
author = {Marylyn D Ritchie and Bill C White and Joel S Parker and Lance W Hahn and Jason H Moore},
year = {2003},
publisher = {BioMed Central},
number = {1},
volume = {4},
journal = {BMC bioinformatics},
title = {Optimizationof neural network architecture using genetic programming improvesdetection and modeling of gene-gene interactions in studies of humandiseases},
pages = {28},
}

@inproceedings{goodfellow2014generative,
author = {Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
year = {2014},
booktitle = {Advances in neural information processing systems},
title = {Generative adversarial nets},
pages = {2672--2680},
}

@article{Raczynski2013,
author = {Stanislaw A. Raczynski and Emmanuel Vincent and Shigeki Sagayama},
pages = {1830--1840},
doi = {10.1109/TASL.2013.2258012},
year = {2013},
title = {Dynamic bayesian networks for symbolic polyphonic pitch modeling},
issn = {15587916},
number = {9},
volume = {21},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
abstract = {Symbolic pitch modeling is a way of incorporating knowledge about relations between pitches into the process of analyzing musical information or signals. In this paper, we propose a family of probabilistic symbolic polyphonic pitch models, which account for both the 'horizontal' and the 'vertical' pitch structure. These models are formulated as linear or log-linear interpolations of up to five sub-models, each of which is responsible for modeling a different type of relation. The ability of the models to predict symbolic pitch data is evaluated in terms of their cross-entropy, and of a newly proposed 'contextual cross-entropy' measure. Their performance is then measured on synthesized polyphonic audio signals in terms of the accuracy of multiple pitch estimation in combination with a Nonnegative Matrix Factorization-based acoustic model. In both experiments, the log-linear combination of at least one 'vertical' (e.g., harmony) and one 'horizontal' (e.g., note duration) sub-model outperformed a pitch-dependent Bernoulli prior by more than 60% in relative cross-entropy and 3% in absolute multiple pitch estimation accuracy. This work provides a proof of concept of the usefulness of model interpolation, which may be used for improved symbolic modeling of other aspects of music in the future. \textcopyright 2013 IEEE.},
keywords = {music transcription},
mendeley-tags = {music transcription},
}

@article{Bengio2007,
author = {Yoshua Bengio and Yann LeCun and Yann Lecun},
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), rea- soning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, withmin- imal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally lim- ited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very ineffi- cient in terms of required number of computational elements and examples. Sec- ond, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learn- ing) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more ab- stract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence. 1},
issn = {00099104},
journal = {Large Scale Kernel Machines},
year = {2007},
doi = {10.1.1.72.4580},
pages = {321--360},
number = {1},
isbn = {1002620262},
title = {Scaling Learning Algorithms towards AI},
pmid = {11359439},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Clune2013,
author = {J. Clune and J.-B. Mouret and H. Lipson},
title = {The evolutionary origins of modularity},
abstract = {A central biological question is how natural organisms are so evolvable (capable of quickly adapting to new environments). A key driver of evolvability is the widespread modularity of biological networks--their organization as functional, sparsely connected subunits--but there is no consensus regarding why modularity itself evolved. Although most hypotheses assume indirect selection for evolvability, here we demonstrate that the ubiquitous, direct selection pressure to reduce the cost of connections between network nodes causes the emergence of modular networks. Computational evolution experiments with selection pressures to maximize network performance and minimize connection costs yield networks that are significantly more modular and more evolvable than control experiments that only select for performance. These results will catalyse research in numerous disciplines, such as neuroscience and genetics, and enhance our ability to harness evolution for engineering purposes.},
year = {2013},
eprint = {1207.2743v1},
pages = {20122863--20122863},
pmid = {23363632},
doi = {10.1098/rspb.2012.2863},
url = {http://rspb.royalsocietypublishing.org/cgi/doi/10.1098/rspb.2012.2863},
journal = {Proceedings of the Royal Society B: Biological Sciences},
issn = {0962-8452},
arxivid = {1207.2743v1},
volume = {280},
archiveprefix = {arXiv},
number = {1755},
isbn = {1471-2954 (Electronic)\n0962-8452 (Linking)},
keywords = {computational biology,evolution},
mendeley-tags = {computational biology,evolution},
}

@article{Leshno1991,
author = {Moshe Leshno and Shimon Schocken},
pages = {1--16},
url = {https://archive.nyu.edu/bitstream/2451/14384/1/IS-91-26.pdf},
year = {1991},
number = {21},
title = {Multilayer Feedforward Networks with Non-Polynomial Activation Functions Can Approximate Any Function},
keywords = {theory},
mendeley-tags = {theory},
}

@article{M??ller2001,
author = {Klaus Robert M??ller and Sebastian Mika and Gunnar R??tsch and Koji Tsuda and Bernhard Sch??lkopf},
pages = {181--201},
journal = {IEEE Transactions on Neural Networks},
doi = {10.1109/72.914517},
number = {2},
title = {An introduction to kernel-based learning algorithms},
volume = {12},
pmid = {18244377},
issn = {10459227},
year = {2001},
abstract = {This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by discussing applications such as optical character recognition and DNA analysis.},
isbn = {1045-9227},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Tang2014,
author = {Duyu Tang and Bing Qin and Furu Wei and Li Dong and Ting Liu and Ming Zhou},
number = {11},
title = {A Joint Segmentation and Classification Framework for Sentence Level Sentiment Classification},
abstract = {In this paper, we propose a joint segmentation and classification framework for sentence-level sentiment classification. It is widely recognized that phrasal information is crucial for sentiment classification. However, existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains, such as 'not bad,' 'bad' and 'a great deal of,' 'great'. We address this issue by developing a joint framework for sentence-level sentiment classification. It simultaneously generates useful segmentations and predicts sentence-level polarity based on the segmentation results. Specifically, we develop a candidate generation model to produce segmentation candidates of a sentence; a segmentation ranking model to score the usefulness of a segmentation candidate for sentiment classification; and a classification model for predicting the sentiment polarity of a segmentation. We train the joint framework directly from sentences annotated with only sentiment polarity, without using any syntactic or sentiment annotations in segmentation level. We conduct experiments for sentiment classification on two benchmark datasets: a tweet dataset and a review dataset. Experimental results show that: 1) our method performs comparably with state-of-The-art methods on both datasets; 2) joint modeling segmentation and classification outperforms pipelined baseline methods in various experimental settings.},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
issn = {15587916},
volume = {23},
isbn = {2329-9290 VO - 23},
pages = {1750--1761},
year = {2015},
doi = {10.1109/TASLP.2015.2449071},
keywords = {sentiment analysis},
mendeley-tags = {sentiment analysis},
}

@article{Mao2000,
author = {K Z Mao and K C Tan and W Ser},
year = {2000},
volume = {11},
pages = {1009--1016},
title = {Probabilistic neural network structure determination for pattern classification},
journal = {IEEE Transactions on Neural Networks},
number = {4},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
}

@article{Ritchie2003,
author = {M D Ritchie and B C White and J S Parker and L W Hahn and J H Moore},
year = {2003},
doi = {10.1186/1471-2105-4-28},
title = {Optimization of neural network architecture using genetic programming improves detection and modeling of gene-gene interactions in studies of human diseases},
abstract = {BACKGROUND: Appropriate definition of neural network architecture prior to data analysis is crucial for successful data mining. This can be challenging when the underlying model of the data is unknown. The goal of this study was to determine whether optimizing neural network architecture using genetic programming as a machine learning strategy would improve the ability of neural networks to model and detect nonlinear interactions among genes in studies of common human diseases. RESULTS: Using simulated data, we show that a genetic programming optimized neural network approach is able to model gene-gene interactions as well as a traditional back propagation neural network. Furthermore, the genetic programming optimized neural network is better than the traditional back propagation neural network approach in terms of predictive ability and power to detect gene-gene interactions when non-functional polymorphisms are present. CONCLUSION: This study suggests that a machine learning strategy for optimizing neural network architecture may be preferable to traditional trial-and-error approaches for the identification and characterization of gene-gene interactions in common, complex human diseases.},
journal = {BMC bioinformatics},
issn = {1471-2105},
isbn = {1471-2105 (Electronic)\r1471-2105 (Linking)},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12846935},
pmid = {12846935},
volume = {4},
pages = {28},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Srivastava2014,
author = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
volume = {15},
year = {2014},
pages = {1929--1958},
title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
isbn = {1532-4435},
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different " thinned " networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
arxivid = {1102.4807},
journal = {Journal of Machine Learning Research},
archiveprefix = {arXiv},
issn = {15337928},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Goodfellow2014,
author = {Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
abstract = {We propose a new framework for estimating generative models via an adversar- ial process; in which we simultaneously train two models: a generative model G that captures the data distribution; and a discriminative model D that estimates the probability that a sample came from the training data rather thanG. The train- ing procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D; a unique solution exists; with G recovering the training data distribution andD equal to 1 2 everywhere. In the case where G andD are defined by multilayer perceptrons; the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference net- works during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 1},
archiveprefix = {arXiv},
arxivid = {arXiv:1406.2661v1},
eprint = {arXiv:1406.2661v1},
doi = {10.1001/jamainternmed.2016.8245},
isbn = {1406.2661},
issn = {10495258},
title = {Generative Adversarial Nets (NIPS version)},
pages = {2672--2680},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
journal = {Advances in Neural Information Processing Systems 27},
year = {2014},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Hayes2013,
author = {Brian Hayes},
number = {2},
doi = {10.1511/2013.101.92},
journal = {American Scientist},
pages = {92--97},
year = {2013},
volume = {101},
title = {First links in the Markov chain},
issn = {00030996},
}

@article{Yosinski2014,
author = {Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
archiveprefix = {arXiv},
arxivid = {1411.1792},
url = {http://arxiv.org/abs/1411.1792},
eprint = {1411.1792},
title = {How transferable are features in deep neural networks?},
issn = {10495258},
pages = {1--9},
year = {2014},
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Wu2017,
author = {Songtao Wu and Shenghua Zhong and Yan Liu},
issn = {15737721},
journal = {Multimedia Tools and Applications},
archiveprefix = {arXiv},
pages = {1--17},
year = {2017},
isbn = {978-1-4673-6964-0},
eprint = {1512.03385},
title = {Deep residual learning for image Recognition},
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
pmid = {23554596},
arxivid = {1512.03385},
doi = {10.1007/s11042-017-4440-4},
keywords = {object detection},
mendeley-tags = {object detection},
}

@article{Jiang1999,
author = {J. Jiang},
doi = {10.1016/S0923-5965(98)00041-1},
abstract = {Apart from the existing technology on image compression represented by series of JPEG, MPEG and H.26x standards, new technology such as neural networks and genetic algorithms are being developed to explore the future of image coding. Successful applications of neural networks to vector quantization have now become well established, and other aspects of neural network involvement in this area are stepping up to play significant roles in assisting with those traditional technologies. This paper presents an extensive survey on the development of neural networks for image compression which covers three categories: direct image compression by neural networks; neural network implementation of existing techniques, and neural network based technology which provide improvement over traditional algorithms.},
issn = {09235965},
volume = {14},
title = {Image compression with neural networks - a survey},
pages = {737--760},
number = {9},
year = {1999},
isbn = {0923-5965},
journal = {Signal Processing: Image Communication},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Silver2016,
author = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and S Dieleman and  er and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
volume = {529},
number = {7587},
issn = {0028-0836},
doi = {10.1038/nature16961},
pages = {484--489},
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks' to evaluate board positions and ‘policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
archiveprefix = {arXiv},
eprint = {1610.00633},
publisher = {Nature Publishing Group},
journal = {Nature},
title = {Mastering the game of Go with deep neural networks and tree search},
isbn = {1476-4687 (Electronic)\r0028-0836 (Linking)},
pmid = {26819042},
url = {http://www.nature.com/doifinder/10.1038/nature16961},
year = {2016},
arxivid = {1610.00633},
keywords = {games},
mendeley-tags = {games},
}

@article{Hayashi2017,
author = {Yukio Hayashi},
volume = {6},
year = {2018},
title = {A new design principle of robust onion-like networks self-organized in growth},
eprint = {1706.03910},
journal = {Network Science},
arxivid = {1706.03910},
issn = {20501250},
doi = {10.1017/nws.2017.25},
archiveprefix = {arXiv},
abstract = {Today's economy, production activity, and our life are sustained by social and technological network infrastructures, while new threats of network attacks by destructing loops have been found recently in network science. We inversely take into account the weakness, and propose a new design principle for incrementally growing robust networks. The networks are self-organized by enhancing interwoven long loops. In particular, we consider the range-limited approximation of linking by intermediations in a few hops, and show the strong robustness in the growth without degrading efficiency of paths. Moreover, we demonstrate that the tolerance of connectivity is reformable even from extremely vulnerable real networks according to our proposed growing process with some investment. These results may indicate a prospective direction to the future growth of our network infrastructures.},
pages = {54--70},
url = {http://arxiv.org/abs/1706.03910},
number = {1},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{Hausknecht2017,
author = {Matthew Hausknecht and Wen Ke Li and Michael Mauk and Peter Stone},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
issn = {21622388},
abstract = {This paper describes the learning and control capabilities of a biologically constrained bottom-up model of the mammalian cerebellum. Results are presented from six tasks: 1) eyelid conditioning; 2) pendulum balancing; 3) proportional-integral-derivative control; 4) robot balancing; 5) pattern recognition; and 6) MNIST handwritten digit recognition. These tasks span several paradigms of machine learning, including supervised learning, reinforcement learning, control, and pattern recognition. Results over these six domains indicate that the cerebellar simulation is capable of robustly identifying static input patterns even when randomized across the sensory apparatus. This capability allows the simulated cerebellum to perform several different supervised learning and control tasks. On the other hand, both reinforcement learning and temporal pattern recognition prove problematic due to the delayed nature of error signals and the simulator's inability to solve the credit assignment problem. These results are consistent with previous findings which hypothesize that in the human brain, the basal ganglia is responsible for reinforcement learning, while the cerebellum handles supervised learning.},
pmid = {26829807},
volume = {28},
number = {3},
title = {Machine Learning Capabilities of a Simulated Cerebellum},
pages = {510--522},
isbn = {8750141007},
doi = {10.1109/TNNLS.2015.2512838},
year = {2017},
keywords = {health},
mendeley-tags = {health},
}

@article{Bennasar2015,
author = {Mohamed Bennasar and Yulia Hicks and Rossitza Setchi},
isbn = {0957-4174},
issn = {09574174},
title = {Feature selection using Joint Mutual Information Maximisation},
publisher = {Elsevier Ltd.},
doi = {10.1016/j.eswa.2015.07.007},
journal = {Expert Systems with Applications},
number = {22},
pages = {8520--8532},
abstract = {Feature selection is used in many application areas relevant to expert and intelligent systems, such as data mining and machine learning, image processing, anomaly detection, bioinformatics and natural language processing. Feature selection based on information theory is a popular approach due its computational efficiency, scalability in terms of the dataset dimensionality, and independence from the classifier. Common drawbacks of this approach are the lack of information about the interaction between the features and the classifier, and the selection of redundant and irrelevant features. The latter is due to the limitations of the employed goal functions leading to overestimation of the feature significance. To address this problem, this article introduces two new nonlinear feature selection methods, namely Joint Mutual Information Maximisation (JMIM) and Normalised Joint Mutual Information Maximisation (NJMIM); both these methods use mutual information and the 'maximum of the minimum' criterion, which alleviates the problem of overestimation of the feature significance as demonstrated both theoretically and experimentally. The proposed methods are compared using eleven publically available datasets with five competing methods. The results demonstrate that the JMIM method outperforms the other methods on most tested public datasets, reducing the relative average classification error by almost 6% in comparison to the next best performing method. The statistical significance of the results is confirmed by the ANOVA test. Moreover, this method produces the best trade-off between accuracy and stability.},
url = {http://dx.doi.org/10.1016/j.eswa.2015.07.007},
volume = {42},
year = {2015},
keywords = {other},
mendeley-tags = {other},
}

@article{Phumrattanaprapin2016,
author = {Khanittha;Punyaphol Horata Phumrattanaprapin},
year = {2016},
title = {Extended Hierarchical Extreme Learning Machine with Multilayer Perceptron},
number = {2},
pages = {196--204},
volume = {10},
keywords = {elm},
mendeley-tags = {elm},
}

@article{Huang2015,
author = {Guang Bin Huang},
abstract = {Abstract—The emergent machine learning technique - Ex- treme Learning Machines (ELMs) - has become a hot area of research over the past years, which is attributed to the growing research activities and significant contributions made by numerous researchers around the world. Recently, it has come to our attention that a number of misplaced notions and misunderstandings are being dissipated on the relationships between ELM and some earlier works. This paper wishes to clarify that i) ELM theories manage to address the open problem which has puzzled the neural networks, machine learning and neuroscience communities for 60 years: whether hidden nodes / neurons need to be tuned in learning, and proved that in contrast to the common knowledge and conventional neural network learning tenets, hidden nodes / neurons do not need to be iteratively tuned in wide types of neural networks and learning models (Fourier series, biological learning, etc). Unlike ELM theories, none of those earlier works provides theoretical foundations on feedforward neural networks with random hidden nodes; ii) ELM is proposed for both generalized single hidden layer feedfoward network and multi hidden layers feedforward networks; iii) Homogeneous architecture based ELM is proposed for feature learning, clustering, regression and (binary / multi- class) classification. iv) Compared to ELM, SVM and LS-SVM tend to provide suboptimal solutions, and SVM and LS-SVM do not consider feature representations in hidden layers of multi layers of networks either.},
issn = {18669964},
publisher = {Springer US},
doi = {10.1007/s12559-015-9333-0},
number = {3},
title = {What are Extreme Learning Machines? Filling the Gap Between Frank Rosenblatt's Dream and John von Neumann's Puzzle},
pages = {263--278},
volume = {7},
year = {2015},
isbn = {1866-9956},
journal = {Cognitive Computation},
keywords = {elm},
mendeley-tags = {elm},
}

@article{KenOHanlonandMarkD.PlumbleyQueenMaryUniversityofLondon2014,
author = {Ken O'Hanlon and Mark D. Plumbley},
abstract = {Non-negative Matrix Factorisation (NMF) is a popular tool in musical signal processing. However, problems using this methodology in the context of Automatic Music Transcription (AMT) have been noted resulting in the proposal of supervised and constrained variants of NMF for this purpose. Group sparsity has previously been seen to be effective for AMT when used with stepwise methods. In this paper group sparsity is introduced to supervised NMF decompositions and a dictionary tuning approach to AMT is proposed based upon group sparse NMF using the $\beta$-divergence. Experimental results are given showing improved AMT results over the state-of-the-art NMF-based AMT system. \textcopyright 2014 IEEE.},
number = {May},
doi = {10.1109/ICASSP.2014.6854173},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
year = {2014},
issn = {15206149},
title = {Polyphonic piano transcription using non-negative Matrix Factorisation with group sparsity},
volume = {1},
isbn = {9781479928927},
pages = {3112--3116},
keywords = {automatic music transcription,group sparsity,nonnegative matrix factorisation},
mendeley-tags = {automatic music transcription,group sparsity,nonnegative matrix factorisation},
}

@article{Leite2016,
author = {M L G Leite and P M Purcidonio and C Tarjano},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966709823&partnerID=40&md5=fb40f17143479a7221ff1b696cdfd846},
journal = {Espacios},
abstract = {The systematic innovation has been considered one of the most important practices in the business environment, increasingly uncertain and changeable. Understanding how changes they are occurring in society motivated by advances in information technology have impacted the innovation process, through the lens of startups. it is essential for the economic growth of a country, since most new products come these processes. The aim of this study is to develop a new model of development products in startups and small organizations seeking to develop physical products from innovations based on creativity.},
title = {The process of product development for startups based on creative innovation},
issn = {07981015 (ISSN)},
number = {7},
volume = {37},
year = {2016},
keywords = {innovation,product development,startups},
mendeley-tags = {innovation,product development,startups},
}

@article{Berthon2007,
author = {Pierre R. Berthon and Leyl Pitt and  F. and Ian McCarthy and Steven M. Kates},
issn = {00076813},
volume = {50},
number = {1},
journal = {Business Horizons},
abstract = {Creative consumers (defined as customers who adapt, modify, or transform a proprietary offering) represent an intriguing paradox for business. On one hand, they can signify a black hole for future revenue, with breach of copyright and intellectual property. On the other hand, they represent a gold mine of ideas and business opportunities. Central to business is the need to create and capture value, and creative consumers demand a shift in the mindsets and business models of how firms accomplish both. Based upon their attitude and action toward customer innovation, we develop a typology of firms' stances toward creative consumers. We then consider the implications of the stances model for corporate strategy and examine a three-step approach to dealing with creative consumers: awareness, analysis, and response. \textcopyright 2006 Kelley School of Business, Indiana University.},
month = {jan},
title = {When customers get clever: Managerial approaches to dealing with creative consumers},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007681306000796},
year = {2007},
pages = {39--47},
doi = {10.1016/j.bushor.2006.05.005},
keywords = {creative customers,diagnostics,firm stance,strategic response},
mendeley-tags = {creative customers,diagnostics,firm stance,strategic response},
}

@article{Index2013,
author = {Industrial Index},
year = {2013},
title = {Technology Is Wiping Out Companies Faster than Ever},
pages = {2013--2014},
}

@article{Estelles-Arolas2012,
author = {Enrique Estell\'es-Arolas and Fern Gonz\'alez-Ladr\'on-De-Guevara and  o},
volume = {38},
number = {2},
title = {Towards an integrated crowdsourcing definition},
doi = {10.1177/0165551512437638},
abstract = {'Crowdsourcing' is a relatively recent concept that encompasses many practices. This diversity leads to the blurring of the limits of crowdsourcing that may be identified virtually with any type of internet-based collaborative activity, such as co-creation or user innovation. Varying definitions of crowdsourcing exist, and therefore some authors present certain specific examples of crowdsourcing as paradigmatic, while others present the same examples as the opposite. In this article, existing definitions of crowdsourcing are analysed to extract common elements and to establish the basic characteristics of any crowdsourcing initiative. Based on these existing definitions, an exhaustive and consistent definition for crowdsourcing is presented and contrasted in 11 cases. \textcopyright The Author(s) 2012.},
year = {2012},
pages = {189--200},
issn = {01655515},
isbn = {0165551500000},
journal = {Journal of Information Science},
keywords = {crowdsourcing,definition,innovation},
mendeley-tags = {crowdsourcing,definition,innovation},
}

@article{Angell,
author = {Thomas Homer-Dixon},
volume = {40},
doi = {10.1109/MSPEC.2003.1197480},
issn = {00189235},
year = {2003},
journal = {IEEE Spectrum},
pages = {11--12},
title = {Winners and losers in the information age},
number = {5},
}

@article{Pisano2008,
author = {Gary P. Pisano and Roberto Verganti},
volume = {86},
year = {2008},
journal = {Harvard Business Review},
pages = {78--86},
abstract = {Nowadays, virtually no companies innovate alone. Firms team up with a variety of partners, in a wide number of ways, to create new technologies, products, and services. But what is the best way to leverage the power of outsiders? To help executives answer that question, Pisano, of Harvard Business School, and Verganti, of Politecnico di Milano, developed a simple framework focused on two questions: Given your strategy, how open or closed should your network of collaborators be? And who should decide which problems to tackle and which solutions to adopt? There are four basic modes of collaboration, say the authors. An elite circle is a closed network with a hierarchical governance: One company selects the participants, defines the problem, and chooses the solution. For instance, Alessi, an Italian home-products company, invited 200 outside experts in postmodern architecture to contribute ideas for new home-product designs. An innovation mall is hierarchical but open: Anyone can post a problem or propose solutions in it, but the company posting the problem chooses the solution. An example is lnnoCentive.com, an eBay-like site where companies post scientific challenges. An innovation community is open and decentralized: Anyone can propose problems, offer solutions, and decide which ideas to use - as happens in the Linux open-source software community. A consortium is a private group of participants that operate as equals and jointly select problems, decide how to conduct work, and choose solutions. IBM has set up a number of consortia with other companies to develop nextgeneration semiconductor technologies. No one approach is superior; each involves strategic trade-offs. When choosing among modes, firms must weigh their advantages and challenges, and assess which will work best with their strategy, capabilities, structure, and assets.},
issn = {00178012},
title = {Which kind of collaboration is right for you?},
number = {12},
url = {http://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=35387060&site=ehost-live%5Cnhttp://content.ebscohost.com/ContentServer.asp?T=P&P=AN&K=35387060&S=R&D=buh&EbscoContent=dGJyMMvl7ESep7Q4wtvhOLCmr0uep65Ssqu4TLGWxWXS&ContentCustomer=dGJyMPGotk%2Bxr},
doi = {10.1108/sd.2009.05625dad.001},
}

@article{Dodgson2006,
author = {Mark Dodgson and David Gann and Ammon Salter},
doi = {10.1111/j.1467-9310.2006.00429.x},
year = {2006},
journal = {R and D Management},
pages = {333--346},
number = {3},
abstract = {As with all new ideas, the concept of Open Innovation requires extensive empirical investigation, testing and development. This paper analyzes Procter and Gamble's 'Connect and Develop' strategy as a case study of the major organizational and technological changes associated with open innovation. It argues that although some of the organizational changes accompanying open innovation are beginning to be described in the literature, more analysis is warranted into the ways technological changes have facilitated open innovation strategies, particularly related to new product development. Information and communications technologies enable the exchange of distributed sources of information in the open innovation process. The case study shows that furthermore a suite of new technologies for data mining, simulation, prototyping and visual representation, what we call 'innovation technology', help to support open innovation in Procter and Gamble. The paper concludes with a suggested research agenda for furthering understanding of the role played by and consequences of this technology. \textcopyright 2006 Blackwell Publishing Ltd.},
volume = {36},
issn = {00336807},
title = {The role of technology in the shift towards open innovation: The case of Procter & Gamble},
}

@article{Piller2006,
author = {Frank T. Piller and Dominik Walcher},
volume = {36},
number = {3},
year = {2006},
issn = {00336807},
doi = {10.1111/j.1467-9310.2006.00432.x},
abstract = {Research has shown that many innovations originate not in the manufacturer but the user domain. Internet-based toolkits for idea competitions (TIC) are a novel way for manufacturers to access innovative ideas and solutions from users. Idea competitions build on the nature of competition as a means to encourage users to participate at an open innovation process, to inspire their creativity, and to increase the quality of the submissions. When the contest ends, submissions are evaluated by an expert panel. Users whose submissions score highest receive an award from the manufacturer, which is often granted in exchange for the right to exploit the solution in its domain. Following the idea of evolutionary prototyping, we developed a TIC in cooperation with a manufacturer of sports goods. The TIC was launched as a pilot in one of the company's markets. Submissions were evaluated using the consensual assessment technique. The evaluation of this study provides suggestions for further research, but also implications for managers willing to explore TIC in their organization. \textcopyright 2006 Blackwell Publishing Ltd.},
journal = {R and D Management},
pages = {307--318},
title = {Toolkits for idea competitions: A novel method to integrate users in new product development},
url = {http://doi.wiley.com/10.1111/j.1467-9310.2006.00432.x},
}

@article{Poetz2012,
author = {Marion K. Poetz and Martin Schreier},
year = {2012},
month = {mar},
issn = {07376782},
number = {2},
doi = {10.1111/j.1540-5885.2011.00893.x},
pages = {245--256},
abstract = {Generating ideas for new products used to be the exclusive domain of marketers, engineers, and/or designers. Users have only recently been recognized as an alternative source of new product ideas. Whereas some have attributed great potential to outsourcing idea generation to the "crowd" of users ("crowdsourcing"), others have clearly been more skeptical. The authors join this debate by presenting a real-world comparison of ideas actually generated by a firm's professionals with those generated by users in the course of an idea generation contest. Both professionals and users provided ideas to solve an effective and relevant problem in the consumer goods market for baby products. Executives from the underlying company evaluated all ideas (blind to their source) in terms of key quality dimensions including novelty, customer benefit, and feasibility. The study reveals that the crowdsourcing process generated user ideas that score significantly higher in terms of novelty and customer benefit, and somewhat lower in terms of feasibility. However, the average values for feasibility-in sharp contrast to novelty and customer benefit-tended to be relatively high overall, meaning that feasibility did not constitute a narrow bottleneck in this study. Even more interestingly, it is found that user ideas are placed more frequently than expected among the very best in terms of novelty and customer benefit. These findings, which are quite counterintuitive from the perspective of classic new product development (NPD) literature, suggest that, at least under certain conditions, crowdsourcing might constitute a promising method to gather user ideas that can complement those of a firm's professionals at the idea generation stage in NPD. \textcopyright 2012 Product Development & Management Association.},
title = {The value of crowdsourcing: Can users really compete with professionals in generating new product ideas?},
url = {http://doi.wiley.com/10.1111/j.1540-5885.2011.00893.x},
journal = {Journal of Product Innovation Management},
volume = {29},
}

@article{Alberts1997,
author = {David S Alberts and Daniel S Papp},
isbn = {1579060412},
journal = {CCRP Publication Series},
title = {The Information Age : An Anthology on Its Impact and Consequences Table of Contents},
year = {1997},
}

@book{Norman,
author = {Don Norman},
year = {2016},
abstract = {Even the smartest among us can feel inept as we fail to figure out which switch turns on which light or stove burner, or whether to push, pull, or slide a door. The fault lies in product designs that ignore the needs of users and the principles of cognitive psychology. A bestseller in the United States, this classic work on the cognitive aspects of design contains examples of both good and bad design and simple rules that designers can use to improve the usability of objects as diverse as cars, computers, doors, and telephones.-From publisher description.},
doi = {10.15358/9783800648108},
isbn = {9780465050659},
title = {The Design of Everyday Things},
booktitle = {The Design of Everyday Things},
}

@article{Lee-mortimer1994,
author = {Andrew Lee-Mortimer},
number = {2},
doi = {10.1108/09642369210054252},
issn = {13523074},
year = {1994},
title = {Strategic design},
abstract = {This article emphasises the importance of product development which can only be achieved through the application of appropriate designs. Thus, design is probably the single most powerful tool that can be used to position the company as 'world class' and motivate staff to excellence. The UK has excellent design skills, bit poor processes. As a result, companies do not translate skills into goods that people want to buy.},
journal = {World Class Design to Manufacture},
volume = {1},
pages = {31--34},
}

@article{Dewick2002a,
author = {Paul Dewick and Ken Green and Marcela Miozzo},
number = {3},
volume = {36},
year = {2004},
doi = {10.1016/S0016-3287(03)00157-5},
title = {Technological change, industry structure and the environment},
journal = {Futures},
pages = {267--293},
abstract = {This paper contributes towards the construction and application of a method to assess the long-term impact of the development of pervasive technologies on the environment. It seeks to integrate insights from studies of technology regarding long-term growth with questions of sustainability. Using a methodology based on long-wave theory and a sector classification based on technological characteristics, the likely effects of the three pervasive technologies (information technology, biotechnology and nanotechnology) on the input-output structure of selected sectors and on the levels of emissions of industrial greenhouse gases are considered. \textcopyright 2003 Elsevier Ltd. All rights reserved.},
issn = {00163287},
}

@article{Wang2011,
author = {Jin Wang and Haining Zhang and Guodong Lu and Zheng Liu},
month = {jan},
issn = {02683768},
volume = {54},
abstract = {With the development of computer-aided design (CAD) technology and increasing demands of customized footwear, shoe-lasts are requested to be designed rapidly so as to speed-up the process of footwear manufacturing. Thus, this study presents a CAD system for shoe-last rapid customized design based on the piecewise reconstruction to realize the interactive deformation and separate/global shoe-last form reuse. First, piecewise remodeling method is proposed based on the multi-layer parametric definition and contour curves are extracted from the mesh. Then, five types of proper constraints to support surface manipulation are proposed, and the draft-driven deformation by the contour curve bending can realize the interactive local surface design in free angle of view. Finally, shoe-last styles can be saved and reused globally or separately to share design results between different shoe-lasts. Experimental examples show that customized shoe-lasts can be easily and rapidly generated by adopting the parametric design methods. \textcopyright Springer-Verlag London Limited 2010.},
doi = {10.1007/s00170-010-3144-y},
journal = {International Journal of Advanced Manufacturing Technology},
number = {1-4},
title = {Rapid parametric design methods for shoe-last customization},
url = {http://link.springer.com/10.1007/s00170-010-3144-y},
year = {2011},
pages = {173--186},
keywords = {form reus,interactive deformation,parametric design,shoe-last},
mendeley-tags = {form reus,interactive deformation,parametric design,shoe-last},
}

@article{Schumpeter1994,
author = {Joseph A Schumpeter and Thomas Mccraw and Phillip Mirowski},
abstract = {Schumpeter began by proclaiming that histories of economics should confine themselves to economic analysis, which he defined as " the analytic or scientific aspects of economic thought" (1954: 1). Schumpeter then proceeded to ignore his own edict, for over 1000 small-print pages. Having preached analysis-only Schumpeter practiced more ecumenically, weaving together intellectual history, biography, and economic sociology. Indeed, Schumpeter spent most of his last decade writing the 800,000 words of the ferociously erudite History, and thereby failing to complete a long-planned work of economic analysis. Thomas McCraw's splendid new book brilliantly illuminates this Schumpeterian paradox, and the many others that made Schumpeter, as Phillip Mirowski put it, " a living, breathing contradiction " (1994: 5). Prophet of Innovation is not just a beautifully drawn portrait of Schumpeter's life and times, it is also a distinguished business historian's meditation on the two opposed cultures of political economy post-1870: history and theory. The Prophet of Innovation, among its other accomplishments, tells the story of how a great and productive intellect wrestled with the two-cultures problem in political economy. In the work of Schumpeter, McCraw finds the very personification of political economy's struggle between history and theory. Just as Schumpeter's work personifies the roles for history and theory in economics, so too does McCraw make Schumpeter's turbulent life and times a metaphor for Schumpeter's great subject, capitalism. Schumpeter was four when his father died. An exile, he moved his household 23 times in his lifetime, living in five different countries. His first marriage failed. Though brilliant and widely accomplished, Schumpeter had to reinvent himself many times. He failed as a lawyer, was dismissed as president of a private Vienna bank, and, as the new Austrian republic's finance minister, lasted a mere seven months. Most damaging of all, in 1926 Schumpeter's second wife Annie died in childbirth, and the child died as well. Schumpeter's beloved mother died in the same year, a three-fold emotional wounding from which Schumpeter, then 42, never fully recovered. Ahead still lay the Great Depression and another murderous war},
year = {1994},
title = {Thomas K . McCraw , Cambridge : Harvard University Press , 719 pages ,},
pages = {1--8},
}

@article{Sampler1998,
author = {Jeffrey L. Sampler},
abstract = {An account is given on what constitutes the real boundaries of competition for the new millennium, as well as the impact that it has on firms' competitive behavior. To analyze industry structure, the concepts of information separability and information specificity, are introduced. Propositions characterizing the nature of industry structure in information-intensive industries are also suggested.},
journal = {IEEE Engineering Management Review},
title = {Redefining industry structure for the information age},
publisher = {Wiley Online Library},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0266(199804)19:4%3C343::AID-SMJ975%3E3.0.CO;2-G/abstract},
issn = {03608581},
volume = {27},
number = {2},
year = {1999},
pages = {68--78},
keywords = {industry boundary,industry structure,information,information age,information separability},
mendeley-tags = {industry boundary,industry structure,information,information age,information separability},
}

@book{Zikmund2012,
author = {William G. Zikmund and Barry J. Babin and Jon Carr and Mitch Griffin},
booktitle = {IEEE Transactions on Information Theory},
pmid = {880153},
abstract = {This is an electronic version of the print textbook. Due to electronic rights restrictions, some third party content may be suppressed. Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. The publisher reserves the right to remove content from this title at any time if subsequent rights restrictions require it. For valuable information on pricing, previous editions, changes to current editions, and alternate formats, please visit www.cengage.com/highered to search by ISBN#, author, title, or keyword for materials in your areas of interest.},
volume = {58},
issn = {14683156},
isbn = {9781111221294},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6071007},
year = {2012},
title = {Licensed to : CengageBrain User Licensed to : CengageBrain User},
number = {3},
pages = {1743--1756},
}

@misc{,
title = {Leaps and bounds.pdf},
}

@article{Noble2011,
author = {Charles H. Noble},
number = {3},
doi = {10.1111/j.1540-5885.2011.00808.x},
abstract = {While the popular understanding of the influence of design is growing, academic research has largely been restricted to considering consumer-level responses to design elements. This paper reviews this past work and proposes a more strategic research agenda for the field, with the potential to explicate linkages between design elements and strategies and outcomes related to innovation and corporate performance. \textcopyright 2011 Product Development & Management Association.},
publisher = {Blackwell Publishing Inc},
url = {http://dx.doi.org/10.1111/j.1540-5885.2011.00808.x},
issn = {07376782},
title = {On elevating strategic design research},
volume = {28},
year = {2011},
pages = {389--393},
journal = {Journal of Product Innovation Management},
}

@article{,
year = {2000},
title = {Copyright \textcopyright2000. All Rights Reserved.},
}

@article{Arthur1875,
author = {By W Brian Arthur},
title = {Is the Information Revolution Dead ?},
year = {1875},
}

@article{Stilgoe2013,
author = {Jack Stilgoe and Richard Owen and Phil Macnaghten},
issn = {00487333},
title = {Developing a framework for responsible innovation},
doi = {10.1016/j.respol.2013.05.008},
pages = {1568--1580},
number = {9},
abstract = {The governance of emerging science and innovation is a major challenge for contemporary democracies. In this paper we present a framework for understanding and supporting efforts aimed at 'responsible innovation'. The framework was developed in part through work with one of the first major research projects in the controversial area of geoengineering, funded by the UK Research Councils. We describe this case study, and how this became a location to articulate and explore four integrated dimensions of responsible innovation: anticipation, reflexivity, inclusion and responsiveness. Although the framework for responsible innovation was designed for use by the UK Research Councils and the scientific communities they support, we argue that it has more general application and relevance. \textcopyright 2013 Elsevier B.V. All rights reserved.},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0048733313000930},
publisher = {Elsevier B.V.},
month = {nov},
volume = {42},
journal = {Research Policy},
year = {2013},
keywords = {emerging technologies,ethics,geoengineering,governance,responsible innovation},
mendeley-tags = {emerging technologies,ethics,geoengineering,governance,responsible innovation},
}

@misc{,
title = {Democratizing innovation.pdf},
}

@article{Scott1987,
author = {Mel Scott and Richard Bruce},
year = {1987},
doi = {10.1016/0024-6301(87)90071-9},
pages = {45--52},
volume = {20},
abstract = {As a small business develops it moves through five growth stages, each with its own distinctive characteristics. Because the transition from one stage to the next requires change, it will be accompanied by some crisis or another. Crises tend to be disruptive and the problems of change can be minimized if managers are proactive rather than reactive. Prior knowledge of what generates crises and what to expect in each stage will smooth the process of change. This article proposes a model of small business growth to enable managers of small businesses to plan for future growth. The model has been successfully tested and used by the authors in analysing and solving the problem of growing small businesses. The model isolates the five growth stages, the sort of things that will precipitate crises and the major strategies that should be considered at each stage. Its main purpose is as a diagnostic tool in analysing the firm's present position and in planning what will be required as it progresses to the next stage of its development. \textcopyright 1987.},
number = {3},
issn = {00246301},
journal = {Long Range Planning},
title = {Five stages of growth in small business},
}

@article{Ordanini2011,
author = {Andrea Ordanini and Lucia Miceli and Marta Pizzetti and A. Parasuraman},
doi = {10.1108/09564231111155079},
year = {2011},
issn = {17575818},
title = {Crowd-funding: Transforming customers into investors through innovative service platforms},
number = {4},
abstract = {Purpose – The purpose of this paper is to analyze the emerging crowd-funding phenomenon, that is a collective effort by consumers who network and pool their money together, usually via the internet, in order to invest in and support efforts initiated by other people or organizations. Successful service businesses that organize crowd-funding and act as intermediaries are emerging, attesting to the viability of this means of attracting investment. Design/methodology/approach – The research employs a "grounded theory" approach, performing an in-depth qualitative analysis of three cases involving crowd-funding initiatives: SellaBand in the music business, Trampoline in financial services, and Kapipal in non-profit services. These cases were selected to represent a diverse set of crowd-funding operations that vary in terms of risk/return for the investor and the type of payoff associated to the investment. Findings – The research addresses two research questions: how and why do consumers turn into crowd-funding participants? and how and why do service providers set up a crowd-funding initiative? Concerning the first research question, the authors' findings reveal purposes, characteristics, roles and tasks, and investment size of crowd-funding activity from the consumer's point of view. Regarding the second research question, the authors' analysis reveals purposes, service roles, and network effects of crowd-funding activity investigated from the point of view of the service organization that set up the initiative. Practical implications – The findings also have implications for service managers interested in launching and/or managing crowd-funding initiatives. Originality/value – The paper addresses an emerging phenomenon and contributes to service theory in terms of extending the consumer's role from co-production and co-creation to investment. \textcopyright 2011, Emerald Group Publishing Limited.},
journal = {Journal of Service Management},
pages = {443--470},
url = {http://www.emeraldinsight.com/10.1108/09564231111155079},
volume = {22},
keywords = {crowd-funding,customer-investors,customers,investments,service innovation},
mendeley-tags = {crowd-funding,customer-investors,customers,investments,service innovation},
}

@article{Bettis-Outland2012,
author = { Bettis-Outl and Harriette },
title = {Decision-making's impact on organizational learning and information overload},
abstract = {Although an abundance of academic literature positions organizational information processing as antecedent to decision making, little attention is paid to the possibility that decision making can be antecedent to certain elements of organizational information processing. Specifically, does the decision making process impact the type of organizational learning that takes place? Do different approaches to decision making alter the amount and variety of information made available to the organization, that is, the level of information overload? This paper examines incremental and comprehensive decision making to understand the effects of different decision making types on organizational learning and information overload. Incrementalism suggests that decision making should take place in small steps or increments. This approach analyzes only a few scenarios to make decisions resulting in few, if any, major organizational changes. However, comprehensive decision making requires the consideration of all possible scenarios and potential outcomes, resulting in a major overhaul of traditions and procedures within the organization. Consequently, each decision making approach has a different impact on organizational learning and information overload. \textcopyright 2011 Elsevier Inc.},
journal = {Journal of Business Research},
url = {http://www.sciencedirect.com/science/article/pii/S0148296310002845},
month = {jun},
number = {6},
volume = {65},
doi = {10.1016/j.jbusres.2010.12.021},
year = {2012},
issn = {01482963},
pages = {814--820},
publisher = {Elsevier Inc.},
keywords = {decision making,incrementalism,information overload,organizational learning},
mendeley-tags = {decision making,incrementalism,information overload,organizational learning},
}

@article{Brabham2008,
author = {Daren C. Brabham},
journal = {Convergence},
month = {feb},
pages = {75--90},
number = {1},
year = {2008},
url = {http://con.sagepub.com/cgi/doi/10.1177/1354856507084420},
volume = {14},
doi = {10.1177/1354856507084420},
issn = {13548565},
title = {Crowdsourcing as a model for problem solving: An introduction and cases},
isbn = {1354856507084},
abstract = {Crowdsourcing is an online, distributed problem-solving and production model that has emerged in recent years. Notable examples of the model include Threadless, iStockphoto, InnoCentive, the Goldcorp Challenge, and user-generated advertising contests. This article provides an introduction to crowdsourcing, both its theoretical grounding and exemplar cases, taking care to distinguish crowdsourcing from open source production. This article also explores the possibilities for the model, its potential to exploit a crowd of innovators, and its potential for use beyond forprofit sectors. Finally, this article proposes an agenda for research into crowdsourcing. Copyright \textcopyright 2008 Sage Publications.},
keywords = {collective intelligence,crowdsourcing,distributed problem solving,goldcorp challenge,innocentive,istockphoto,open source,threadless,wisdom of crowds},
mendeley-tags = {collective intelligence,crowdsourcing,distributed problem solving,goldcorp challenge,innocentive,istockphoto,open source,threadless,wisdom of crowds},
}

@article{Elliot2013,
author = {Esi Abbam Elliot and Cheryl Nakata},
month = {dec},
year = {2013},
pages = {110--125},
url = {http://doi.wiley.com/10.1111/jpim.12066},
journal = {Journal of Product Innovation Management},
doi = {10.1111/jpim.12066},
title = {Cross-cultural creativity: Conceptualization and propositions for global new product development},
number = {SUPPL 1},
abstract = {In today's global business environment, where multinational companies are pressed to increase revenues in order to survive, creativity may hold the key to ensuring their new product development (NPD) efforts lead to innovations with worldwide appeal, such as Apple's iPad and Gillette's Fusion Razor. To leverage creativity for effective global NPD, businesses want to know how cultures differ in their concepts of creativity and the impact of those differences on approaches to developing new products. Because global new products are increasingly developed in, by, and for multiple cultures, a particular need is for a culturally reflective understanding, or conceptualization, of creativity. While creativity is believed to be culturally tied, the dominant framework of creativity used in business and management assumes that creativity is culturally indifferent or insensitive. This knowledge gap is addressed by studying the role of creativity in NPD practices in a cross-cultural or global context. The study begins by first developing a culturally anchored conceptualization of creativity. Called cross-cultural creativity, the concept draws on creativity insights from the field of art and aesthetics. The concept specifies two modes of creativity, neither of which is superior to the other, called the spontaneous or S route and the divergent or D route. The S route emphasizes adaptiveness, processes, intuitiveness, and metamorphism, while the D route focuses on disruptiveness, results, rationality, and literalism. Next, this new concept is applied to NPD by positing how creativity in distinct cultures may shape NPD practices, as illustrated by Japanese and U.S. firms. Research propositions are formulated to capture these patterns, and thereafter, theoretical and practical implications of the framework and propositions are discussed. The implications center on global NPD, which is a complex enterprise involving typically more than one culture to design and develop new products for several geographic markets. The study is of interest to researchers needing a globally situated, culturally attached framework of creativity for international NPD studies, and managers seeking to exploit creativity in multinational and multicultural innovation projects. \textcopyright 2013 Product Development & Management Association.},
issn = {15405885},
volume = {30},
}

@article{Foster2012,
author = { Innosight},
year = {2012},
journal = {Innosight},
url = {http://www.innosight.com/innovation-resources/strategy-innovation/creative-destruction-whips-through-corporate-america.cfm},
title = {Creative Destruction Whips through Corporate America},
keywords = {bear stearns,kodak,radio shack},
mendeley-tags = {bear stearns,kodak,radio shack},
}

@misc{Alves1922,
author = {Alda Judith Alves},
abstract = {O artigo analisa o papel da revis\~ao da bibliografia em trabalhos de pesquisa e aponta as principais defici\^encias observadas em teses de mestrado e doutorado, no que se refere a esse aspecto. A primeira se\cc\~ao destaca a import\^ancia da an\'alise cr\'itica do estado atual do conhecimento na \'area de interesse do pesquisador para a problematiza\cc\~ao do tema a ser investigado. A segunda trata do referencial te\'orico e discute as dificuldades encontradas na constru\cc\~ao te\'orica no campo da educa\cc\~ao. Finalmente, a terceira se\cc\~ao apresenta os equ\'ivocos mais freq\"uentes observados em revis\~oes de bibliografia, utilizando o recurso da caricatura para tornar mais vis\'iveis certos tra\ccos.},
year = {1922},
number = {81},
pages = {53--60},
title = {A Revis\~ao da bibliografia em teses e disserta\cc\~oes},
booktitle = {Cadernos de Pesquisa},
keywords = {ensino superior,metodologia de pesquisa,p\'os-gradua\cc\~ao,revis\~ao de bibliografia},
mendeley-tags = {ensino superior,metodologia de pesquisa,p\'os-gradua\cc\~ao,revis\~ao de bibliografia},
}

@article{Sawhney2005,
author = {Mohanbir Sawhney and Gianmario Verona and  Pr and Emanuela elli},
abstract = {In the networked world, firms are recognizing the power of the Internet as a platform for co-creating value with customers. We focus on how the Internet has impacted the process of collaborative innovation - a key process in value co-creation. We outline the distinctive capabilities of the Internet as a platform for customer engagement, including interactivity, enhanced reach, persistence, speed, and flexibility, and suggest that firms can use these capabilities to engage customers in collaborative product innovation through a variety of Internet-based mechanisms. We discuss how these mechanisms can facilitate collaborative innovation at different stages of the New Product Development process (back end vs. front end stages) and for differing levels of customer involvement (high reach vs. high richness). We present two detailed exploratory case studies to illustrate the integrated and systematic usage of Internet-based collaborative innovation mechanisms - Ducati from the motorbike industry and Eli Lilly from the pharmaceutical industry. We derive implications for managerial practice and academic research on collaborative innovation. \textcopyright 2005 Wiley Periodicals, Inc. and Direct Marketing Educational Foundation, Inc.},
number = {4},
year = {2005},
month = {jan},
publisher = {Elsevier},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1094996805700785},
issn = {10949968},
doi = {10.1002/dir.20046},
journal = {Journal of Interactive Marketing},
volume = {19},
pages = {4--17},
title = {Collaborating to create: The internet as a platform for customer engagement in product innovation},
}

@article{Dewick2006,
author = {Paul Dewick and Ken Green and Toby Fleetwood and Marcela Miozzo},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0040162506000862},
year = {2006},
pages = {1084--1106},
abstract = {Future disruptive, pervasive technologies will have important consequences for industrial structure, economic growth and the environment. Drawing on theories of technological diffusion, industrial evolution and long-term technological change this paper explores the effect of the development and diffusion of two future pervasive technologies on five industrial sectors in three regions during the 21st century in terms of their effect on economic structural change. Through semi-structured interviews with over 100 experts in the two technologies, the paper quantifies the effects of future biotechnologies and nanotechnologies on the industrial structure of the EU, USA and China in 2020 and 2050. The paper finds that as a result of the development and diffusion of future biotechnologies and nanotechnologies, some industries grow whilst others decline and some new ones emerge. The evidence suggests that the effect is different across countries and time; whereas the experts commonly believe that effect of the technologies on the industrial structure of the EU and US is likely to be similar, the effect in China is considered to be less by 2020 but the same as in the EU and US by 2050. This finding has important implications for the location of production, economic growth and energy demand in the future. \textcopyright 2006 Elsevier Inc. All rights reserved.},
doi = {10.1016/j.techfore.2006.04.002},
month = {nov},
number = {9},
journal = {Technological Forecasting and Social Change},
volume = {73},
issn = {00401625},
title = {Modelling creative destruction: Technological diffusion and industrial structure change to 2050},
keywords = {biotechnologies,energy,industrial structure,nanotechnologies,technological diffusion},
mendeley-tags = {biotechnologies,energy,industrial structure,nanotechnologies,technological diffusion},
}

@article{Anderson2012,
author = {Simon P. Anderson and Andr\'e de Palma},
issn = {07416261},
abstract = {The Information Age has a surfeit of information received relative to what is processed. We model multiple sectors competing for consumer attention, with competition in price within each sector. Sector advertising levels follow a constant elasticity of substitution (CES) form, and within-sector prices are dispersed with a truncated Pareto distribution. The "information hump" shows highest ad levels for intermediate attention levels. Overall, advertising is excessive, although the allocation across sectors is optimal. The blame for information overload falls most on product categories with low information transmission costs and low profits. \textcopyright 2012, RAND.},
title = {Competition for attention in the Information (overload) Age},
url = {http://doi.wiley.com/10.1111/j.1756-2171.2011.00155.x},
volume = {43},
year = {2012},
doi = {10.1111/j.1756-2171.2011.00155.x},
journal = {RAND Journal of Economics},
number = {1},
pages = {1--25},
}

@book{Adler,
author = {Isabel K Adler},
isbn = {9788565424004},
title = {Design Thinking Design Thinking Inova\cc\~ao em neg\'ocios},
}

@article{Sampieri,
author = {Roberto Hern Sampieri and  ez},
title = {No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title},
isbn = {9783540773405},
pages = {634},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sampieri - Unknown - No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title(2).pdf\:pdf},
}

@article{Maeda,
author = {John Maeda},
title = {l aw s o f},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maeda - Unknown - l aw s o f.pdf\:pdf},
}

@book{,
title = {No Title},
isbn = {9780983648703},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title.pdf\:pdf},
}

@article{Ledford2013,
author = {B Y Heidi Ledford},
year = {2013},
title = {START-UP},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ledford - 2013 - START-UP.pdf\:pdf},
}

@book{Thea,
author = {Rossing The},
title = {No Title},
isbn = {0060189878},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The - Unknown - No Title.pdf\:pdf},
}

@article{Hutchins2013,
author = {Aaron Hutchins},
pages = {649206},
title = {Top of page},
year = {2013},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutchins - 2013 - Top of page.pdf\:pdf},
}

@article{1942,
author = {ＮＡＫＡＩ Ｔ},
title = {Ｎｏｔｕｌａ ａｄ ｐｌａｎｔａｓ Ａｓｉａ ＯｒｉｅｎｔａｌｉｓNo Title},
pages = {467},
year = {1942},
journal = {Botany},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 1942 - No Title.pdf\:pdf},
}

@article{Weinman2014,
author = {Camera Parts and Camera Shots and Shot Angles and Shot Movement and Light Sources and Tripod Motion},
pages = {1--7},
year = {2014},
number = {May 2012},
title = {Top of Page Top of Page},
volume = {7},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinman - 2014 - Top of page.pdf\:pdf},
}

@article{The,
author = {W. Brian Arthur},
pages = {65--72},
title = {Is the information revolution dead?.If history is a guide, it is not},
number = {March 2002},
journal = {Business},
year = {2002},
file = {\:C/\:/Users/tesse/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The - Unknown - DEAD.pdf\:pdf},
}

@article{Klein2016,
author = {Eve Klein},
abstract = {This article is concerned with the ways virtual instrument software simulates acoustic human performance. In particular, it examines two case studies-virtual orchestral instruments and virtual singing instruments-to consider how their design and implementation seek to express human music performance by adopting the micro and macro sonic variations of timing, pitch, dynamics, articulation, ambience, and other limitations imposed by the physical relationship between the player and the instrument. Baudrillard considers that "simulation threatens the difference between the 'true' and the 'false', the 'real' and the 'imaginary'" (1994: 3). By feigning the acoustic markers of expressive human musical performance, virtual instrument designers and composer-users encourage the listener to produce, in themselves, the experience of hearing an orchestra or singer. Users also contribute to the recontextualization of human performance by feeding back into the cultures and development cycles of virtual instrument software, where sonic gestures are recurrently refreshed. The construction of virtual instruments as devices of musical expressivity is, therefore, an evolving, mutually constructed, and performative endeavour.},
issn = {20793871},
journal = {IASPM Journal},
year = {2016},
title = {Feigning humanity: Virtual instruments, simulation and performativity},
doi = {10.5429/2079-3871(2016)v6i2.3en},
volume = {6},
number = {2},
pages = {22--48},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 Feigning Humanity Virtual Instruments, Simulation and Performativity - Klein.pdf\:pdf},
keywords = {musical expressivity,performativity,simulation,synthesizers,virtual instruments,virtual orchestras,vocaloid},
mendeley-tags = {musical expressivity,performativity,simulation,synthesizers,virtual instruments,virtual orchestras,vocaloid},
}

@article{Vamvakousis2016,
author = {Zacharias Vamvakousis and Rafael Ramirez},
number = {JUN},
volume = {7},
issn = {16641078},
journal = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2016.00906},
title = {The EyeHarp: A gaze-controlled digital musical instrument},
pages = {1--14},
abstract = {We present and evaluate the EyeHarp, a new gaze-controlled Digital Musical Instrument, which aims to enable people with severe motor disabilities to learn, perform, and compose music using only their gaze as control mechanism. It consists of (1) a step-sequencer layer, which serves for constructing chords/arpeggios, and (2) a melody layer, for playing melodies and changing the chords/arpeggios. We have conducted a pilot evaluation of the EyeHarp involving 39 participants with no disabilities from both a performer and an audience perspective. In the first case, eight people with normal vision and no motor disability participated in a music-playing session in which both quantitative and qualitative data were collected. In the second case 31 people qualitatively evaluated the EyeHarp in a concert setting consisting of two parts: a solo performance part, and an ensemble (EyeHarp, two guitars, and flute) performance part. The obtained results indicate that, similarly to traditional music instruments, the proposed digital musical instrument has a steep learning curve, and allows to produce expressive performances both from the performer and audience perspective.},
year = {2016},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 The EyeHarp A Gaze-Controlled Digital Musical Instrument - Vamvakousis and Ramirez.pdf\:pdf},
keywords = {accessible interfaces,digital musical instrument,disabilities,gaze interaction,music performance},
mendeley-tags = {accessible interfaces,digital musical instrument,disabilities,gaze interaction,music performance},
}

@article{Calegario2017,
author = {Filipe Calegario and  W and Marcelo M. erley and Stephane Huot and Giordano Cabral and Geber Ramalho},
title = {A Method and Toolkit for Digital Musical Instruments: Generating Ideas and Prototypes},
number = {1},
pages = {63--71},
doi = {10.1109/MMUL.2017.18},
abstract = {Digital musical instruments (DMIs) make up a class of devices in which gestural control and sound production are physically decoupled, but digitally mapped. This work discusses aspects of DMI design by focusing on the complexity of the design space and the importance of prototyping cycles. The authors' research questions cover how to provide an initial path for generating DMI ideas and how to reduce the time and effort required to build functional DMI prototypes. To address these questions, they propose a new methodology and an associated physical prototyping toolkit, which has building blocks inspired by of existing instruments. Preliminary tests with musicians and DMI designers revealed a strong potential for its use in the development of DMIs, and also uncovered limitations of the current toolkit. This article is part of a special issue on multimedia technologies for enriched music.},
issn = {1070986X},
journal = {IEEE Multimedia},
volume = {24},
year = {2017},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2017 A Method and Toolkit for Digital Musical Instruments Generating Ideas and Prototypes - Calegario et al..pdf\:pdf},
keywords = {design ideation toolkit,design of digital musical instruments,digital musical instrument,dmi,hackers,hardware,idea generation,morphological chart,multimedia,new interface for musical expression,nime,prototype,prototyping toolkit,visualization},
mendeley-tags = {design ideation toolkit,design of digital musical instruments,digital musical instrument,dmi,hackers,hardware,idea generation,morphological chart,multimedia,new interface for musical expression,nime,prototype,prototyping toolkit,visualization},
}

@book{2017SchmidEvaluating,
author = {Gian-Marco Schmid},
doi = {10.1007/978-3-658-18420-9},
year = {2017},
isbn = {978-3-658-18419-3 978-3-658-18420-9},
publisher = {Springer Fachmedien Wiesbaden},
booktitle = {Evaluating the Experiential Quality of Musical Instruments},
title = {Evaluating the Experiential Quality of Musical Instruments},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2017 Evaluating the Experiential Quality of Musical Instruments - Schmid.pdf\:pdf},
}

@article{Tahlroglu2020,
author = {Koray Tahlroǧlu and Thor Magnusson and Adam Parkinson and Iris Garrelfs and Atau Tanaka},
issn = {14698153},
title = {Digital Musical Instruments as Probes: How computation changes the mode-of-being of musical instruments},
volume = {25},
doi = {10.1017/S1355771819000475},
year = {2020},
abstract = {This article explores how computation opens up possibilities for new musical practices to emerge through technology design. Using the notion of the cultural probe as a lens, we consider the digital musical instrument as an experimental device that yields findings across the fields of music, sociology and acoustics. As part of an artistic-research methodology, the instrumental object as a probe is offered as a means for artists to answer questions that are often formulated outside semantic language. This article considers how computation plays an important role in the authors' personal performance practices in different ways, which reflect the changed mode-of-being of new musical instruments and our individual and collective relations with them.},
journal = {Organised Sound},
number = {1},
pages = {64--74},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2020 Digital Musical Instruments as Probes How computation changes the mode-of-being of musical instruments - Tahıroğlu et al..pdf\:pdf},
}

@book{Emerson2020,
author = {Gina Emerson and Hauke Egermann},
isbn = {0000000170147},
pages = {313--329},
issn = {10298649},
doi = {10.1177/1029864918802983},
number = {3},
year = {2020},
title = {Exploring the motivations for building new digital musical instruments},
volume = {24},
abstract = {Over the past four decades, the number, diversity and complexity of digital musical instruments (DMIs) has increased rapidly. There are very few constraints on DMI design as such systems can be easily reconfigured, offering near limitless flexibility for music-making. Given that new acoustic musical instruments have in many cases been created in response to the limitations of available technologies, what motivates the development of new DMIs? We conducted an interview study with ten designers of new DMIs, in order to explore (a) the motivations electronic musicians may have for wanting to build their own instruments; and (b) the extent to which these motivations relate to the context in which the artist works and performs (academic vs club settings). We found that four categories of motivation were mentioned most often: M1 – wanting to bring greater embodiment to the activity of performing and producing electronic music; M2 – wanting to improve audience experiences of DMI performances; M3 – wanting to develop new sounds, and M4 – wanting to build responsive systems for improvisation. There were also some detectable trends in motivation according to the context in which the artists work and perform. Our results offer the first systematically gathered insights into the motivations for new DMI design. It appears that the challenges of controlling digital sound synthesis drive the development of new DMIs, rather than the shortcomings of any one particular design or existing technology.},
booktitle = {Musicae Scientiae},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2020 Exploring the motivations for building new digital musical instruments - Emerson and Egermann.pdf\:pdf},
keywords = {digital musical instruments,embodiment,expressivity,motivation},
mendeley-tags = {digital musical instruments,embodiment,expressivity,motivation},
}

@article{2015YoungHci,
author = {Gareth W. Young and Dave Murphy},
doi = {10.13140/rg.2.1.3949.9364},
shorttitle = {HCI Models for Digital Musical Instruments},
year = {2020},
journal = {arXiv},
abstract = {Here we present an analysis of literature relating to the evaluation methodologies of Digital Musical Instruments (DMIs) derived from the field of Human Computer Interaction (HCI). We then apply choice aspects from these existing evaluation models and apply them to an optimized evaluation for assessing new DMIs.},
issn = {23318422},
title = {HCI models for digital musical instruments: Methodologies for rigorous testing of digital musical instruments},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/HCI Models for Digital Musical Instruments Methodologies for Rigorous Testing of Digital Musical Instruments - Young and Murphy.pdf\:pdf},
keywords = {digital musical instrument,evaluation techniques,human computer interaction},
mendeley-tags = {digital musical instrument,evaluation techniques,human computer interaction},
}

@article{Mehes2017,
author = {S Mehes and  or and Maarten van Walstijn and Paul Stapleton},
pages = {399--403},
abstract = {Exploration is an intrinsic element of designing and engaging with acoustic as well as digital musical instruments. This paper reports on the ongoing development of a virtual-acoustic instrument based on a physical model of a string coupled nonlinearly to a plate. The performer drives the model by tactile interaction with a string-board controller fitted with piezo-electric sensors. The string-plate model is formulated in a way that prioritises its parametric explorability. Where the roles of creating performance gestures and designing instruments are traditionally separated, such a design provides a continuum across these domains. The string-plate model, its real-time implementation, and the control interface are described, and the system is preliminarily evaluated through informal observations of how musicians engage with the system.},
year = {2017},
url = {http://www.nime.org/proceedings/2017/nime2017_paper0075.pdf},
title = {Virtual-Acoustic Instrument Design: Exploring the Parameter Space of a String-Plate Model},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/Virtual-Acoustic Instrument Design Exploring the Parameter Space of a String-Plate Model - Mehes et al..pdf\:pdf},
}

@article{Valimaki1996,
author = {Vesa Valimaki and Tapio Takala},
number = {2},
issn = {14698153},
pages = {75},
doi = {10.1017/S1355771896000039},
abstract = {Physical modelling of musical instruments is an exciting new paradigm in digital sound synthesis. The basic idea is to imitate the sound production mechanism of an acoustic musical instrument using a computer program. The sound produced by such a model will automatically resemble that of the real instrument, if the model has been devised in a proper way. In this article we review the history and present techniques of physical modelling. It appears that the many seemingly very different modelling methods try to achieve the same result: to simulate the solutions of the wave equation in a simplified manner. We concentrate on the digital waveguide modelling technique which has gained much popularity among both researchers and engineers in the music technology industry. The benefits and drawbacks of the new technology are considered, and concurrent research topics are discussed. The physical modelling approach offers many new applications, especially in the fields of multimedia and virtual reality. \textcopyright 1996, Cambridge University Press. All rights reserved.},
year = {1996},
isbn = {1355771896000},
journal = {Organised Sound},
title = {Virtual musical instruments - natural sound using physical models},
volume = {1},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/1996 Virtual musical instruments — natural sound using physical models - V/"alim/"aki and Takala.pdf\:pdf},
}

@article{OModhrain2011,
author = {Sile O'Modhrain},
issn = {01489267},
volume = {35},
doi = {10.1162/COMJ_a_00038},
number = {1},
pages = {28--42},
title = {A framework for the evaluation of digital musical instruments},
journal = {Computer Music Journal},
year = {2011},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2011 A Framework for the Evaluation of Digital Musical Instruments - O'Modhrain.pdf\:pdf},
}

@article{Zoran2011,
author = {Amit Zoran},
title = {The 3D Printed Flute: Digital Fabrication and Design of Musical Instruments},
number = {4},
pages = {379--387},
abstract = {This paper considers the controversy of modern acoustic instruments, which may have come to an evolutionary impasse, due to its high standardization that makes it difficult to explore design modifications. A new approach for the design and fabrication of an acoustic instrument is presented, using digital fabrication technologies, and specifically 3D printing, which has the potential to influence new designs, and to lead to new acoustics and ergonomic innovations. This paper describes the key concepts of this approach, presenting the development process of such a 3D printed instrument-a prototype ofa 3D printed concert flute, some other 3D printed elements, and a conceptual example of an innovative trumpet-discussing the potential of the new technology in fabricating and designing of musical instruments. \textcopyright 2011 Copyright Taylor and Francis Group, LLC.},
doi = {10.1080/09298215.2011.621541},
issn = {09298215},
year = {2011},
journal = {Journal of New Music Research},
volume = {40},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2011 The 3D Printed Flute Digital Fabrication and Design of Musical Instruments - Zoran.pdf\:pdf},
}

@article{Hewitt2006,
author = {Kevin C Hewitt and Michael Paesler},
title = {I Nstrument D Esign and T Echniques},
pages = {1--6},
year = {2006},
journal = {Physics},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2014 BLURRING THE LINES AN INTEGRATED COMPOSITIONAL MODEL FOR DIGITAL MUSIC INSTRUMENT DESIGN - Dalgleish et al..pdf\:pdf},
}

@article{Medeiros2014,
author = {Rodrigo Medeiros and Filipe Calegario and Giordano Cabral and Geber Ramalho},
pages = {643--652},
year = {2014},
abstract = {The new interfaces are changing the way we interact with computers. In the musical context, those new technologies open a wide range of possibilities in the creation of New Interfaces for Musical Expression (NIME). Despite 10 years of research in NIME, it is hard to find artifacts that have been widely or convincingly adopted by musicians. In this paper, we discuss some NIME design challenges, highlighting particularities related to the digital and musical nature of these artifacts, such as virtuosity, cultural elements, context of use, creation catalysis, success criteria, adoption strategy, etc. With these challenges, we aim to call attention for the intersection of music, computing and design, which can be an interesting area for people working on product design and interaction design.},
journal = {International Conference of Design, User Experience, and Usability},
title = {Challenges in Designing New Interfaces},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2014 Challenges in Designing New Interfaces for Musical Expression - Medeiros et al..pdf\:pdf},
keywords = {design challenges,digital musical instrument,interaction design,musical expression,new interfaces for,user experience},
mendeley-tags = {design challenges,digital musical instrument,interaction design,musical expression,new interfaces for,user experience},
}

@inproceedings{2016JackEffect,
author = {Robert H. Jack and Tony Stockman and Andrew McPherson},
booktitle = {ACM International Conference Proceeding Series},
publisher = {ACM Press},
year = {2016},
volume = {04-06-October-2016},
abstract = {When designing digital musical instruments the importance of low and consistent action-to-sound latency is widely accepted. This paper investigates the effects of latency (0-20ms) on instrument quality evaluation and performer interaction. We present findings from an experiment conducted with musicians who performed on an percussive digital musical instrument with variable amounts of latency. Three latency conditions were tested against a zero latency condition, 10ms, 20ms and 10ms ± 3ms jitter. The zero latency condition was significantly rated more positively than the 10ms with jitter and 20ms latency conditions in six quality measures, emphasising the importance of not only low, but stable latency in digital musical instruments. There was no significant difference in rating between the zero latency condition and 10ms condition. A quantitative analysis of timing accuracy in a metronome task under latency conditions showed no significant difference in mean synchronisation error. This suggests that the 20ms and 10ms with jitter latency conditions degrade subjective impressions of an instrument, but without significantly affecting the timing performance of our participants. These findings are discussed in terms of control intimacy and instrument transparency.},
title = {Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument},
doi = {10.1145/2986416.2986428},
url = {http://dl.acm.org/citation.cfm?doid=2986416.2986428},
pages = {116--123},
isbn = {9781450348225},
file = {\:C/\:/Users/tesse/Desktop/Files/Dropbox/BIBrep/Articles/DMI/2016 Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument - Jack et al..pdf\:pdf},
keywords = {control intimacy,digital musical instruments,effort,interaction,latency,multisensory feedback,perceived quality},
mendeley-tags = {control intimacy,digital musical instruments,effort,interaction,latency,multisensory feedback,perceived quality},
}

@inproceedings{hanson1989comparing,
author = {Stephen Jos\'e Hanson and Lorien Y Pratt},
year = {1989},
booktitle = {Advances in neural information processing systems},
pages = {177--185},
title = {Comparing biases for minimal network construction with back-propagation},
__markedentry = {[tesse:1]},
}

@inproceedings{mozer1989skeletonization,
author = {Michael C Mozer and Paul Smolensky},
booktitle = {Advances in neural information processing systems},
pages = {107--115},
__markedentry = {[tesse:1]},
title = {Skeletonization: A technique for trimming the fat from a network via relevance assessment},
year = {1989},
}

@inproceedings{lecun1990optimal,
author = {Yann LeCun and John S Denker and Sara A Solla},
pages = {598--605},
booktitle = {Advances in neural information processing systems},
year = {1990},
__markedentry = {[tesse:1]},
title = {Optimal brain damage},
}

@article{reed1993pruning,
author = {Russell Reed},
__markedentry = {[tesse:1]},
title = {Pruning algorithms-a survey},
year = {1993},
volume = {4},
publisher = {IEEE},
pages = {740--747},
journal = {IEEE transactions on Neural Networks},
number = {5},
}

@inproceedings{blum1989training,
author = {Avrim Blum and Ronald L Rivest},
booktitle = {Advances in neural information processing systems},
pages = {494--501},
title = {Training a 3-node neural network is NP-complete},
year = {1989},
}

@inproceedings{livni2014computational,
author = {Roi Livni and Shai Shalev-Shwartz and Ohad Shamir},
year = {2014},
booktitle = {Advances in neural information processing systems},
title = {On the computational efficiency of training neural networks},
pages = {855--863},
}

@article{2018SilverGeneral,
author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
year = {2018},
pages = {1140--1144},
doi = {10.1126/science.aar6404},
title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
journal = {Science},
publisher = {American Association for the Advancement of Science (AAAS)},
volume = {362},
number = {6419},
month = {dec},
}

@inproceedings{2018TobingEvaluation,
author = {Patrick Lumban Tobing and Tomoki Hayashi and Yi-Chiao Wu and Kazuhiro Kobayashi and Tomoki Toda},
month = {dec},
booktitle = {2018 IEEE Spoken Language Technology Workshop (SLT)},
doi = {10.1109/slt.2018.8639608},
publisher = {IEEE},
year = {2018},
title = {An Evaluation of Deep Spectral Mappings and WaveNet Vocoder for Voice Conversion},
}

@article{Yadav2007a,
author = {R. N. Yadav and P. K. Kalra and J. John},
journal = {Applied Soft Computing Journal},
title = {Time series prediction with single multiplicative neuron model},
volume = {7},
number = {4},
issn = {15684946},
pages = {1157--1163},
abstract = {Single neuron models are typical functional replica of the biological neuron that are derived using their individual and group responses in networks. In recent past, a lot of work in this area has produced advanced neuron models for both analog and binary data patterns. Popular among these are the higher-order neurons, fuzzy neurons and other polynomial neurons. In this paper, we propose a new neuron model based on a polynomial architecture. Instead of considering all the higher-order terms, a simple aggregation function is used. The aggregation function is considered as a product of linear functions in different dimensions of the space. The functional mapping capability of the proposed neuron model is demonstrated through some well known time series prediction problems and is compared with the standard multilayer neural network. \textcopyright 2006 Elsevier B.V. All rights reserved.},
year = {2007},
doi = {10.1016/j.asoc.2006.01.003},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Wang2016b,
author = {Jie Wang and Jun Wang and Wen Fang and Hongli Niu},
doi = {10.1155/2016/4742515},
issn = {16875273},
journal = {Computational Intelligence and Neuroscience},
pmid = {27293423},
year = {2016},
title = {Financial Time Series Prediction Using Elman Recurrent Random Neural Networks},
abstract = {In recent years, financial market dynamics forecasting has been a focus of economic research. To predict the price indices of stock markets, we developed an architecture which combined Elman recurrent neural networks with stochastic time effective function. By analyzing the proposed model with the linear regression, complexity invariant distance (CID), and multiscale CID (MCID) analysis methods and taking the model compared with different models such as the backpropagation neural network (BPNN), the stochastic time effective neural network (STNN), and the Elman recurrent neural network (ERNN), the empirical results show that the proposed neural network displays the best performance among these neural networks in financial time series forecasting. Further, the empirical research is performed in testing the predictive effects of SSE, TWSE, KOSPI, and Nikkei225 with the established model, and the corresponding statistical comparisons of the above market indices are also exhibited. The experimental results show that this approach gives good performance in predicting the values from the stock market indices.},
volume = {2016},
isbn = {1687-5265},
}

@article{Ritchie2003,
author = {Marylyn D. Ritchie and Bill C. White and Joel S. Parker and Lance W. Hahn and Jason H. Moore},
year = {2003},
abstract = {Background: Appropriate definition of neural network architecture prior to data analysis is crucial for successful data mining. This can be challenging when the underlying model of the data is unknown. The goal of this study was to determine whether optimizing neural network architecture using genetic programming as a machine learning strategy would improve the ability of neural networks to model and detect nonlinear interactions among genes in studies of common human diseases. Results: Using simulated data, we show that a genetic programming optimized neural network approach is able to model gene-gene interactions as well as a traditional back propagation neural network. Furthermore, the genetic programming optimized neural network is better than the traditional back propagation neural network approach in terms of predictive ability and power to detect gene-gene interactions when non-functional polymorphisms are present. Conclusion: This study suggests that a machine learning strategy for optimizing neural network architecture may be preferable to traditional trial-and-error approaches for the identification and characterization of gene-gene interactions in common, complex human diseases. \textcopyright 2003 Ritchie et al; licensee BioMed Central Ltd.},
issn = {14712105},
title = {Optimization of neural network architecture using genetic programming improves detection and modelling of gene-gene interactions in studies of human diseases},
pmid = {12846935},
pages = {28},
isbn = {1471-2105 (Electronic)\r1471-2105 (Linking)},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12846935},
doi = {10.1186/1471-2105-4-28},
volume = {4},
journal = {BMC Bioinformatics},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@article{ludermir2006optimization,
author = {Teresa B. Ludermir and Akio Yamazaki and Cleber Zanchettin},
issn = {10459227},
pages = {1452--1459},
pmid = {17131660},
doi = {10.1109/TNN.2006.881047},
number = {6},
journal = {IEEE Transactions on Neural Networks},
abstract = {This paper introduces a methodology for neural network global optimization. The aim is the simultaneous optimization of multilayer perceptron (MLP) network weights and architectures, in order to generate topologies with few connections and high classification performance for any data sets. The approach combines the advantages of simulated annealing, tabu search and the backpropagation training algorithm in order to generate an automatic process for producing networks with high classification performance and low complexity. Experimental results obtained with four classification problems and one prediction problem has shown to be better than those obtained by the most commonly used optimization techniques. \textcopyright 2006 IEEE.},
publisher = {IEEE},
year = {2006},
title = {An optimization methodology for neural network weights and architectures},
volume = {17},
keywords = {multilayer perceptron (mlp,optimization of weights and architectures,simulating annealing,tabu search},
mendeley-tags = {multilayer perceptron (mlp,optimization of weights and architectures,simulating annealing,tabu search},
}

@article{rt17,
author = {Sebastian Risi and Julian Togelius},
abstract = {This paper surveys research on applying neuroevolution (NE) to games. In neuroevolution, artificial neural networks are trained through evolutionary algorithms, taking inspiration from the way biological brains evolved. We analyse the application of NE in games along five different axes, which are the role NE is chosen to play in a game, the different types of neural networks used, the way these networks are evolved, how the fitness is determined and what type of input the network receives. The article also highlights important open research challenges in the field.},
archiveprefix = {arXiv},
eprint = {1410.7326},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
volume = {PP},
arxivid = {1410.7326},
doi = {10.1109/TCIAIG.2015.2494596},
issn = {1943068X},
title = {Neuroevolution in games: State of the art and open challenges},
year = {2015},
number = {99},
}

@article{Jing,
author = {Yongcheng Jing and Yezhou Yang and Zunlei Feng and Jingwen Ye and Yizhou Yu and Mingli Song},
doi = {10.1109/TVCG.2019.2921336},
arxivid = {1705.04058},
number = {11},
title = {Neural Style Transfer: A Review},
eprint = {1705.04058},
pmid = {31180860},
pages = {3365--3385},
abstract = {The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then, NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper, we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then, we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future research. A list of papers discussed in this review, corresponding codes, pre-trained models and more comparison results are publicly available at: https://osf.io/f8tu4/.},
volume = {26},
year = {2020},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
archiveprefix = {arXiv},
keywords = {convolutional neural network (cnn,neural style transfer (nst},
mendeley-tags = {convolutional neural network (cnn,neural style transfer (nst},
}

@article{Bell2015,
author = {Sean Bell and C. Lawrence Zitnick and Kavita Bala and Ross Girshick},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
issn = {10636919},
pages = {2874--2883},
isbn = {9781467388504},
pmid = {21803542},
archiveprefix = {arXiv},
url = {http://arxiv.org/abs/1512.04143},
volume = {2016-December},
eprint = {1512.04143},
abstract = {It is well known that contextual and multi-scale representations are important for accurate visual recognition. In this paper we present the Inside-Outside Net (ION), an object detector that exploits information both inside and outside the region of interest. Contextual information outside the region of interest is integrated using spatial recurrent neural networks. Inside, we use skip pooling to extract information at multiple scales and levels of abstraction. Through extensive experiments we evaluate the design space and provide readers with an overview of what tricks of the trade are important. ION improves state-of-the-art on PASCAL VOC 2012 object detection from 73.9% to 77.9% mAP. On the new and more challenging MS COCO dataset, we improve state-of-the-art from 19.7% to 33.1% mAP. In the 2015 MS COCO Detection Challenge, our ION model won 'Best Student Entry' and finished 3rd place overall. As intuition suggests, our detection results provide strong evidence that context and multi-scale representations improve small object detection.},
doi = {10.1109/CVPR.2016.314},
arxivid = {1512.04143},
year = {2016},
title = {Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks},
keywords = {object detection},
mendeley-tags = {object detection},
}

@article{Kim2014,
author = {Yoon Kim},
abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
issn = {10709908},
pages = {1746--1751},
eprint = {1408.5882},
title = {Convolutional neural networks for sentence classification},
year = {2014},
doi = {10.3115/v1/d14-1181},
isbn = {9781937284961},
arxivid = {1408.5882},
pmid = {10463930},
archiveprefix = {arXiv},
journal = {EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
url = {http://arxiv.org/abs/1408.5882},
keywords = {sentence classification,sentiment analysis},
mendeley-tags = {sentence classification,sentiment analysis},
}

@article{Xu2017,
author = {Lamei Xu and Jin Lin and Lina Wang and Chunyong Yin and Jin Wang},
pages = {199--204},
doi = {10.14257/astl.2017.143.41},
number = {Ast},
title = {Deep Convolutional Neural Network based Approach for Aspect-based Sentiment Analysis},
journal = {Advanced Science and Technology Letters},
volume = {143},
year = {2017},
abstract = {Sentiment analysis is an important task in natural language process-ing and has a wide range of applications. This paper describes our deep learning approach to multilingual aspect-based sentiment analysis. Our model use a deep convolutional neural network for both aspect extraction and aspect-based sentiment analysis. We take aspect extraction as a multi-label classification pro-blem, outputting probabilities over aspects parameterized by a threshold. For the sentiment towards an aspect, we concatenate an aspect vector with every word embedding and apply a convolution over it. Experiments result shows that our system performs comparably well on the Yelp reviews.},
keywords = {sentiment analysis},
mendeley-tags = {sentiment analysis},
}

@article{Theis2017,
author = {Lucas Theis and Wenzhe Shi and Andrew Cunningham and Ferenc Husz\'ar},
eprint = {1703.00395},
year = {2017},
pages = {1--19},
title = {Lossy image compression with compressive autoencoders},
arxivid = {1703.00395},
archiveprefix = {arXiv},
url = {http://arxiv.org/abs/1703.00395},
abstract = {We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.},
journal = {arXiv},
issn = {23318422},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Southall2016a,
author = {Carl Southall and Ryan Stables and Jason Hockman},
year = {2016},
title = {Automatic drum transcription using bi-directional recurrent neural networks},
journal = {Proceedings of the 17th International Society for Music Information Retrieval Conference, ISMIR 2016},
pages = {591--597},
isbn = {9780692755068},
abstract = {Automatic drum transcription (ADT) systems attempt to generate a symbolic music notation for percussive instruments in audio recordings. Neural networks have already been shown to perform well in fields related to ADT such as source separation and onset detection due to their utilisation of time-series data in classification. We propose the use of neural networks for ADT in order to exploit their ability to capture a complex configuration of features associated with individual or combined drum classes. In this paper we present a bi-directional recurrent neural network for offline detection of percussive onsets from specified drum classes and a recurrent neural network suitable for online operation. In both systems, a separate network is trained to identify onsets for each drum class under observation—that is, kick drum, snare drum, hi-hats, and combinations thereof. We perform four evaluations utilising the IDMT-SMT-Drums and ENST minus one datasets, which cover solo percussion and polyphonic audio respectively. The results demonstrate the effectiveness of the presented methods for solo percussion and a capacity for identifying snare drums, which are historically the most difficult drum class to detect.},
keywords = {music transcription,tesis},
mendeley-tags = {music transcription,tesis},
}

@article{Zhao2016,
author = {Xiangyun Zhao and Xiaodan Liang and Luoqi Liu and Teng Li and Yugang Han and Nuno Vasconcelos and Shuicheng Yan},
doi = {10.1007/978-3-319-46475-6_27},
year = {2016},
pmid = {4520227},
eprint = {1607.06997},
archiveprefix = {arXiv},
isbn = {9783319464749},
issn = {16113349},
pages = {425--442},
title = {Peak-piloted deep network for facial expression recognition},
abstract = {Objective functions for training of deep networks for facerelated recognition tasks, such as facial expression recognition (FER), usually consider each sample independently. In this work, we present a novel peak-piloted deep network (PPDN) that uses a sample with peak expression (easy sample) to supervise the intermediate feature responses for a sample of non-peak expression (hard sample) of the same type and from the same subject. The expression evolving process from non-peak expression to peak expression can thus be implicitly embedded in the network to achieve the invariance to expression intensities. A special-purpose backpropagation procedure, peak gradient suppression (PGS), is proposed for network training. It drives the intermediate-layer feature responses of nonpeak expression samples towards those of the corresponding peak expression samples, while avoiding the inverse.This avoids degrading the recognition capability for samples of peak expression due to interference from their non-peak expression counterparts. Extensive comparisons on two popular FER datasets, Oulu-CASIA and CK+, demonstrate the superiority of the PPDN over state-of-the-art FER methods, as well as the advantages of both the network structure and the optimization strategy. Moreover, it is shown that PPDN is a general architecture, extensible to other tasks by proper definition of peak and non-peak samples. This is validated by experiments that show state-of-the-art performance on pose-invariant face recognition, using the Multi-PIE dataset.},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
institution = {Springer},
volume = {9906 LNCS},
url = {http://arxiv.org/abs/1607.06997},
arxivid = {1607.06997},
keywords = {facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
}

@article{Xu2015,
author = {Wenduan Xu and Michael Auli and Stephen Clark},
doi = {10.3115/v1/p15-2041},
title = {CCG supertagging with a recurrent neural network},
url = {https://doi.org/10.3115/v1/p15-2041},
journal = {ACL-IJCNLP 2015 - 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Proceedings of the Conference},
year = {2015},
isbn = {9781941643730},
volume = {2},
abstract = {Recent work on supertagging using a feed-forward neural network achieved signifi-cant improvements for CCG supertagging and parsing (Lewis and Steedman, 2014). However, their architecture is limited to considering local contexts and does not naturally model sequences of arbitrary length. In this paper, we show how di-rectly capturing sequence information us-ing a recurrent neural network leads to fur-ther accuracy improvements for both su-pertagging (up to 1.9%) and parsing (up to 1% FI), on CCGBank, Wikipedia and biomedical text.},
number = {2014},
pages = {250--255},
publisher = {Association for Computational Linguistics},
keywords = {sentence classification},
mendeley-tags = {sentence classification},
}

@article{Deng2013,
author = {Li Deng and Geoffrey Hinton and Brian Kingsbury},
pmid = {23127789},
issn = {15206149},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6639344},
arxivid = {arXiv:1303.5778v1},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
title = {New types of deep neural network learning for speech recognition and related applications: An overview},
archiveprefix = {arXiv},
abstract = {In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled 'New Types of Deep Neural Network Learning for Speech Recognition and Related Applications,' as organized by the authors. We also describe the historical context in which acoustic models based on deep neural networks have been developed. The technical overview of the papers presented in our special session is organized into five ways of improving deep learning methods: (1) better optimization; (2) better types of neural activation function and better network architectures; (3) better ways to determine the myriad hyper-parameters of deep neural networks; (4) more appropriate ways to preprocess speech for deep neural networks; and (5) ways of leveraging multiple languages or dialects that are more easily achieved with deep neural networks than with Gaussian mixture models. \textcopyright 2013 IEEE.},
doi = {10.1109/ICASSP.2013.6639344},
institution = {IEEE},
eprint = {arXiv:1303.5778v1},
isbn = {9781479903566},
year = {2013},
pages = {8599--8603},
keywords = {review,speech recognition},
mendeley-tags = {review,speech recognition},
}

@article{Zhang2016b,
author = {Yu Zhang and William Chan and Navdeep Jaitly},
year = {2017},
pages = {4845--4849},
url = {http://arxiv.org/abs/1610.03022},
title = {Very deep convolutional networks for end-to-end speech recognition},
eprint = {1610.03022},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
archiveprefix = {arXiv},
isbn = {9781509041176},
institution = {IEEE},
arxivid = {1610.03022},
abstract = {Sequence-to-sequence models have shown success in end-to-end speech recognition. However these models have only used shallow acoustic encoder networks. In our work, we successively train very deep convolutional networks to add more expressive power and better generalization for end-to-end ASR models. We apply network-in-network principles, batch normalization, residual connections and convolutional LSTMs to build very deep recurrent and convolutional structures. Our models exploit the spectral structure in the feature space and add computational depth without overfitting issues. We experiment with the WSJ ASR task and achieve 10.5% word error rate without any dictionary or language model using a 15 layer deep network.},
doi = {10.1109/ICASSP.2017.7953077},
issn = {15206149},
keywords = {speech recognition,state of the art},
mendeley-tags = {speech recognition,state of the art},
}

@article{Boulanger-lewandowski2014,
author = { Boulanger-Lew and Nicolas owski and Jasha Droppo and Mike Seltzer and Dong Yu},
doi = {10.1109/ICASSP.2014.6854638},
pages = {5417--5421},
year = {2014},
issn = {15206149},
isbn = {9781479928927},
number = {2},
title = {Phone sequence modeling with recurrent neural networks},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
abstract = {In this paper, we investigate phone sequence modeling with recurrent neural networks in the context of speech recognition. We introduce a hybrid architecture that combines a phonetic model with an arbitrary frame-level acoustic model and we propose efficient algorithms for training, decoding and sequence alignment. We evaluate the advantage of our phonetic model on the TIMIT and Switchboard-mini datasets in complementarity to a powerful context-dependent deep neural network (DNN) acoustic classifier and a higher-level 3-gram language model. Consistent improvements of 2-10% in phone accuracy and 3% in word error rate suggest that our approach can readily replace HMMs in current state-of-the-art systems. \textcopyright 2014 IEEE.},
institution = {IEEE},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{Ding2016,
author = {Hui Ding and Shaohua Kevin Zhou and Rama Chellappa},
doi = {10.1109/FG.2017.23},
journal = {Proceedings - 12th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2017 - 1st International Workshop on Adaptive Shot Learning for Gesture Understanding and Production, ASL4GUP 2017, Biometrics in the Wild, Bwild 2017, Heterogeneous Face Recognition, HFR 2017, Joint Challenge on Dominant and Complementary Emotion Recognition Using Micro Emotion Features and Head-Pose Estimation, DCER and HPE 2017 and 3rd Facial Expression Recognition and Analysis Challenge, FERA 2017},
pages = {118--126},
year = {2017},
issn = {2160-7508},
abstract = {Relatively small data sets available for expression recognition research make the training of deep networks very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redundant information from the pretrained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully-connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization results show that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu- CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art.},
eprint = {1609.06591},
title = {FaceNet2ExpNet: Regularizing a Deep Face Recognition Net for Expression Recognition},
url = {http://arxiv.org/abs/1609.06591},
archiveprefix = {arXiv},
institution = {IEEE},
arxivid = {1609.06591},
isbn = {9781509040230},
keywords = {facial expression,state of the art},
mendeley-tags = {facial expression,state of the art},
}

@article{Costa2017,
author = {Y Costa and re M.G. and Luiz S. Oliveira and Carlos N. Silla},
publisher = {Elsevier B.V.},
doi = {10.1016/j.asoc.2016.12.024},
journal = {Applied Soft Computing Journal},
volume = {52},
year = {2017},
pages = {28--38},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616306421},
title = {An evaluation of Convolutional Neural Networks for music classification using spectrograms},
abstract = {Music genre recognition based on visual representation has been successfully explored over the last years. Classifiers trained with textural descriptors (e.g., Local Binary Patterns, Local Phase Quantization, and Gabor filters) extracted from the spectrograms have achieved state-of-the-art results on several music datasets. In this work, though, we argue that we can go further with the time-frequency analysis through the use of representation learning. To show that, we compare the results obtained with a Convolutional Neural Network (CNN) with the results obtained by using handcrafted features and SVM classifiers. In addition, we have performed experiments fusing the results obtained with learned features and handcrafted features to assess the complementarity between these representations for the music classification task. Experiments were conducted on three music databases with distinct characteristics, specifically a western music collection largely used in research benchmarks (ISMIR 2004 Database), a collection of Latin American music (LMD database), and a collection of field recordings of ethnic African music. Our experiments show that the CNN compares favorably to other classifiers in several scenarios, hence, it is a very interesting alternative for music genre recognition. Considering the African database, the CNN surpassed the handcrafted representations and also the state-of-the-art by a margin. In the case of the LMD database, the combination of CNN and Robust Local Binary Pattern achieved a recognition rate of 92%, which to the best of our knowledge, is the best result (using an artist filter) on this dataset so far. On the ISMIR 2004 dataset, although the CNN did not improve the state of the art, it performed better than the classifiers based individually on other kind of features.},
issn = {15684946},
keywords = {music classification,state of the art},
mendeley-tags = {music classification,state of the art},
}

@article{LeCun1998,
author = {Yann LeCun and L\'eon Bottou and Yoshua Bengio and Patrick Haffner},
doi = {10.1109/5.726791},
number = {11},
eprint = {1102.0183},
pmid = {15823584},
arxivid = {1102.0183},
title = {Gradient-based learning applied to document recognition},
volume = {86},
year = {1998},
issn = {00189219},
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of two dimensional (2-D) shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN's), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank check is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day. \textcopyright 1998 IEEE.},
archiveprefix = {arXiv},
journal = {Proceedings of the IEEE},
pages = {2278--2323},
publisher = {IEEE},
isbn = {0018-9219},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Shizhou2016,
author = {Zhang Shizhou and Yihong Gong and Wang Jinjun},
year = {2016},
pages = {2343--2349},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
volume = {2016-January},
abstract = {In this paper, we choose to learn useful cues from object recognition mechanisms of the human visual cortex, and propose a DCNN performance improvement method without the need for increasing the network complexity. Inspired by the categoryselective property of the neuron population in the IT layer of the human visual cortex, we enforce the neuron responses at the top DCNN layer to be category selective. To achieve this, we propose the Sparse Category-Selective Objective Function (SCSOF) to modulate the neuron outputs of the top DCNN layer. The proposed method is generic and can be applied to any DCNN models. As experimental results show, when applying the proposed method to the "Quick" model and NIN models, image classification performances are remarkably improved on four widely used benchmark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN, which demonstrate the effectiveness of the presented method.},
issn = {10450823},
title = {Improving DCNN performance with sparse category-selective objective function},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Guang-BinHuang2014,
author = {Guang Bin Huang and Qin Yu Zhu and Chee Kheong Siew},
abstract = {It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: 1) the slow gradient-based learning algorithms are extensively used to train neural networks, and 2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these traditional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses the input weights and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide the best generalization performance at extremely fast learning speed. The experimental results based on realworld benchmarking function approximation and classification problems including large complex applications show that the new algorithm can produce best generalization performance in some cases and can learn much faster than traditional popular learning algorithms for feedforward neural networks.},
isbn = {0780383591},
issn = {10987576},
doi = {10.1109/IJCNN.2004.1380068},
title = {Extreme learning machine: A new learning scheme of feedforward neural networks},
year = {2004},
url = {http://ieeexplore.ieee.org/document/1380068/},
institution = {IEEE},
number = {August 2004},
journal = {IEEE International Conference on Neural Networks - Conference Proceedings},
pages = {985--990},
volume = {2},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Wu2012,
author = {Yue Wu and Jianqing Hu and Wei Wu and Yong Zhou and K. L. Du},
doi = {10.1109/ICICTA.2012.89},
isbn = {9780769546377},
institution = {IEEE},
journal = {Proceedings - 2012 5th International Conference on Intelligent Computation Technology and Automation, ICICTA 2012},
year = {2012},
abstract = {The Hopfield model is a well-known dynamic associative-memory model. In this paper, we investigate various aspects of the Hopfield model for associative memory. We conduct a systematic simulation investigation of several storage algorithms for Hopfield networks, and conclude that the perceptron learning based storage algorithms can achieve much better storage capacity than the Hebbian learning based algorithms. \textcopyright 2012 IEEE.},
number = {January},
title = {Storage capacity of the hopfield network associative memory},
pages = {330--336},
keywords = {theory},
mendeley-tags = {theory},
}

@article{DIppolito2014a,
author = {Beatrice D'Ippolito},
issn = {01664972},
url = {http://www.sciencedirect.com/science/article/pii/S016649721400008X},
journal = {Technovation},
volume = {34},
year = {2014},
pages = {716--730},
abstract = {Scholars dedicated increasing attention towards appreciating how design has changed individualsperception of new products, firmsunderstanding and formulation of strategy, or other relevant actorsapproach to innovation and technology management. By emphasising the importance of design for the definition of consumersneeds, the restructuring of firmsorganisational structures and strategies, and the evolution of firmsvalue creation processes, this review paper identifies relevant research gaps and questions that would benefit from future scholarly attention. In particular, it is suggested that such effort should address the analysis of how design consumption can help better comprehend consumersneeds; what are the implications of design thinking on the skill sets of design professionals; the organisational structure of firms, including the reconfiguration of other business functions, and their strategy; and whether and how design thinking can shape firmsvalue creation processes and contribute to the formalisation of design tasks.},
isbn = {0166-4972},
doi = {10.1016/j.technovation.2014.01.007},
month = {feb},
number = {11},
pmid = {1629546633},
publisher = {Elsevier},
title = {The importance of design for firmscompetitiveness: A review of the literature},
keywords = {consumers' needs,design,firm competitiveness,literature review,research gaps,strategy making,value creation},
mendeley-tags = {consumers' needs,design,firm competitiveness,literature review,research gaps,strategy making,value creation},
}

@book{2017MinskyPerceptrons,
author = {M.L. Minsky and S. Papert},
url = {http://cdsweb.cern.ch/record/114106},
year = {1988},
title = {Perceptrons (An introduction to computational geometry): Epilogue},
publisher = {MIT Press},
booktitle = {Handbook of attachment: Theory, research, and clinical},
isbn = {0262631113},
keywords = {linear-classification neural-networks seminal},
mendeley-tags = {linear-classification neural-networks seminal},
}

@article{2019Wang3D,
author = {Keze Wang and Liang Lin and Chenhan Jiang and Chen Qian and Pengxu Wei},
abstract = {Driven by recent computer vision and robotic applications, recovering 3D human poses has become increasingly important and attracted growing interests. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate priors /constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images. Specifically, the proposed mechanism involves two dual learning tasks, i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between 3D and 2D human poses in a type of "free" self-supervision for accurate 3D human pose estimation. The 2D-to-3D pose implies to sequentially regress intermediate 3D poses by transforming the pose representation from the 2D domain to the 3D domain under the sequence-dependent temporal context, while the 3D-to-2D pose projection contributes to refining the intermediate 3D poses by maintaining geometric consistency between the 2D projections of 3D poses and the estimated 2D poses. Therefore, these two dual learning tasks enable our model to adaptively learn from 3D human pose data and external large-scale 2D human pose data. We further apply our self-supervised correction mechanism to develop a 3D human pose machine, which jointly integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge. Extensive evaluations on the Human3.6M and HumanEva-I benchmarks demonstrate the superior performance and efficiency of our framework over all the compared competing methods.},
issn = {23318422},
title = {3D human pose machines with self-supervised learning},
url = {http://arxiv.org/abs/1901.03798},
year = {2019},
journal = {arXiv},
keywords = {convolutional neural networks,geometric deep learning,human pose estimation,self-supervised learning,spatio-temporal modeling},
mendeley-tags = {convolutional neural networks,geometric deep learning,human pose estimation,self-supervised learning,spatio-temporal modeling},
}

@phdthesis{2004TraubeInterdisciplinary,
author = {Caroline Traube},
pages = {218},
isbn = {0494063467},
school = {McGill University},
title = {An Interdisciplinary Study of the Timbre of the Classical Guitar .},
url = {http://www.academia.edu/914878/An_interdisciplinary_study_of_the_timbre_of_the_classical_guitar},
year = {2004},
abstract = {This dissertation proposes an interdisciplinary approach for the study of the timbre of the classical guitar. We start by identifying the static control parameters of timbre, relating to the structural components of the guitar and the dynamic control parameters of timbre, relating to the gestures applied by the performer on the instrument. From the plucked string physical model (obtained from the tranverse wave equation), we derive a digital signal interpretation of the plucking eﬀect which is a comb ﬁltering. Then we investigate how subjective characteristics of sound, like timbre, are related to gesture parameters. The starting point for exploration is an inventory of verbal descriptors commonly used by professional musicians to describe the brightness, the colour, the shape and the texture of the sounds they produce on their instruments. An explanation for the voice-like nature of guitar tones is proposed based on the observation that the maxima of the comb-ﬁltershaped magnitude spectrum of guitar tones are located at frequencies similar to the formant frequencies of a subset of identiﬁable vowels. These analogies at the spectral level might account for the origin of some timbre descriptors such as open, oval, round, thin, closed, nasal and hollow, that seem to refer to phonetic gestures. In a experiment conducted to conﬁrm these analogies, participants were asked to associate a consonant to the attack and a vowel to the decay of guitar tones. The results of this study support the idea that some perceptual dimensions of the guitar timbre space can be borrowed from phonetics. Finally, we address the problem of the indirect acquisition of instrumental gesture parameters. Pursuing previous research on the estimation of the plucking position from a recording, we propose a new estimation method based on an iterative weighted least-square algorithm, starting from a ﬁrst approximation derived from a variant of the autocorrelation function of the signal.},
number = {October},
}

@inproceedings{2005Florianreinforcement,
author = {Rǎzvan V. Florian},
booktitle = {Proceedings - Seventh International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2005},
publisher = {IEEE},
doi = {10.1109/SYNASC.2005.13},
year = {2005},
abstract = {The paper presents a new reinforcement learning mechanism for spiking neural networks. The algorithm is derived for networks of stochastic integrate-and-fire neurons, but it can be also applied to generic spiking neural networks. Learning is achieved by synaptic changes that depend on the firing ofpre- and postsynaptic neurons, and that are modulated with a global reinforcement signal. The efficacy of the algorithm is verified in a biologically-inspired experiment, featuring a simulated worm that searches for food. Our model recovers a form of neural plasticity experimentally observed in animals, combining spiketiming-dependent synaptic changes of one sign with nonassociative synaptic changes of the opposite sign determined by presynaptic spikes. The model also predicts that the time constant of spike-timing-dependent synaptic changes is equal to the membrane time constant of the neuron, in agreement with experimental observations in the brain. This study also led to the discovery of a biologically-plausible reinforcement learning mechanism that works by modulating spike-timing-dependent plasticity (STDP) with a global reward signal. \textcopyright 2005 IEEE.},
pages = {299--306},
isbn = {0769524532},
volume = {2005},
title = {A reinforcement learning algorithm for spiking neural networks},
url = {http://ieeexplore.ieee.org/document/1595864/},
}

@article{2015MnihHuman,
author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and  Fidjel and Andreas K.  and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
volume = {518},
pages = {529--533},
number = {7540},
doi = {10.1038/nature14236},
title = {Human-level control through deep reinforcement learning},
issn = {14764687},
journal = {Nature},
pmid = {25719670},
year = {2015},
abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
url = {http://www.nature.com/articles/nature14236},
}

@misc{2013MnihPlaying,
author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
arxivid = {1312.5602},
title = {Playing Atari with Deep Reinforcement Learning},
url = {http://arxiv.org/abs/1312.5602},
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
eprint = {1312.5602},
archiveprefix = {arXiv},
year = {2013},
}

@article{1999ChellapillaEvolution,
author = {Kumar Chellapilla and David B. Fogel},
title = {Evolution, neural networks, games, and intelligence},
number = {9},
year = {1999},
journal = {Proceedings of the IEEE},
abstract = {Intelligence pertains to the ability to make appropriate decisions in light of specific goals and to adapt behavior to meet those goals in a range of environments. Mathematical games provide a framework for studying intelligent behavior in models of real-worm settings or restricted domains. The behavior of alternative strategies in these games is defined by each individual's stimulus-response mapping. Limiting these behaviors to linear functions of the environmental conditions renders the results to be little more than a facade: effective decision making in any complex environment almost always requires nonlinear stimulus-response mappings. The obstacle then comes in choosing the appropriate representation and learning algorithm. Neural networks and evolutionary algorithms provide useful means for addressing these issues. This paper describes efforts to hybridize neural and evolutionary computation to learn appropriate strategies in zero- and nonzero-sum games, including the iterated prisoner's dilemma, tic-tac-toe, and checkers. With respect to checkers, the evolutionary algorithm was able to discover a neural network that can be used to play at a near-expert level without injecting expert knowledge about how to play the game. The implications of evolutionary learning with respect to machine intelligence are also discussed. It is argued that evolution provides the framework for explaining naturally occurring intelligent entities and can be used to design machines that are also capable of intelligent behavior.},
volume = {87},
issn = {00189219},
doi = {10.1109/5.784222},
url = {http://ieeexplore.ieee.org/document/784222/},
pages = {1471--1496},
}

@article{2014Sigtiarnn,
author = {Siddharth Sigtia and Emmanouil Benetos and Srikanth Cherla and Tillman Weyde and Artur S. d'Avila Garcez and Simon Dixon},
abstract = {In this paper, we investigate the use of Music Language Models (MLMs) for improving Automatic Music Transcription performance. The MLMs are trained on sequences of symbolic polyphonic music from the Nottingham dataset. We train Recurrent Neural Network (RNN)-based models, as they are capable of capturing complex temporal structure present in symbolic music data. Similar to the function of language models in automatic speech recognition, we use the MLMs to generate a prior probability for the occurrence of a sequence. The acoustic AMT model is based on probabilistic latent component analysis, and prior information from the MLM is incorporated into the transcription framework using Dirichlet priors. We test our hybrid models on a dataset of multiple-instrument polyphonic music and report a significant 3% improvement in terms of F-measure, when compared to using an acoustic-only model.},
journal = {Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014},
year = {2014},
title = {An RNN-based music language model for improving automatic music transcription},
pages = {53--58},
}

@incollection{2015Daskinp,
author = {Mark S Daskin and Kayse Lee Maass},
isbn = {978-3-319-13110-8 978-3-319-13111-5},
pages = {21--45},
title = {Location Science},
year = {2015},
editor = {Laporte, Gilbert and Nickel, Stefan and da Gama, Francisco},
booktitle = {Location Science},
doi = {10.1007/978-3-319-13111-5},
abstract = {Abstract Fixed-Charge Facility Location Problems are among core problems in Location Science. There is a finite set of users with demand of service and a finite set of potential locations for the facilities that will offer service to users. Two types of decisions must be made: Location decisions determine where to establish the facilities whereas allocation decisions dictate how to satisfy the users demand from the established facilities. Potential applications of various types arise in many different contexts. We provide an overview of the main elements that may intervene in the modeling and the solution process of Fixed-Charge Facility Location Problems, namely, modeling hypotheses and their implications, characteristics of formulations and their relation to other formulations, properties of the domains, and appropriate solution techniques.},
publisher = {Springer International Publishing},
}

@book{2014GanderScientific,
author = { G and Walter er and  G and Martin J. er and Felix Kwok},
abstract = {Scientific computing is the study of how to use computers effectively to solve problems that arise from the mathematical modeling of phenomena in science and engineering. It is based on mathematics, numerical and symbolic/algebraic computations and visualization. This book serves as an introduction to both the theory and practice of scientific computing, with each chapter presenting the basic algorithms that serve as the workhorses of many scientific codes; we explain both the theory behind these algorithms and how they must be implemented in order to work reliably in finite-precision arithmetic. The book includes many programs written in Matlab and Maple – Maple is often used to derive numerical algorithms, whereas Matlab is used to implement them. The theory is developed in such a way that students can learn by themselves as they work through the text. Each chapter contains numerous examples and problems to help readers understand the material "hands-on".},
pages = {360},
publisher = {Springer International Publishing},
volume = {11},
isbn = {978-3-319-04324-1},
series = {Texts in Computational Science and Engineering},
url = {http://link.springer.com/10.1007/978-3-319-04325-8},
title = {Scientific Computing - An Introduction using Maple and MATLAB},
doi = {10.1007/978-3-319-04325-8},
year = {2014},
}

@incollection{2011VerterUncapacitated,
author = {Vedat Verter},
issn = {08848289},
editor = {Eiselt, H A and Marianov, Vladimir},
doi = {10.1007/978-1-4419-7572-0_2},
volume = {155},
publisher = {Springer US},
booktitle = {International Series in Operations Research and Management Science},
pages = {25--37},
year = {2011},
isbn = {978-1-4419-7571-3 978-1-4419-7572-0},
title = {Uncapacitated and capacitated facility location problems},
}

@inproceedings{2018FukumotoGeneration,
author = {Yuuya Fukumoto and Daiki Shimizu and Chihiro Shibata},
year = {2018},
volume = {2},
isbn = {9781538626665},
issn = {07303157},
publisher = {IEEE},
title = {Generation of Character Illustrations from Stick Figures Using a Modification of Generative Adversarial Network},
pages = {183--186},
doi = {10.1109/COMPSAC.2018.10225},
url = {https://ieeexplore.ieee.org/document/8377853/},
booktitle = {Proceedings - International Computer Software and Applications Conference},
abstract = {We propose a modification of generative adversarial networks (GANs) that generate illustrations of human figures from given poses represented by stick figures. In recent years, while various methods that generate images of characters using GANs have been proposed, it is not yet possible for users to freely designate poses of human figures. When generating an image of a character, the pose of the character takes is an important component of its composition. Thus it is necessary fora user who wants to create an illustration to be able to specify the pose easily. We collected a set of illustrations of human figures from the internet, and for each illustration, a simple line drawing that specifies the pose was drawn manually. We constructed a GAN that takes a line drawing as its input and creates an illustration of a person in a pose that matches the line drawing. These networks are learned using the data set we prepared. In this paper, we propose a new network architecture. After constructing two networks both of which have almost the same structure as pix2pix, which is a variant model of GANs, we stack up those networks based on the idea of stack GAN. The experimental results show that, from stick figures representing common poses such as a standing pose, our methods was able to successfully generate images of characters. However, in the case of stick figures having rare poses that were not in the dataset, such as figures raising a hand or lying down, the generated images were blurred and not of a high-quality but still had the desired shapes. By expanding the dataset to include various poses, it is possible to generate diverse poses more precisely.},
keywords = {deep learning,generative adversarial networks,image generation},
mendeley-tags = {deep learning,generative adversarial networks,image generation},
}

@article{2018ChanEverybody,
author = {Caroline Chan and Shiry Ginosar and Tinghui Zhou and Alexei A. Efros},
year = {2018},
issn = {23318422},
journal = {arXiv},
abstract = {This paper presents a simple method for "do as I do" motion transfer: given a source video of a person dancing we can transfer that performance to a novel (amateur) target after only a few minutes of the target subject performing standard moves. We pose this problem as a per-frame image-to-image translation with spatio-temporal smoothing. Using pose detections as an intermediate representation between source and target, we learn a mapping from pose images to a target subject's appearance. We adapt this setup for temporally coherent video generation including realistic face synthesis. Our video demo can be found at https://youtu.be/PCBTZh41Ris.},
doi = {10.1080/07303084.2006.10597803},
title = {Everybody Dance Now},
url = {http://arxiv.org/abs/1808.07371},
keywords = {generative adversarial networks,motion transfer,video generation},
mendeley-tags = {generative adversarial networks,motion transfer,video generation},
}

@article{2018CaoReview,
author = {Weipeng Cao and Xizhao Wang and Zhong Ming and Jinzhu Gao},
pages = {278--287},
doi = {10.1016/j.neucom.2017.08.040},
volume = {275},
year = {2018},
title = {A review on neural networks with random weights},
journal = {Neurocomputing},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231217314613},
issn = {18728286},
abstract = {In big data fields, with increasing computing capability, artificial neural networks have shown great strength in solving data classification and regression problems. The traditional training of neural networks depends generally on the error back propagation method to iteratively tune all the parameters. When the number of hidden layers increases, this kind of training has many problems such as slow convergence, time consuming, and local minima. To avoid these problems, neural networks with random weights (NNRW) are proposed in which the weights between the hidden layer and input layer are randomly selected and the weights between the output layer and hidden layer are obtained analytically. Researchers have shown that NNRW has much lower training complexity in comparison with the traditional training of feed-forward neural networks. This paper objectively reviews the advantages and disadvantages of NNRW model, tries to reveal the essence of NNRW, gives our comments and remarks on NNRW, and provides some useful guidelines for users to choose a mechanism to train a feed-forward neural network.},
keywords = {feed-forward neural networks,neural networks with random weights,training mechanism},
mendeley-tags = {feed-forward neural networks,neural networks with random weights,training mechanism},
}

@article{2017LinRecurrent,
author = {Mude Lin and Liang Lin and Xiaodan Liang and Keze Wang and Hui Cheng},
url = {http://arxiv.org/abs/1707.09695},
year = {2017},
journal = {arXiv},
title = {Recurrent 3D pose sequence machines},
issn = {23318422},
abstract = {3D human articulated pose recovery from monocular image sequences is very challenging due to the diverse appearances, viewpoints, occlusions, and also the human 3D pose is inherently ambiguous from the monocular imagery. It is thus critical to exploit rich spatial and temporal long-range dependencies among body joints for accurate 3D pose sequence prediction. Existing approaches usually manually design some elaborate prior terms and human body kinematic constraints for capturing structures, which are often insufficient to exploit all intrinsic structures and not scalable for all scenarios. In contrast, this paper presents a Recurrent 3D Pose Sequence Machine(RPSM) to automatically learn the image-dependent structural constraint and sequence-dependent temporal context by using a multi-stage sequential refinement. At each stage, our RPSM is composed of three modules to predict the 3D pose sequences based on the previously learned 2D pose representations and 3D poses: (i) a 2D pose module extracting the image-dependent pose representations, (ii) a 3D pose recurrent module regressing 3D poses and (iii) a feature adaption module serving as a bridge between module (i) and (ii) to enable the representation transformation from 2D to 3D domain. These three modules are then assembled into a sequential prediction framework to refine the predicted poses with multiple recurrent stages. Extensive evaluations on the Human3.6M dataset and HumanEva-I dataset show that our RPSM outperforms all state-of-the-art approaches for 3D pose estimation.},
}

@article{2016GiryesDeep,
author = {Raja Giryes and Guillermo Sapiro and Alex M. Bronstein},
url = {http://arxiv.org/abs/1504.08291},
archiveprefix = {arXiv},
journal = {IEEE Transactions on Signal Processing},
pages = {3444--3457},
doi = {10.1109/TSP.2016.2546221},
arxivid = {1504.08291},
year = {2016},
abstract = {Three important properties of a classification machinery are i) the system preserves the core information of the input data; ii) the training examples convey information about unseen data; and iii) the system is able to treat differently points from different classes. In this paper, we show that these fundamental properties are satisfied by the architecture of deep neural networks. We formally prove that these networks with random Gaussian weights perform a distance-preserving embedding of the data, with a special treatment for in-class and out-of-class data. Similar points at the input of the network are likely to have a similar output. The theoretical analysis of deep networks here presented exploits tools used in the compressed sensing and dictionary learning literature, thereby making a formal connection between these important topics. The derived results allow drawing conclusions on the metric learning properties of the network and their relation to its structure, as well as providing bounds on the required size of the training set such that the training examples would represent faithfully the unseen data. The results are validated with state-of-the-art trained networks.},
eprint = {1504.08291},
title = {Deep Neural Networks with Random Gaussian Weights: A Universal Classification Strategy?},
number = {13},
volume = {64},
shorttitle = {Deep Neural Networks with Random Gaussian Weights},
issn = {19410476},
}

@article{2014RingbauerExperimental,
author = {Martin Ringbauer and Matthew A. Broome and Casey R. Myers and Andrew G. White and Timothy C. Ralph},
issn = {20411723},
volume = {5},
url = {http://www.nature.com/articles/ncomms5145},
year = {2014},
journal = {Nature Communications},
doi = {10.1038/ncomms5145},
abstract = {Closed timelike curves are among the most controversial features of modern physics. As legitimate solutions to Einstein's field equations, they allow for time travel, which instinctively seems paradoxical. However, in the quantum regime these paradoxes can be resolved, leaving closed timelike curves consistent with relativity. The study of these systems therefore provides valuable insight into nonlinearities and the emergence of causal structures in quantum mechanics-essential for any formulation of a quantum theory of gravity. Here we experimentally simulate the nonlinear behaviour of a qubit interacting unitarily with an older version of itself, addressing some of the fascinating effects that arise in systems traversing a closed timelike curve. These include perfect discrimination of non-orthogonal states and, most intriguingly, the ability to distinguish nominally equivalent ways of preparing pure quantum states. Finally, we examine the dependence of these effects on the initial qubit state, the form of the unitary interaction and the influence of decoherence. \textcopyright 2014 Macmillan Publishers Limited.},
eprint = {1501.05014},
arxivid = {1501.05014},
number = {1},
title = {Experimental simulation of closed timelike curves},
archiveprefix = {arXiv},
}

@inproceedings{2014ToshevDeeppose,
author = {Alex Toshev and  er and Christian Szegedy},
year = {2014},
archiveprefix = {arXiv},
eprint = {1312.4659},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.214},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909610},
arxivid = {1312.4659},
pages = {1653--1660},
publisher = {IEEE},
shorttitle = {DeepPose},
title = {DeepPose: Human pose estimation via deep neural networks},
isbn = {9781479951178},
abstract = {We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regres- sors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formula- tion which capitalizes on recent advances in Deep Learn- ing. We present a detailed empirical analysis with state-of- art or better performance on four academic benchmarks of diverse real-world images.},
issn = {10636919},
keywords = {cascades,deep learning,human pose estimation,neural networks},
mendeley-tags = {cascades,deep learning,human pose estimation,neural networks},
}

@article{2017JanochaLoss,
author = {Katarzyna Janocha and Wojciech Marian Czarnecki},
issn = {23318422},
abstract = {Deep neural networks are currently among the most commonly used classifiers. Despite easily achieving very good performance, one of the best selling points of these models is their modular design - one can conveniently adapt their architecture to specific needs, change connectivity patterns, attach specialised layers, experiment with a large amount of activation functions, normalisation schemes and many others. While one can find impressively wide spread of various configurations of almost every aspect of the deep nets, one element is, in authors' opinion, underrepresented - while solving classification problems, vast majority of papers and applications simply use log loss. In this paper we try to investigate how particular choices of loss functions a ect deep models and their learning dynamics, as well as resulting classifiers robustness to various e ects. We perform experiments on classical datasets, as well as provide some additional, theoretical insights into the problem. In particular we show that L1and L2losses are, quite surprisingly, justified classification objectives for deep nets, by providing probabilistic interpretation in terms of expected misclassification. We also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones.},
journal = {arXiv},
url = {http://arxiv.org/abs/1702.05659},
title = {On loss functions for deep neural networks in classification},
year = {2017},
}

@article{2016RoszkowskaApplication,
author = {  and Ewa Roszkowska},
issn = {15067637},
publisher = {University of Bialystok},
title = {The Application of UTA Method for Support Evaluation Negotiation Offers},
doi = {10.15290/ose.2016.02.80.11},
year = {2016},
abstract = {The MCDA technique has been extensively and successfully applied for supporting decision making in negotiation processes. The mostly used techniques SAW, AHP or TOPSIS are based on direct preference information which requires from negotiator a clear and precise definition all the parameters of the preference model (e.g. issue weights, option rates, aspiration and reservation values etc.), so those techniques can be successfully applied in well-structured negotiation problems. But, many real negotiation problems are illstructured, that means that the negotiation space is imprecisely defined, and the negotiator's preferences the vagueness or imperfect.},
pages = {144--162},
url = {http://repozytorium.uwb.edu.pl/jspui/handle/11320/4640},
number = {2(80)},
journal = {Optimum. Studia Ekonomiczne},
}

@article{2018StierAnalysing,
author = {Julian Stier and Gabriele Gianini and Michael Granitzer and Konstantin Ziegler},
doi = {10.1016/j.procS.2018.07.257},
title = {Analysing Neural Network Topologies: A Game Theoretic Approach},
archiveprefix = {arXiv},
year = {2018},
url = {https://linkinghub.elsevier.com/retrieve/pii/S187705091831233X},
arxivid = {1904.08166},
pages = {234--243},
volume = {126},
journal = {Procedia Computer Science},
abstract = {Artificial Neural Networks have shown impressive success in very different application caseS. Choosing a proper network architecture is a critical decision for a network's success, usually done in a manual manner. As a straightforward strategy, large, mostly fully connected architectures are selected, thereby relying on a good optimization strategy to find proper weights while at the same time avoiding overfitting. However, large parts of the final network are redundant. In the best case, large parts of the network become simply irrelevant for later inferencing. In the worst case, highly parameterized architectures hinder proper optimization and allow the easy creation of adverserial examples fooling the network. A first step in removing irrelevant architectural parts lies in identifying those parts, which requires measuring the contribution of individual components such as neuronS. In previous work, heuristics based on using the weight distribution of a neuron as contribution measure have shown some success, but do not provide a proper theoretical understanding. Therefore, in our work we investigate game theoretic measures, namely the shapley value (sV), in order to separate relevant from irrelevant parts of an artificial neural network. We begin by designing a coalitional game for an artificial neural network, where neurons form coalitions and the average contributions of neurons to coalitions yield to the shapley value. In order to measure how well the shapley value measures the contribution of individual neurons, we remove low-contributing neurons and measure its impact on the network performance. In our experiments we show that the shapley value outperforms other heuristics for measuring the contribution of neuronS.},
shorttitle = {Analysing Neural Network Topologies},
eprint = {1904.08166},
issn = {18770509},
keywords = {neural network pruning,neural networks,shapley value,topology optimization},
mendeley-tags = {neural network pruning,neural networks,shapley value,topology optimization},
}

@article{ShohamMultiagent,
author = {Yoav Shoham and Kevin Leyton-Brown},
isbn = {9780511811654},
journal = {Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations},
pages = {1--483},
volume = {9780521899437},
abstract = {This exciting and pioneering new overview of multiagent systems, which are online systems composed of multiple interacting intelligent agents, i.e., online trading, offers a newly seen computer science perspective on multiagent systems, while integrating ideas from operations research, game theory, economics, logic, and even philosophy and linguistics. The authors emphasize foundations to create a broad and rigorous treatment of their subject, with thorough presentations of distributed problem solving, game theory, multiagent communication and learning, social choice, mechanism design, auctions, cooperative game theory, and modal logics of knowledge and belief. For each topic, basic concepts are introduced, examples are given, proofs of key results are offered, and algorithmic considerations are examined. An appendix covers background material in probability theory, classical logic, Markov decision processes and mathematical programming. Written by two of the leading researchers of this engaging field, this book will surely serve as THE reference for researchers in the fastest-growing area of computer science, and be used as a text for advanced undergraduate or graduate courses.},
doi = {10.1017/CBO9780511811654},
year = {2008},
title = {Multiagent systems: Algorithmic, Game-Theoretic, and logical foundations},
}

@book{2018SuttonReinforcement,
author = {Richard S Sutton and Andrew G Barto},
isbn = {978-0-262-03924-6},
publisher = {The MIT Press},
series = {Adaptive computation and machine learning series},
abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
edition = {Second edition},
title = {Reinforcement learning: an introduction},
shorttitle = {Reinforcement learning},
keywords = {reinforcement learning},
mendeley-tags = {reinforcement learning},
}

@inproceedings{2017Pike-burkeOptimistic,
author = {Ciara Pike-Burke and Steffen Gr\"unew\"alder},
pages = {9},
booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017},
abstract = {The stochastic knapsack problem is a stochastic resource allocation problem that arises frequently and yet is exceptionally hard to solve. We derive and study an optimistic planning algorithm specifically designed for the stochastic knapsack problem. Unlike other optimistic planning algorithms for MDPs, our algorithm, OpStoK, avoids the use of discounting and is adaptive to the amount of resources available. We achieve this behavior by means of a concentration inequality that simultaneously applies to capacity and reward estimates. Crucially, we are able to guarantee that the aforementioned confidence regions hold collectively over all time steps by an application of Doob's inequality. We demonstrate that the method returns an -optimal solution to the stochastic knapsack problem with high probability. To the best of our knowledge, our algorithm is the first which provides such guarantees for the stochastic knapsack problem. Furthermore, our algorithm is an anytime algorithm and will return a good solution even if stopped prematurely. This is particularly important given the difficulty of the problem. We also provide theoretical conditions to guarantee OpStoK does not expand all policies and demonstrate favorable performance in a simple experimental setting.},
year = {2017},
title = {Optimistic planning for the stochastic knapsack problem},
}

@book{2015ChrupalaLearning,
author = {Grzegorz Chrupala and Akos Kadar and Afra Alishahi and Chengqing Zong and Michael Strube},
annote = {OCLC: 6893507677},
isbn = {978-1-941643-73-0},
abstract = {We propose Imaginet, a model of learning visually grounded representations of language from coupled textual and visual input. The model consists of two Gated Recurrent Unit networks with shared word embeddings, and uses a multi-task objective by receiving a textual description of a scene and trying to concurrently predict its visual representation and the next word in the sentence. Like humans, it acquires meaning representations for individual words from descriptions of visual scenes. Moreover, it learns to effectively use sequential structure in semantic interpretation of multi-word phrases.},
publisher = {Association for Computational Linguistics},
title = {Learning language through pictures},
}

@article{DeanApproximating,
author = {Brian C. Dean and Michel X. Goemans and Jan Vondr\'ak},
journal = {Mathematics of Operations Research},
year = {2008},
pages = {945--964},
volume = {33},
title = {Approximating the stochastic knapsack problem: The benefit of adaptivity},
issn = {0364765X},
doi = {10.1287/moor.1080.0330},
number = {4},
abstract = {We consider a stochastic variant of the NP-hard 0/1 knapsack problem, in which item values are deterministic and item sizes are independent random variables with known, arbitrary distributions. Items are placed in the knapsack sequentially, and the act of placing an item in the knapsack instantiates its size. Our goal is to compute a solution "policy" that maximizes the expected value of items successfully placed in the knapsack, where the final overflowing item, contributes no value. We consider both nonadaptive policies (that designate a priori a fixed sequence of items to insert) and adaptive policies (that can make dynamic choices based on the instantiated sizes of items placed in the knapsack thus far). An important facet of our work lies in characterizing the benefit of adaptivity. For this purpose we advocate the use of a measure called the adaptivity gap: the ratio of the expected value obtained by an optimal adaptive policy to that obtained by an optimal nonadaptive policy. We bound the adaptivity gap of the stochastic knapsack problem by demonstrating a polynomial-time algorithm that computes a nonadaptive policy whose expected value approximates that of an optimal adaptive policy to within a factor of four. We also devise a polynomial-time adaptive policy that approximates the optimal adaptive policy to within a factor of 3 + $\epsilon$ for any constant $\epsilon$ > 0. \textcopyright 2008 INFORMS.},
keywords = {adaptivity,approximation algorithm,knapsack problem,stochastic models},
mendeley-tags = {adaptivity,approximation algorithm,knapsack problem,stochastic models},
}

@book{1999LevineNew,
author = {T Beck and A Demirg\"u\cc-Kunt and R Levine},
booktitle = {The World Bank Economic Review},
pages = {null},
isbn = {null},
number = {June},
volume = {null},
doi = {10.1596/1813-9450-2146},
publisher = {The World Bank},
year = {1999},
series = {Policy Research Working Papers},
abstract = {This paper introduces a new database of indicators of financial development and structure across countries and over time. This database is unique in that it unites a wide variety of indicators that measure the size, activity and efficiency of financial intermediaries and markets. It improves on previous efforts by presenting data on the public share of commercial banks, by introducing indicators of the size and activity of nonbank financial institutions and by presenting measures of the size of bond and primary equity markets. This paper describes the sources, the construction and the intuition for the different indicators and presents descriptive statistics.},
title = {A new database on financial development and structure, Domestic Finance Working Paper 2146},
}

@article{1995LacherNeural,
author = {R. C. Lacher and Pamela K. Coats and Shanker C. Sharma and L. Franklin Fant},
abstract = {We present here a neural network applied to a universal business problem: the estimation of the future fiscal health of a corporation. The commonly used accounting and financial tool for such classification and prediction is a multiple discriminant analysis (MDA) of financial ratios. But the MDA technique has limitations based on its assumptions of linear separability, multivariate normality, and independence of the predictive variables. A neural network, being free from such constraining assumptions, is able to achieve superior results. Our neural network model is the Cascade-Correlation architecture recently developed by Scott E. Fahlman and Christian Lebiere at Carnegie Mellon University. This new approach solves the hidden architecture enigma encountered using other types of neural networks. Also, Cascade-Correlation manages error signals in a manner which significantly improves execution speed. Our research is the first to use Cascade-Correlation for corporate health estimation. \textcopyright 1995.},
journal = {European Journal of Operational Research},
number = {1},
title = {A neural network for classifying the financial health of a firm},
url = {http://linkinghub.elsevier.com/retrieve/pii/0377221793E02742},
volume = {85},
issn = {03772217},
doi = {10.1016/0377-2217(93)E0274-2},
year = {1995},
pages = {53--65},
keywords = {artificial intelligence,classification,forecasting,neural network},
mendeley-tags = {artificial intelligence,classification,forecasting,neural network},
}

@article{2015TeshniziComparison,
author = {Saeed Hosseini Teshnizi and Sayyed Mohhamad Taghi Ayatollahi},
journal = {Acta Informatica Medica},
volume = {23},
year = {2015},
abstract = {Background and objective: Artificial Neural Networks (ANNs) have recently been applied in situations where an analysis based on the logistic regression (LR) is a standard statistical approach; direct comparisons of the results, however, are seldom attempted. In this study, we compared both logistic regression models and feed-forward neural networks on the academic failure data set. Methods: The data for this study included 18 questions about study situation of 275 undergraduate students selected randomly from among nursing and midwifery and paramedic schools of Hormozgan University of Medical Sciences in 2013. Logistic regression with forward method and feed forward Artificial Neural Network with 15 neurons in hidden layer were fitted to the dataset. The accuracy of the models in predicting academic failure was compared by using ROC (Receiver Operating Characteristic) and classification accuracy. Results: Among nine ANNs, the ANN with 15 neurons in hidden layer was a better ANN compared with LR. The Area Under Receiver Operating Characteristics (AUROC) of the LR model and ANN with 15 neurons in hidden layers, were estimated as 0.55 and 0.89, respectively and ANN was significantly greater than the LR. The LR and ANN models respectively classified 77.5% and 84.3% of the students correctly. Conclusion: Based on this dataset, it seems the classification of the students in two groups with and without academic failure by using ANN with 15 neurons in the hidden layer is better than the LR model.},
number = {5},
title = {A comparison of logistic regression model and artificial neural networks in predicting of student's academic failure},
doi = {10.5455/aim.2015.23.296-300},
pages = {296--300},
url = {http://www.scopemed.org/fulltextpdf.php?mno=203919},
issn = {19865988},
keywords = {academic failure,artificial neural network,logistic regression},
mendeley-tags = {academic failure,artificial neural network,logistic regression},
}

@article{2018LehtinenNoise2noise,
author = {Jaakko Lehtinen and Jacob Munkberg and Jon Hasselgren and Samuli Laine and Tero Karras and Miika Aittala and Timo Aila},
issn = {23318422},
shorttitle = {Noise2Noise},
url = {http://arxiv.org/abs/1803.04189},
year = {2018},
abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning-learning to map corrupted observations to clean signals-with a simple and powerful conclusion: It is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans- A ll corrupted by different processes-based on noisy data only.},
journal = {arXiv},
title = {Noise2Noise: Learning Image Restoration without Clean Data},
}

@inproceedings{2018MasuyamaModal,
author = {Yoshiki Masuyama and Tsubasa Kusano and Kohei Yatabe and Yasuhiro Oikawa},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2018.8462350},
title = {Modal Decomposition of Musical Instrument Sound Via Alternating Direction Method of Multipliers},
url = {https://ieeexplore.ieee.org/document/8462350/},
year = {2018},
publisher = {IEEE},
volume = {2018-April},
abstract = {For a musical instrument sound containing partials, or modes, the behavior of modes around the attack time is particularly important. However, accurately decomposing it around the attack time is not an easy task, especially when the onset is sharp. This is because spectra of the modes are peaky while the sharp onsets need a broad one. In this paper, an optimization-based method of modal decomposition is proposed to achieve accurate decomposition around the attack time. The proposed method is formulated as a constrained optimization problem to enforce the perfect reconstruction property which is important for accurate decomposition. For optimization, the alternating direction method of multipliers (ADMM) is utilized, where the update of variables is calculated in closed form. The proposed method realizes accurate modal decomposition in the simulation and real piano sounds.},
isbn = {9781538646588},
pages = {631--635},
issn = {15206149},
keywords = {causality,constrained filtering,fourier transform,perfect reconstruction,piano},
mendeley-tags = {causality,constrained filtering,fourier transform,perfect reconstruction,piano},
}

@inproceedings{2017NecasovaSolving,
author = {Gabriela Ne\vcasov\'a and Filip Kocina and Petr Veigend and Jan Chaloupka and V\'aclav \vS\'atek and Jiř\'i Kunovsk\'y},
isbn = {9780735415386},
doi = {10.1063/1.4992649},
publisher = {Author(s)},
title = {Solving wave equation using finite differences and Taylor series},
volume = {1863},
booktitle = {AIP Conference Proceedings},
abstract = {The paper deals with the numerical solution of partial differential equations (PDEs), especially wave equation. Two methods are used to obtain numerical solution of the wave equation. The Finite Difference Method (FDM) is used for transformation of wave equation to the system of ordinary differential equations (ODEs), different types of difference formulas are used. The influence of arithmetic to higher order difference formulas is also presented. The Modern Taylor Series Method (MTSM) allows to solve ODEs numerically with extremely high precision. An important feature of this method is an automatic integration order setting, i.e. using as many Taylor series terms as the defined accuracy requires.},
issn = {15517616},
pages = {480013},
year = {2017},
}

@report{2017EisenachNonparametrically,
author = {Pakshal Bohra and Joaquim Campos and Harshit Gupta and Shayan Aziznejad and Michael Unser},
abstract = {We develop an efficient computational solution to train deep neural networks (DNN) with free-form activation functions. To make the problem well-posed, we augment the cost functional of the DNN by adding an appropriate shape regularization: the sum of the second-order total-variations of the trainable nonlinearities. The representer theorem for DNNs tells us that the optimal activation functions are adaptive piecewise-linear splines, which allows us to recast the problem as a parametric optimization. The challenging point is that the corresponding basis functions (ReLUs) are poorly conditioned and that the determination of their number and positioning is also part of the problem. We circumvent the difficulty by using an equivalent B-spline basis to encode the activation functions and by expressing the regularization as an $ell _1$-penalty. This results in the specification of parametric activation function modules that can be implemented and optimized efficiently on standard development platforms. We present experimental results that demonstrate the benefit of our approach.},
year = {2020},
booktitle = {IEEE Open Journal of Signal Processing},
pages = {295--309},
institution = {Princeton University},
volume = {1},
title = {Learning Activation Functions in Deep (Spline) Neural Networks},
doi = {10.1109/ojsp.2020.3039379},
type = {techreport},
keywords = {adaptive activation functions,deep neural network},
mendeley-tags = {adaptive activation functions,deep neural network},
}

@article{2018IshikawaGeometric,
author = {Ai Ishikawa and Dominik L. Michels and Takaharu Yaguchi},
abstract = {During the last decade, much attention has been given to sound rendering and the simulation of acoustic phenomena by solving appropriate models described by Hamiltonian partial differential equations. In this contribution, we introduce a procedure to develop appropriate tools inspired from geometric integration in order to simulate musical sounds. Geometric integrators are numerical integrators of excellent quality that are designed exclusively for Hamiltonian ordinary differential equations. The introduced procedure is a combination of two techniques in geometric integration: the semi-discretization method by Celledoni et al. (J Comput Phys 231:6770–6789, 2012) and symplectic partitioned Runge–Kutta methods. This combination turns out to be a right procedure that derives numerical schemes that are effective and suitable for computation of musical sounds. By using this procedure we derive a series of explicit integration algorithms for a simple model describing piano sounds as a representative example for virtual instruments. We demonstrate the advantage of the numerical methods by evaluating a variety of numerical test cases.},
volume = {35},
title = {Geometric-integration tools for the simulation of musical sounds},
number = {2},
issn = {1868937X},
year = {2018},
pages = {511--540},
doi = {10.1007/s13160-017-0292-6},
journal = {Japan Journal of Industrial and Applied Mathematics},
keywords = {acoustic phenomena,acoustic simulation,geometric integration,musical sounds,partitioned runge–kutta methods,separable hamiltonian system,sound rendering,sound simulation,symplectic integration,virtual instruments,virtual piano},
mendeley-tags = {acoustic phenomena,acoustic simulation,geometric integration,musical sounds,partitioned runge–kutta methods,separable hamiltonian system,sound rendering,sound simulation,symplectic integration,virtual instruments,virtual piano},
}

@article{2016MoriseWorld,
author = {Masanori Morise and Fumiya Yokomori and Kenji Ozawa},
volume = {E99D},
shorttitle = {WORLD},
journal = {IEICE Transactions on Information and Systems},
abstract = {A vocoder-based speech synthesis system, named WORLD, was developed in an effort to improve the sound quality of realtime applications using speech. Speech analysis, manipulation, and synthesis on the basis of vocoders are used in various kinds of speech research. Although several high-quality speech synthesis systems have been developed, real-time processing has been difficult with them because of their high computational costs. This new speech synthesis system has not only sound quality but also quick processing. It consists of three analysis algorithms and one synthesis algorithm proposed in our previous research. The effectiveness of the system was evaluated by comparing its output with against natural speech including consonants. Its processing speed was also compared with those of conventional systems. The results showed that WORLD was superior to the other systems in terms of both sound quality and processing speed. In particular, it was over ten times faster than the conventional systems, and the real time factor (RTF) indicated that it was fast enough for real-time processing.},
issn = {17451361},
pages = {1877--1884},
doi = {10.1587/transinf.2015EDP7457},
title = {WORLD: A vocoder-based high-quality speech synthesis system for real-time applications},
url = {https://www.jstage.jst.go.jp/article/transinf/E99.D/7/E99.D///////%5C%5C_2015EDP7457////////%5C%5C_article},
year = {2016},
number = {7},
keywords = {realtime processing,sound quality,speech analysis,speech synthesis,vocoder},
mendeley-tags = {realtime processing,sound quality,speech analysis,speech synthesis,vocoder},
}

@misc{2006DongFinite,
author = {Erik Schl\"ogl and Erik Schl\"ogl},
title = {Finite difference methods for partial differential equations},
url = {https://w3.pppl.gov/m3d/1dwave/2006-04-12///////%5C%5C_18.085///////%5C%5C_Wave.pdf},
year = {2019},
doi = {10.1201/9781315365435-5},
booktitle = {Quantitative Finance},
pages = {173--184},
}

@article{2015SouzaFilhoMusica,
author = {N. E. Souza Filho and B. A. Gon\ccalves and V. T. Oliveira},
issn = {01024744},
title = {M\'usica para estudantes de engenharia: S\'intese sonora de tema de jazz},
journal = {Revista Brasileira de Ensino de Fisica},
volume = {37},
doi = {10.1590/S1806-11173721804},
abstract = {The production of sound by acoustic musical instruments is caused by the vibration of a resonant structure that can be described by signal corresponding to the temporal evolution of the vibration associated with the sound pressure. The fact that the sound can be characterized by a set of signals, suggests that a device can generate sound and therefore imitate sounds of acoustic instruments. Such device is called a synthesizer, its main component in sound production is an oscillator. This work presents the synthesis of a classic theme of West Coast Jazz that has as peculiarity an odd metric. All the notes were identified in the score and synthesized on computer.},
number = {2},
pages = {2310--2313},
url = {http://www.scielo.br/scielo.php?script=sci///////%5C%5C_arttext///////%5C%5C&pid=S1806-11172015000200014///////%5C%5C&lng=pt///////%5C%5C&tlng=pt},
year = {2015},
shorttitle = {M\'usica para estudantes de engenharia},
keywords = {music,oscillations,sound synthesis,waves},
mendeley-tags = {music,oscillations,sound synthesis,waves},
}

@article{2015HilleHow,
author = {Adrian Hille and J\"urgen Schupp},
volume = {44},
issn = {02727757},
doi = {10.1016/j.econedurev.2014.10.007},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0272775714000995},
abstract = {Despite numerous studies on skill development, we know little about the effects of extracurricular music activities on cognitive and non-cognitive skills. This study examines how music training during childhood and youth affects the development of cognitive skills, school grades, personality, time use and ambition using data from the German Socio-Economic Panel (SOEP). Our findings suggest that adolescents with music training have better school grades, are more conscientious, open and ambitious. These effects are stronger among adolescents from lower socio-economic status. In order to address the non-random selection into playing music, we take into account detailed information on the child and its parents, which may determine both the decision to pursue music lessons and educational outcomes. While lacking truly exogenous variations in music activities, our results are robust to a large range of sensitivity tests. We thereby approach causality better than previous observational studies.},
journal = {Economics of Education Review},
pages = {56--82},
year = {2015},
title = {How learning a musical instrument affects the development of skills},
keywords = {cognitive and non-cognitive skills,educational achievement,music,soep},
mendeley-tags = {cognitive and non-cognitive skills,educational achievement,music,soep},
}

@article{2015ChatziioannouEnergy,
author = {Vasileios Chatziioannou and Maarten Van Walstijn},
doi = {10.1016/j.jsv.2014.11.017},
issn = {10958568},
journal = {Journal of Sound and Vibration},
title = {Energy conserving schemes for the simulation of musical instrument contact dynamics},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0022460X14009146},
pages = {262--279},
year = {2015},
volume = {339},
abstract = {Collisions are an innate part of the function of many musical instruments. Due to the nonlinear nature of contact forces, special care has to be taken in the construction of numerical schemes for simulation and sound synthesis. Finite difference schemes and other time-stepping algorithms used for musical instrument modelling purposes are normally arrived at by discretising a Newtonian description of the system. However because impact forces are non-analytic functions of the phase space variables, algorithm stability can rarely be established this way. This paper presents a systematic approach to deriving energy conserving schemes for frictionless impact modelling. The proposed numerical formulations follow from discretising Hamilton's equations of motion, generally leading to an implicit system of nonlinear equations that can be solved with Newton's method. The approach is first outlined for point mass collisions and then extended to distributed settings, such as vibrating strings and beams colliding with rigid obstacles. Stability and other relevant properties of the proposed approach are discussed and further demonstrated with simulation examples. The methodology is exemplified through a case study on tanpura string vibration, with the results confirming the main findings of previous studies on the role of the bridge in sound generation with this type of string instrument.},
}

@article{2013ParsaeianComparison,
author = {M. Parsaeian and K. Mohammad and M. Mahmoudi and H. Zeraati},
abstract = {Background: The purpose of this investigation was to compare empirically predictive ability of an artificial neural network with a logistic regression in prediction of low back pain. Methods: Data from the second national health survey were considered in this investigation. This data includes the information of low back pain and its associated risk factors among Iranian people aged 15 years and older. Artificial neural network and logistic regression models were developed using a set of 17294 data and they were validated in a test set of 17295 data. Hosmer and Lemeshow recommendation for model selection was used in fitting the logistic regression. A three-layer perceptron with 9 inputs, 3 hidden and 1 output neurons was employed. The efficiency of two models was compared by receiver operating characteristic analysis, root mean square and -2 Loglikelihood criteria. Results: The area under the ROC curve (SE), root mean square and -2Loglikelihood of the logistic regression was 0.752 (0.004), 0.3832 and 14769.2, respectively. The area under the ROC curve (SE), root mean square and -2Loglikelihood of the artificial neural network was 0.754 (0.004), 0.3770 and 14757.6, respectively. Conclusions: Based on these three criteria, artificial neural network would give better performance than logistic regression. Although, the difference is statistically significant, it does not seem to be clinically significant.},
journal = {Iranian Journal of Public Health},
pages = {86--92},
year = {2012},
issn = {22516093},
number = {6},
pmid = {23113198},
title = {Comparison of logistic regression and artificial neural network in low back pain prediction: Second national health survey},
volume = {41},
keywords = {artificial neural network,logistic regression,low back pain,second national health survey},
mendeley-tags = {artificial neural network,logistic regression,low back pain,second national health survey},
}

@article{2012HinrichsenEntropy,
author = {Haye Hinrichsen},
journal = {Revista Brasileira de Ensino de Fisica},
issn = {01024744},
arxivid = {1203.5101},
eprint = {1203.5101},
volume = {34},
pages = {1--8},
number = {2},
url = {http://www.scielo.br/scielo.php?script=sci///////%5C%5C_arttext///////%5C%5C&pid=S1806-11172012000200004///////%5C%5C&lng=en///////%5C%5C&tlng=en},
year = {2012},
archiveprefix = {arXiv},
doi = {10.1590/s1806-11172012000200004},
abstract = {The human sense of hearing perceives a combination of sounds 'in tune' if the corresponding harmonic spectra are correlated, meaning that the neuronal excitation pattern in the inner ear exhibits some kind of order. Based on this observation it is suggested that musical instruments such as pianos can be tuned by minimizing the Shannon entropy of suitably preprocessed Fourier spectra. This method reproduces not only the correct stretch curve but also similar pitch uctuations as in the case of high-quality aural tuning. \textcopyright by the Sociedade Brasileira de F\'isica.},
title = {Entropy-based tuning of musical instruments},
keywords = {acoustics,biophysics,classical physics},
mendeley-tags = {acoustics,biophysics,classical physics},
}

@article{2004SmithVirtual,
author = {Julius O. Smith},
abstract = {This article gives an overview of selected developments in musical sound synthesis based on physical models of musical instruments–sometimes called "virtual acoustic" sound synthesis. Emphasis is placed on techniques which yield the highest playability and sound quality in real time at a reasonable computational expense. \textcopyright 2004, Taylor & Francis Group, LLC.},
pages = {283--304},
number = {3},
title = {Virtual Acoustic Musical Instruments: Review and Update},
doi = {10.1080/0929821042000317859},
volume = {33},
issn = {17445027},
year = {2004},
journal = {Journal of New Music Research},
shorttitle = {Virtual Acoustic Musical Instruments},
}

@article{2010Bioucas-diasMultiplicative,
author = {Jos\'e M. Bioucas-Dias and M\'ario A.T. Figueiredo},
year = {2010},
eprint = {0912.1845},
journal = {IEEE Transactions on Image Processing},
title = {Multiplicative noise removal using variable splitting and constrained optimization},
volume = {19},
archiveprefix = {arXiv},
issn = {10577149},
abstract = {Multiplicative noise (also known as speckle noise) models are central to the study of coherent imaging systems, such as synthetic aperture radar and sonar, and ultrasound and laser imaging. These models introduce two additional layers of difficulties with respect to the standard Gaussian additive noise scenario: 1) the noise is multiplied by (rather than added to) the original image; 2) the noise is not Gaussian, with Rayleigh and Gamma being commonly used densities. These two features of multiplicative noise models preclude the direct application of most state-of-the-art algorithms, which are designed for solving unconstrained optimization problems where the objective has two terms: a quadratic data term (log-likelihood), reflecting the additive and Gaussian nature of the noise, plus a convex (possibly nonsmooth) regularizer (e.g., a total variation or wavelet-based regularizer/prior). In this paper, we address these difficulties by: 1) converting the multiplicative model into an additive one by taking logarithms, as proposed by some other authors; 2) using variable splitting to obtain an equivalent constrained problem; and 3) dealing with this optimization problem using the augmented Lagrangian framework. A set of experiments shows that the proposed method, which we name MIDAL (multiplicative image denoising by augmented Lagrangian), yields state-of-the-art results both in terms of speed and denoising performance. \textcopyright 2006 IEEE.},
number = {7},
pages = {1720--1730},
url = {http://arxiv.org/abs/0912.1845},
doi = {10.1109/TIP.2010.2045029},
arxivid = {0912.1845},
keywords = {augmented lagrangian,douglasa,multiplicative noise,rachford splitting,speckled images,synthetic aperture radar,total variation,variable splitting},
mendeley-tags = {augmented lagrangian,douglasa,multiplicative noise,rachford splitting,speckled images,synthetic aperture radar,total variation,variable splitting},
}

@article{2010MignotDigital,
author = {R\'emi Mignot and Thomas H\'elie and Denis Matignon},
number = {4},
url = {http://ieeexplore.ieee.org/document/5446589/},
shorttitle = {Digital Waveguide Modeling for Wind Instruments},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
issn = {15587916},
title = {Digital waveguide modeling for wind instruments: Building a statespace representation based on the websterlokshin model},
pages = {843--854},
year = {2010},
abstract = {This paper deals with digital waveguide modeling of wind instruments. It presents the application of statespace representations for the refined acoustic model of WebsterLokshin. This acoustic model describes the propagation of longitudinal waves in axisymmetric acoustic pipes with a varying cross-section, visco-thermal losses at the walls, and without assuming planar or spherical waves. Moreover, three types of discontinuities of the shape can be taken into account (radius, slope, and curvature). The purpose of this work is to build low-cost digital simulations in the time domain based on the WebsterLokshin model. First, decomposing a resonator into independent elementary parts and isolating delay operators lead to a KellyLochbaum network of input/output systems and delays. Second, for a systematic assembling of elements, their statespace representations are derived in discrete time. Then, standard tools of automatic control are used to reduce the complexity of digital simulations in the time domain. The method is applied to a real trombone, and results of simulations are presented and compared with measurements. This method seems to be a promising approach in term of modularity, complexity of calculation, and accuracy, for any acoustic resonators based on tubes. \textcopyright 2010 IEEE.},
doi = {10.1109/TASL.2009.2038671},
volume = {18},
keywords = {acoustic signal processing,acoustic waveguides,linear delay filters,partial differential equations,signal synthesis,statespace methods},
mendeley-tags = {acoustic signal processing,acoustic waveguides,linear delay filters,partial differential equations,signal synthesis,statespace methods},
}

@article{2009SchneiderNeural,
author = {Peter Schneider and Martina Wengenroth},
abstract = {With respect to enormous inter-individual differences in sound perception, this article aims to review the research background of the neural basis of individual sound perception. Principally, two basic listening types can be distinguished: 'holistic' or 'synthetic' listeners recognize the sound as a whole, and appreciate its pitch and timbre as characteristic qualities of the entire sound; and 'spectral' or 'analytical' listeners break up the sound into its harmonic constituents, at the expense of timbral qualities of the sound as a whole. In-between these two extreme listening modes, intermediate listeners perceive holistic and spectral cues simultaneously to varying degrees (auditory ambiguity). Several recent neurological investigations have pinpointed these perceptual differences to neuroanatomical and neurophysiological measures of the auditory cortex. Furthermore, it has been shown that individual auditory perception bias corresponds to musical instrument preference and musical performance style. Multimodal research findings point towards an individual 'fingerprint' of auditory cortex and perception profiles; however, whether these properties are shaped by intense training or rather reflect innate, genetically determined predisposition remains a matter of unresolved debate. \textcopyright 2009 Taylor & Francis.},
doi = {10.1080/07494460903404402},
issn = {07494467},
journal = {Contemporary Music Review},
year = {2009},
volume = {28},
pages = {315--328},
title = {The neural basis of individual holistic and spectral sound perception},
number = {3},
keywords = {heschl's gyrus,interindividual variability,pitch,sound perception,timbre},
mendeley-tags = {heschl's gyrus,interindividual variability,pitch,sound perception,timbre},
}

@article{2008CharlesTutorial,
author = {Jean Fran\ccois Charles},
title = {A tutorial on spectral sound processing using Max/MSP and jitter},
volume = {32},
journal = {Computer Music Journal},
issn = {01489267},
pages = {87--102},
year = {2008},
doi = {10.1162/comj.2008.32.3.87},
number = {3},
}

@article{2007ParentCase,
author = {Milena M. Parent and David L. Deephouse},
doi = {10.1007/s10551-007-9533-y},
year = {2007},
issn = {01674544},
pages = {1--23},
number = {1},
abstract = {The purpose of this article is to examine stakeholder identification and prioritization by managers using the power, legitimacy, and urgency framework of Mitchell et al. (Academy of Management Review 22, 853-886; 1997). We use a multi-method, comparative case study of two large-scale sporting event organizing committees, with a particular focus on interviews with managers at three hierarchical levels. We support the positive relationship between number of stakeholder attributes and perceived stakeholder salience. Managers' hierarchical level and role have direct and moderating effects on stakeholder identification and perceived salience. We also found that most stakeholders were definitive, dominant, or dormant types - the other five types were rare. Power has the most important effect on salience, followed by urgency and legitimacy. Based on our case study, we offer several ways to advance the theory of stakeholder identification and salience. \textcopyright 2007 Springer Science+Business Media B.V.},
title = {A case study of stakeholder identification and prioritization by managers},
journal = {Journal of Business Ethics},
volume = {75},
keywords = {case study,interview data,relationship,stakeholder,stakeholder management,stakeholder theory},
mendeley-tags = {case study,interview data,relationship,stakeholder,stakeholder management,stakeholder theory},
}

@article{kandus_fisica_nodate,
author = { K and Alej us and  ra and Friedrich Wolfgang Gutmann and Caio M\'ario Castro de Castilho},
title = {A f\'isica das oscila\cc\~oes mec\^anicas em instrumentos musicais: Exemplo do berimbau},
volume = {28},
pages = {427--433},
issn = {01024744},
number = {4},
doi = {10.1590/S0102-47442006000400004},
journal = {Revista Brasileira de Ensino de Fisica},
year = {2006},
abstract = {In this work it is discussed the wave propagation in an elastic medium, particularly along strings and the air. The basic principles of the wave propagation are presented, taking as an example case a typical instrument from the state of Bahia, well known by all Brazilians, the berimbau. Copyright by the Sociedade Brasileira de F\'isica.},
keywords = {berimbau,mechanical oscillations,musical instruments},
mendeley-tags = {berimbau,mechanical oscillations,musical instruments},
}

@article{erkut_finite_nodate,
author = {Erkut Cumhur and Matti Karjalainen and Cumhur Erkut and Matti Karjalainen},
volume = {10},
year = {2002},
abstract = {The one-dimensional digital waveguides, combined with the commuted synthesis method, allow modeling and high-quality synthesis of plucked string instrument tones in a very efficient manner. However, the increasing computational power of the modern processors makes it feasible to experiment with more complex algorithms also for real-time sound synthesis purposes. By certain simplifications, time-domain methods based on finite differences (FDTD) are efficient enough to run in real time on modern processors and yet they are more flexible than the computationally less expensive commuted synthesis. The resulting structures, which are called 1-D FDTD waveguides, have previously been shown to be equal to or to approximate many properties of digital waveguides, including lossless and lossy propagation, input and output ports, terminations, and scattering junctions. The numerical stability of the 1-D FDTD waveguides, as well as their initialization and formation of the traveling waves are well understood. However, a careful comparison between 1-D FDTD waveguides and conventional digital waveguides in terms of their limitations, computational efficiency, accuracy, and interaction has not been carried out. The aim of this paper is to fill this gap by highlighting important properties of both methods side by side in string instrument modeling and synthesis. We then try to combine the best properties of both methods and discuss the interaction of the two model structures. Synthetic tones and short musical phrases obtained by both synthesis models will be demonstrated during the presentation. These sound examples will also be available at http://www.acoustics.hut.fi/demos/.},
title = {Finite Difference Method vs. Digital Waveguide Method In String Instrument Modeling and Synthesis},
isbn = {929043452X},
number = {1},
journal = {Audio},
pages = {4},
url = {http://www.acoustics.hut.fi/$\sim$mak/PUB/ISMA2002_Erkut.pdf},
}

@article{monti_department_2000,
author = {David J Moore and Environmental Monitoring},
journal = {North},
title = {Department of Geography King's College London, Strand, London WC2R 2LS, UK},
year = {2010},
abstract = {This paper describes an algorithm, which performs monophonic music transcription. A pitch tracker calculates the fundamental frequency of the signal from the autocorrelation function. A continuity-restoration block takes the extracted pitch and determines the score corresponding to the original performance. The signal envelope analysis completes the transcription system, calculating attack-sustain-decay-release times, which improves the synthesis process. Attention is also paid to the extraction of timbre and wavetable synthesis.},
pages = {1--2},
}

@article{1999AgleWho,
author = {Bradley R. Agle and Ronald K. Mitchell and Jeffrey A. Sonnenfeld},
title = {Who matters to CEOs? An investigation of stakeholder attributes and salience, corporate performance, and CEO values},
journal = {Academy of Management Journal},
doi = {10.2307/256973},
volume = {42},
issn = {00014273},
year = {1999},
pages = {507--525},
number = {5},
abstract = {Using unique data provided by the CEOs of 80 large U.S. firms, we examined relationships among the stakeholder attributes of power, legitimacy, urgency, and salience; CEO values; and corporate performance. We found strong support for the attribute-salience relationship and some significant relationships among CEO values, salience, and corporate social performance but found no support for a salience-financial performance link. Our findings suggest a need for continued emphasis on the development of normative stakeholder theory.},
}

@article{2004Costa-giomiEffects,
author = {Eugenia Costa-Giomi},
doi = {10.1177/0305735604041491},
issn = {17413087},
journal = {Psychology of Music},
abstract = {This study of the effects of three years of piano instruction is based on a sample of 117 fourth-grade children attending public schools in Montreal. The children had never participated in formal music instruction, did not have a piano at home, and their annual family income was below $40,000 Can. Children in the experimental group (n= 63) received individual piano lessons weekly for three years and were given an acoustic piano at no cost to their families. Children in the control group (n= 54) did not participate in formal music instruction. Participants were administered tests of self-esteem, academic achievement, cognitive abilities, musical abilities, and motor proficiency at the beginning of the project and throughout the three years of piano instruction. The results indicated that piano instruction had a positive effect on children's self-esteem and school music marks but did not affect their academic achievement in math and language as measured by standardized tests and school report cards. Copyright \textcopyright 2004 Society for Education, Music and Psychology Research.},
year = {2004},
title = {Effects of three years of piano instruction on children's academic achievement, school performance and self-esteem},
volume = {32},
pages = {139--152},
number = {2},
keywords = {academic achievement,children,language,math,music education,music instruction},
mendeley-tags = {academic achievement,children,language,math,music education,music instruction},
}

@article{2015LixinConstruction,
author = {Lixin Zhang and Long Wang},
number = {1},
issn = {1874110X},
url = {http://benthamopen.com/ABSTRACT/TOCSJ-9-2055},
journal = {Open Cybernetics and Systemics Journal},
year = {2015},
title = {Construction of the logistic regression estimation model in early warning on pure financial indicators},
volume = {9},
abstract = {In order to establish a reasonable and effective financial crisis early warning model, the article chooses some financial indicators and uses factor analysis to get the common factors to conduct the most salient financial indicators. In the case that multirole linearity is not significant, the article uses the logistic regression to analyse eligible financial data and obtains the financial crisis warning model. Then the article found that this model has a high predictive accuracy.},
pages = {2055--2059},
doi = {10.2174/1874110X01509012055},
keywords = {early warning,experimental analysis,factor analysis,financial indicators,logistic regression estimation},
mendeley-tags = {early warning,experimental analysis,factor analysis,financial indicators,logistic regression estimation},
}

@book{2011JensenComputational,
author = {Finn B. Jensen and William A. Kuperman and Michael B. Porter and Henrik Schmidt},
title = {Computational Ocean Acoustics},
year = {2011},
booktitle = {Computational Ocean Acoustics},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
isbn = {978-1-4419-8677-1 978-1-4419-8678-8},
publisher = {Springer New York},
doi = {10.1007/978-1-4419-8678-8},
}

@article{SalihSecond,
author = {A Salih},
pages = {24},
title = {Second-Order Wave Equation},
}

@misc{2005KnutWave,
author = {Knut-Andreas Lie},
year = {2005},
title = {The Wave Equation in 1D and 2D},
pages = {48},
booktitle = {Spring},
}

@article{2012SimicInsolvency,
author = {Dragan Simi\'c and Ilija Kova\vcevi\'c and Svetlana Simi\'c},
issn = {13689894},
journal = {Logic Journal of the IGPL},
abstract = {The prediction of corporate financial failure, crucial for the prevention and mitigation of economic downturns in a national economy, requires the categorization of healthy and unhealthy companies. This study examines the case of Serbia and applies multivariant statistical methods and specific artificial neural network architectures-the self-organizing map (SOM)-to assess the corporate financial health of various companies. Financial ratios drawn from corporate balance sheets become the independent variables in a multivariate discriminant analysis (MDA). These financial ratios and the discriminant Z-score in the MDA form the input for the SOM, which creates a hybrid MDA-SOM model that is capable of predicting corporate financial insolvency. The experimental results of this research correctly estimate company financial health in 95% of cases. These are reliable predictions that are comparable with similar studies in other countries. \textcopyright The Author 2011. Published by Oxford University Press. All rights reserved.},
number = {3},
pages = {536--549},
title = {Insolvency prediction for assessing corporate financial health},
volume = {20},
doi = {10.1093/jigpal/jzr009},
year = {2012},
keywords = {corporate financial health,corporate insolvency,multivariate discriminant analysis,self-organized maps},
mendeley-tags = {corporate financial health,corporate insolvency,multivariate discriminant analysis,self-organized maps},
}

@article{2011MokhatabRafieiFinancial,
author = {F. Mokhatab Rafiei and S. M. Manzari and S. Bostanian},
volume = {38},
year = {2011},
abstract = {The purpose of this study is to design a model to predict financial health of companies. Financial ratios for 180 manufacturing companies quoted in Tehran Stock Exchange for one year (year ended March 21, 2008) have been used. Three models; based on artificial neural networks (ANN), genetic algorithm (GA), and multiple discriminant analysis (MDA) are utilized to classify the bankrupt from non bankrupt corporations. ANN model achieved 98.6% and 96.3% accuracy rates in training and holdout samples, respectively. To evaluate the reliability of the model, the data were examined with genetic algorithm and Multivariate discriminate analysis method. GA model attained only 92.5% and 91.5% accuracy rates and MDA reached 80.6% and 79.9 in training and holdout samples, respectively. \textcopyright 2011 Published by Elsevier Ltd.},
journal = {Expert Systems with Applications},
number = {8},
shorttitle = {Financial health prediction models using artificial neural networks, genetic algorithm and multivariate discriminant analysis},
pages = {10210--10217},
issn = {09574174},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417411002880},
doi = {10.1016/j.eswa.2011.02.082},
title = {Financial health prediction models using artificial neural networks, genetic algorithm and multivariate discriminant analysis: Iranian evidence},
keywords = {artificial neural networks,discriminant analysis,financial health prediction,financial ratios,genetic algorithm,iranian company},
mendeley-tags = {artificial neural networks,discriminant analysis,financial health prediction,financial ratios,genetic algorithm,iranian company},
}

@article{freitas_universidade_nodate,
author = {Universidade Federal Fluminense and Escola D E Engenharia},
title = {Universidade federal fluminense escola de engenharia departamento de engenharia qu\'imica},
year = {2011},
pages = {133},
}

@article{ghosh_comparative_nodate,
author = {Arka Ghosh},
abstract = {— Financial forecasting is an example of a signal processing problem w hi ch is challenging due to Small sizes, high noi se, non-stationarity, and non-linearity,but fast forecasting of stock market price is very important for strategi c business planning.Present study is aimed to develop a comparative predictive model w ith Feedforward Multilayer Arti ficial Neural Netw ork & Recurr ent Time Delay Neural Netw ork for the Financial Timeseries Prediction.This study is developed with the help of histori cal stockprice dataset made a vailable by GoogleFinance.To develop this prediction model Backpropagation method w ith Gradient Descent learning has been implemented.Finally the Neural Net ,learned w ith said algorithm is found to be skillful predictor for non-stationary noisy Financial Timeseries. Over past fifteen years, a view has emerged that computing based on models inspired by our understanding of the structure and function of the biological neural networks may hold the key to the success of solving intelligent tasks by machines like noisy time series prediction and more[1]. A neural network is a massively parallel distributed processor that has a natural propensity for storing experiential knowledge and making it available for use. It resembles the brain in two respects: Knowledge is acquired by the network through a learning process and interneuron connection strengths known as synaptic weights are used to store the knowledge[2]. Moreover, recently the Markets have become a more accessible investment tool, not only for strategic investors but for common people as well. Consequently they are not only related to macroeconomic parameters, but they influence everyday life in a more direct way. Therefore they constitute a mechanism which has important and direct social impacts. The characteristic that all Stock Markets have in common is the uncertainty, which is related with their short and long-term future state. This feature is undesirable for the investor but it is also unavoidable whenever the Stock Market is selected as the investment tool. The best that one can do is to try to reduce this uncertainty. Stock Market Prediction (or Forecasting) is one of the instruments in this process. We cannot exactly predict what will happen tomorrow, but from previous experiences we can roughly predict tomorrow. In this paper this knowledge based approach is taken. The accuracy of the predictive system which is made by ANN can be tuned with help of different network architectures. Network is consists of input layer ,hidden layer & output layer of neuron, no of neurons per layer can be configured according to the needed result accuracy & throughput,there is no cut & bound rule for that.the network can be trained by using sample training data set,this neural network model is very much useful for mapping unknown functional dependencies between different input & output tuples.In this paper two types of neural network architecture,feed forward multilayer network & timedelay recurrent network is used for the prediction of the NASDAQ stock price.A comparative error study for both network architecture is introduced in this paper.},
pages = {7},
year = {2011},
title = {Comparative study of Financial Time Series Prediction by Artificial Neural Network with Gradient Descent Learning},
keywords = {computer science - artificial intelligence,computer science - neural and evolutionary computing},
mendeley-tags = {computer science - artificial intelligence,computer science - neural and evolutionary computing},
}

@article{2015VakhtinaCapital,
author = {Elena Vakhtina and Jan Henrik Wosnitza},
year = {2015},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437114005937},
abstract = {In this investigation, we examine the univariate as well as the multivariate capabilities of the log-periodic [super-exponential] power law (LPPL) for the prediction of bank runs. The research is built upon daily CDS spreads of 40 international banks for the period from June 2007 to March 2010, i.e. at the heart of the global financial crisis. For this time period, 20 of the financial institutions received federal bailouts and are labeled as defaults while the remaining institutions are categorized as non-defaults. The employed multivariate pattern recognition approach represents a modification of the CORA3 algorithm. The approach is found to be robust regardless of reasonable changes of its inputs. Despite the fact that distinct alarm indices for banks do not clearly demonstrate predictive capabilities of the LPPL, the synchronized alarm indices confirm the multivariate discriminative power of LPPL patterns in CDS spread developments acknowledged by bootstrap intervals with 70% confidence level.},
title = {Capital market based warning indicators of bank runs},
issn = {03784371},
doi = {10.1016/j.physa.2014.07.024},
volume = {417},
pages = {304--320},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {bank run prediction,cora3 algorithm,credit default swap spreads,econophysics,log-periodic [super-exponential] power law,phase transition},
mendeley-tags = {bank run prediction,cora3 algorithm,credit default swap spreads,econophysics,log-periodic [super-exponential] power law,phase transition},
}

@article{2013AliajBank’s,
author = {Ada Aliaj and Ilir Hoti},
volume = {4},
doi = {10.5901/mjss.2013.v4n10p490},
year = {2013},
issn = {20399340},
title = {Bank's rating a need or necessity in Albanian Banking System},
number = {10},
url = {http://www.mcser.org/journal/index.php/mjss/article/view/1219},
abstract = {Financial Transactions have increased and have become more complex over this 20 years. This paper examines the importance of credit ratings assigned to banks in Europe and the positive and negative impacts. We will also see Albanian Banking system over the last 5 years focusing on the risks it faces. The aim of this article is to analyze and identify the importance of Banks' Rating. Actually, banks are the dominant sector within Albanian financial system, managing more than 95.5% of total financial assets. Although banks sometimes use internal models as a substitute for credit ratings for their credit assessments, the internal models themselves often tend to rely heavily on ratings for actual or methodological input. Investors' reliance on credit ratings has increased over the past 30 years. Acquiring information is costly, particularly for fixed income investors, given collective action problems. Thus investors seek to outsource creditworthiness assessments to rating agencies. Finally we will see if there is a need of Banks Rating in Albanian's Banks, the requirements of Basel III and the regulatory of the Bank of Albania.},
journal = {Mediterranean Journal of Social Sciences},
pages = {490--496},
keywords = {banking system,credit rating,rating agencies},
mendeley-tags = {banking system,credit rating,rating agencies},
}

@article{los_atendimento_nodate,
author = {Geovana Zimmermann Los and Ernani Ott and Patr\'icia Schneider Severo and Jo\~ao Eduardo Prud\^encio Tinoco},
volume = {2},
journal = {Revista De Tecnologia Aplicada (Rta)},
issn = {2237-3713},
title = {Atendimento de institui\cc\~oes financeiras \`as recomenda\cc\~oes de evidencia\cc\~ao ambiental da Global Reporting Initiative (GRI)},
number = {2},
year = {2013},
abstract = {Este artigo descreve o comportamento de cinco institui\cc\~oes financeiras pertencentes \`a carteira do \'Indice de Sustentabilidade Empresarial (ISE) da BM&FBovespa do ano de 2011 quanto ao atendimento ao que preceitua a Global Reporting Initiative (GRI) - Suplemento Setorial de Servi\ccos Financeiros (SSSF) sobre a evidencia\cc\~ao nos Relat\'orios de Sustentabilidade de informa\cc\~oes de car\'ater ambiental. A pesquisa \'e aplicada, qualitativa, descritiva e documental, tendo-se adotado a t\'ecnica de an\'alise de conte\'udo. Os resultados do estudo revelam que as divulga\cc\~oes realizadas pelas institui\cc\~oes financeiras da amostra s\~ao aderentes ao que estabelece o padr\~ao verificado, pois a quase totalidade faz refer\^encia aos indicadores. No entanto, quanto \`as unidades de medida evidenciadas pelas institui\cc\~oes nos indicadores n\~ao h\'a estabelecimento de um padr\~ao, o que dificulta a compara\cc\~ao da pr\'opria institui\cc\~ao em rela\cc\~ao ao consumo do exerc\'icio atual e do anterior, bem como a compara\cc\~ao entre as institui\cc\~oes.},
pages = {58--80},
keywords = {evidencia\cc\~ao ambiental 2. global reporting initiat,servi\ccos financeiros. 4. \'indice de sustentabili},
mendeley-tags = {evidencia\cc\~ao ambiental 2. global reporting initiat,servi\ccos financeiros. 4. \'indice de sustentabili},
}

@article{esumo_alise_nodate,
author = {Silvana Karina and De Melo Travassos},
title = {An\'alise Comparativa Dos Relat\'orios De Sustentabilidade Do Global Reporting Initiative Com \^Enfase Nas Empresas De Capital},
abstract = {The environmental matter has been studied in several areas of the scientific knowledge due the scenery of development,. In this sense, the Global Reporting Initiative (GRI), an independent organization, is developing a strategic world-wide accepted model through guidelines based on principles. The goal of this article is identify the behavioral diversities regarding to the economic and environmental aspects of the partner capital open companies acting in Brazil that adopt GRI's Guidelines. Besides advancing, this global net which is ruled in sustainability allow that the companies choose the indicative they want to report, and also it does not demand the submission of reports to the external audit. The methodology of the research is data rising and bibliographical, with exploratory purpose. It was identified that GRI's Indicators contributes for the sustainable development as well as guarantee the inevitable tendency consisting in what is demonstrated, corresponding to the reality of the open capital companies with performance in Brazil, country that prioritizes GRI's Principles.},
url = {http://veredas.favip.edu.br/ojs/index.php/veredas1/article/download/124/99},
journal = {Veredas Favip-Revista  \ldots},
year = {2013},
pages = {14},
keywords = {an\'alise comparativa dos relat\'orios,de sustentabilidade do global,global reporting initiative,nas,open capital companies,reporting initiative com \^enfase,sustainable development},
mendeley-tags = {an\'alise comparativa dos relat\'orios,de sustentabilidade do global,global reporting initiative,nas,open capital companies,reporting initiative com \^enfase,sustainable development},
}

@book{2009ClarkePrinciples,
author = {Liliana L\'opez Kleine},
isbn = {978-0-387-98134-5 978-0-387-98135-2},
series = {Springer series in statistics},
title = {Principles and Theory for Data Mining and Machine Learning},
annote = {OCLC: ocn440103793},
publisher = {Springer},
issn = {1467-985X},
number = {3},
abstract = {The idea for this book came from the time the authors spent at the Statistics and Applied Mathematical Sciences Institute (SAMSI) in Research Triangle Park in North Carolina starting in fall 2003. The rst author was there for a total of two years, the rst year as a Duke/SAMSI Research Fellow. The second author was there for a year as a Post-Doctoral Scholar. The third author has the great fortune to be in RTP p- manently. SAMSI was – and remains – an incredibly rich intellectual environment with a general atmosphere of free-wheeling inquiry that cuts across established elds. SAMSI encourages creativity: It is the kind of place where researchers can be found at work in the small hours of the morning – computing, interpreting computations, and developing methodology. Visiting SAMSI is a unique and wonderful experience. The people most responsible for making SAMSI the great success it is include Jim Berger, Alan Karr, and Steve Marron. We would also like to express our gratitude to Dalene Stangl and all the others from Duke, UNC-Chapel Hill, and NC State, as well as to the visitors (short and long term) who were involved in the SAMSI programs. It was a magical time we remember with ongoing appreciation.},
booktitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
doi = {10.1111/j.1467-985x.2010.00646_3.x},
pages = {691--692},
year = {2010},
volume = {173},
keywords = {data mining,data mining,machine learning,maschinelles lernen,statistical methods,statistik},
mendeley-tags = {data mining,data mining,machine learning,maschinelles lernen,statistical methods,statistik},
}

@book{2002AgrestiCategorical,
author = {S. D. Withers},
edition = {2nd ed},
year = {2009},
abstract = {This article describes the origins of categorical data analysis and the main categorical methods applied in geographic and regional science research. After introducing important terminology by using a 2×2 contingency table, categorical methods are reviewed for two distinctive situations - association and prediction. First, loglinear models are reviewed as a method of assessing associations and likelihoods among a set of categorical variables. Second, logistic regression is reviewed as a method for predicting the probability of a dichotomous response variable from among predictor variables. Additional approaches to categorical data analysis, such as the conditional logit, the multinomial logit, probit, and lograte models, are also discussed. The article concludes by describing recent developments in spatially explicit versions of categorical data methods for geographical research.},
series = {Wiley series in probability and statistics},
isbn = {9780080449104},
pages = {456--462},
publisher = {Wiley-Interscience},
booktitle = {International Encyclopedia of Human Geography},
title = {Categorical Data Analysis},
doi = {10.1016/B978-008044910-4.00409-0},
keywords = {contingency table,hierarchical models,logistic regression,logit,loglinear models,lograte models,maximum likelihood estimation,odds ratio,probit},
mendeley-tags = {contingency table,hierarchical models,logistic regression,logit,loglinear models,lograte models,maximum likelihood estimation,odds ratio,probit},
}

@book{2015YeeVector,
author = {Thomas W. Yee},
year = {2015},
publisher = {Springer},
doi = {10.1007/978-1-4939-2818-7},
series = {Springer series in statistics},
shorttitle = {Vector generalized linear and additive models},
booktitle = {Vector Generalized Linear and Additive Models: With an Implementation in R},
title = {Vector Generalized Linear and Additive Models: With an Implementation in R},
annote = {OCLC: ocn907271683},
isbn = {9781493928187},
pages = {1--589},
abstract = {This book presents a greatly enlarged statistical framework compared to generalized linear models (GLMs) with which to approach regression modelling. Comprising of about half-a-dozen major classes of statistical models, and fortified with necessary infrastructure to make the models more fully operable, the framework allows analyses based on many semi-traditional applied statistics models to be performed as a coherent whole. Since their advent in 1972, GLMs have unified important distributions under a single umbrella with enormous implications. However, GLMs are not flexible enough to cope with the demands of practical data analysis. And data-driven GLMs, in the form of generalized additive models (GAMs), are also largely confined to the exponential family. The methodology here and accompanying software (the extensive VGAM R package) are directed at these limitations and are described comprehensively for the first time in one volume. This book treats distributions and classical models as generalized regression models, and the result is a much broader application base for GLMs and GAMs. The book can be used in senior undergraduate or first-year postgraduate courses on GLMs or categorical data analysis and as a methodology resource for VGAM users. In the second part of the book, the R package VGAM allows readers to grasp immediately applications of the methodology. R code is integrated in the text, and datasets are used throughout. Potential applications include ecology, finance, biostatistics, and social sciences. The methodological contribution of this book stands alone and does not require use of the VGAM package.},
keywords = {datenverarbeitung,hochleistungsrechnen,linear models (statistics,lineares modell,regression analysis,statistisches modell,vector spaces,wahrscheinlichkeitstheorie},
mendeley-tags = {datenverarbeitung,hochleistungsrechnen,linear models (statistics,lineares modell,regression analysis,statistisches modell,vector spaces,wahrscheinlichkeitstheorie},
}

@article{1979DeMeersmanLeast,
author = {R. De Meersman},
abstract = {It is shown how a least squares problem subject to equality constraints can be replaced by an unconstrained least squares problem. Constraints and equations may be non linear. Results seem to be too complicated to be applied to general cases but can quite successfully be used for special problems like the closing of balances for instance. \textcopyright 1979.},
url = {https://linkinghub.elsevier.com/retrieve/pii/0771050X79900445},
journal = {Journal of Computational and Applied Mathematics},
doi = {10.1016/0771-050X(79)90044-5},
issn = {0771050X},
pages = {277--281},
title = {Least squares with non-linear equality constraints Application to closing of balances},
volume = {5},
year = {1979},
number = {4},
}

@book{2014PoularikasAdaptive,
author = {Alex Poularikas and er D.},
publisher = {CRC Press},
pages = {1--343},
title = {Adaptive filtering: Fundamentals of least mean squares with MATLAB\textregistered},
doi = {10.1201/b17464},
abstract = {Adaptive filters are used in many diverse applications, appearing in everything from military instruments to cellphones and home appliances. Adaptive Filtering: Fundamentals of Least Mean Squares with MATLAB\textregistered covers the core concepts of this important field, focusing on a vital part of the statistical signal processing area-the least mean square (LMS) adaptive filter. This largely self-contained text: • Discusses random variables, stochastic processes, vectors, matrices, determinants, discrete random signals, and probability distributions • Explains how to find the eigenvalues and eigenvectors of a matrix and the properties of the error surfaces • Explores the Wiener filter and its practical uses, details the steepest descent method, and develops the Newton's algorithm • Addresses the basics of the LMS adaptive filter algorithm, considers LMS adaptive filter variants, and provides numerous examples • Delivers a concise introduction to MATLAB\textregistered, supplying problems, computer experiments, and more than 110 functions and script files Featuring robust appendices complete with mathematical tables and formulas, Adaptive Filtering: Fundamentals of Least Mean Squares with MATLAB\textregistered clearly describes the key principles of adaptive filtering and effectively demonstrates how to apply them to solve real-world problems.},
shorttitle = {Adaptive Filtering},
booktitle = {Adaptive Filtering: Fundamentals of Least Mean Squares with MATLAB},
isbn = {9781482253368},
url = {https://www.taylorfrancis.com/books/9781482253368},
year = {2017},
}

@article{2014StankovicInstantaneous,
author = {Ljubi\vsa Stankovi\'c and Igor Djurovi\'c and Srdjan Stankovi\'c and Marko Simeunovi\'c and Slobodan Djukanovi\'c and Milo\vs Dakovi\'c},
doi = {10.1016/j.dsp.2014.09.008},
abstract = {The instantaneous frequency (IF) is a very important feature of nonstationary signals in numerous applications. The first overview of the concept and application of the IF estimators is presented in seminal papers by Boashash. Since then, a significant knowledge has been gained about the performance of the IF estimators. This knowledge has been used not only for development of various IF estimators but also for introduction of novel time-frequency (TF) representations. The IF estimation in environments characterized by low signal-to-noise (SNR) has achieved significant benefits from these theoretical developments. In this paper, we review some of the most important developments in the last two decades related to the concept of the IF, performance analysis of IF estimators, and development of IF estimators for low SNR environments.},
title = {Instantaneous frequency in time-frequency analysis: Enhanced concepts and performance of estimation algorithms},
pages = {1--13},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1051200414002838},
volume = {35},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
shorttitle = {Instantaneous frequency in time–frequency analysis},
year = {2014},
keywords = {instantaneous frequency,non-parametric estimation,parametric estimation,robust estimation,time-frequency signal analysis},
mendeley-tags = {instantaneous frequency,non-parametric estimation,parametric estimation,robust estimation,time-frequency signal analysis},
}

@book{2004StrikwerdaFinite,
author = {V. T. and John C. Strikwerda},
doi = {10.2307/2008454},
booktitle = {Mathematics of Computation},
publisher = {Society for Industrial and Applied Mathematics},
abstract = {This book provides a unified and accessible introduction to the basic theory of finite difference schemes applied to the numerical solution of partial differential equations. Originally published in 1989, its objective remains to clearly present the basic methods necessary to perform finite difference schemes and to understand the theory underlying the schemes. Finite Difference Schemes and Partial Differential Equations, Second Edition is one of the few texts in the field to not only present the theory of stability in a rigorous and clear manner but also to discuss the theory of initial-boundary value problems in relation to finite difference schemes. Fourier analysis is used throughout the book to give a unified treatment of many of the important ideas found in the first eleven chapters. The material on elliptic partial differential equations found in the later chapters provides an introduction that will enable students to progress to more advanced texts and to knowledgeably implement the basic methods. This updated edition includes several important modifications. stability and is more prevalent throughout the book. The author has added many new figures and tables to clarify important concepts and illustrate the properties of finite difference schemes.},
isbn = {978-0-89871-567-5},
issn = {00255718},
title = {Finite Difference Schemes and Partial Differential Equations.},
year = {1990},
number = {192},
pages = {869},
volume = {55},
edition = {2nd ed},
keywords = {differential equations,finite differences,numerical solutions,partial},
mendeley-tags = {differential equations,finite differences,numerical solutions,partial},
}

@article{zhdanov_solving_nodate,
author = {Aleks Zhdanov and r Ivanovich and Sofya Yuryevna Gogoleva},
volume = {15},
issn = {16072510},
journal = {Applied Mathematics E - Notes},
abstract = {This article is devoted to a new algorithm for solving least squares problems with linear equality constraints. The presented algorithm can help solve large dimension ill-conditioned problems e¢ ciently.},
pages = {218--224},
title = {Solving least squares problems with equality constraints based on augmented regularized normal equations},
year = {2016},
}

@article{2013RiskusImproved,
author = {Aleksas Ri\vskus and Giedrius Liutkus},
title = {An improved algorithm for the approximation of a cubic Bezier curve and its application for approximating quadratic Bezier curve},
issn = {1392124X},
url = {http://www.itc.ktu.lt/index.php/ITC/article/view/1707},
journal = {Information Technology and Control},
pages = {302--308},
number = {4},
volume = {42},
doi = {10.5755/j01.itc.42.4.1707},
abstract = {In this paper an improved version of an earlier proposed algorithm for approximating cubic Bezier curve by a set of circular arcs is presented. It is investigated how the improved algorithm fits for approximation of quadratic Bezier curves. These issues occur in CAD/CAM systems during data exchange into data formats which do not support Bezier curves. Experimental results on examples, widely used in the sources enlisted in references, are presented. Two typographical errors, made in the previous article, are corrected.},
year = {2013},
keywords = {approximation,bezier curve,circular arc,control point},
mendeley-tags = {approximation,bezier curve,circular arc,control point},
}

@book{2011BeckSociedade,
author = {Ulrich Beck},
annote = {OCLC: 753356287},
title = {Sociedade de Risco: rumo a uma outra Modernidade},
year = {2011},
isbn = {8573264500},
number = {2},
booktitle = {Editora 34},
abstract = {Literaturangaben},
shorttitle = {Sociedade de risco},
pages = {384},
publisher = {Editora 34},
}

@book{2017HorstmannScala,
author = {C Horstmann},
isbn = {9780321774095},
annote = {OCLC: ocn964820811},
pages = {113},
publisher = {Addison-Wesley},
abstract = {Scala is a modern programming language for the Java Virtual Machine (JVM) that combines the best features of object-oriented and functional programming languages. Using Scala, you can write programs more concisely than in Java, as well as leverage the full power of concurrency. Since Scala runs on the JVM, it can access any Java library and is interoperable with Java frameworks.       Scala for the Impatient   concisely shows developers what Scala can do and how to do it. In this book, Cay Horstmann, the principal author of the international best-selling Core Java™, offers a rapid, code-based introduction that's completely practical. Horstmann introduces Scala concepts and techniques in "blog-sized" chunks that you can quickly master and apply. Hands-on activities guide you through well-defined stages of competency, from basic to expert. Coverage includes   Getting started quickly with Scala's interpreter, syntax, tools, and unique idioms   Mastering core language features: functions, arrays, maps, tuples, packages, imports, exception handling, and more   Becoming familiar with object-oriented programming in Scala: classes, inheritance, and traits   Using Scala for real-world programming tasks: working with files, regular expressions, and XML   Working with higher-order functions and the powerful Scala collections library   Leveraging Scala's powerful pattern matching and case classes   Creating concurrent programs with Scala actors   Implementing domain-specific languages   Understanding the Scala type system   Applying advanced "power tools" such as annotations, implicits, and delimited continuations  Scala is rapidly reaching a tipping point that will reshape the experience of programming. This book will help object-oriented programmers build on their existing skills, allowing them to immediately construct useful applications as they gradually master advanced programming techniques.},
edition = {Second edition},
year = {2012},
title = {Scala for the Impatient},
url = {http://www.citeulike.org/group/15926/article/9539546},
keywords = {computer programming,functional programming (computer science,programming languages (electronic computers,scala (computer program language},
mendeley-tags = {computer programming,functional programming (computer science,programming languages (electronic computers,scala (computer program language},
}

@book{1997DodgeComputer,
author = {Charles Dodge and Thomas A Jerse},
edition = {2. ed},
shorttitle = {Computer music},
annote = {OCLC: 247058281},
title = {Computer music: synthesis, composition, and performance},
publisher = {Schirmer Books [u.a.]},
isbn = {978-0-02-864682-4},
}

@book{2014KoenigSpectral,
author = {David M. Koenig},
month = {nov},
publisher = {Oxford University Press},
booktitle = {Spectral Analysis of Musical Sounds with Emphasis on the Piano},
year = {2015},
title = {Spectral Analysis of Musical Sounds with Emphasis on the Piano},
isbn = {978-0-19-872290-8},
doi = {10.1093/acprof:oso/9780198722908.001.0001},
abstract = {This book addresses the analysis of musical sounds from the viewpoint of someone at the intersection among physicists, engineers, piano technicians, and musicians.},
}

@book{2008MontgomeryIntroduction,
author = {Theresa L. Utlaut},
doi = {10.1080/00224065.2008.11917751},
isbn = {978-0-471-65397-4},
volume = {40},
number = {4},
publisher = {Wiley},
pages = {476--478},
url = {https://www.amazon.com/Introduction-Analysis-Forecasting-Douglas-Montgomery/dp/0471653977?SubscriptionId=AKIAIOBINVZYXZQZ2U3A///////%5C%5C&tag=chimbori05-20///////%5C%5C&linkCode=xm2///////%5C%5C&camp=2025///////%5C%5C&creative=165953///////%5C%5C&creativeASIN=0471653977},
title = {Introduction to Time Series Analysis and Forecasting},
booktitle = {Journal of Quality Technology},
year = {2008},
abstract = {applicability for this approach.},
issn = {0022-4065},
}

@collection{2018KarasavvoglouEconomy,
author = {Anastasios Karasavvoglou and Sre\'cko Goi\'c and Persefoni Polychronidou and Pavlos Delias},
booktitle = {Proceedings of the 8th International Conference on the Economies of the Balkan and Eastern European Countries in the Changing World (EBEEC) in Split, Croatia, 2016},
isbn = {9783319703763},
publisher = {Springer International Publishing},
year = {2018},
pages = {903},
abstract = {This volume comprises papers presented at the 8th international conference "The Economies of the Balkan and Eastern European Countries in the Changing World" (EBEEC) held in Split, Croatia in 2016. The papers cover a wide range of current issues relevant for the whole of Eastern Europe, such as European integration, economic growth, labour markets, education and tourism. Written by experienced researchers in the field of economic challenges for Eastern Europe, the papers not only analyse recent problems, but also offer policies to resolve them. Furthermore, they offer insights into the theoretical and empirical foundations of the economic processes described. The proceedings of the conference appeals to all those interested in the further economic development of the Balkan and Eastern European countries.},
title = {Economy, Finance and Business in Southeastern and Central Europe},
url = {https://link.springer.com/book/10.1007%2F978-3-319-70377-0#about},
editor = {Karasavvoglou, Anastasios and Goi\'c, Sre\'cko and Polychronidou, Persefoni and Delias, Pavlos},
doi = {10.1007/978-3-319-70377-0},
series = {Springer Proceedings in Business and Economics},
keywords = {accounting,balkan,banking,eastern european countries,economic crisis,economic development,economic growth,education,european integration,financial development,labour market,macroeconomics,tourism},
mendeley-tags = {accounting,balkan,banking,eastern european countries,economic crisis,economic development,economic growth,education,european integration,financial development,labour market,macroeconomics,tourism},
}

@collection{2006KomaraEncyclopedia,
pages = {43--4373--43--4373},
editor = {Komara, Edward M},
abstract = {This comprehensive two-volume set brings together all aspects of the blues from performers and musical styles to record labels and cultural issues, including regional evolution and history. Organized in an accessible A-to-Z format, the Encyclopedia of the Blues is an essential reference resource for information on this unique American music genre. Coverage includes: \textperiodcentered The whole history of the blues, from its antecedents in African and American types of music to the contemporary styles performed today \textperiodcentered Artists active throughout the United States and from foreign countries \textperiodcentered The business of the blues, including individual record labels active since the prewar era \textperiodcentered Aspects particular to blues lyrics and music \textperiodcentered Specific issues such as race or gender as related to the blues \textperiodcentered Reference lists of blues periodicals, blues newsletters, libraries, and museums.},
isbn = {978-0-415-92699-7 978-0-415-92700-0 978-0-415-92701-7},
title = {Encyclopedia of the blues},
year = {2006},
doi = {10.5860/choice.43-4373},
booktitle = {Choice Reviews Online},
publisher = {Routledge},
issn = {0009-4978},
volume = {43},
number = {08},
keywords = {biography dictionaries,blues (music,blues musicians,encyclopedias},
mendeley-tags = {biography dictionaries,blues (music,blues musicians,encyclopedias},
}

@article{1969HansonExtensions,
author = {Richard J. Hanson and Charles L. Lawson},
title = {Extensions and Applications of the Householder Algorithm for Solving Linear Least Squares Problems},
url = {https://www.jstor.org/stable/2004965?origin=crossref},
year = {1969},
doi = {10.2307/2004965},
volume = {23},
number = {108},
publisher = {American Mathematical Society (AMS)},
issn = {00255718},
pages = {787},
journal = {Mathematics of Computation},
}

@article{GallierFundamentals,
author = {J.S. Chahal},
pages = {947},
year = {2018},
journal = {Fundamentals of Linear Algebra},
title = {Fundamentals of Linear Algebra},
doi = {10.1201/9780429425479},
}

@book{2009GesserLibras?,
author = {Kleber Aparecido da Silva and Joseane Severo},
isbn = {978-85-7934-001-7},
annote = {OCLC: 817147074},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
pages = {1197--1202},
title = {Que l\'ingua \'e essa?: cren\ccas e preconceitos em torno da l\'ingua de sinais e da realidade surda},
doi = {10.1590/1984-639820145507},
publisher = {Par\'abola Ed.},
shorttitle = {Libras?},
year = {2014},
volume = {14},
booktitle = {Revista Brasileira de Lingu\'istica Aplicada},
number = {4},
issn = {1984-6398},
}

@article{myers_smarter_nodate,
author = {Mark Myers},
pages = {288},
title = {A Smarter Way to Learn JavaScript: The new approach that uses technology to cut your effort in half},
year = {2013},
keywords = {com},
mendeley-tags = {com},
}

@book{2013GolubMatrix,
author = {A. Iserles and G. H. Golub and C. F. Van Loan},
year = {1990},
series = {Johns Hopkins studies in the mathematical sciences},
abstract = {Revised and updated, the third edition of Golub and Van Loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. This new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of CS decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified Gram-Schmidt process, and new material devoted to GMRES, QMR, and other methods designed to handle the sparse unsymmetric linear system problem.},
isbn = {978-1-4214-0794-4},
volume = {74},
edition = {Fourth edition},
publisher = {The Johns Hopkins University Press},
annote = {OCLC: ocn824733531},
number = {469},
pages = {322},
booktitle = {The Mathematical Gazette},
issn = {00255572},
doi = {10.2307/3619868},
title = {Matrix Computations},
keywords = {data processing,matrices},
mendeley-tags = {data processing,matrices},
}

@incollection{2013RossFront,
author = {Sheldon M Ross},
publisher = {Elsevier},
pages = {i--ii},
isbn = {978-0-12-415825-2},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9780124158252000140},
booktitle = {Simulation},
title = {Front Matter},
doi = {10.1016/b978-0-12-415825-2.00014-0},
year = {2013},
}

@article{1959GardnerMethod,
author = {Donald G. Gardner and Jeanne C. Gardner and George Laush and W. Wayne Meinke},
abstract = {A frequently encountered problem in many branches of science involves the resolution of experimental data into a sum of independent exponential curves of the form f(t)=∑ni=1Niexp(- $\lambda$it), i-l in order to estimate the physically significant parameters Ni and X,-. Such problems arise, for example, in the analysis of multicomponent radioactive decay curves, and in the study of the dielectric properties of certain compounds. This paper is concerned with the numerical evaluation of a mathematical approach to the problem. The approach is based on the inversion of the Laplace integral equation by a method of Fourier transforms. The results of the analysis appear in the form of a frequency spectrum. Each true peak in the spectrum indicates a component, the abscissa value at the center of the peak is the decay constant X,-, while the height of the peak is directly proportional to Ni/$\lambda$t. Results obtained on an IBM 650 computer indicate that the method may possess certain advantages over previous methods of analysis.},
issn = {00219606},
title = {Method for the analysis of multicomponent exponential decay curves},
volume = {31},
pages = {978--986},
doi = {10.1063/1.1730560},
journal = {The Journal of Chemical Physics},
year = {1959},
number = {4},
keywords = {qualityassured},
mendeley-tags = {qualityassured},
}

@article{1983KarplusDigital,
author = {Kevin Karplus and Alex Strong},
doi = {10.2307/3680062},
pages = {43--55},
abstract = {A digital real-time synthesis technique is described that can be implemented readily and inexpensively on almost any computer, including microprocessors. Not only are the algorithms simple to implement in software, but hardware realizations are easily done. Despite the simplicity of the techniques, the sound is surprisingly rich and natural. For musicians interested primarily in performing and composing music, rather than designing instruments, these algorithms provide a welcome new technique. For those interested in instrument design, they open a new field of effective techniques to explore.},
journal = {Computer Music Journal},
url = {https://www.jstor.org/stable/3680062?origin=crossref},
year = {1983},
volume = {7},
issn = {01489267},
number = {2},
title = {Digital Synthesis of Plucked-String and Drum Timbres.},
}

@article{1998FontanaPhysical,
author = {Federico Fontana and Davide Rocchesso},
number = {3},
year = {1998},
abstract = {Recent research on Physical Modeling has led to 2-D discrete-time structures based on the Digital Waveguides. These structures are well suited for efficient yet accurate simulation of wave propagation in an ideal membrane. Nevertheless, real membranes exhibit a different behaviour, due to the environmental conditions and to the material they are made of. In this work we consider some aspects, crucial for the audio signal, of the physical phenomena concerning real membranes, and we will develop a 2-D waveguide model encompassing the effects of these aspects. In order to excite the simulated membrane, we will consider a hammer model previously developed for piano strings, and here adapted to fit the hammer-membrane interaction.},
pages = {529--542},
title = {Physical Modeling of Membranes for Percussion Instruments},
volume = {84},
issn = {00017884},
journal = {Acustica},
}

@article{2006VaelimaekiDiscrete,
author = {Vesa V\"alim\"aki and Jyri Pakarinen and Cumhur Erkut and Matti Karjalainen},
pages = {1--78},
year = {2006},
number = {1},
issn = {00344885},
volume = {69},
title = {Discrete-time modelling of musical instruments},
journal = {Reports on Progress in Physics},
abstract = {This article describes physical modelling techniques that can be used for simulating musical instruments. The methods are closely related to digital signal processing. They discretize the system with respect to time, because the aim is to run the simulation using a computer. The physics-based modelling methods can be classified as mass-spring, modal, wave digital, finite difference, digital waveguide and source-filter models. We present the basic theory and a discussion on possible extensions for each modelling technique. For some methods, a simple model example is chosen from the existing literature demonstrating a typical use of the method. For instance, in the case of the digital waveguide modelling technique a vibrating string model is discussed, and in the case of the wave digital filter technique we present a classical piano hammer model. We tackle some nonlinear and time-varying models and include new results on the digital waveguide modelling of a nonlinear string. Current trends and future directions in physical modelling of musical instruments are discussed. \textcopyright 2006 IOP Publishing Ltd.},
doi = {10.1088/0034-4885/69/1/R01},
url = {http://stacks.iop.org/0034-4885/69/i=1/a=R01?key=crossref.fc944552766588c9a4a07777ff78c7f1},
}

@article{2014BilbaoNumerical,
author = {S. Bilbao and A. Torin and V. Chatziioannou},
number = {1},
pages = {155--173},
journal = {Acta Acustica united with Acustica},
year = {2015},
volume = {101},
url = {http://arxiv.org/abs/1405.2589},
doi = {10.3813/AAA.918813},
issn = {16101928},
abstract = {Collisions play an important role in many aspects of the physics of musical instruments. The striking action of a hammer or mallet in keyboard and percussion instruments is perhaps the most important example, but others include reed-beating efects in wind instruments, the string/neck interaction in fretted instruments such as the guitar as well as in the sitar and the wire/membrane interaction in the snare drum. From a simulation perspective, whether the eventual goal is the validation of musical instrument models or sound synthesis, such highly nonlinear problems pose various dificulties, not the least of which is the risk of numerical instability. In this article, a novel finite diference time domain simulation framework for such collision problems is developed, where numerical stability follows from strict numerical energy conservation or dissipation, and where a power law formulation for collisions is employed, as a potential function within a passive formulation. The power law serves both as a model of deformable collision, and as a mathematical penalty under perfectly rigid, non-deformable collision. Various numerical examples, illustrating the unifying features of such methods across a wide variety of systems in musical acoustics are presented, including numerical stability and energy conservation/dissipation, bounds on spurious penetration in the case of rigid collisions, as well as various aspects of musical instrument physics.},
archiveprefix = {arXiv},
title = {Numerical modeling of collisions in musical instruments},
eprint = {1405.2589},
arxivid = {1405.2589},
}

@article{2016LyubimovMathematical,
author = {N. A. Lyubimov and E. V. Zakharov},
number = {2},
volume = {62},
issn = {10637710},
doi = {10.1134/S1063771016020093},
title = {Mathematical model of acoustic speech production with mobile walls of the vocal tract},
year = {2016},
pages = {225--234},
journal = {Acoustical Physics},
abstract = {A mathematical speech production model is considered that describes acoustic oscillation propagation in a vocal tract with mobile walls. The wave field function satisfies the Helmholtz equation with boundary conditions of the third kind (impedance type). The impedance mode corresponds to a threeparameter pendulum oscillation model. The experimental research demonstrates the nonlinear character of how the mobility of the vocal tract walls influence the spectral envelope of a speech signal.},
keywords = {helmholtz equation,impedance,speech production model},
mendeley-tags = {helmholtz equation,impedance,speech production model},
}

@inproceedings{1998LairdEfficient,
author = {J. Laird and P. Masri and C. N. Canagarajah},
abstract = {Digital waveguides may be used to construct efficient physical models of musical instruments and other resonant systems. They are commonly used to model systems with simple boundary conditions, such as strings and square membranes. Membranes are modelled by connecting digital waveguides together to form a mesh; however when modelling circular membranes, such as those found in percussive drums or microphones, the mesh does not approximate well to the boundary shape. It was found that a two-dimensional triangular mesh structure, with rimguides attached around the edge could overcome this. In this paper several rimguide strategies have been explored. The best of these involves adjusting the phase delay so that the model is accurate for frequencies close to DC. The improvement is particularly noticeable for efficient (low sample rate) implementations.},
booktitle = {IEE Colloquium (Digest)},
pages = {12},
doi = {10.1049/ic:19980829},
publisher = {IEE},
issn = {09633308},
number = {470},
volume = {1998},
year = {1998},
title = {Efficient and accurate synthesis of circular membranes using digital waveguides},
}

@article{2007MurphyAcoustic,
author = {Damian T. Murphy and Antti Kelloniemi and Jack Mullen and Simon Shelley},
doi = {10.1109/MSP.2007.323264},
volume = {24},
year = {2007},
pages = {55--66},
url = {http://ieeexplore.ieee.org/document/4117929/},
title = {Acoustic modeling using the digital waveguide mesh},
journal = {IEEE Signal Processing Magazine},
number = {2},
issn = {10535888},
}

@inproceedings{2008DiukObject,
author = {Carlso Diuk and Andre Cohen and Michael L. Littman},
year = {2008},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
isbn = {9781605582054},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390187},
abstract = {Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the well-known Taxi domain, plus a real-life videogame. Copyright 2008 by the author(s)/owner(s).},
pages = {240--247},
title = {An object-oriented representation for efficient reinforcement learning},
doi = {10.1145/1390156.1390187},
publisher = {ACM Press},
}

@inproceedings{2010IoanaTime,
author = {Cornel Ioana and Jerome I. Mars and Alex Serbanescu and  ru and Srdjan Stankovic},
year = {2010},
shorttitle = {Time-frequency-phase tracking approach},
url = {http://ieeexplore.ieee.org/document/5495259/},
issn = {15206149},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
abstract = {One of the most challenging applications of time-frequency representations deals with the analysis of the signal issued from natural environment. Recently, the interest for passive underwater context increased, basically due to the rich information carried out by the natural signals. Taken into account the non-linear multi-component time-frequency behavior of such signals, their analysis is a complex problem. In this paper we introduce a new time-frequency analysis concept that aims to extract the non-linear time-frequency components. The main feature of this technique is the joint use of time-amplitude, time-frequency and time-phase information. This is materialized by a short-time polynomial phase modeling and the fusion of local information according to the best locally matches of local cubic frequency modulations. Tests provided on real data illustrate the benefits of the proposed approach. \textcopyright2010 IEEE.},
title = {Time-frequency-phase tracking approach: Application to underwater signals in a passive context},
publisher = {IEEE},
pages = {5634--5637},
isbn = {9781424442966},
doi = {10.1109/ICASSP.2010.5495259},
keywords = {signal representations,time-frequency analysis,time-varying filters},
mendeley-tags = {signal representations,time-frequency analysis,time-varying filters},
}

@article{2017LanctotUnified,
author = {Marc Lanctot and Vinicius Zambaldi and Audrūnas Gruslys and Angeliki Lazaridou and Karl Tuyls and Julien P\'erolat and David Silver and Thore Graepel},
issn = {23318422},
year = {2017},
title = {A unified game-theoretic approach to multiagent reinforcement learning},
url = {http://arxiv.org/abs/1711.00832},
journal = {arXiv},
abstract = {To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.},
}

@article{GiannakopoulosDeep,
author = {Petros Giannakopoulos and Yannis Cotronis},
issn = {23318422},
title = {A Deep Q-Learning Agent for the L-Game with Variable Batch Training},
year = {2018},
abstract = {We employ the Deep Q-Learning algorithm with Experience Replay to train an agent capable of achieving a high-level of play in the L-Game while selflearning from low-dimensional states. We also employ variable batch size for training in order to mitigate the loss of the rare reward signal and significantly accelerate training. Despite the large action space due to the number of possible moves, the low-dimensional state space and the rarity of rewards, which only come at the end of a game, DQL is successful in training an agent capable of strong play without the use of any search methods or domain knowledge.},
journal = {arXiv},
pages = {6},
}

@article{hu_multiagent_nodate,
author = {B Pertuiset},
title = {Obituary: Sixto Obrador, 1911--1978.},
pmid = {371347},
doi = {10.1007/bf01769133},
number = {3-4},
journal = {Acta neurochirurgica},
volume = {45},
pages = {197--8},
year = {1979},
isbn = {1558605568},
abstract = {In this paper, we adopt general-sum stochastic games as a framework for multiagent reinforcement learning. Our work extends previous work by Littman on zero-sum stochastic games to a broader framework. We design a multiagent Q-learning method under this framework, and prove that it converges to a Nash equilibrium under specified conditions. This algorithm is useful for finding the optimal strategy when there exists a unique Nash equilibrium in the game. When there exist multiple Nash equilibria in the game, this algorithm should be combined with other learning techniques to find optimal strategies.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/371347},
issn = {0001-6268},
}

@article{horie_neural_nodate,
author = {R. Horie and E. Aiyoshi},
abstract = {We propose a new mutually coupled plural Neural Networks (N.N.) modules and its application to associative memories from the view point of noncooperative game theory. First, We propose a new dynamical searching model named Parallel Steepest Descent Method with Braking operators (PSDMB) which searches the Nash Equilibrium (NE) points under [0, 1]-interval or nonnegative constraints. Second, we propose a new mutually coupled plural N.N. modules named Game Neural Networks (GNN) to realize the proposed PSDMB with quadratic objective functions. In Addition, we indicate relations between the PSDMB, the GNN and the Lotka-Volterra equation. Last, for an application of the proposed GNN, we propose two kinds of multi modular associative memories which can associate the combined patterns composed of plural partial patterns: (1) the combined patterns are stored as the NE points and robust for noisy inputs; (2) the circulative sequence of the combined patterns are stored as saddles of a heteroclinic cycle.},
doi = {10.1109/icsmc.1998.728171},
journal = {Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
title = {Neural Networks realization of searching models for Nash Equilibrium points and their application to associative memories},
volume = {2},
year = {1998},
pages = {1886--1891},
issn = {08843627},
}

@article{erev_predicting_nodate,
author = {Ido Erev and Alvin E. Roth},
issn = {00028282},
abstract = {We examine learning in all experiments we could locate involving 100 periods or more of games with a unique equilibrium in mixed strategies, and in a new experiment. We study both the ex post ("best fit") descriptive power of learning models, and their ex ante predictive power, by simulating each experiment using parameters estimated from the other experiments. Even a one-parameter reinforcement learning model robustly outperforms the equilibrium predictions. Predictive power is improved by adding "forgetting" and "experimentation," or by allowing greater rationality as in probabilistic fictitious play. Implications for developing a low-rationality, cognitive game theory are discussed.},
volume = {88},
year = {1998},
doi = {10.2307/117009},
pages = {848--881},
number = {4},
title = {Predicting How People Play Games: Reinforcement Learning in Experimental Games with Unique, Mixed Strategy Equilibria},
journal = {American Economic Review},
}

@article{HuNash,
author = {Junling Hu and Michael P Wellman},
title = {Nash Q-Learning for General-Sum Stochastic Games},
abstract = {We extend Q-learning to a noncooperative multiagent context, using the framework of generalsum stochastic games. A learning agent maintains Q-functions over joint actions, and performs updates based on assuming Nash equilibrium behavior over the current Q-values. This learning protocol provably converges given certain restrictions on the stage games (deﬁned by Q-values) that arise during learning. Experiments with a pair of two-player grid games suggest that such restrictions on the game structure are not necessarily required. Stage games encountered during learning in both grid environments violate the conditions. However, learning consistently converges in the ﬁrst grid game, which has a unique equilibrium Q-function, but sometimes fails to converge in the second, which has three different equilibrium Q-functions. In a comparison of ofﬂine learning performance in both games, we ﬁnd agents are more likely to reach a joint optimal path with Nash Q-learning than with a single-agent Q-learning method. When at least one agent adopts Nash Q-learning, the performance of both agents is better than using single-agent Q-learning. We have also implemented an online version of Nash Q-learning that balances exploration with exploitation, yielding improved performance.},
pages = {31},
}

@book{2014KamlerHelping,
author = {Barbara Kamler and Pat Thomson},
shorttitle = {Helping doctoral students write},
year = {2014},
title = {Helping doctoral students write: Pedagogies for supervision, second edition},
abstract = {Helping Doctoral Students Write offers a proven approach to effective doctoral writing. By treating research as writing and writing as research, the authors offer pedagogical strategies for doctoral supervisors that will assist the production of well-argued and lively dissertations.It is clear that many doctoral candidates find research writing complicated and difficult, but the advice they receive often glosses over the complexities of writing and/or locates the problem in the writer. Kamler and Thomson provide a highly effective framework for scholarly work that is located in personal, institutional and cultural contexts.The pedagogical approach developed in the book is based on the notion of writing as a social practice. This approach allows supervisors to think of doctoral writers as novices who need to learn new ways with words as they enter the discursive practices of scholarly communities. This involves learning sophisticated writing practices with specific sets of conventions and textual characteristics. The authors offer supervisors practical advice on helping with commonly encountered writing tasks such as the proposal, the journal abstract, the literature review and constructing the dissertation argument.The first edition of this book has helped many academics and thousands of research students produce better written material. Now fully updated the second edition includes:• Examples from a broader range of academic disciplines• A new chapter on writing from the thesis for peer reviewed journals• More advice on reading and note taking, performance and conferences,• Further information on developing a personal academic writing style, and• Advice on the use of social media (blogs, tweets and wikis) to create trans-disciplinary and trans-national networks and conversations.Their discussion of the complexities of forming a scholarly identity is illustrated throughout by stories and writings of actual doctoral students.In conclusion, they present a persuasive and proven argument that universities must move away from simply auditing supervision to supporting the development of scholarly research communities. Any supervisor keen to help their students develop as academics will find the ideas and practical solutions presented in this book fascinating and insightful reading.},
pages = {1--191},
doi = {10.4324/9781315813639},
isbn = {978-0-415-82348-7 978-0-415-82349-4},
volume = {9781315813639},
edition = {Second edition},
booktitle = {Taylor and Francis Ltd 5},
publisher = {Routledge},
keywords = {academic,dissertations,education / general,education / higher,education / research},
mendeley-tags = {academic,dissertations,education / general,education / higher,education / research},
}

@article{2007SgroiNeural,
author = {Daniel Sgroi and Daniel J. Zizzo},
title = {Neural networks and bounded rationality},
abstract = {Traditionally the emphasis in neural network research has been on improving their performance as a means of pattern recognition. Here we take an alternative approach and explore the remarkable similarity between the under-performance of neural networks trained to behave optimally in economic situations and observed human performance in the laboratory under similar circumstances. In particular, we show that neural networks are consistent with observed laboratory play in two very important senses. Firstly, they select a rule for behavior which appears very similar to that used by laboratory subjects. Secondly, using this rule they perform optimally only approximately 60% of the time. \textcopyright 2006 Elsevier B.V. All rights reserved.},
year = {2007},
url = {https://linkinghub.elsevier.com/retrieve/pii/S037843710601048X},
pages = {717--725},
number = {2},
journal = {Physica A: Statistical Mechanics and its Applications},
issn = {03784371},
volume = {375},
doi = {10.1016/j.physa.2006.10.026},
keywords = {bounded rationality,game theory,learning,neural networks},
mendeley-tags = {bounded rationality,game theory,learning,neural networks},
}

@article{2008MarchioriPredicting,
author = {Davide Marchiori and Massimo Warglien},
pmid = {18292345},
issn = {00368075},
volume = {319},
pages = {1111--1113},
doi = {10.1126/science.1151185},
title = {Predicting human interactive learning by regret-driven neural networks},
year = {2008},
number = {5866},
journal = {Science},
abstract = {Much of human learning in a social context has an interactive nature: What an individual learns is affected by what other individuals are learning at the same time. Games represent a widely accepted paradigm for representing interactive decision-making. We explored the potential value of neural networks for modeling and predicting human interactive learning in repeated games. We found that even very simple learning networks, driven by regret-based feedback, accurately predict observed human behavior in different experiments on 21 games with unique equilibria in mixed strategies. Introducing regret in the feedback dramatically improved the performance of the neural network. We show that regret-based models provide better predictions of learning than established economic models.},
}

@article{SpiliopoulosLearning,
author = {Leonidas Spiliopoulos},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
year = {2011},
title = {Learning Backward Induction: A Neural Network Agent Approach},
pages = {10},
abstract = {This paper addresses the question of whether neural networks (NNs), a realistic cognitive model of human information processing, can learn to backward induce in a two-stage game with a unique subgame-perfect Nash equilibrium. The NNs were found to predict the Nash equilibrium approximately 70% of the time in new games. Similarly to humans, the neural network agents are also found to suffer from subgame and truncation inconsistency, supporting the contention that they are appropriate models of general learning in humans. The agents were found to behave in a bounded rational manner as a result of the endogenous emergence of decision heuristics. In particular a very simple heuristic socialmax, that chooses the cell with the highest social payoff explains their behavior approximately 60% of the time, whereas the ownmax heuristic that simply chooses the cell with the maximum payoff for that agent fares worse explaining behavior roughly 38%, albeit still significantly better than chance. These two heuristics were found to be ecologically valid for the backward induction problem as they predicted the Nash equilibrium in 67% and 50% of the games respectively. Compared to various standard classification algorithms, the NNs were found to be only slightly more accurate than standard discriminant analyses. However, the latter do not model the dynamic learning process and have an ad hoc postulated functional form. In contrast, a NN agent's behavior evolves with experience and is capable of taking on any functional form according to the universal approximation theorem.},
doi = {10.2139/ssrn.812044},
}

@inproceedings{2009BabesQ,
author = {Monica Babes and Michael Wunder and Michael Littman},
abstract = {Q-learning is a simple, powerful algorithm for behavior learning. It was derived in the context of single agent decision making in Markov decision process environments, but its applicability is much broader—in experiments in multiagent environments, Q-learning has also performed well. Our preliminary analysis using dynamical systems ﬁnds that Qlearning's indirect control of behavior via estimates of value contributes to its beneﬁcial performance in general-sum 2player games like the Prisoner's Dilemma.},
booktitle = {Proc. of 8th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2009)},
pages = {4},
title = {Q-learning in Two-Player Two-Action Games},
}

@article{2010WierstraRecurrent,
author = {Daan Wierstra and Alex F\"orster and  er and Jan Peters and J\"urgen Schmidhuber},
number = {5},
year = {2009},
issn = {13689894},
journal = {Logic Journal of the IGPL},
abstract = {Reinforcement learning for partially observable Markov decision problems (POMDPs) is a challenge as it requires policies with an internal state. Traditional approaches suffer significantly from this shortcoming and usually make strong assumptions on the problem domain such as perfect system models, state-estimators and a Markovian hidden system. Recurrent neural networks (RNNs) offer a natural framework for dealing with policy learning using hidden state and require only few limiting assumptions. As they can be trained well using gradient descent, they are suited for policy gradient approaches. In this paper, we present a policy gradient method, the Recurrent Policy Gradient which constitutes a model-free reinforcement learning method. It is aimed at training limited-memory stochastic policies on problems which require long-term memories of past observations. The approach involves approximating a policy gradient for a recurrent neural network by backpropagating return-weighted characteristic eligibilities through time. Using a "Long Short-Term Memory" RNN architecture, we are able to outperform previous RL methods on three important benchmark tasks. Furthermore, we show that using history-dependent baselines helps reducing estimation variance significantly, thus enabling our approach to tackle more challenging, highly stochastic environments. \textcopyright The Author 2009. Published by Oxford University Press. All rights reserved.},
doi = {10.1093/jigpal/jzp049},
volume = {18},
title = {Recurrent policy gradients},
pages = {620--634},
keywords = {partially observable markov decision problems (pomdps,policy gradient methods,recurrent neural networks,reinforcement learning},
mendeley-tags = {partially observable markov decision problems (pomdps,policy gradient methods,recurrent neural networks,reinforcement learning},
}

@inproceedings{2010VassiliadesMultiagent,
author = {Vassilis Vassiliades and Chris Christodoulou},
isbn = {9781424469178},
shorttitle = {Multiagent Reinforcement Learning in the Iterated Prisoner's Dilemma},
doi = {10.1109/IJCNN.2010.5596937},
abstract = {In this paper, we investigate the importance of rewards in Multiagent Reinforcement Learning in the context of the Iterated Prisoner's Dilemma. We use an evolutionary algorithm to evolve valid payoff structures with the aim of encouraging mutual cooperation. An exhaustive analysis is performed by investigating the effect of: i) the lower and upper bounds of the search space of the payoff values, ii) the reward sign, iii) the population size, and iv) the mutation operators used. Our results indicate that valid structures that encourage cooperation can quickly be obtained, while their analysis shows that: i) they should contain a mixture of positive and negative values and ii) the magnitude of the positive values should be much smaller than the magnitude of the negative values. \textcopyright 2010 IEEE.},
pages = {1--8},
url = {http://ieeexplore.ieee.org/document/5596937/},
title = {Multiagent reinforcement learning in the iterated prisoner's dilemma: Fast cooperation through evolved payoffs},
year = {2010},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
publisher = {IEEE},
}

@article{2014HeNeural,
author = {Xing He and Junzhi Yu and Tingwen Huang and Chu Li and  ong and Chaojie Li},
issn = {18792782},
pages = {73--78},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608014001348},
pmid = {24945472},
volume = {57},
abstract = {In this paper, based on an equivalent mixed linear complementarity problem, we propose a neural network to solve multiuser power control optimization problems (MPCOP), which is modeled as the noncooperative Nash game in modern digital subscriber line (DSL). If the channel crosstalk coefficients matrix is positive semidefinite, it is shown that the proposed neural network is stable in the sense of Lyapunov and global convergence to a Nash equilibrium, and the Nash equilibrium is unique if the channel crosstalk coefficients matrix is positive definite. Finally, simulation results on two numerical examples show the effectiveness and performance of the proposed neural network. \textcopyright 2014 Elsevier Ltd.},
year = {2014},
journal = {Neural Networks},
title = {Neural network for solving Nash equilibrium problem in application of multiuser power control},
doi = {10.1016/j.neunet.2014.06.002},
keywords = {global convergence,multiuser power control,nash game,neural network},
mendeley-tags = {global convergence,multiuser power control,nash game,neural network},
}

@article{2015NarasimhanLanguage,
author = {Karthik Narasimhan and Tejas D. Kulkarni and Regina Barzilay},
archiveprefix = {arXiv},
year = {2015},
doi = {10.18653/v1/d15-1001},
arxivid = {1506.08941},
journal = {Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
url = {http://arxiv.org/abs/1506.08941},
title = {Language understanding for text-based games using deep reinforcement learning},
isbn = {9781941643327},
eprint = {1506.08941},
pages = {1--11},
abstract = {In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations.1.},
}

@article{schuurmans_deep_nodate,
author = {Dale Schuurmans and Martin Zinkevich},
issn = {10495258},
abstract = {We investigate a reduction of supervised learning to game playing that reveals new connections and learning methods. For convex one-layer problems, we demonstrate an equivalence between global minimizers of the training problem and Nash equilibria in a simple game. We then show how the game can be extended to general acyclic neural networks with differentiable convex gates, establishing a bijection between the Nash equilibria and critical (or KKT) points of the deep learning problem. Based on these connections we investigate alternative learning methods, and find that regret matching can achieve competitive training performance while producing sparser models than current deep learning strategies.},
journal = {Advances in Neural Information Processing Systems},
pages = {1686--1694},
title = {Deep learning games},
year = {2016},
}

@article{2015HausknechtDeep,
author = {Matthew Hausknecht and Peter Stone},
eprint = {1507.06527},
archiveprefix = {arXiv},
pages = {29--37},
url = {http://arxiv.org/abs/1507.06527},
journal = {AAAI Fall Symposium - Technical Report},
isbn = {9781577357520},
arxivid = {1507.06527},
year = {2015},
title = {Deep recurrent q-learning for partially observable MDPs},
abstract = {Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting Deep Recurrent Q-Network (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.},
volume = {FS-15-06},
}

@article{2017UrbanGaussian,
author = {Sebastian Urban and Marcus Basalla and Patrick Van Der Smagt},
url = {http://arxiv.org/abs/1711.11059},
title = {Gaussian process neurons learn stochastic activation functions},
year = {2017},
journal = {arXiv},
abstract = {We propose stochastic, non-parametric activation functions that are fully learnable and individual to each neuron. Complexity and the risk of overfitting are controlled by placing a Gaussian process prior over these functions. The result is the Gaussian process neuron, a probabilistic unit that can be used as the basic building block for probabilistic graphical models that resemble the structure of neural networks. The proposed model can intrinsically handle uncertainties in its inputs and self-estimate the confidence of its predictions. Using variational Bayesian inference and the central limit theorem, a fully deterministic loss function is derived, allowing it to be trained as efficiently as a conventional neural network using mini-batch gradient descent. The posterior distribution of activation functions is inferred from the training data alongside the weights of the network. The proposed model favorably compares to deep Gaussian processes, both in model complexity and efficiency of inference. It can be directly applied to recurrent or convolutional network structures, allowing its use in audio and image processing tasks. As an preliminary empirical evaluation we present experiments on regression and classification tasks, in which our model achieves performance comparable to or better than a Dropout regularized neural network with a fixed activation function. Experiments are ongoing and results will be added as they become available.},
arxivid = {1711.11059},
issn = {23318422},
eprint = {1711.11059},
archiveprefix = {arXiv},
}

@article{2017HarperReinforcement,
author = {Marc Harper and Vincent Knight and Martin Jones and Georgios Koutsovoulos and Nikoleta E. Glynatsi and Owen Campbell},
pages = {e0188046},
title = {Reinforcement learning produces dominant strategies for the Iterated Prisoner's Dilemma},
abstract = {We present tournament results and several powerful strategies for the Iterated Prisoner's Dilemma created using reinforcement learning techniques (evolutionary and particle swarm algorithms). These strategies are trained to perform well against a corpus of over 170 distinct opponents, including many well-known and classic strategies. All the trained strategies win standard tournaments against the total collection of other opponents. The trained strategies and one particular human made designed strategy are the top performers in noisy tournaments also.},
pmid = {29228001},
journal = {PLoS ONE},
volume = {12},
doi = {10.1371/JOURNAL.PONE.0188046},
editor = {Deng, Yong},
number = {12},
issn = {19326203},
year = {2017},
}

@inproceedings{2017KorukhovaTraining,
author = {Yulia Korukhova and Sergey Kuryshev},
isbn = {9789897582196},
booktitle = {ICAART 2017 - Proceedings of the 9th International Conference on Agents and Artificial Intelligence},
shorttitle = {Training Agents with Neural Networks in Systems with Imperfect Information},
year = {2017},
volume = {1},
title = {Training agents with neural networks in systems with imperfect information},
abstract = {The paper deals with multi-Agent system that represents trading agents acting in the environment with imperfect information. Fictitious play algorithm, first proposed by Brown in 1951, is a popular theoretical model of training agents. However, it is not applicable to larger systems with imperfect information due to its computational complexity. In this paper we propose a modification of the algorithm. We use neural networks for fast approximate calculation of the best responses. An important feature of the algorithm is the absence of agent's a priori knowledge about the system. Agents' learning goes through trial and error with winning actions being reinforced and entered into the training set and losing actions being cut from the strategy. The proposed algorithm has been used in a small game with imperfect information. And the ability of the algorithm to remove iteratively dominated strategies of agents' behavior has been demonstrated.},
pages = {296--301},
url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006242102960301},
doi = {10.5220/0006242102960301},
publisher = {SCITEPRESS - Science and Technology Publications},
keywords = {dominated strategies,multi-agent systems,neural networks},
mendeley-tags = {dominated strategies,multi-agent systems,neural networks},
}

@article{KamraPolicy,
author = {Nitin Kamra and Umang Gupta and Fei Fang and Yan Liu and Milind Tambe},
year = {2018},
title = {Policy learning for continuous space security games using neural networks},
pages = {1103--1112},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
isbn = {9781577358008},
abstract = {A wealth of algorithms centered around (integer) linear programming have been proposed to compute equilibrium strategies in security games with discrete states and actions. However, in practice many domains possess continuous state and action spaces. In this paper, we consider a continuous space security game model with infinite-size action sets for players and present a novel deep learning based approach to extend the existing toolkit for solving security games. Specifically, we present (i) OptGradFP, a novel and general algorithm that searches for the optimal defender strategy in a parameterized continuous search space, and can also be used to learn policies over multiple game states simultaneously; (ii) OptGradFP-NN, a convolutional neural network based implementation of OptGradFP for continuous space security games. We demonstrate the potential to predict good defender strategies via experiments and analysis of OptGradFP and OptGradFP-NN on discrete and continuous game settings.},
}

@article{2018WangTowards,
author = {Weixun Wang and Jianye Hao and Yixi Wang and Matthew Taylor},
archiveprefix = {arXiv},
year = {2018},
shorttitle = {Towards Cooperation in Sequential Prisoner's Dilemmas},
abstract = {The Iterated Prisoner's Dilemma has guided research on social dilemmas for decades. However, it distinguishes between only two atomic actions: cooperate and defect. In real-world prisoner's dilemmas, these choices are temporally extended and different strategies may correspond to sequences of actions, reflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma (SPD) game to better capture the aforementioned characteristics. In this work, we propose a deep multiagent reinforcement learning approach that investigates the evolution of mutual cooperation in SPD games. Our approach consists of two phases. The first phase is offline: it synthesizes policies with different cooperation degrees and then trains a cooperation degree detection network. The second phase is online: an agent adaptively selects its policy based on the detected degree of opponent cooperation. The effectiveness of our approach is demonstrated in two representative SPD 2D games: the Apple-Pear game and the Fruit Gathering game. Experimental results show that our strategy can avoid being exploited by exploitative opponents and achieve cooperation with cooperative opponents.},
arxivid = {1803.00162},
title = {Towards cooperation in sequential Prisoner's dilemmas: A deep multiagent reinforcement learning approach},
url = {http://arxiv.org/abs/1803.00162},
journal = {arXiv},
eprint = {1803.00162},
issn = {23318422},
}

@collection{1995ChauvinBackpropagation,
series = {Developments in connectionist theory},
title = {Backpropagation: theory, architectures, and applications},
publisher = {Lawrence Erlbaum Associates},
isbn = {978-0-8058-1258-9 978-0-8058-1259-6},
editor = {Chauvin, Yves and Rumelhart, David E},
shorttitle = {Backpropagation},
keywords = {back propagation (artificial intelligence},
mendeley-tags = {back propagation (artificial intelligence},
}

@unpublished{2014SathyanarayanaGentle,
author = {Shashi Sathyanarayana and D Ph},
year = {2016},
title = {A Gentle Introduction to Backpropagation A Gentle Introduction to Backpropagation},
pages = {15},
number = {July},
}

@article{ChenAccelerator,
author = {Yu-Hsin Chen and Tushar Krishna and Joel Emer and Vivienne Sze},
title = {Accelerator for Deep Convolutional Neural Networks},
pages = {4},
}

@inproceedings{2018FukudaStochastic,
author = {Yasushi Fukuda and Takayuki Kawahara},
title = {Stochastic weights binary neural networks on FPGA},
pages = {1--3},
year = {2018},
isbn = {9781538614457},
abstract = {To achieve an advanced Internet of Things (IoT), it is necessary to combine artificial intelligence (AI) with IoT. Compact circuits that can operate AI functions will be useful for this purpose. Therefore, we propose stochastic weights binary neural networks (SWBNN). SWBNNs are more accurate than binary neural networks (BNN) with small circuits. BNNs can be realized with small circuits since binary calculation needs simpler circuits than real number calculation. However, BNNs have lower accuracy than networks with real numbers. Thus, the proposed SWBNNs are BNNs that behave stochastically, which makes them more accurate than BNNs. Moreover, SWBNNs can still be achieved with small circuits since they execute binary calculation. As a result, the accuracy for the test data of SWBNNs is closer to the accuracy for learning data than the accuracy for the test data of BNNs is. Especially when using the CIFAR10 database, the difference in the identification accuracy rate between learning data and test data decreased from 6% for BNNs to 2% for SWBNNs. From results of a field-programmable gate array (FPGA) implementation, circuits of SWBNNs are sufficiently small although they are 10% bigger than those of BNNs. Therefore, SWBNNs are more accurate than BNNs, and the circuit costs ofintroducing stochastic weights are low.},
booktitle = {Proceedings - 2018 7th International Symposium on Next-Generation Electronics, ISNE 2018},
doi = {10.1109/ISNE.2018.8394726},
keywords = {bnn,fpga,iot,neural-network,stochastic},
mendeley-tags = {bnn,fpga,iot,neural-network,stochastic},
}

@article{2009SaitisPhysical,
author = {Charalampos Saitis and Sarah Orr and Maarten van Walstijn},
doi = {10.1121/1.4784255},
issn = {0001-4966},
title = {Physical modeling of the piano: An investigation into the effect of string stiffness on the hammer string interaction.},
abstract = {The stiff string wave equation has four solutions, two of which are fast-decaying waves introduced by the string stiffness. In the case of digital waveguide modeling of piano strings these are normally neglected. Some recent reports have suggested that all four traveling waves should be considered, at least at the neighborhood of interaction points (i.e., the hammer and the boundaries). This paper investigates the effect of omitting string stiffness in the context of sound synthesis of the piano by physical modeling. A stiff, lossy string with a spatially distributed hammer force excitation is implemented using both a finite-difference time-domain scheme and a digital waveguide model. The two models are designed so as to have the exact same features but for the two stiffness-related solutions. Numerical experiments are employed to study the contact force and string velocity signals for different initial hammer velocity values. The results generally confirm that the two fast-decaying waves have only a marginal effect on the overall string motion. However, small audible differences result for bass strings struck with high initial hammer velocities.},
volume = {125},
pages = {2684--2684},
number = {4},
year = {2009},
shorttitle = {Physical modeling of the piano},
journal = {The Journal of the Acoustical Society of America},
}

@unpublished{2001AirdTowards,
author = {Marc Aird and Joel Laird},
booktitle = {Proc. Music Without Walls},
year = {2001},
title = {Towards material modelling in physical models using digital waveguides},
}

@book{2014MontgomeryApplied,
author = {Douglas C. Montgomery and George C. Runger},
title = {Applied Statistics and Probability for Engineers},
edition = {Sixth edition},
pages = {383},
year = {1994},
issn = {14695898},
isbn = {978-1-118-53971-2},
doi = {10.1080/03043799408928333},
booktitle = {European Journal of Engineering Education},
number = {3},
volume = {19},
abstract = {"This best-selling engineering statistics text provides a practical approach that is more oriented to engineering and the chemical and physical sciences than many similar texts. It is packed with unique problem sets that reflect realistic situations engineers will encounter in their working lives. This text shows how statistics, the science of data is just as important for engineers as the mechanical, electrical, and materials sciences"--},
publisher = {John Wiley and Sons, Inc},
}

@thesis{1989WatkinsLearning,
author = {Ben J.A. Kr\"ose},
booktitle = {Robotics and Autonomous Systems},
doi = {10.1016/0921-8890(95)00026-C},
number = {4},
year = {1995},
pages = {233--235},
issn = {09218890},
institution = {King's College, Cambridge},
type = {phdthesis},
volume = {15},
title = {Learning from delayed rewards},
}

@misc{2018PeirceSolving,
author = {Anthony Peirce},
annote = {Introductory lecture notes on Partial Differential Equations},
year = {2014},
abstract = {In this lecture we introduce the finite difference method that is widely used for approximating PDEs using the computer. We use the definition of the derivative and Taylor series to derive finite difference approximations to the first and second derivatives of a function. We then use these finite difference quotients to approximate the derivatives in the heat equation and to derive a finite difference approximation to the heat equation. Similarly, the technique is applied to the wave equation and Laplace's Equation. The technique is illustrated using an EXCEL spreadsheets.},
url = {https://www.math.ubc.ca//textasciitilde peirce/M257///////%5C%5C_316///////%5C%5C_2012///////%5C%5C_Lecture///////%5C%5C_8.pdf},
publisher = {The University of British Columbia},
title = {Solving the Heat, Laplace and Wave equations using finite difference methods},
keywords = {finite difference approximations to derivatives,key concepts,laplace's equation,the finite difference method,the heat equation,the wave equation},
mendeley-tags = {finite difference approximations to derivatives,key concepts,laplace's equation,the finite difference method,the heat equation,the wave equation},
}

@article{1996SandholmMultiagent,
author = { S and Tuomas W. holm and Robert H. Crites},
title = {Multiagent reinforcement learning in the Iterated Prisoner's Dilemma},
pmid = {8924633},
url = {http://www.sciencedirect.com/science/article/pii/0303264795015515},
pages = {147--166},
doi = {10.1016/0303-2647(95)01551-5},
journal = {BioSystems},
number = {1-2},
year = {1996},
abstract = {Reinforcement learning (RL) is based on the idea that the tendency to produce an action should be strengthened (reinforced) if it produces favourable results, and weakened if it produces unfavourable results. Q-learning is a recent RL algorithm that does not need a model of its environment and can be used on-line. Therefore, it is well suited for use in repeated games against an unknown opponent. Most RL research has been confined to single-agent settings or to multiagent settings where the agents have totally positively correlated payoffs (team problems) or totally negatively correlated payoffs (zero-sum games). This paper is an empirical study of reinforcement learning in the Iterated Prisoner's Dilemma (IPD), where the agents' payoffs are neither totally positively nor totally negatively correlated. RL is considerably more difficult in such a domain. This paper investigates the ability of a variety of Q-learning agents to play the IPD game against an unknown opponent. In some experiments, the opponent is the fixed strategy Tit-For-Tat, while in others it is another Q-learner. All the Q-learners learned to play optimally against Tit-For-Tat. Playing against another learner was more difficult because the adaptation of the other learner created a non-stationary environment, and because the other learner was not endowed with any a priori knowledge about the IPD game such as a policy designed to encourage cooperation. The learners that were studied varied along three dimensions: the length of history they received as context, the type of memory they employed (look up tables based on restricted history windows or recurrent neural networks that can theoretically store features from arbitrarily deep in the past), and the exploration schedule they followed. Although all the learners faced difficulties when playing against other learners, agents with longer history windows, lookup table memories, and longer exploration schedules fared best in the IPD games.},
volume = {37},
issn = {03032647},
keywords = {exploration,machine learning,multiagent learning,prisoner's dilemma,recurrent neural network,reinforcement learning},
mendeley-tags = {exploration,machine learning,multiagent learning,prisoner's dilemma,recurrent neural network,reinforcement learning},
}

@book{2012HarringtonMachine,
author = {Ohad Nachtomy and Ayelet Shavit and Zohar Yakhini},
publisher = {Manning Publications Co},
url = {http://www.springerlink.com/content/cq421151870796n6/},
year = {2007},
volume = {38},
title = {Gene expression and the concept of the phenotype},
abstract = {While the definition of the 'genotype' has undergone dramatic changes in the transition from classical to molecular genetics, the definition of the 'phenotype' has remained for a long time within the classical framework. In addition, while the notion of the genotype has received significant attention from philosophers of biology, the notion of the phenotype has not. Recent developments in the technology of measuring gene-expression levels have made it possible to conceive of phenotypic traits in terms of levels of gene expression. We demonstrate that not only has this become possible but it has also become an actual practice. This suggests a significant change in our conception of the phenotype: as in the case of the 'genotype', phenotypes can now be conceived in quantitative and measurable terms on a comprehensive molecular level. We discuss in what sense gene expression profiles can be regarded as phenotypic traits and whether these traits are better described as a novel concept of phenotype or as an extension of the classical concept. We argue for an extension of the classical concept and call for an examination of the type of extension involved. \textcopyright 2006 Elsevier Ltd. All rights reserved.},
booktitle = {Studies in History and Philosophy of Science Part C :Studies in History and Philosophy of Biological and Biomedical Sciences},
doi = {10.1016/j.shpsc.2006.12.014},
number = {1},
pages = {238--254},
issn = {13698486},
pmid = {17324816},
annote = {OCLC: ocn746834657},
isbn = {9781617290183},
keywords = {concept extension,gene expression,genotype,phenotype},
mendeley-tags = {concept extension,gene expression,genotype,phenotype},
}

@book{1992HollandAdaptation,
author = {Charles E. Taylor},
year = {1994},
number = {1},
doi = {10.1086/418447},
edition = {1st MIT Press ed},
isbn = {978-0-262-08213-6 978-0-262-58111-0},
pages = {88--89},
abstract = {Genetic algorithms were developed initially by Holland et al. in the 1960s and 1970s!!! Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. John H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and is Director of the University of Michigan/Santa Fe Institute Advanced Research Program.},
publisher = {MIT Press},
shorttitle = {Adaptation in natural and artificial systems},
volume = {69},
title = { Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. Complex Adaptive Systems. John H. Holland },
booktitle = {The Quarterly Review of Biology},
series = {Complex adaptive systems},
issn = {0033-5770},
keywords = {adaptation (biology,adaptive control systems,mathematical models},
mendeley-tags = {adaptation (biology,adaptive control systems,mathematical models},
}

@article{2018WangPacking,
author = {Yunhe Wang and Chang Xu and Chao Xu and Dacheng Tao},
pages = {2495--2510},
volume = {41},
year = {2019},
title = {Packing Convolutional Neural Networks in the Frequency Domain},
abstract = {Deep convolutional neural networks (CNNs) are successfully used in a number of applications. However, their storage and computational requirements have largely prevented their widespread use on mobile devices. Here we present a series of approaches for compressing and speeding up CNNs in the frequency domain, which focuses not only on smaller weights but on all the weights and their underlying connections. By treating convolution filters as images, we decompose their representations in the frequency domain as common parts (i.e., cluster centers) shared by other similar filters and their individual private parts (i.e., individual residuals). A large number of low-energy frequency coefficients in both parts can be discarded to produce high compression without significantly compression romising accuracy. Furthermore, we explore a data-driven method for removing redundancies in both spatial and frequency domains, which allows us to discard more useless weights by keeping similar accuracies. After obtaining the optimal sparse CNN in the frequency domain, we relax the computational burden of convolution operations in CNNs by linearly combining the convolution responses of discrete cosine transform (DCT) bases. The compression and speed-up ratios of the proposed algorithm are thoroughly analyzed and evaluated on benchmark image datasets to demonstrate its superiority over state-of-the-art methods.},
doi = {10.1109/TPAMI.2018.2857824},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
issn = {19393539},
pmid = {30028693},
keywords = {cnn compression,dct bases,discrete cosine transform,frequency domain speed-up},
mendeley-tags = {cnn compression,dct bases,discrete cosine transform,frequency domain speed-up},
}

@book{2017McclureTensorflow,
author = {Nick McClure},
publisher = {Packt Publishing},
title = {TensorFlow Machine Learning},
isbn = {9781786462169},
year = {2020},
abstract = {بباا},
annote = {OCLC: 992150633},
pages = {351},
url = {https://www.tensorflow.org/federated},
}

@incollection{2006WerbosBackwards,
author = {Paul J. Werbos},
year = {2006},
doi = {10.1007/3-540-28438-9_2},
isbn = {9783540284031},
publisher = {Springer-Verlag},
pages = {15--34},
editor = {B\"ucker, Martin and Corliss, George and Naumann, Uwe and Hovland, Paul and Norris, Boyana},
shorttitle = {Backwards Differentiation in AD and Neural Nets},
booktitle = {Lecture Notes in Computational Science and Engineering},
abstract = {Backwards calculation of derivatives - sometimes called the reverse mode, the full adjoint method, or backpropagation - has been developed and applied in many fields. This paper reviews several strands of history, advanced capabilities and types of application - particularly those which are crucial to the development of brain-like capabilities in intelligent control and artificial intelligence.},
title = {Backwards Differentiation in AD and Neural Nets: Past Links and New Opportunities},
issn = {14397358},
volume = {50},
keywords = {adjoint,approximate dynamic programming,backpropagation,implicit systems,intelligent control,mlp,neural networks,recurrent networks,reinforcement learning,reverse mode},
mendeley-tags = {adjoint,approximate dynamic programming,backpropagation,implicit systems,intelligent control,mlp,neural networks,recurrent networks,reinforcement learning,reverse mode},
}

@book{2008PoliField,
author = {Riccardo Poli and W.B. Langdon and N.F. McPhee},
publisher = {Lulu Press]},
year = {2008},
pages = {8},
title = {A Field Guide to Genetic Programing},
number = {March},
booktitle = {Wyvern},
annote = {OCLC: 837998350},
isbn = {978-1-4092-0073-4},
url = {http://www.essex.ac.uk/wyvern/2008-04/Wyvern April 08 7126.pdf},
abstract = {A Field Guide to Genetic Programing is aimed at those new to genetic programming},
keywords = {genetic algorithms,genetic programming},
mendeley-tags = {genetic algorithms,genetic programming},
}

@article{2004LengLine,
author = {Gang Leng and Girijesh Prasad and Thomas Martin McGinnity},
issn = {08936080},
title = {An on-line algorithm for creating self-organizing fuzzy neural networks},
pages = {1477--1493},
number = {10},
volume = {17},
abstract = {This paper presents a new on-line algorithm for creating a self-organizing fuzzy neural network (SOFNN) from sample patterns to implement a singleton or Takagi-Sugeno (TS) type fuzzy model. The SOFNN is based on ellipsoidal basis function (EBF) neurons consisting of a center vector and a width vector. New methods of the structure learning and the parameter learning, based on new adding and pruning techniques and a recursive on-line learning algorithm, are proposed and developed. A proof of the convergence of both the estimation error and the linear network parameters is also given in the paper. The proposed methods are very simple and effective and generate a fuzzy neural model with a high accuracy and compact structure. Simulation work shows that the SOFNN has the capability of self-organization to determine the structure and parameters of the network automatically. \textcopyright 2004 Published by Elsevier Ltd.},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608004001698},
year = {2004},
doi = {10.1016/j.neunet.2004.07.009},
pmid = {15541949},
journal = {Neural Networks},
keywords = {ebf,recursive least squares algorithm,self-organizing fuzzy neural network,ts model},
mendeley-tags = {ebf,recursive least squares algorithm,self-organizing fuzzy neural network,ts model},
}

@article{2017LiFrequency,
author = {Junxuan Li and Shaodi You and Antonio Robles-Kelly},
title = {A frequency domain neural network for fast image super-resolution},
journal = {arXiv},
url = {http://arxiv.org/abs/1712.03037},
arxivid = {1712.03037},
archiveprefix = {arXiv},
eprint = {1712.03037},
year = {2017},
issn = {23318422},
abstract = {In this paper, we present a frequency domain neural network for image super-resolution. The network employs the convolution theorem so as to cast convolutions in the spatial domain as products in the frequency domain. Moreover, the non-linearity in deep nets, often achieved by a rectifier unit, is here cast as a convolution in the frequency domain. This not only yields a network which is very computationally efficient at testing but also one whose parameters can all be learnt accordingly. The network can be trained using back propagation and is devoid of complex numbers due to the use of the Hartley transform as an alternative to the Fourier transform. Moreover, the network is potentially applicable to other problems elsewhere in computer vision and image processing which are often cast in the frequency domain. We show results on super-resolution and compare against alternatives elsewhere in the literature. In our experiments, our network is one to two orders of magnitude faster than the alternatives with an imperceptible loss of performance.},
}

@inproceedings{2016ChenCompressing,
author = {Wenlin Chen and James Wilson and Stephen Tyree and Kilian Q. Weinberger and Yixin Chen},
year = {2016},
volume = {13-17-August-2016},
doi = {10.1145/2939672.2939839},
isbn = {9781450342322},
title = {Compressing convolutional neural networks in the frequency domain},
pages = {1475--1484},
abstract = {Convolutional neural networks (CNN) are increasingly used in many areas of computer vision. They are particularly attractive because of their ability to "absorb" great quantities of labeled data through millions of parameters. However, as model sizes increase, so do the storage and memory requirements of the classifiers, hindering many applications such as image and speech recognition on mobile phones and other devices. In this paper, we present a novel network architecture, Frequency-Sensitive Hashed Nets (FreshNets), which exploits inherent redundancy in both convolutional layers and fully-connected layers of a deep learning model, leading to dramatic savings in memory and storage consumption. Based on the key observation that the weights of learned convolutional filters are typically smooth and low-frequency, we first convert filter weights to the frequency domain with a discrete cosine transform (DCT) and use a low-cost hash function to randomly group frequency parameters into hash buckets. All parameters assigned the same hash bucket share a single value learned with standard backpropagation. To further reduce model size, we allocate fewer hash buckets to high-frequency components, which are generally less important. We evaluate FreshNets on eight data sets, and show that it leads to better compressed performance than several relevant baselines.},
url = {http://dl.acm.org/citation.cfm?doid=2939672.2939839},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
publisher = {ACM Press},
keywords = {convolutional neural networks,hashing,model compression},
mendeley-tags = {convolutional neural networks,hashing,model compression},
}

@collection{1979DenkerErgodic,
isbn = {978-0-387-09517-2},
publisher = {Springer-Verlag},
shorttitle = {Ergodic theory},
editor = {Denker, Manfred and Jacobs, Konrad},
title = {Ergodic theory: proceedings, Oberwolfach, Germany, June 11-17, 1978},
series = {Lecture notes in mathematics ; 729},
}

@article{2018MukhometzianovCapsnet,
author = {Rinat Mukhometzianov and Juan Carrillo},
url = {http://arxiv.org/abs/1805.11195},
abstract = {Image classification has become one of the main tasks in the field of computer vision technologies. In this context, a recent algorithm called CapsNet that implements an approach based on activity vectors and dynamic routing between capsules may overcome some of the limitations of the current state of the art artificial neural networks (ANN) classifiers, such as convolutional neural networks (CNN). In this paper, we evaluated the performance of the CapsNet algorithm in comparison with three well-known classifiers (Fisherfaces, LeNet, and ResNet). We tested the classification accuracy on four datasets with a different number of instances and classes, including images of faces, traffic signs, and everyday objects. The evaluation results show that even for simple architectures, training the CapsNet algorithm requires significant computational resources and its classification performance falls below the average accuracy values of the other three classifiers. However, we argue that CapsNet seems to be a promising new technique for image classification, and further experiments using more robust computation resources and refined CapsNet architectures may produce better outcomes.},
issn = {23318422},
title = {CapsNet comparative performance evaluation for image classification},
year = {2018},
journal = {arXiv},
keywords = {capsule networks,convolutional neural networks,image classification},
mendeley-tags = {capsule networks,convolutional neural networks,image classification},
}

@article{2007FastlCritical,
author = {Eberhard Zwicker and Hugo Fastl},
year = {1999},
doi = {10.1007/978-3-662-09562-1_6},
pages = {149--173},
annote = {OCLC: 7328866217},
title = {Critical Bands and Excitation},
}

@article{CookReal,
author = {Perry R. Cook},
abstract = {Virtual environments such as games and animated and "real" movies require realistic sound effects that can be integrated by computer synthesis. The book emphasizes physical modeling of sound and focuses on real-world interactive sound effects. It is intended for game developers, graphics programmers, developers of virtual reality systems and training simulators, and others who want to learn about computational sound. It is written at an introductory level with mathematical foundations provided in appendices.},
journal = {Real Sound Synthesis for Interactive Applications},
year = {2002},
isbn = {9781498765466},
pages = {1--250},
title = {Real sound synthesis for interactive applications},
doi = {10.1201/b19597},
}

@book{2003TrautmannDigital,
author = {Lutz Trautmann and Rudolf Rabenstein},
booktitle = {Digital Sound Synthesis by Physical Modeling Using the Functional Transformation Method},
abstract = {Based on Trautmann's Ph.D. Thesis},
isbn = {978-1-4613-4900-6 978-1-4615-0049-0},
publisher = {Springer US},
title = {Digital Sound Synthesis by Physical Modeling Using the Functional Transformation Method},
year = {2003},
doi = {10.1007/978-1-4615-0049-0},
}

@book{2003JaynesProbability,
author = {Edwin T Jaynes and G Larry Bretthorst and EBSCO Publishing},
isbn = {978-0-511-06589-7},
url = {http://www5.unitn.it/Biblioteca/it/Web/LibriElettroniciDettaglio/50847},
annote = {OCLC: 982265136},
shorttitle = {Probability theory},
title = {Probability theory: the logic of science},
publisher = {Cambridge University Press},
abstract = {The standard rules of probability can be interpreted as uniquely valid principles in logic. In this book, E.T. Jaynes dispels the imaginary distinction between'probability theory'and'statistical inference', leaving a logical unity and simplicity, which provides greater technical power and flexibility in applications. This book goes beyond the conventional mathematics of probability theory, viewing the subject in a wider context. New results are discussed, along with applications of probability theory to a wide variety of problems in physics, mathematics, economics, chemistry and biology. It contains many exercises and problems, and is suitable for use as a textbook on graduate level courses involving data analysis. The material is aimed at readers who are already familiar with applied mathematics at an advanced undergraduate level or higher. The book will be of interest to scientists working in any area where inference from incomplete information is necessary. (A cura dell'editore).},
}

@book{2013FieldDiscovering,
author = {Andy Field and Jeremy Miles and Zo\"e Field},
annote = {OCLC: 854989686},
booktitle = {Choice Reviews Online},
number = {04},
publisher = {Sage},
edition = {Reprint},
abstract = {Andy Field's self-deprecating, vivacious but yet easy to understand writing style has won him many plaudits, and now an award from the British Psychological Society (2007), for his irreplaceable Discovering Statistics Using SPSS. The Third Edition is now even more accessible to the introductory student at the very beginning of their statistical journey. The textbook now uniquely walks students from very basic to advanced level concepts, all the while grounding knowledge though the use of SPSS. Accompanied by an improved Companion Web site at www.sagepub.co.uk/field3e including animated "SPSS walk-throughs" of tests discussed in the textbook; assessment materials and datasets pertinent to lecturers/instructors in Business & Management and Health Sciences; and a suite of other materials for lecturers/instructors and students as per the 2nd Edition. The original CD-Rom materials are now found on this Web site as well.},
title = {Discovering statistics using R},
year = {2012},
issn = {0009-4978},
pages = {50--2114--50--2114},
volume = {50},
isbn = {978-1-4462-0045-2 978-1-4462-0046-9},
doi = {10.5860/choice.50-2114},
}

@book{2012TijmsUnderstanding,
author = {Henk Tijms},
abstract = {Understanding Probability is a unique and stimulating approach to a first course in probability. The first part of the book demystifies probability and uses many wonderful probability applications from everyday life to help the reader develop a feel for probabilities. The second part, covering a wide range of topics, teaches clearly and simply the basics of probability. This fully revised third edition has been packed with even more exercises and examples and it includes new sections on Bayesian inference, Markov chain Monte-Carlo simulation, hitting probabilities in random walks and Brownian motion, and a new chapter on continuous-time Markov chains with applications. Here you will find all the material taught in an introductory probability course. The first part of the book, with its easy-going style, can be read by anybody with a reasonable background in high school mathematics. The second part of the book requires a basic course in calculus.},
isbn = {9781139206990},
annote = {OCLC: 803790744},
booktitle = {Understanding Probability, Third Edition},
doi = {10.1017/CBO9781139206990},
publisher = {Cambridge Univ. Press},
pages = {1--562},
edition = {3. ed},
year = {2012},
title = {Understanding probability, third edition},
keywords = {chance,mathematical analysis,mathematics / probability /\\& statistics / general,probabilities},
mendeley-tags = {chance,mathematical analysis,mathematics / probability /\\& statistics / general,probabilities},
}

@article{KennedyHilbert,
author = {Rodney A. Kennedy and Parastoo Sadeghi},
title = {Hilbert space methods in signal processing},
journal = {Hilbert Space Methods in Signal Processing},
abstract = {This lively and accessible book describes the theory and applications of Hilbert spaces and also presents the history of the subject to reveal the ideas behind theorems and the human struggle that led to them. The authors begin by establishing the concept of 'countably infinite', which is central to the proper understanding of separable Hilbert spaces. Fundamental ideas such as convergence, completeness and dense sets are first demonstrated through simple familiar examples and then formalised. Having addressed fundamental topics in Hilbert spaces, the authors then go on to cover the theory of bounded, compact and integral operators at an advanced but accessible level. Finally, the theory is put into action, considering signal processing on the unit sphere, as well as reproducing kernel Hilbert spaces. The text is interspersed with historical comments about central figures in the development of the theory, which helps bring the subject to life.},
volume = {9781107010031},
isbn = {9780511844515},
doi = {10.1017/CBO9780511844515},
pages = {1--420},
year = {2011},
}

@book{2017FanoTwenty,
author = {Guido Fano and S. M. Blinder},
isbn = {9783319587318},
title = {B-Twenty-First Century Quantum Mechanics: Hilbert Space to Quantum Computers},
shorttitle = {Twenty-First Century Quantum Mechanics},
abstract = {Many years ago, my math teacher assigned me the task to give a presentation to the rest of the class. Time to prepare, 2 weeks; topic, group theory and its application to quantum mechanics. I politely observed that I had not yet had a course on quantum theory; I knew nothing about it. Teacher's reply was: "Well, you study it." His name was Guido Fano. This is how Guido Fano had me learning quantum theory. At home, alone, with a bunch of books on my desk, Dirac's one on top of all. I have been forever grateful to him, for this and much more. If I got into theoretical physics, it's thanks to him, the trust that I found, with surprise, from him. Today, when I realize that there is something that I should know and do not know (which of course happen contin- uously), I hear his voice in my mind saying "Well, you study it." But the second lesson I learned from Guido Fano, both about life and quantum theory, was even more crucial. After my presentation to the class, I thanked him and said: "I have now learned quantum mechanics." His reply was "No you haven't." How true. And not just because a couple of weeks couldn't suffice to digest the theory, but because nearly a century from Heisenberg and Dirac hasn't sufficed the community of us all to come to terms with this theory. In the months after my presentation, I kept discovering, first from Fano himself, and then over and over for the rest of my life, how multifaceted is this theory, and how slippery our actual understanding to it. The more I have learned about the theory, the less clear it has become. When comes the moment of saying what we really have learned about the world in finding that quantum mechanics works so effectively—well, we disagree among ourselves, and there are nearly as many opinions as physicists (not counting the philosophers). Long time later, with this new book on quantum theory, once again Guido Fano, together with his overseas colleague S.M. Blinder, opens up new sides of quantum mechanics for me. The beauty of this book, in my opinion, is that it merges very different traditions of thinking about the theory and teaching it. For a theory still so perplexing, this is what we need; in order to understand it better, to learn it better, but also to learn how to better use it. If had to start again learning quantum theory from scratch, as I did 40 years ago, I would do as I did: at home, alone, with many texts on my desk. But I would certainly have, next to Dirac's one, this book.},
publisher = {Springer International Publishing},
series = {UNITEXT for Physics},
booktitle = {Program},
doi = {10.1007/978-3-319-58732-5},
year = {2017},
}

@book{2017SamuelProgramming,
author = {Stephen Samuel and Stefan Bocutiu},
isbn = {9781787126367},
shorttitle = {Programming Kotlin},
title = {Programming Kotlin : familiarize yourself with all of Kotlin's features with this in-depth guide},
}

@article{1982Jacquet-lagrezeAssessing,
author = {E. Jacquet-Lagreze and J. Siskos},
abstract = {The purpose of the method presented in this paper is to assess additive utility functions which aggregate multiple criteria in a composite criterion, using the information given by a subjective ranking on a set of stimuli or actions (weak-order comparison judgments) and the multicriteria evaluations of these actions. It is an ordinal regression method using linear programming to estimate the parameters of the utility function. Stability and sensitivity analysis leads to the assessment of a set of utility functions by means of post-optimality analysis techniques in linear programming. Finally, a simple illustrative example is presented and some extensions of the method are proposed. \textcopyright 1982.},
number = {2},
doi = {10.1016/0377-2217(82)90155-2},
journal = {European Journal of Operational Research},
issn = {03772217},
url = {https://linkinghub.elsevier.com/retrieve/pii/0377221782901552},
volume = {10},
title = {Assessing a set of additive utility functions for multicriteria decision-making, the UTA method},
year = {1982},
pages = {151--164},
}

@article{2001BeutheComparative,
author = {Michel Beuthe and Giuseppe Scannella},
journal = {European Journal of Operational Research},
doi = {10.1016/S0377-2217(00)00042-4},
pages = {246--262},
title = {Comparative analysis of UTA multicriteria methods},
year = {2001},
abstract = {This paper reviews the main variants of the utility additive (UTA) multicriteria method, and systematically compares their predictive performance on two sets of data. It analyzes both those cases where the model provides a ranking with errors and those without errors. First, it shows that the reference projects should be chosen carefully in order to elicit as much information as possible from the decision maker: a set of projects satisfying a fractional factorial plan is recommended. Second, it discusses the use of alternative post-optimality methods for solving the problem of multiple solutions and their different predictive performances. Third, it presents the results of simulations based on utility functions involving interdependence between criteria, and shows that UTA handles this problem effectively by an adjustment of its coefficients. Finally, the influence of the model's parameters on the predictive performance is also investigated.},
volume = {130},
issn = {03772217},
number = {2},
}

@incollection{2005SiskosUta,
author = {Yannis Siskos and Evangelos Grigoroudis and Nikolaos F. Matsatsinis},
abstract = {UTA methods refer to the philosophy of assessing a set of value or utility functions, assuming the axiomatic basis of MAUT and adopting the preference disaggregation principle. UTA methodology uses linear programming techniques in order to optimally infer additive value/utility functions, so that these functions are as consistent as possible with the global decision-maker's preferences (inference principle). The main objective of this chapter is to analytically present the UTA method and its variants and to summarize the progress made in this field. The historical background and the philosophy of the aggregation-disaggregation approach are firstly given. The detailed presentation of the basic UTA algorithm is presented, including discussion on the stability and sensitivity analyses. Several variants of the UTA method, which incorporate different forms of optimality criteria, are also discussed. The implementation of the UTA methods is illustrated by a general overview of UTA-based DSSs, as well as real-world decision-making applications. Finally, several potential future research developments are discussed.},
issn = {08848289},
isbn = {978-0-387-23067-2},
doi = {10.1007/978-1-4939-3094-4_9},
year = {2016},
pages = {315--362},
title = {UTA methods},
booktitle = {International Series in Operations Research and Management Science},
publisher = {Springer-Verlag},
volume = {233},
keywords = {additive utility,multicriteria analysis,ordinal regression,preference disaggregation,uta methods},
mendeley-tags = {additive utility,multicriteria analysis,ordinal regression,preference disaggregation,uta methods},
}

@book{1979HwangMultiple,
author = {Tomas Gal},
number = {4},
abstract = {Intermodal transportation forms the backbone of the world trade and\nexhibits significant growth resulting in modifications to the structure\nof maritime and land -based transportation systems, as well as in\nthe increase of the volume and value of intermodal traffic moved\nby each individual mode. Railroads play an important role within\nthe intermodal chain. Their own interests and environment-conscious\npublic policy have railroads aiming to increase their market share.\nTo address the challenge of efficiently competing with trucking in\noffering customers timely, flexible, and �low�-cost transportation\nservices, railroads propose new types of services and enhanced performances.\nFrom an Operations Research point of view, this requires that models\nbe revisited and appropriate methods be devised. The paper discusses\nsome of these issues and developments focusing on tactical planning\nissues and identifies challenging and promising research directions.},
series = {Lecture Notes in Economics and Mathematical Systems},
booktitle = {European Journal of Operational Research},
issn = {03772217},
isbn = {978-3-540-09111-0},
pages = {287--288},
doi = {10.1016/0377-2217(80)90117-4},
title = {Multiple objective decision making - methods and applications: A state-of-the art survey},
publisher = {Springer Berlin Heidelberg},
volume = {4},
year = {1980},
}

@book{2013IshizakaMulti,
author = {Alessio Ishizaka and Philippe Nemery},
shorttitle = {Multi-criteria decision analysis},
title = {Multi-criteria decision analysis: methods and software},
isbn = {978-1-119-97407-9 978-1-118-64490-4},
publisher = {Wiley},
annote = {OCLC: 931031284},
}

@book{2000TriantaphyllouMulti,
author = {E Triantaphyllou},
isbn = {9789814560733},
pages = {35--48},
publisher = {Springer US},
title = {Multi-Criteria Decision Making Methods. In: Multi-criteria Decision Making Methods: A Comparative Study},
abstract = {, 2000. (pp. 5-21). Springer, Boston, MA.},
number = {August},
doi = {10.1007/978-1-4757-3157-6},
series = {Applied Optimization},
url = {http://link.springer.com/10.1007/978-1-4757-3157-6},
volume = {44 Springe},
shorttitle = {Multi-criteria Decision Making Methods},
year = {2000},
booktitle = {Applied Optimization},
keywords = {fuzzy decision making analytical,hierarchy process,methods decision making in,water resources},
mendeley-tags = {fuzzy decision making analytical,hierarchy process,methods decision making in,water resources},
}

@book{2009BritainMulti,
author = {Great Britain and Department for Communities and Local Government},
isbn = {978-1-4098-1023-0},
annote = {OCLC: 502304922},
url = {http://www.communities.gov.uk/documents/corporate/pdf/1132618.pdf},
publisher = {Communities and Local Government},
title = {Multi-criteria analysis: a manual.},
shorttitle = {Multi-criteria analysis},
}

@book{2002BeltonMultiple,
author = {S. BELTON and T.S. STEWART},
year = {2002},
publisher = {Springer US},
abstract = {The field of multiple criteria decision analysis (MCDA), also termed multiple criteria decision aid, or multiple criteria decision making (MCDM), has developed rapidly over the past quarter century and in the process a number of divergent schools of thought have emerged. This can make it difficult for a new entrant into the field to develop a comprehensive appreciation of the range of tools and approaches which are available to assist decision makers in dealing with the ever-present difficulties of seeking compromise or consensus between conflicting inter ests and goals, i.e. the "multiple criteria". The diversity of philosophies and models makes it equally difficult for potential users of MCDA, i.e. management scientists and/or decision makers facing problems involving conflicting goals, to gain a clear understanding of which methodologies are appropriate to their particular context. Our intention in writing this book has been to provide a compre hensive yet widely accessible overview of the main streams of thought within MCDA. We aim to provide readers with sufficient awareness of the underlying philosophies and theories, understanding of the practi cal details of the methods, and insight into practice to enable them to implement any of the approaches in an informed manner. As the title of the book indicates, our emphasis is on developing an integrated view of MCDA, which we perceive to incorporate both integration of differ ent schools of thought within MCDA, and integration of MCDA with broader management theory, science and practice.},
annote = {OCLC: 903189757},
isbn = {978-1-4613-5582-3 978-1-4615-1495-4},
title = {Multiple Criteria Decision Analysis. An Integrated Approach. Kluwer Academic Publishers, Massachusetts.},
}

@book{2010TrappenbergFundamentals,
author = {Thomas P Trappenberg},
publisher = {Oxford University Press},
year = {2003},
number = {05},
pages = {40--2778--40--2778},
edition = {Second edition},
booktitle = {Choice Reviews Online},
doi = {10.5860/choice.40-2778},
annote = {OCLC: 699333421},
volume = {40},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
isbn = {978-0-19-956841-3},
title = {Fundamentals of computational neuroscience},
issn = {0009-4978},
}

@book{2015DharaniBiology,
author = {Krishnagopal Dharani},
year = {2014},
abstract = {The question of "what is thought" has intrigued society for ages, yet it is still a puzzle how the human brain can produce a myriad of thoughts and can store seemingly endless memories. All we know is that sensations received from the outside world imprint some sort of molecular signatures in neurons - or perhaps synapses - for future retrieval. What are these molecular signatures, and how are they made? How are thoughts generated and stored in neurons? The Biology of Thought explores these issues and proposes a new molecular model that sheds light on the basis of human thought. Step-by-step it describes a new hypothesis for how thought is produced at the micro-level in the brain - right at the neuron. Despite its many advances, the neurobiology field lacks a comprehensive explanation of the fundamental aspects of thought generation at the neuron level, and its relation to intelligence and memory. Derived from existing research in the field, this book attempts to lay biological foundations for this phenomenon through a novel mechanism termed the "Molecular-Grid Model" that may explain how biological electrochemical events occurring at the neuron interact to generate thoughts. The proposed molecular model is a testable hypothesis that hopes to change the way we understand critical brain function, and provides a starting point for major advances in this field that will be of interest to neuroscientists the world over.},
isbn = {9780128009000},
annote = {OCLC: 931711206},
publisher = {Elsevier Acad. Press},
pages = {1--229},
booktitle = {The Biology of Thought: A Neuronal Mechanism in the Generation of Thought - A New Molecular Model},
shorttitle = {The biology of thought},
title = {The biology of thought: A neuronal mechanism in the generation of thought - A new molecular model},
}

@book{2016BearNeuroscience,
author = {Isaac K. Wood},
booktitle = {Journal of Child and Family Studies},
doi = {10.1007/bf02234670},
number = {3},
isbn = {978-0-7817-7817-6},
shorttitle = {Neuroscience},
publisher = {Lippincott Williams //\\\& Wilkins},
pages = {377--379},
title = {Neuroscience: Exploring the brain},
year = {1996},
volume = {5},
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
annote = {OCLC: 1090148410},
issn = {1062-1024},
}

@book{2015SterlingPrinciples,
author = {Peter Sterling and Simon Laughlin},
publisher = {The MIT Press},
doi = {10.7551/mitpress/9780262028707.001.0001},
title = {Principles of neural design},
booktitle = {Principles of Neural Design},
annote = {OCLC: 915145186},
year = {2015},
pages = {1--542},
isbn = {9780262327312},
issn = {0009-4978},
abstract = {Neuroscience research has exploded, with more than fifty thousand neuroscientists applying increasingly advanced methods. A mountain of new facts and mechanisms has emerged. And yet a principled framework to organize this knowledge has been missing. In this book, Peter Sterling and Simon Laughlin, two leading neuroscientists, strive to fill this gap, outlining a set of organizing principles to explain the whys of neural design that allow the brain to compute so efficiently. Setting out to –reverse engineer— the brain -- disassembling it to understand it -- Sterling and Laughlin first consider why an animal should need a brain, tracing computational abilities from bacterium to protozoan to worm. They examine bigger brains and the advantages of –anticipatory regulation— identify constraints on neural design and the need to –nanofy— and demonstrate the routes to efficiency in an integrated molecular system, phototransduction. They show that the principles of neural design at finer scales and lower levels apply at larger scales and higher levels; describe neural wiring efficiency; and discuss learning as a principle of biological design that includes –save only what is needed.—Sterling and Laughlin avoid speculation about how the brain might work and endeavor to make sense of what is already known. Their distinctive contribution is to gather a coherent set of basic rules and exemplify them across spatial and functional scales. .},
keywords = {brain,learning,neural circuitry,neural pathways,physiology,physiology},
mendeley-tags = {brain,learning,neural circuitry,neural pathways,physiology,physiology},
}

@article{LedouxHow,
author = {S Self},
year = {2003},
title = {How Our Brains Become Who We Are},
journal = {Joseph LeDoux Viking Penguin},
pages = {1--227},
}

@article{DayanTheoretical,
author = {Wesley J. Wildman and Richard Sosis and Patrick McNamara},
pages = {181--182},
title = {Theoretical Neuroscience},
number = {3},
volume = {4},
doi = {10.1080/2153599X.2014.951911},
journal = {Religion, Brain and Behavior},
issn = {21535981},
year = {2014},
}

@book{2014VanderbeiLinear,
author = { V and Robert J. erbei},
publisher = {Springer},
shorttitle = {Linear programming},
volume = {285},
year = {2020},
edition = {4. ed},
issn = {22147934},
title = {Linear programming: Foundations and extensions},
booktitle = {International Series in Operations Research and Management Science},
isbn = {978-1-4614-7629-0 978-1-4614-7630-6},
annote = {OCLC: 859535863},
series = {International series in operations research //\\\& management science},
doi = {10.2307/3010658},
number = {196},
pages = {1--465},
}

@book{2000SchrijverTheory,
author = {David K. Smith and Alex Schrijver and  er},
issn = {01605682},
year = {1987},
isbn = {978-0-471-98232-6},
title = {Theory of Linear and Integer Programming.},
series = {Wiley-Interscience series in discrete mathematics and optimization},
number = {6},
pages = {561},
annote = {OCLC: 247967491},
abstract = {applicability for this approach.},
publisher = {Wiley},
edition = {Reprinted},
booktitle = {The Journal of the Operational Research Society},
doi = {10.2307/2582770},
volume = {38},
}

@book{2016ChiconeInvitation,
author = {Carmen (professor Of Mathematics Chicone University Of Mi},
annote = {OCLC: 1023278769},
isbn = {978-0-12-804153-6},
title = {Invitation to applied mathematics - differential equations, modeling, and c.},
}

@book{2013LukeEssentials,
author = {Luke (George Mason University) Sean},
annote = {OCLC: 876159426},
title = {Essentials of Metaheuristics: A Set of Undergraduate Lecture Notes},
abstract = {This is a set of lecture notes for an undergraduate class on metaheuristics. They were constructed for a course I taught in Spring of 2009, and I wrote them because, well, theres a lack of undergraduate texts on the topic. As these are lecture notes for an undergraduate class on the topic, which is unusual, these notes have certain traits. First, theyre informal and contain a number of my own personal biases and misinformation. Second, they are light on theory and examples: theyre mostly descriptions of algorithms and handwavy, intuitive explanations about why and where youd want to use them. Third, theyre chock full of algorithms great and small. I think these notes would best serve as a complement to a textbook, but can also stand alone as rapid introduction to the field. I make no guarantees whatsoever about the correctness of the algorithms or text in these notes. Indeed, theyre likely to have a lot of errors. Please tell me of any errors you find (and correct!). Some complex algorithms have been presented in simplified versions. In those cases Ive noted it.},
edition = {Second edition, online version 2.0},
pages = {1--220},
year = {2010},
issn = {1389-2576},
booktitle = {Optimization},
publisher = {lulu.com},
shorttitle = {Essentials of metaheuristics},
isbn = {9780557148592},
}

@inproceedings{1992VemulapatiSolving,
author = {Udaya B. Vemulapati},
url = {http://ieeexplore.ieee.org/document/232669/},
pages = {381--384},
year = {1992},
booktitle = {Proccedings of the Scalable High Performance Computing Conference-SHPCC-92},
isbn = {0818627751},
doi = {10.1109/shpcc.1992.232669},
title = {Solving equality constrained least squares problems},
abstract = {Constrained least squares problems occur often in practice, mostly as sub-problems in many optimization contexts. For solving large and sparse instances of these problems on parallel architectures with distributed memory, the use of static data structures to represent the sparse matrix is preferred during the factorization. But the accurate detection of the rank of the constraint matrix is also very critical to the accuracy of the computed solution. In this work, we examine the solution of the constrained problem using weighting approach. We demonstrate that all computations can be carried out using a static data structure that is generated using the symbolic structure of the input matrices, making use of a recently proposed rank detection procedure. We show good speed-ups in solving large and sparse equality conditioned least squares problems on hypercubes up to 128 processors.},
publisher = {IEEE Comput. Soc. Press},
}

@book{2015BjoerckNumerical,
author = {Ake Bjorck},
abstract = {Work on this book started more than 15 years ago, when I began a revision of a textbook from 1974 on numerical methods. That book devoted only about 90 pages to matrix computations compared to the more than 700 pages of the present book. This difference reflects not only a change in ambition, but also an increase in size and importance of the subject. A stunning growth in hardware performance has allowed more sophisticated mathematical models to be employed in sciences and engineering. In most of these applications, solution of systems of linear equations and/or eigenvalue problems lies at the core. Increased problem sizes and changes in computer architecture have also made the development of new methods and new implementations of old ones necessary. Although there is a link between matrix computations and linear algebra as taught in departments of mathematics, there are also several important differences. Matrices are used to represent many different objects such as networks and images, besides linear transformations. Concepts such as ill-conditioning, norms, and orthogonality, which do not extend to arbitrary fields, are central to matrix com- putations. This is the reason for not using ‘‘linear algebra'' in the title of the book.},
series = {Texts in Applied Mathematics},
url = {http://link.springer.com/10.1007/978-3-319-05089-8},
doi = {10.1007/978-3-319-05089-8},
publisher = {Springer International Publishing},
volume = {59},
year = {2015},
isbn = {978-3-319-05088-1},
pages = {800},
title = {Numerical Methods in Matrix Computations},
}

@article{SelesnickLeast,
author = {Ivan Selesnick},
title = {Least Squares with Examples in Signal Processing 1 NYU-Poly},
number = {2},
url = {http://eeweb.poly.edu/iselesni/lecture_notes/},
year = {2013},
pages = {1--25},
abstract = {These notes address (approximate) solutions to linear equations by least squares. We deal with the 'easy' case wherein the system matrix is full rank. If the system matrix is rank deficient, then other methods are needed, e.g., QR decomposition, singular value decomposition, or the pseudo-inverse, [2, 3]. In these notes, least squares is illustrated by applying it to several basic problems in signal processing: 1. Linear prediction 2. Smoothing 3. Deconvolution 4. System identification 5. Estimating missing data For the use of least squares in filter design, see [1].},
}

@collection{2017JawaidGreen,
editor = {Jawaid, Mohammad and Salit, Mohd Sapuan and Alothman, Othman Y},
isbn = {978-3-319-49381-7 978-3-319-49382-4},
series = {Green energy and technology},
shorttitle = {Green biocomposites},
title = {Green biocomposites: design and applications},
publisher = {Springer International Publishing},
}

@collection{2017JawaidGreena,
author = {Mohammad Jawaid and Salit Mohd Sapuan and Othman Y. Alotman},
title = {Green Biocomposites Manufacturing and Properties},
pages = {409},
annote = {OCLC: 964576721},
editor = {Jawaid, Hohammad and Sapuan, Salit Mohd and Alothman, Othman Y},
shorttitle = {Green biocomposites},
publisher = {Springer International Publishing},
isbn = {978-3-319-46609-5},
series = {Green energy and technology},
year = {2017},
doi = {10.1007/978-3-319-46610-1},
abstract = {Prosthetic socket is one of important part as it involved interface or connecting link between stump and prosthetic components. Besides the functionality of socket itself, it also involved satisfaction on patient due to the force distribution and pressure on stump. Selecting the right liner is essential in order to ensure the prosthesis fits well and is comfortable to wear. The quality and comfort of a prosthetic socket and its design can determine the daily extent of period, as the patients can use their artificial limbs and lead as normal life as possible. Technological advancement has led to wider range of modern orthopedic and prosthetic device. Fibre reinforced composites are most widely used for upper- and lower- limb prostheses due to their superior strength and excellent biocompatibility. In this review, the use of fibre reinforced composite materials for prostheses are viewed. This review article intended to present general information regarding the structure and function of type and application for current prosthetic socket design for the benefit of the reader. This paper also discussed the comfort measurement of residual limb on prosthetic socket.},
url = {http://link.springer.com/10.1007/978-3-319-49382-4},
}

@article{PhillipsBio,
author = {Steven Phillips},
pages = {97},
title = {Bio-Composite Material Applications To},
year = {2009},
}

@collection{2013EbnesajjadHandbook,
author = {Sina Ebnesajjad},
doi = {10.1016/C2011-0-07342-8},
annote = {OCLC: 820108309},
isbn = {9781455730032},
series = {Plastics design library (PDL)},
title = {Handbook of Biopolymers and Biodegradable Plastics: Properties, Processing and Applications},
year = {2012},
editor = {Ebnesajjad, Sina},
abstract = {Biopolymers and Biodegradable Plastics are a hot issue across the Plastics industry, and for many of the industry sectors that use plastic, from packaging to medical devices and from the construction indusry to the automotive sector. This book brings together a number of key biopolymer and biodegradable plastics topics in one place for a broad audience of engineers and scientists, especially those designing with biopolymers and biodegradable plastics, or evaluating the options for switching from traditional plastics to biopolymers. Topics covered include preparation, fabrication, applications and recycling (including biodegradability and compostability). Applications in key areas such as films, coatings controlled release and tissue engineering are discussed. Dr Ebnesajjad provides readers with an in-depth reference for the plastics industry - material suppliers and processors, bio-polymer producers, bio-polymer processors and fabricators - and for industry sectors utilizing biopolymers - automotive, packaging, construction, wind turbine manufacturers, film manufacturers, adhesive and coating industries, medical device manufacturers, biomedical engineers, and the recycling industry. Essential information and practical guidance for engineers and scientists working with bioplastics, or evaluating a migration to bioplastics. Includes key published material on biopolymers, updated specifically for this Handbook, and new material including coverage of PLA and Tissue Engineering Scaffolds. Coverage of materials and applications together in one handbook enables engineers and scientists to make informed design decisions.},
publisher = {Elsevier},
shorttitle = {Handbook of biopolymers and biodegradable plastics},
pages = {1--462},
booktitle = {Handbook of Biopolymers and Biodegradable Plastics: Properties, Processing and Applications},
}

@article{PillaHandbook,
author = {Srikanth Pilla},
pages = {622},
isbn = {9780470626078},
abstract = {In today's world, bioplastics are becoming increasingly prominent owing mainly to scarcity of oil, increase in the cost of petroleum-based commodities, and growing environmental concerns with the dumping of non-biodegradable plastics in landfills. This book summarizes the field of bioplastics by illustrating how they form a unique class of research area that integrates pure and applied sciences such as chemistry, engineering and materials science, to initate solutions. Compelling science demystics this complex and often ambiguous branch of study for benefit of all those concerned with bioplastics. \textcopyright 2011 Scrivener Publishing LLC. All rights reserved.},
doi = {10.1002/9781118203699},
year = {2011},
title = {Handbook of Bioplastics and Biocomposites Engineering Applications},
journal = {Handbook of Bioplastics and Biocomposites Engineering Applications},
}

@article{2015KesslerGreen,
author = {Michael R Kessler and Vijay Kumar Thakur},
title = {Green biorenewable biocomposites: from knowledge to industrial applications},
abstract = {Over the last decades, due to the increased environmental awareness, numerous studies for production of biocomposites based on natural fibers have been published and many comprehensive reviews have been published. Compared with conventional reinforcements, such as glass and carbon fibers, natural fibers which are renewable resources, offer several other advantages including a wide availability (based on different vegetable species), recyclability, low density and low costs, low abrasion and preserving mechanical properties. Application of cellulose fibers in composites is not only beneficial from an ecological point of view, lowering the environmental impact of the final product within the production, usage and disposal period, but it offers further technical and economical benefits. Especially, natural fiber-reinforced biocomposites have the potential to replace current materials used for automotive industrial applications. In order to obtain composites with the best mechanical properties, most of the research activities in the last decades have been concentrated on the surface physical and chemical modifications of the fibers mainly to optimize their interfacial behavior. In the first part of this work, besides the overview of the state-of-the-art description regarding biocomposites, we will also present characterization results of the lab-scaled flax fiber reinforced biopolymer matrices (PLA) as well as compared with the same-industrially produced composites. In the second part of the paper, biocomposites based on "self-reinforced cellulose" or "all-cellulose" composites prepared from cotton textile fabrics by partial fiber surface dissolution in lithium chloride dissolved in N, N-dimethylacetamide will be presented. Two different parameters have been studied: (i) surface treatment medium (alkaline/enzyme/bleaching) and (ii) cotton textile preforms (knits, woven).},
publisher = {American Library Association},
journal = {Choice Reviews Online},
number = {11},
doi = {10.5860/choice.191046},
volume = {52},
pages = {52--5901--52--5901},
shorttitle = {Green biorenewable biocomposites},
year = {2015},
month = {jun},
issn = {0009-4978},
}

@book{2016BucurHandbook,
author = {Voichita Bucur},
doi = {10.1007/978-3-319-32080-9},
abstract = {Introduction This book addresses core questions about the role of materials in general and of wood in particular in the construction of string instruments used in the modern symphony orchestra - violins, violas, cellos and basses. Further attention is given to materials for classical guitars, harps, harpsichords and pianos. While some of the approaches discussed are traditional, most of them depend upon new scientific approaches to the study of the structure of materials, such as for example wood cell structure, which is visible only using modern high resolution microscopic techniques. Many examples of modern and classical instruments are examined, together with the relevance of classical techniques for the treatment of wood. Composite materials, especially designed for soundboards could be a good substitute for some traditional wood species. The body and soundboard of the instrument are of major importance for their acoustical properties, but the study also examines traditional and new wood species used for items such as bows, the instrument neck, string pegs, etc. Wood species' properties for musical instruments and growth origins of woods used by great makers such as Antonio Stradivari are examined and compared with more recently grown woods available to current makers. The role of varnish in the appearance and acoustics of the final instrument is also discussed, since it has often been proposed as a ‘secret ingredient' used by great makers. Aspects related to strings are commented. As well as discussing these subjects, with many illustrations from classical and contemporary instruments, the book gives attention to conservation and restoration of old instruments and the physical results of these techniques. There is also discussion of the current value of old instruments both for modern performances and as works of art having great monetary value. The book will be of interest and value to researchers, advanced students, music historians, and contemporary string instrument makers. Musicians in general, particularly those playing string instruments, will also find its revelations fascinating. It will also attract the attention of those using wood for a variety of other purposes, for its use in musical instruments uncovers many of its fundamental features.},
isbn = {9783319320809},
pages = {1--975},
title = {Handbook of materials for string musical instruments},
year = {2016},
publisher = {Springer International Publishing},
booktitle = {Handbook of Materials for String Musical Instruments},
keywords = {acoustic properties of woods,conservation and restoration of musical insrtuments,construction of string instruments,historic musical instruments,materials mechanics in musical instruments,the materials science of string instruments,wood anysotropy in musical instruments},
mendeley-tags = {acoustic properties of woods,conservation and restoration of musical insrtuments,construction of string instruments,historic musical instruments,materials mechanics in musical instruments,the materials science of string instruments,wood anysotropy in musical instruments},
}

@article{LewisIntroduction,
author = {Mark C Lewis and Lisa L Lacher},
journal = {Introduction to Programming and Problem-Solving Using Scala, Second Edition},
doi = {10.1201/9781315382609},
year = {2016},
title = {Introduction to Programming and Problem-Solving Using Scala, Second Edition},
pages = {591},
}

@book{2005BucklandProgramming,
author = { Buckl and Mat },
series = {Wordware game developer's library},
title = {Programming Game AI by Example},
isbn = {978-1-55622-078-4},
abstract = {Programming Game AI By Example Provides A Comprehensive And Practical Introduction To The "Bread And Butter" AI Techniques Used By The Game Development Industry, Leading The Reader Through The Process Of Designing, Programming, And Implementing Intelligent Agents For Action Games Using The C++ Programming Language. Techniques Covered Include State- And Goal-Based Behavior, Inter-Agent Communication, Individual And Group Steering Behaviors, Team AI, Graph Theory, Search, Path Planning And Optimization, Triggers, Scripting, Scripted Finite State Machines, Perceptual Modeling, Goal Evaluation, Goal Arbitration, And Fuzzy Logic.},
pages = {521},
publisher = {Wordware Publ},
annote = {OCLC: 249763995},
year = {2005},
}

@article{bugnion_scala:applied_nodate,
author = {Pascal Bugnion},
title = {Scala:Applied Machine Learning},
pages = {1623},
}

@book{2004OdianPrinciples,
author = {Joseph A. Biesenberger and Donald H. Sebastian},
publisher = {Wiley-Interscience},
year = {1983},
booktitle = {Princ of Polym Eng},
isbn = {0471086169},
title = {Principles of Polymerization Engineering.},
abstract = {This book deals specifically with processes aimed at the manufacture of polymeric materials. Consistent with the task of engineering science, it emphasizes concepts and principles. The goal is the formulation of generalizations that will be useful in the design, scaling, and modification of polymerization processes. Strategy consists of constructing and analyzing the behavior of relevant model processes and is therefore largely heuristic. Results, whenever possible, take the form of dimensionless algorithms or criteria, with clear physical significance to facilitate their application to actual processes. Actual processes are used occasionally as examples, where sufficient knowledge and data are available. This book is directed primarily toward the industrial engineer or scientist in research or development with a firm technical background who is attempting to apply that background to polymerization processes. It should also be suitable as a text for courses dealing with chemical engineering aspects of polymer processes. Chapter 1 consists of a collection of fundamental concepts on which subsequent chapters are based. Chapter 2 discusses phenomena that are inherent in polymerization reactions. Chapters 3-5 deal with physical factors that affect, or are affected by, polymerizations on an engineering scale. Chapter 6 treats postreactor separation of unreacted monomer and/or diluents.},
edition = {4. ed},
annote = {OCLC: 249002704},
}

@article{1997SussmanStructure,
author = {Gerald Jay Sussman and Hal Abelson},
issn = {08981221},
abstract = {Structure and Interpretation of Computer Programs has had a dramatic impact on computer science curricula over the past decade. This long-awaited revision contains changes throughout the text.There are new implementations of most of the major programming systems in the book, including the interpreters and compilers, and the authors have incorporated many small changes that reflect their experience teaching the course at MIT since the first edition was published.A new theme has been introduced that emphasizes the central role played by different approaches to dealing with time in computational models: objects with state, concurrent programming, functional programming and lazy evaluation, and nondeterministic programming. There are new example sections on higher-order procedures in graphics and on applications of stream processing in numerical programming, and many new exercises.In addition, all the programs have been reworked to run in any Scheme implementation that adheres to the IEEE standard.},
journal = {Computers & Mathematics with Applications},
number = {4},
volume = {33},
doi = {10.1016/s0898-1221(97)90051-1},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0898122197900511},
year = {1997},
pages = {133},
publisher = {Elsevier BV},
title = {Structure and interpretation of computer programs, (second edition)},
month = {feb},
}

@book{2017BallWriting,
author = {Thorsten Ball},
booktitle = {Dk},
archiveprefix = {arXiv},
isbn = {9788578110796},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
issn = {1098-6596},
eprint = {arXiv:1011.1669v3},
pages = {1689--1699},
pmid = {25246403},
volume = {53},
title = {Writing An Interpreter In Go},
number = {9},
arxivid = {arXiv:1011.1669v3},
year = {2015},
keywords = {icle},
mendeley-tags = {icle},
}

@book{2016EngQt5,
author = {Lee Zhi Eng},
title = {Qt5 C++ GUI programming cookbook : use Qt5 to design and build a graphical user interface that is functional, appealing, and user-friendly for your software application},
annote = {OCLC: 960408279},
year = {2016},
isbn = {9781783280278},
publisher = {Packt Publishing},
shorttitle = {Qt5 C++ GUI programming cookbook},
series = {Quick answers to common problems},
}

@book{2009HaykinNeural,
author = {Simon Haykin},
isbn = {9780131471399},
abstract = {Fluid and authoritative, this well-organized book represents the first comprehensive treatment of neural networks from an engineering perspective, providing extensive, state-of-the-art coverage that will expose readers to the myriad facets of neural networks and help them appreciate the technology's origin, capabilities, and potential applications.Examines all the important aspects of this emerging technolgy, covering the learning process, back propogation, radial basis functions, recurrent networks, self-organizing systems, modular networks, temporal processing, neurodynamics, and VLSI implementation. Integrates computer experiments throughout to demonstrate how neural networks are designed and perform in practice. Chapter objectives, problems, worked examples, a bibliography, photographs, illustrations, and a thorough glossary all reinforce concepts throughout. New chapters delve into such areas as support vector machines, and reinforcement learning/neurodynamic programming, plus readers will find an entire chapter of case studies to illustrate the real-life, practical applications of neural networks. A highly detailed bibliography is included for easy reference.For professional engineers and research scientists.},
publisher = {Pearson},
edition = {3. ed},
title = {Neural Networks and Learning Machines},
year = {2008},
volume = {3},
booktitle = {Pearson Prentice Hall New Jersey USA 936 pLinks},
issn = {14337851},
pages = {906},
annote = {OCLC: 857737780},
keywords = {machines learning,neural network},
mendeley-tags = {machines learning,neural network},
}

@article{deng_deep_nodate,
author = {Li Deng and Dong Yu},
pages = {197},
title = {Deep Learning: Methods and Applications},
volume = {7},
}

@collection{2014KowaliwGrowing,
author = {Kowaliw Taras and Bredeche Nicolas and Ren\`e Doursat},
annote = {OCLC: 892794596},
issn = {1860949X},
booktitle = {Studies in Computational Intelligence},
volume = {557},
shorttitle = {Growing adaptive machines},
isbn = {978-3-642-55336-3 978-3-642-55337-0},
editor = {Kowaliw, Taras and Bredeche, Nicolas and Doursat, Ren\'e},
publisher = {Springer},
doi = {10.1007/978-3-642-55337-0},
number = {557},
year = {2014},
series = {Studies in computational intelligence},
title = {Growing adaptive machines combining development and learning in artificial neural networks},
}

@article{CilimkovicNeural,
author = {Mirza Cilimkovic},
abstract = {Neural Networks (NN) are important data mining tool used for classification and clustering. It is an attempt to build machine that will mimic brain activities and be able to learn. NN usually learns by examples. If NN is supplied with enough examples, it should be able to perform classification and even discover new trends or patterns in data. Basic NN is composed of three layers, input, output and hidden layer. Each layer can have number of nodes and nodes from input layer are connected to the nodes from hidden layer. Nodes from hidden layer are connected to the nodes from output layer. Those connections represent weights between nodes. This paper describes one of most popular NN algorithms, Back Propagation (BP) Algorithm. The aim is to show the logic behind this algorithm. Idea behind BP algorithm is quite simple, output of NN is evaluated against desired output. If results are not satisfactory, connection (weights) between layers are modified and process is repeated again and again until error is small enough. Simple BP example is demonstrated in this paper with NN architecture also covered. New implementation of BP algorithm are emerging and there are few parameters that could be changed to improve performance of BP.},
number = {July},
title = {Neural Networks and Back Propagation Algorithm},
year = {2010},
journal = {Fett.Tu-Sofia.Bg},
url = {http://fett.tu-sofia.bg/et/2006/ET2006 BOOK 1/Circuits and Systems/173 Paper-V_Skorpil.pdf},
pages = {3 -- 7},
keywords = {artificial neural networks,back propagation algorithm,neural networks},
mendeley-tags = {artificial neural networks,back propagation algorithm,neural networks},
}

@book{2016ShanmuganathanArtificial,
author = {Subana Shanmuganathan},
title = {Artificial neural network modelling: An introduction},
year = {2016},
abstract = {While scientists from different disciplines, such as neuroscience, medicine and high performance computing, eagerly attempt to understand how the human brain functioning happens, Knowledge Engineers in computing have been successful in making use of the brain models thus far discovered to introduce heuristics into computational algorithmic modelling. Gaining further understanding on human brain/nerve cell anatomy, structure, and how the human brain functions, is described to be significant especially, to devise treatments for presently described as incurable brain and nervous system related diseases, such as Alzheimer's and epilepsy. Despite some major breakthroughs seen over the last few decades neuroanatomists and neurobiologists of the medical world are yet to understand how we humans think, learn and remember, and how our cognition and behaviour are linked. In this context, the chapter outlines the most recent human brain research initiatives following which early Artificial Neural Network (ANN) architectures, components, related terms and hybrids are elaborated.},
pages = {1--14},
doi = {10.1007/978-3-319-28495-8_1},
annote = {OCLC: 939520392},
issn = {1860949X},
volume = {628},
isbn = {978-3-319-28495-8 978-3-319-28493-4},
booktitle = {Studies in Computational Intelligence},
}

@book{2019VasilevPython,
author = {Ivan Vasilev and Daniel Slater and Gianmario Spacagna and Peter Roelants and Valentino Zocca},
booktitle = {Packt Publishing},
title = {Python Deep Learning: Exploring Deep Learning Techniques and Neural Network Architectures with PyTorch, Keras and TensorFlow},
year = {2018},
url = {http://proquest.safaribooksonline.com/?fpi=9781789348460},
annote = {OCLC: 1086398837},
abstract = {2nd ed. Description based upon print version of record. Types of GANs The book will help you learn deep neural networks and their applications in computer vision, generative models, and natural language processing. It will also introduce you to the area of reinforcement learning, where you'll learn the state-of-the-art algorithms to teach the machines how to play games like Go and Atari. Cover; Title Page; Copyright and Credits; About Packt; Contributors; Table of Contents; Preface; Chapter 1: Machine Learning -- an Introduction; Introduction to machine learning; Different machine learning approaches; Supervised learning; Linear and logistic regression; Support vector machines; Decision Trees; Naive Bayes; Unsupervised learning; K-means; Reinforcement learning; Q-learning; Components of an ML solution; Neural networks; Introduction to PyTorch; Summary; Chapter 2: Neural Networks; The need for neural networks; An introduction to neural networks; An introduction to neurons An introduction to layersMulti-layer neural networks; Different types of activation function; Putting it all together with an example; Training neural networks ; Linear regression; Logistic regression; Backpropagation; Code example of a neural network for the XOR function ; Summary; Chapter 3: Deep Learning Fundamentals; Introduction to deep learning; Fundamental deep learning concepts ; Feature learning; Deep learning algorithms; Deep networks; A brief history of contemporary deep learning; Training deep networks; Applications of deep learning; The reasons for deep learning's popularity Introducing popular open source librariesTensorFlow; Keras; PyTorch; Using Keras to classify handwritten digits; Using Keras to classify images of objects; Summary; Chapter 4: Computer Vision with Convolutional Networks; Intuition and justification for CNN; Convolutional layers; A coding example of convolution operation; Stride and padding in convolutional layers; 1D, 2D, and 3D convolutions; 1x1 convolutions; Backpropagation in convolutional layers; Convolutional layers in deep learning libraries; Pooling layers; The structure of a convolutional network Classifying handwritten digits with a convolutional network Improving the performance of CNNs; Data pre-processing; Regularization; Weight decay; Dropout; Data augmentation; Batch normalization; A CNN example with Keras and CIFAR-10; Summary; Chapter 5: Advanced Computer Vision; Transfer learning; Transfer learning example with PyTorch; Advanced network architectures; VGG; VGG with Keras, PyTorch, and TensorFlow; Residual networks; Inception networks; Inception v1; Inception v2 and v3; Inception v4 and Inception-ResNet; Xception and MobileNets; DenseNets; Capsule networks Limitations of convolutional networksCapsules; Dynamic routing; Structure of the capsule network; Advanced computer vision tasks; Object detection; Approaches to object detection; Object detection with YOLOv3; A code example of YOLOv3 with OpenCV; Semantic segmentation; Artistic style transfer; Summary; Chapter 6: Generating Images with GANs and VAEs; Intuition and justification of generative models; Variational autoencoders; Generating new MNIST digits with VAE; Generative Adversarial networks; Training GANs; Training the discriminator; Training the generator; Putting it all together},
isbn = {1789348463, 978-1789348460},
shorttitle = {Python deep learning},
pages = {367},
}

@book{1999AnthonyNeural,
author = {Martin Anthony and Peter L. Bartlett},
abstract = {This book describes recent theoretical advances in the study of artificial neural networks. It explores probabilistic models of supervised learning problems, and addresses the key statistical and computational questions. Research on pattern classification with binary-output networks is surveyed, including a discussion of the relevance of the Vapnik-Chervonenkis dimension. Estimates of this dimension are calculated for several neural network models. A model of classification by real-output networks is developed, and the usefulness of classification with a large margin is demonstrated. The authors explain the role of scale-sensitive versions of the Vapnik-Chervonenkis dimension in large margin classification, and in real estimation. They also discuss the computational complexity of neural network learning, describing a variety of hardness results, and outlining two efficient constructive learning algorithms. The book is self-contained and is intended to be accessible to researchers and graduate students in computer science, engineering, and mathematics.},
title = {Neural Network Learning},
booktitle = {Neural Network Learning},
isbn = {978-0-511-62421-6},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511624216},
year = {1999},
shorttitle = {Neural Network Learning},
publisher = {Cambridge University Press},
doi = {10.1017/cbo9780511624216},
}

@book{2007GalushkinNeural,
author = {Galushkin Alex and  er},
annote = {OCLC: 938669307},
booktitle = {Journal of Chemical Information and Modeling},
pages = {1689--1699},
isbn = {9788578110796},
pmid = {25246403},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {Neural Networks Theory},
issn = {1098-6596},
volume = {53},
year = {2007},
number = {9},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
keywords = {icle},
mendeley-tags = {icle},
}

@book{2016LayLinear,
author = {David C Lay and Steven R Lay and Judith McDonald},
abstract = {With traditional linear algebra texts, the course is relatively easy for students during the early stages as material is presented in a familiar, concrete setting. However, when abstract concepts are introduced, students often hit a wall. Instructors seem to agree that certain concepts (such as linear independence, spanning, subspace, vector space, and linear transformations) are not easily understood and require time to assimilate. These concepts are fundamental to the study of linear algebra, so students' understanding of them is vital to mastering the subject. This text makes these concepts more accessible by introducing them early in a familiar, concrete Rn setting, developing them gradually, and returning to them throughout the text so that when they are discussed in the abstract, students are readily able to understand.},
volume = {373},
number = {SUPPL.},
isbn = {978-0-321-98238-4},
doi = {10.2307/2978065},
annote = {OCLC: 875056178},
issn = {00243795},
year = {2003},
booktitle = {Linear Algebra and Its Applications},
title = {Linear Algebra and Its Applications},
}

@book{2008Leyton-brownEssentials,
author = {Kevin Leyton-Brown and Yoav Shoham},
number = {1},
year = {2008},
pages = {1--88},
isbn = {978-1-59829-593-1 978-1-59829-594-8},
issn = {1939-4608},
series = {Synthesis lectures on artificial intelligence and machine learning},
abstract = {applicability for this approach.},
title = {Essentials of Game Theory: A Concise Multidisciplinary Introduction},
doi = {10.2200/s00108ed1v01y200802aim003},
volume = {2},
annote = {OCLC: 236164649},
publisher = {Morgan ////////\\\& Claypool Publishers},
booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
shorttitle = {Essentials of game theory},
}

@book{2009GintisGame,
author = {Herbert Gintis},
edition = {2. ed},
title = {Game theory evolving: A problem-centered introduction to modeling strategic interaction second edition},
abstract = {Since its original publication in 2000,Game Theory Evolvinghas been considered the best textbook on evolutionary game theory. This completely revised and updated second edition ofGame Theory Evolvingcontains new material and shows students how to apply game theory to model human behavior in ways that reflect the special nature of sociality and individuality. The textbook continues its in-depth look at cooperation in teams, agent-based simulations, experimental economics, the evolution and diffusion of preferences, and the connection between biology and economics.Recognizing that students learn by doing, the textbook introduces principles through practice. Herbert Gintis exposes students to the techniques and applications of game theory through a wealth of sophisticated and surprisingly fun-to-solve problems involving human and animal behavior. The second edition includes solutions to the problems presented and information related to agent-based modeling. In addition, the textbook incorporates instruction in using mathematical software to solve complex problems.Game Theory Evolvingis perfect for graduate and upper-level undergraduate economics students, and is a terrific introduction for ambitious do-it-yourselfers throughout the behavioral sciences.Revised and updated edition relevant for courses across disciplinesPerfect for graduate and upper-level undergraduate economics coursesSolutions to problems presented throughoutIncorporates instruction in using computational software for complex problem solvingIncludes in-depth discussions of agent-based modeling. \textcopyright 2009 by Princeton University Press. All Rights Reserved.},
shorttitle = {Game theory evolving},
booktitle = {Game Theory Evolving: A Problem-Centered Introduction to Modeling Strategic Interaction Second Edition},
isbn = {9780691140506},
annote = {OCLC: 845420030},
publisher = {Princeton Univ. Press},
year = {2009},
}

@book{2005HayesSchaums,
author = {G H FRIED and G J HADEMENOS},
year = {1999},
isbn = {978-0-07-027389-4},
pages = {455},
abstract = {Includes indexes.},
publisher = {McGraw Hill},
title = {Schaum's outline of theory and problems of biology.},
annote = {OCLC: 255732140},
edition = {Nachdr.},
series = {Schaum's outline series},
}

@book{2016AmiotMusic,
author = {Emmanuel Amiot},
url = {http://link.springer.com/10.1007/978-3-319-45581-5},
publisher = {Springer International Publishing},
doi = {10.1007/978-3-319-45581-5},
isbn = {978-3-319-45580-8},
series = {Computational Music Science},
year = {2016},
title = {Music Through Fourier Space},
}

@book{2018BroughtonDiscrete,
author = {S. Allen Broughton and Kurt Bryan},
edition = {Second edition},
doi = {10.1002/9781118032442},
isbn = {9781119473329},
pages = {1--442},
publisher = {John Wiley},
abstract = {A thorough guide to the classical and contemporary mathematical methods of modern signal and image processing. Discrete Fourier Analysis and Wavelets presents a thorough introduction to the mathematical foundations of signal and image processing. Key concepts and applications are addressed in a thought-provoking manner and are implemented using vector, matrix, and linear algebra methods. With a balanced focus on mathematical theory and computational techniques, this self-contained book equips readers with the essential knowledge needed to transition smoothly from mathematical models to practical digital data applications. The book first establishes a complete vector space and matrix framework for analyzing signals and images. Classical methods such as the discrete Fourier transform, the discrete cosine transform, and their application to JPEG compression are outlined followed by coverage of the Fourier series and the general theory of inner product spaces and orthogonal bases. The book then addresses convolution, filtering, and windowing techniques for signals and images. Finally, modern approaches are introduced, including wavelets and the theory of filter banks as a means of understanding the multiscale localized analysis underlying the JPEG 2000 compression standard.. Throughout the book, examples using image compression demonstrate how mathematical theory translates into application. Additional applications such as progressive transmission of images, image denoising, spectrographic analysis, and edge detection are discussed. Each chapter provides a series of exercises as well as a MATLAB project that allows readers to apply mathematical concepts to solving real problems. Additional MATLAB routines are available via the book's related Web site. With its insightful treatment of the underlying mathematics in image compression and signal processing, Discrete Fourier Analysis and Wavelets is an ideal book for mathematics, engineering, and computer science courses at the upper-undergraduate and beginning graduate levels. It is also a valuable resource for mathematicians, engineers, and other practitioners who would like to learn more about the relevance of mathematics in digital data processing.},
booktitle = {Discrete Fourier Analysis and Wavelets: Applications to Signal and Image Processing: Second Edition},
shorttitle = {Discrete fourier analysis and wavelets},
title = {Discrete fourier analysis and wavelets: Applications to signal and image processing: Second edition},
annote = {OCLC: 1030990110},
year = {2018},
}

@book{2014AndreescuComplex,
author = {Titu Andreescu and Dorin Andrica},
annote = {OCLC: 868044080},
booktitle = {Complex Numbers from A to ... Z},
isbn = {978-0-8176-8414-3},
abstract = {"The book reflects the unique experience of the authors. It distills a vast mathematical literature, most of which is unknown to the western public, and captures the essence of an abundant problem culture. The target audience includes undergraduates, high school students and their teachers, mathematical contestants (such as those training for Olympiads or the W.L. Putnam Mathematical Competition) and their coaches, as well as anyone interested in essential mathematics."--Page 4 of cover.},
title = {Complex Numbers from A to ... Z},
year = {2014},
doi = {10.1007/978-0-8176-8415-0},
}

@book{1998NeedhamVisual,
author = {P. Shiu and Tristan Needham},
editor = {Needham, Tristan},
year = {1999},
annote = {OCLC: 632965949},
issn = {00255572},
doi = {10.2307/3618747},
pages = {182},
number = {496},
publisher = {Clarendon Press},
title = {Visual Complex Analysis},
volume = {83},
isbn = {978-0-19-853447-1},
abstract = {This radical first course on complex analysis brings a beautiful and powerful subject to life by consistently using geometry (not calculation) as the means of explanation. Aimed at undergraduate students in mathematics, physics, and engineering, the book's intuitive explanations, lack of advanced prerequisites, and consciously user-friendly prose style will help students to master the subject more readily than was previously possible. The key to this is the book's use of new geometric arguments in place of the standard calculational ones. These geometric arguments are communicated with the aid of hundreds of diagrams of a standard seldom encountered in mathematical works. A new approach to a classical topic, this work will be of interest to students in mathematics, physics, and engineering, as well as to professionals in these fields.},
booktitle = {The Mathematical Gazette},
}

@book{2012ClaydenOrganic,
author = {Jonathan Clayden and Nick Greeves and Stuart Warren},
publisher = {Oxford University Press},
volume = {51},
year = {2012},
annote = {OCLC: 775825174},
pages = {1261},
doi = {10.1016/s0016-0032(26)91405-1},
title = {Organic Chemistry Organic Chemistry},
abstract = {In the last two decades, electricity grids have faced many challenges that they were not designed to handle. These include integrating weather-dependent renewables, distributed generators, storage units and other advanced components, as well as taking into account active demand. These challenges, together with the ageing of infrastructures, make it more difficult to deliver cost- effective, reliable power. To overcome these issues requires creating new network architectures. The research project Fractal Grid proposes fractality as a core concept to model, analyze and design smart grids in their evolution up to 2030 and beyond. This paper presents the project, its methodological approach and the first results.},
booktitle = {Journal of the Franklin Institute},
edition = {Second edition},
issn = {00160032},
isbn = {9780199270293},
number = {7},
keywords = {a general method for,alk 1 ynyl,cycloaddition,dehydrohalogenation,earlier,fer catalysis,halocarbenes,halocarbenes by alkaline,halocyclopropanes,phase trans,substituted,tetrahalopropanes,the generation of,we have proposed},
mendeley-tags = {a general method for,alk 1 ynyl,cycloaddition,dehydrohalogenation,earlier,fer catalysis,halocarbenes,halocarbenes by alkaline,halocyclopropanes,phase trans,substituted,tetrahalopropanes,the generation of,we have proposed},
}

@book{2007HiemenzPolymer,
author = {Paul Christian},
doi = {10.1016/B978-1-84569-741-9.50002-1},
booktitle = {Electrospinning for Tissue Regeneration},
isbn = {9781845697419},
title = {Polymer chemistry},
edition = {2. ed},
publisher = {CRC Press},
abstract = {In this chapter we will look at the nature, preparation and properties of degradable polymers. We will discuss both natural and synthetic polymers and look at how they are either isolated or prepared and also at how they degrade via both biotic and abiotic pathways. \textcopyright 2011 Woodhead Publishing Limited. All rights reserved.},
year = {2011},
pages = {34--50},
annote = {OCLC: 255638513},
keywords = {abiotic,biotic,degradation mechanism,natural polymers,synthetic polymers},
mendeley-tags = {abiotic,biotic,degradation mechanism,natural polymers,synthetic polymers},
}

@article{MorrisFundamentals,
author = {Sudev Naduvath},
abstract = {Contents 1 An informal introduction to the derivative 9 1.1 Review: functions and the slope of a linear function . 9 1.2 The derivative 10 An informal deﬁnition of the derivative, 10.—Locality of the derivative, 11.—Properties of the derivative, 12.—The derivative of the function y = x 2 , 13.—The derivative of a function is a function itself., 14. 1.3 Derivatives of powers and polynomials 16 1.4 Two trivial hangups 16 Changing letters of the alphabet, 16.—Symbolic constants, 17. 1.5 Applications . 18 Velocity, 18.—When do you need a derivative?, 19.—Optimization, 20. 1.6 Review: elementary properties of the real numbers . 21 1.7 The Leibniz notation 23 1.8 Approximations 25 Approximating the derivative, 25.—Approximating ﬁnite changes, 25.—Linear approximation to a curve, 27. Problems 30 2 Limits; techniques of differentiation 39 2.1 The deﬁnition of the limit 39 An informal deﬁnition, 40.—The formal, authoritative deﬁnition of the limit, 41. 2.2 The deﬁnition of the derivative 42 2.3 The product rule . 43 2.4 The chain rule 45 Constant rates of change, 45.—Varying rates of change, 46.—Composition of functions, 48. 2.5 Review: exponents that aren't natural numbers . 48 Basic ideas, 48.—Zero as an exponent, 48.—Negative exponents, 49.—Fractional exponents, 49.—Irrational exponents, 49. 2.6 Proof of the power rule in general 49 Exponents that are natural numbers, 49.—Negative exponents, 49.—Exponents that aren't integers, 50. 2.7 Quotients 51 2.8 Continuity and differentiability 52 Continuity, 52.—More about diﬀerentiability, 53.—Zero derivative at the extremum of a diﬀerentiable function, 54. 2.9 Safe handling of dy and dx . 55 Problems 58 3 The second derivative 653.1 The rate of change of a rate of change 65 3.2 Geometrical interpretation . 66 3.3 Leibniz notation 67 3.4 Applications . 68 Extrema, 68.—Newton's second law, 70.—Indiﬀerence curves, 70. 3.5 Higher derivatives . 71 Problems 73 4 More about limits; curve sketching 77 4.1 Computing limits . 77 The "don't choose $\delta$ to be too small" trick, 77.—Properties of the limit, 78.—When limits fail to exist, 80. 4.2 Variations on the theme of the limit 82 Left and right limits, 82.—Limits at inﬁnity, 83.—Limits that equal inﬁnity, 86. 4.3 Curve sketching 88 Sketching a graph without knowing its equation, 88.—Sketching f 0 and f 00 given the graph of f, 91.—Sketching a graph given its equation, 92. 4.4 Completeness 94 The completeness axiom of the real numbers, 94.—The intermediate and extreme value theorems, 96.—Rolle's theorem and the mean-value theorem, 100. Problems 101 5 More derivatives 107 5.1 Transcendental numbers and functions 107 Transcendental numbers, 107.—Transcendental functions, 108. 5.2 Derivatives of exponentials . 108 5.3 Review: the trigonometric functions . 110 Radian measure, 110.—Sine and cosine, 110.—Arbitrary angles, 110.—Other trigonometric functions, 111. 5.4 Derivatives of trigonometric functions . 111 Derivatives of the sine and cosine, 111. 5.5 Review: the inverse of a function . 113 5.6 Derivative of the inverse of a function . 114 5.7 Review: logarithms 115 Logarithms, 115.—Identities, 116. 5.8 The derivative of a logarithm 116 5.9 Derivatives of inverse trigonometric functions . 118 5.10 Summary of derivatives of transcendental functions 118 5.11 Hyperbolic functions . 119 Problems 120 6 Indeterminate forms and L'Hˆopital's rule 125 6.1 Indeterminate forms 125 Why 1/0 and 0/0 are not morally equivalent, 125.—Indeterminate forms from brute force on a limit, 125. 6 Contents6.2 L'Hˆopital's rule in its simplest form 126 6.3 Fancier versions of L'Hˆopital's rule 127 Multiple applications of the rule, 128.—The indeterminate form ∞/∞, 128.—Limits at inﬁnity, 129.—Proofs, 129. Problems 131 7 From functions to variables 133 7.1 Some unrealistic features of our view of computation so far133 7.2 Newton's method . 133 7.3 Related rates . 136 7.4 Implicit functions . 138 7.5 Implicit differentiation . 139 Some simple examples, 139.—Implicit diﬀerentiation in general, 140. Problems 146 8 The integral 149 8.1 The accumulation of change 149 Change that accumulates in discrete steps, 149.—The area under a graph, 150.—Approximation using a Riemann sum, 150. 8.2 The deﬁnite integral 151 Deﬁnition of the integral of a continuous function, 151.—Leibniz notation, 154. 8.3 The fundamental theorem of calculus . 157 A connection between the derivative and the integral, 157.—What the fundamental theorem says, 157.—A pseudo-proof, 158.—Using the fundamental theorem to integrate; the indeﬁnite integral, 159. 8.4 Using the tool correctly . 162 When do you need an integral?, 162.—Two trivial hangups, 163.— Two ways of checking an integral, 164.—Do I diﬀerentiate this, or do I integrate it?, 165. 8.5 Linearity . 166 8.6 Some technical points . 167 Riemann sums in general, 167.—Integrating discontinuous functions, 167.—Proof of the fundamental theorem, 169. Problems 170 9 Basic techniques of integration 171 9.1 Doing integrals symbolically on a computer 171 9.2 Substitution . 172 9.3 Integrals that can't be done in closed form . 175 9.4 Doing an integral using symmetry or geometry . 177 Answers and solutions 179},
pages = {371},
journal = {Unpublished},
year = {2016},
doi = {10.13140/RG.2.2.30369.81763},
title = {Fundamentals of calculus},
}

@book{2015KaabarFriendly,
author = {Mohammed K.A. Kaabar},
booktitle = {arXiv},
publisher = {CreateSpace},
title = {A Friendly Introduction to Differential Equations},
year = {2018},
doi = {10.13140/RG.2.1.3262.7287},
}

@book{2014BronsonSchaums,
author = {Richard Bronson and Gabriel B.Costa},
title = {Schaum's Outline of Differential Equations},
publisher = {McGraw-Hill Companies, The},
annote = {OCLC: 887191871},
pages = {398},
url = {http://accessengineeringlibrary.com/browse/schaums-outline-of-differential-equations-fourth-edition},
year = {2006},
isbn = {0-07-149110-4},
}

@book{2008HolznerDifferential,
author = {Steven Holzner},
pmid = {25246403},
publisher = {John Wiley and Sons Ltd},
archiveprefix = {arXiv},
eprint = {arXiv:1011.1669v3},
abstract = {applicability for this approach.},
isbn = {9788578110796},
url = {https://www.ebook.de/de/product/7119629/steven///////%5C%5C_holzner///////%5C%5C_differential///////%5C%5C_equations///////%5C%5C_for///////%5C%5C_dummies.html},
year = {2013},
booktitle = {Journal of Chemical Information and Modeling},
pages = {1689--1699},
issn = {1098-6596},
volume = {53},
title = {Differential equations for dummies},
number = {9},
arxivid = {arXiv:1011.1669v3},
keywords = {icle},
mendeley-tags = {icle},
}

@book{2012NagleFundamentals,
author = {M. J. Flowers and R. Kent Nagel and Edward B. Saff},
isbn = {978-0-321-74773-0 978-0-321-75820-0},
annote = {OCLC: 701619880},
publisher = {Pearson Education},
title = {Fundamentals of Differential Equations},
year = {1991},
volume = {75},
doi = {10.2307/3619543},
booktitle = {The Mathematical Gazette},
abstract = {applicability for this approach.},
number = {473},
pages = {387},
issn = {00255572},
}

@book{2016AdzievskiIntroduction,
author = {Kuzman Adzievski and Abul Hasan Siddiqi},
abstract = {With a special emphasis on engineering and science applications, this textbook provides a mathematical introduction to PDEs at the undergraduate level. It takes a new approach to PDEs by presenting computation as an integral part of the study of differential equations. The authors use Mathematica\textregistered along with graphics to improve understanding and interpretation of concepts. They also present exercises in each chapter and solutions to selected examples. Topics discussed include Laplace and Fourier transforms as well as Sturm-Liouville boundary value problems.},
title = {Introduction to Partial Differential Equations for Scientists and Engineers Using Mathematica},
year = {2016},
url = {https://www.taylorfrancis.com/books/9781466510579},
doi = {10.1201/b15775},
publisher = {Chapman and Hall/CRC},
isbn = {978-1-4665-1057-9},
booktitle = {Introduction to Partial Differential Equations for Scientists and Engineers Using Mathematica},
edition = {1},
}

@book{2015LoganFirst,
author = {Rex Watson and Dennis G. Zill},
pages = {239},
booktitle = {The Mathematical Gazette},
number = {472},
series = {Undergraduate texts in mathematics},
annote = {OCLC: 915389739},
doi = {10.2307/3620296},
edition = {Third edition},
isbn = {978-3-319-17851-6 978-3-319-17852-3},
year = {1991},
issn = {00255572},
publisher = {Springer},
volume = {75},
title = {A First Course in Differential Equations with Applications},
}

@article{RudnickiFundamentals,
author = {D. Kolymbas},
pages = {27--42},
doi = {10.1201/9781482283785-8},
title = {Fundamentals of Continuum Mechanics},
abstract = {The constitutive equations for a particular material, together with the conservation laws of mass, linear momentum, angular momentum, and energy, govern the response of that material. Unlike the conservation laws, however, the constitutive equations vary from material to material. In other words, they depend on the physical behavior of the particular material being modeled. In this chapter, we provide a broad overview of constitutive modeling in mechanics and thermomechanics. We describe how the constitutive equations must satisfy the second law of thermodynamics, conservation of angular momentum, material symmetry requirements, and invariance under superposed rigid body motions. Special attention is devoted to determining how various kinematic, kinetic, and thermodynamic quantities transform under a superposed rigid body motion and, in turn, how these transformations can be used to develop appropriate invariance requirements. We also examine useful thermodynamic concepts in constitutive modeling, such as thermomechanical processes and Legendre transformations.},
journal = {Introduction to Hypoplasticity},
year = {2020},
}

@book{2008GonzalezFirst,
author = {Oscar Gonzalez and Andrew M. Stuart},
series = {Cambridge Texts in Applied Mathematics},
publisher = {Cambridge University Press},
doi = {10.1017/CBO9780511619571},
isbn = {9780511619571},
booktitle = {A First Course in Continuum Mechanics},
year = {2008},
title = {A first course in continuum mechanics},
pages = {1--394},
abstract = {A concise account of various classic theories of fluids and solids, this book is for courses in continuum mechanics for graduate students and advanced undergraduates. Thoroughly class-tested in courses at Stanford University and the University of Warwick, it is suitable for both applied mathematicians and engineers. The only prerequisites are an introductory undergraduate knowledge of basic linear algebra and differential equations. Unlike most existing works at this level, this book covers both isothermal and thermal theories. The theories are derived in a unified manner from the fundamental balance laws of continuum mechanics. Intended both for classroom use and for self-study, each chapter contains a wealth of exercises, with fully worked solutions to odd-numbered questions. A complete solutions manual is available to instructors upon request. Short bibliographies appear at the end of each chapter, pointing to material which underpins or expands upon the material discussed.},
}

@book{2014MuellerExpedition,
author = {H. M\"uller Wolfgang},
isbn = {9789400777989},
title = {An Expedition to Continuum Theory},
publisher = {Springer Netherlands},
series = {Solid Mechanics and Its Applications},
year = {2014},
doi = {10.1007/978-94-007-7799-6},
pages = {429},
volume = {210},
}

@book{2008IrgensContinuum,
author = {Fridtjov Irgens},
annote = {OCLC: 253962701},
title = {Continuum mechanics: with 4 tables},
publisher = {Springer},
isbn = {978-3-540-74297-5 978-3-540-74298-2},
shorttitle = {Continuum mechanics},
}

@book{2003SteinComplex,
author = {Elias M. Stein and Rami Shakarchi},
booktitle = {Complex Analysis},
isbn = {9781400831159},
title = {Complex analysis},
series = {Princeton lectures in analysis},
number = {2},
abstract = {With this second volume, we enter the intriguing world of complex analysis. From the first theorems on, the elegance and sweep of the results is evident. The starting point is the simple idea of extending a function initially given for real values of the argument to one that is defined when the argument is complex. From there, one proceeds to the main properties of holomorphic functions, whose proofs are generally short and quite illuminating: the Cauchy theorems, residues, analytic continuation, the argument principle. With this background, the reader is ready to learn a wealth of additional material connecting the subject with other areas of mathematics: the Fourier transform treated by contour integration, the zeta function and the prime number theorem, and an introduction to elliptic functions culminating in their application to combinatorics and number theory. Thoroughly developing a subject with many ramifications, while striking a careful balance between conceptual insights and the technical underpinnings of rigorous analysis, Complex Analysis will be welcomed by students of mathematics, physics, engineering and other sciences. The Princeton Lectures in Analysis represents a sustained effort to introduce the core areas of mathematical analysis while also illustrating the organic unity between them. Numerous examples and applications throughout its four planned volumes, of which Complex Analysis is the second, highlight the far-reaching consequences of certain ideas in analysis to other fields of mathematics and a variety of sciences. Stein and Shakarchi move from an introduction addressing Fourier series and integrals to in-depth considerations of complex analysis; measure and integration theory, and Hilbert spaces; and, finally, further topics such as functional analysis, distributions and elements of probability theory.},
publisher = {Princeton University Press},
year = {2010},
doi = {10.2307/j.ctv1b9f4xt.10},
pages = {1--379},
issn = {00255572},
}

@book{2001RaoTransform,
author = {K. R. Rao and P. C. Yip},
abstract = {Data compression is one of the main contributing factors in the explosive growth in information technology. Without it, a number of consumer and commercial products, such as DVD, videophone, digital camera, MP3, video-streaming and wireless PCS, would have been virtually impossible. Transforming the data to a frequency or other domain enables even more efficient compression. By illustrating this intimate link, The Transform and Data Compression Handbook serves as a much-needed handbook for a wide range of researchers and engineers. The authors describe various discrete transforms and their applications in different disciplines. They cover techniques, such as adaptive quantization and entropy coding, that result in significant reduction in bit rates when applied to the transform coefficients. With clear and concise presentations of the ideas and concepts, as well as detailed descriptions of the algorithms, the authors provide important insight into the applications and their limitations. Data compression is an essential step towards the efficient storage and transmission of information. The Transform and Data Compression Handbook provides a wealth of information regarding different discrete transforms and demonstrates their power and practicality in data compression.},
publisher = {CRC Press},
year = {2000},
doi = {10.1201/9781420037388},
pages = {1--389},
annote = {OCLC: 247573781},
editor = {Rao, Kamisetty Ramamohan and Yip, Pat C},
booktitle = {The Transform and Data Compression Handbook},
series = {The electrical engineering and signal processing series},
title = {The transform and data compression handbook},
isbn = {9781420037388},
}

@misc{2006UlrichEnvelope,
author = {T J Ulrich},
title = {Envelope calculation from the Hilbert transform},
year = {2006},
pages = {1--5},
}

@book{2013DangeloHermitian,
author = {John P D'Angelo},
title = {Hermitian Analysis},
doi = {10.1007/978-1-4614-8526-1},
booktitle = {From Fourier Series to Cauchy-Riemann Geometry},
publisher = {Springer New York},
url = {papers2://publication/uuid/6436A5F4-F468-4C26-A8D0-37F49B2BE196},
isbn = {9781461485254},
pages = {1--211},
year = {2013},
series = {Cornerstones},
}

@incollection{2013BoschEarly,
author = {Jan Bosch and Helena Holmstr\"om Olsson and Jens Bj\"ork and Jens Ljungblad},
doi = {10.1007/978-3-642-44930-7_1},
publisher = {Springer Berlin Heidelberg},
volume = {167},
isbn = {9783642449291},
abstract = {Software startups are more popular than ever and growing in numbers. They operate under conditions of extreme uncertainty and face many challenges. Often, agile development practices and lean principles are suggested as ways to increase the odds of succeeding as a startup, as they both advocate close customer collaboration and short feedback cycles focusing on delivering direct customer value. However, based on an interview study we see that despite guidance and support in terms of well-known and documented development methods, practitioners find it difficult to implement and apply these in practice. To explore this further, and to propose operational support for software startup companies, this study aims at investigating (1) what are the typical challenges when finding a product idea worth scaling, and (2) what solution would serve to address these challenges. To this end, we propose the ‘Early Stage Software Startup Development Model' (ESSSDM). The model extends already existing lean principles, but offers novel support for practitioners for investigating multiple product ideas in parallel, for determining when to move forward with a product idea, and for deciding when to abandon a product idea. The model was evaluated in a software startup project, as well as with industry professionals within the software startup domain.},
pages = {1--15},
shorttitle = {The Early Stage Software Startup Development Model},
year = {2013},
booktitle = {Lecture Notes in Business Information Processing},
editor = {Fitzgerald, Brian and Conboy, Kieran and Power, Ken and Valerdi, Ricardo and Morgan, Lorraine and Stol, Klaas-Jan},
title = {The early stage software startup development model: A framework for operationalizing lean principles in software startups},
issn = {18651348},
keywords = {agile software development,lean principles,process support,software startup companies},
mendeley-tags = {agile software development,lean principles,process support,software startup companies},
}

@incollection{2015GiardinoKey,
author = {Carmine Giardino and Sohaib Shahid Bajwa and Xiaofeng Wang and Pekka Abrahamsson},
issn = {18651348},
volume = {212},
year = {2015},
pages = {52--63},
editor = {Lassenius, Casper and Dings\oyr, Torgeir and Paasivaara, Maria},
isbn = {9783319186115},
doi = {10.1007/978-3-319-18612-2_5},
abstract = {Software startups are newly created companies designed to grow fast. The uncertainty of new markets and development of cuttingedge technologies pose challenges different from those faced by more mature companies. In this study, we focus on exploring the key challenges that early-stage software startups have to cope with from idea conceptualization to the first time to market. To investigate the key challenges, we used a mixed-method research approach which includes both a large-scale survey of 5389 responses and an in-depth multiple-case study. The initial findings reveal that thriving in technology uncertainty and acquiring the first paying customer are among the top challenges, perceived and experienced by early-stage software startups. Our study implies deeper issues that early-stage software startups need to address effectively in validating the problem-solution fit.},
booktitle = {Lecture Notes in Business Information Processing},
publisher = {Springer International Publishing},
title = {Key challenges in early-stage software startups},
keywords = {challenges,customer value,early-stage,software startups,validated learning},
mendeley-tags = {challenges,customer value,early-stage,software startups,validated learning},
}

@book{2001RoadsMicrosound,
author = {Curtis Roads},
publisher = {MIT Press},
title = {Microsound},
annote = {OCLC: 834185525},
isbn = {978-0-262-18215-7},
}

@misc{2002SaloFinite,
author = {Maaria Salo},
abstract = {This paper reviews the finite difference method in the sound synthesis of string instruments. The mathematical basis for the method and the evaluation of the recursion equations are considered. Some stability conditions are discussed. Initial and boundary conditions are reviewed for piano-and guitar-like strings.},
title = {Finite Difference Method in Sound Synthesis},
booktitle = {Math.Tkk.Fi},
pages = {1--12},
url = {http://math.tkk.fi/$\sim$ksalo2/akusem/sem_FDM.pdf},
}

@book{1999WoodardNation,
author = {William L. Van Deburg and Komozi Woodward},
booktitle = {The American Historical Review},
shorttitle = {A nation within a nation},
isbn = {978-0-8078-2457-3 978-0-8078-4761-9},
abstract = {Poet and playwright Amiri Baraka is best known as one of the African American writers who helped ignite the Black Arts Movement. This book examines Baraka's cultural approach to Black Power politics and explores his role in the phenomenal spread of black},
number = {4},
title = {A Nation within a Nation: Amiri Baraka (LeRoi Jones) and Black Power Politics},
volume = {105},
issn = {00028762},
annote = {OCLC: 237335993},
doi = {10.2307/2651504},
publisher = {Univ. of North Carolina Press},
year = {2000},
pages = {1346},
}

@collection{2009CormenIntroduction,
author = {V. J. Rayward-Smith and Thomas H. Cormen and Charles E. Leiserson and Ronald L. Rivest},
isbn = {978-0-262-03384-8 978-0-262-53305-8},
abstract = {This part will get you started in thinking about designing and analyzing algorithms. It is intended to be a gentle introduction to how we specify algorithms, some of the design strategies we will use throughout this book, and many of the fundamental ideas used in algorithm analysis. Later parts of this book will build upon this base. Chapter 1 is an overview of algorithms and their place in modern computing systems. This chapter defines what an algorithm is and lists some examples. It also makes a case that algorithms are a technology, just as are fast hardware, graphical user interfaces, object-oriented systems, and networks. In Chapter 2, we see our first algorithms, which solve the problem of sorting a sequence of n numbers. They are written in a pseudocode which, although not directly translatable to any conventional programming language, conveys the structure of the algorithm clearly enough that a competent programmer can implement it in the language of his choice. The sorting algorithms we examine are insertion sort, which uses an incremental approach, and merge sort, which uses a recursive technique known as divide and conquer. Although the time each requires increases with the value of n, the rate of increase differs between the two algorithms. We determine these running times in Chapter 2, and we develop a useful notation to express them. Chapter 3 precisely defines this notation, which we call asymptotic notation. It starts by defining several asymptotic notations, which we use for bounding algorithm running times from above and/or below. The rest of Chapter 3 is primarily a presentation of mathematical notation. Its purpose is more to ensure that your use of notation matches that in this book than to teach you new mathematical concepts.},
number = {9},
publisher = {MIT Press},
pages = {816},
annote = {OCLC: 698955316},
booktitle = {The Journal of the Operational Research Society},
year = {1991},
issn = {01605682},
edition = {3. ed},
doi = {10.2307/2583667},
title = {Introduction to Algorithms},
editor = {Cormen, Thomas H and Leiserson, Charles Eric and Rivest, Ronald Linn and Stein, Clifford},
volume = {42},
}

@article{2010RabensteinTubular,
author = {Rudolf Rabenstein and Tilman Koch and Christian Popp},
volume = {18},
year = {2010},
pages = {881--890},
shorttitle = {Tubular Bells},
title = {Tubular bells: A physical and algorithmic model},
url = {http://ieeexplore.ieee.org/document/5299084/},
doi = {10.1109/TASL.2009.2035214},
abstract = {Tubular bells are geometrically simple representatives of three-dimensional vibrating structures. Under certain assumptions, a tubular bell can be modeled as a rectangular plate with different types of homogeneous boundary conditions. Suitable functional transformations with respect to time and space turn the corresponding initial-boundary value problem into a two-dimensional transfer function. An algorithmic model follows according to the functional transformation method in digital sound synthesis. As with simpler vibrating structures (strings, membranes) the synthesis algorithms consist of a parallel arrangement of second-order sections. Their coefficients are obtained by simple analytic expressions directly from the physical parameters of the tubular bell. \textcopyright 2010 IEEE.},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
number = {4},
issn = {15587916},
keywords = {audio signal processing,physical modeling,sound synthesis,virtual instruments},
mendeley-tags = {audio signal processing,physical modeling,sound synthesis,virtual instruments},
}

@article{1993ItohCurve,
author = {Koichi Itoh and Yoshio Ohno},
abstract = {This paper presents an algorithm that automatically\ngenerates outline fonts from a grey-level image of a\ncharacter obtained by a scanner. Our algorithm\nbegins by extracting contour points from the image\nand dividing the points into a number of segments at\nthe corner points. The next step is fitting a\npiecewise cubic B\'ezier curve to each segment.\n\nTo fit cubic B\'ezier curves to segments, we use\nleast-squares fitting, without fixing the end points\nof the curves. We locate the end points by\ncomputing the intersection of the adjoining curves.\nThis algorithm greatly improves the shape of the\ncorner of the outline fonts.},
year = {1993},
issn = {0894-3982},
title = {A curve fitting algorithm for character fonts},
number = {3},
pages = {195},
journal = {Electronic Pub\-lish\-ing\emdashOrig\-i\-na\-tion, Dissemination, and Design},
volume = {6},
publisher = {Citeseer},
keywords = {curve fitting algorithm,grey-level characters,kanji characters},
mendeley-tags = {curve fitting algorithm,grey-level characters,kanji characters},
}

@unpublished{2012BarendrechtGentle,
author = {Pj Barendrecht},
title = {A gentle introduction to rational B\'ezier curves and NURBS},
pages = {1--13},
booktitle = {Student.Tue.Nl},
volume = {2012},
url = {http://www.student.tue.nl/S/p.j.barendrecht/GentleIntroToNURBS.pdf},
year = {2012},
}

@misc{2008BertkaIntroduction,
author = {Benjamin T Bertka},
title = {An Introduction to Bezier Curves , B-Splines , and Tensor Product Surfaces with History and Applications},
pages = {1--13},
booktitle = {History},
year = {2008},
}

@collection{2001RogersIntroduction,
author = {David F Rogers},
abstract = {Executive Editor Diane D. Cerra Director of Production and Manufacturing Yonie Overton Senior Production Editor Cheri Palmer Editorial Coordinator Belinda Breyer Cover Design Ross Carron Design Cover Images (1. to r.) Top row: Courtesy of John C. Dill and David F. Rogers ; copyright ...},
issn = {1098-6596},
publisher = {Morgan Kaufmann Publishers},
annote = {OCLC: 247648741},
pmid = {25246403},
arxivid = {arXiv:1011.1669v3},
title = {An introduction to NURBS: with historical perspective},
editor = {Rogers, David F},
isbn = {1558606696},
pages = {344},
year = {2001},
eprint = {arXiv:1011.1669v3},
archiveprefix = {arXiv},
shorttitle = {An introduction to NURBS},
booktitle = {Booksgooglecom},
}

@misc{2012SederbergComputer,
author = {Jean Jacques Risler},
volume = {5},
title = {Computer aided geometric design},
doi = {10.1016/S1570-8659(97)80006-3},
year = {1997},
booktitle = {Handbook of Numerical Analysis},
pages = {715--818},
issn = {15708659},
}

@book{2006FarinCurves,
author = {G Farin},
annote = {OCLC: 254200301},
series = {The Morgan Kaufmann series in computer graphics and geometric modeling},
year = {1997},
publisher = {Morgan Kaufmann Publ},
edition = {5. ed., [Nachdr.]},
title = {Curves and Surfaces for Computational Aided Geometric Design, A Practical Guide},
shorttitle = {Curves and surfaces for CAGD},
isbn = {978-1-55860-737-8},
}

@article{2011BostockD³,
author = {Michael Bostock and Vadim Ogievetsky and Jeffrey Heer},
volume = {17},
pages = {2301--2309},
url = {http://ieeexplore.ieee.org/document/6064996/},
abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations. \textcopyright 2011 IEEE.},
year = {2011},
journal = {IEEE Transactions on Visualization and Computer Graphics},
doi = {10.1109/TVCG.2011.185},
issn = {10772626},
number = {12},
title = {D3 data-driven documents},
keywords = {d graphics,information visualization,toolkits,user interfaces},
mendeley-tags = {d graphics,information visualization,toolkits,user interfaces},
}

@article{cabrinha_bezier_nodate,
author = {Mark Cabrinha},
abstract = {The development of digital fabrication has reintroduced material processes with digital processes. There has been much discussion about the tool and the objects of the tool, but little discussion of the implication of the material process on the digital process. A brief historical review on the development of computer numerical control and the origins of the B\'ezier curve reveals an instrumental fact: computer numerical controlled tools necessitated advancements in computational surfaces which eventually led to NURBS (Non-Uniform Rational B-Splines) surfaces. In other words, the origins of NURBS surfaces resides in its relation to material processes, rather than many current approaches that develop free form surfaces and then force the tool onto the material without regard to the material properties. From this historical and mathematical review, this project develops toward more intelligent construction methods based on the integration of NURBS differential geometry paired with material qualities and processes. Specifically, a digital technique of developing conceptual NURBS geometry into piecewise surface patches are then flattened based on the material thickness and density. From these flattened patches, a material technique is developed to intelligently remove material to allow the rigid flat material to re-develop into physical surface patches. The goal of this research is to develop digital and material techniques toward intelligent construction based on the correspondence between digitally driven surface and digitally driven material processes. The application of this technique as a rational and flexible system is to support the dynamic response of form and material toward such performative aspects as structure, daylight, ventilation, and thermal properties.},
pages = {156--169},
year = {2005},
journal = {ACADIA 2005 Conference: Smart Architecture},
title = {From B\'ezier to NURBS: Integrating material and digital techniques through a plywood shell},
}

@article{RamshawMultiplying,
author = {Lyle Ramshaw},
title = {On multiplying points: the paired algebras of forms and sites},
pages = {173},
}

@book{2010PatrikalakisShape,
author = {Nicholas M. Patrikalakis and Takashi Maekawa},
booktitle = {Shape Interrogation for Computer Aided Design and Manufacturing},
year = {2010},
publisher = {Springer Berlin Heidelberg},
title = {Shape interrogation for computer aided design and manufacturing},
doi = {10.1007/978-3-642-04074-0},
isbn = {9783642040733},
abstract = {Shape interrogation is the process of extraction of information from a geometric model. It is a fundamental component of Computer Aided Design and Manufacturing (CAD/CAM) systems. The authors focus on shape interrogation of geometric models bounded by free-form surfaces. Free-form surfaces, also called sculptured surfaces, are widely used in the bodies of ships, automobiles and aircraft, which have both functionality and attractive shape requirements. Many electronic devices as well as consumer products are designed with aesthetic shapes, which involve free-form surfaces. This book provides the mathematical fundamentals as well as algorithms for various shape interrogation methods. From the reviews: "This book provides the mathematical fundamentals as well as algorithms for various shape interrogation methods including nonlinear polynomial solvers, intersection problems, differential geometry of intersection curves, distance functions, curve and surface interrogation, umbilics and lines of curvature, geodesics, and offset curves and surfaces. [... ] It may well be one of the most important books of the 2002s that has been written on shape interrogation for graduate students in mathematics, engineering, computer science, focusing on geometrical modeling and solid modeling. The book will inform and enlighten professionals in industry and therefore remains essential reading for them too. Currently there are several excellent books in the area of geometric modeling and in the area of solid modeling. The major contribution of this book lies in its skilful manner of providing a bridge between these two areas that is guaranteed to make the target audience cry out aloud with delight." Current Engineering Practice 2002-2003, Vol. 45, Issue 3-4 "This book gives a detailed description of algorithms and computational methods for shape interrogation [... ] The book can be used in a course for advanced graduate students and also as a reference text for researchers and practitioners in CAD/CAM. [... ] is a very detailed and complete book on topics that are important in both the theory and the practice of geometric modeling." L. Henrique de Figueiredo, Mathematical Reviews 2003 a "... This book by Patrikalakis and Maekawa is the first thorough, long overdue, look at this crucial area. [... ] It will serve well any researcher, either in academia or industry, working in the area of freeform design or manufacturing. This work continues from the point where the traditional geometric design and solid modeling books stop. ... Shape interrogation and computational geometry of freeform shapes have been a part of the geometric design and manufacturing community for a long time. This book makes efforts and is likely to become the 'Bible' for this area. As a high-quality produced book, it is a must reference for any advanced researcher or developer who works with splines and freeform representations. If you consider yourself one, this book should probably be on your bookshelf." \textcopyright Springer-Verlag Berlin Heidelberg 2002. All rights are reserved.},
pages = {1--408},
}

@article{2012FaroukiBernstein,
author = {Rida T. Farouki},
doi = {10.1016/j.cagd.2012.03.001},
year = {2012},
issn = {01678396},
number = {6},
pages = {379--419},
volume = {29},
abstract = {One hundred years after the introduction of the Bernstein polynomial basis, we survey the historical development and current state of theory, algorithms, and applications associated with this remarkable method of representing polynomials over finite domains. Originally introduced by Sergei Natanovich Bernstein to facilitate a constructive proof of the Weierstrass approximation theorem, the leisurely convergence rate of Bernstein polynomial approximations to continuous functions caused them to languish in obscurity, pending the advent of digital computers. With the desire to exploit the power of computers for geometric design applications, however, the Bernstein form began to enjoy widespread use as a versatile means of intuitively constructing and manipulating geometric shapes, spurring further development of basic theory, simple and efficient recursive algorithms, recognition of its excellent numerical stability properties, and an increasing diversification of its repertoire of applications. This survey provides a brief historical perspective on the evolution of the Bernstein polynomial basis, and a synopsis of the current state of associated algorithms and applications. \textcopyright 2012 Elsevier B.V. All rights reserved.},
shorttitle = {The Bernstein polynomial basis},
title = {The Bernstein polynomial basis: A centennial retrospective},
journal = {Computer Aided Geometric Design},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167839612000192},
keywords = {b\'ezier curves and surfaces,bernstein basis,numerical stability,polynomial algorithms,polynomial approximation,weierstrass theorem},
mendeley-tags = {b\'ezier curves and surfaces,bernstein basis,numerical stability,polynomial algorithms,polynomial approximation,weierstrass theorem},
}

@book{1995LawsonSolving,
author = {Robert F. Ling and Charles L. Lawson and Richard J. Hanson},
isbn = {978-0-89871-356-5},
issn = {01621459},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
doi = {10.2307/2286501},
number = {360},
booktitle = {Journal of the American Statistical Association},
edition = {10. Dr.},
pages = {930},
series = {Classics in applied mathematics},
annote = {OCLC: 844911591},
publisher = {SIAM},
title = {Solving Least Squares Problems.},
volume = {72},
year = {1977},
}

@book{2000BloomfieldFourier,
author = {Mark Rudnicki and Thomas H Meyer and Victor J Lieffers and Uldis Silins and Vincent A Webb},
year = {2008},
issn = {1432-2285},
title = {A dynamic analysis of windthrow of trees.},
pages = {225--237},
publisher = {John Wiley ////////\\\& Sons, Inc.},
doi = {10.1002/0471722235},
isbn = {978-0-471-72223-6 978-0-471-88948-9},
series = {Wiley Series in Probability and Statistics},
volume = {22},
number = {4},
booktitle = {Trees (Berlin, Germany : West)},
shorttitle = {Fourier Analysis of Time Series},
url = {https://iujfk.files.wordpress.com/2013/04/bloomfield-2000-fourier-analysis-of-time-series-an-introduction-2ed.pdf},
}

@thesis{2002AirdMusical,
author = {Marc Aird},
year = {2002},
institution = {University of Bath},
type = {phdthesis},
url = {http://www.cs.bath.ac.uk/$\sim$mapma/thesis.pdf},
title = {Musical Instrument Modelling Using Digital Waveguides},
abstract = {The technique of DigitalWaveguide Modelling for musical instruments and room acoustics modelling is now quite firmly established. In this thesis we provide an investigation in to the practical use and extension of the technique in musical instrument models, with an emphasis towards models of drums. The standard waveguide technique is described and analysed mathematically for basic models in one, two and three dimensions. Results of simulations are provided and compared against expected theoretical output. Methods to improve the quality of the simulations by considering the boundary termination and correcting the numerical dispersion error are discussed. A model for a drum is presented which utilises a technique to interface 2D and 3D mesh structures. An analysis of the model is provided which compares the output to phenomena found from measurements of real instruments. Extensions to the simple waveguide are proposed which include the modelling of stiff media in both 1D and 2D. These models include bars, stiff strings, plates and stiff membranes and in each case model output is analysed in depth by comparing to expected theoretical output. We also discuss approaches to include material specific frequency dependent damping. The main contributions of this thesis have been in the analysis of the waveguide technique in 3D, the method of correcting dispersion error, the analysis and extension of the 1D and 2D stiff models and the development and extension of the interfacing technique used in the drum model. The original focus of the work was for drum modelling, but the analogies and implications to other musical instruments, and indeed in the area of room acoustics, are quite clear.},
}

@inproceedings{2002BakkerReinforcement,
author = {Bram Bakker},
abstract = {This paper presents reinforcement learning with a Long ShortTerm Memory recurrent neural network: RL-LSTM. Model-free RL-LSTM using Advantage($\lambda$) learning and directed exploration can solve non-Markovian tasks with long-term dependencies between relevant events. This is demonstrated in a T-maze task, as well as in a difficult variation of the pole balancing task.},
booktitle = {Advances in Neural Information Processing Systems},
title = {Reinforcement learning with long short-term memory},
issn = {10495258},
year = {2002},
pages = {1475--1482},
url = {https://papers.nips.cc/paper/1953-reinforcement-learning-with-long-short-term-memory.pdf},
isbn = {0262042088},
publisher = {MIT Press},
}

@book{2012PieglNurbs,
author = {Les Piegl and Wayne Tiller},
volume = {35},
pages = {35--0952--35--0952},
booktitle = {Choice Reviews Online},
isbn = {978-3-540-61545-3},
year = {1997},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
issn = {0009-4978},
number = {02},
title = {The NURBS book},
publisher = {Springer Science //\\\& Business Media},
doi = {10.5860/choice.35-0952},
}

@inproceedings{2005SmithViewpoints,
author = {Julius O Smith},
publisher = {INTERNATIONAL COMPUTER MUSIC ACCOCIATION},
booktitle = {Proceedings of the International Computer Music Conference},
pages = {1--10},
url = {https://ccrma.stanford.edu//textasciitilde jos/kna/kna.pdf},
year = {1991},
issn = {1026-1087},
abstract = {Computer  Conf.  and space domains Numerous time-freq envelopes Several physical variables Memory requirements large More compact  Large operation  reverb natural Can calibrate to nature Can calibrate to nature Can calibrate to any  May calibrate },
title = {Viewpoints on the History of Digital Synthesis},
}

@article{2004Martinez-friasSegmentation,
author = {M. L. Martinez-Frias},
doi = {10.1002/ajmg.a.30016},
issn = {15524825},
title = {Segmentation anomalies of the vertebras and ribs: One expression of the primary developmental field},
volume = {128 A},
number = {2},
year = {2004},
pmid = {15214001},
shorttitle = {Segmentation anomalies of the vertebras and ribs},
pages = {127--131},
journal = {American Journal of Medical Genetics},
}

@collection{2017InstituteGuide,
editor = {Institute, Project Management},
issn = {0009-4978},
volume = {34},
abstract = {The Project Management Body of Knowledge (PMBOK\textregistered ) is an inclusive term that describes the sum of knowledge within the profession of project management. As with other professions such as law, medicine, and accounting, the body of knowl- edge rests with the practitioners and academics that apply and advance it. The full project management body of knowledge includes knowledge of proven tra- ditional practices that are widely applied, as well as knowledge of innovative and advanced practices that have seen more limited use, and includes both published and unpublished material.},
booktitle = {Choice Reviews Online},
isbn = {978-1-62825-184-5},
number = {03},
pages = {34--1636--34--1636},
doi = {10.5860/choice.34-1636},
edition = {Sixth edition},
publisher = {Project Management Institute},
title = {A Guide to the project management body of knowledge},
year = {1996},
series = {PMBOK guide},
}

@book{2017AnthonyFullstack,
author = {Anthony Accomazzo},
shorttitle = {Fullstack React},
pages = {521},
isbn = {978-0-9913446-2-8},
abstract = {Stop wasting your time learning React with incomplete and confusing tutorials. There are so many incorrect, confusing, and out-of-date blog articles One tutorial says one thing and another says something completely different. There are too many options There are fifty different boilerplates and a dozen different Flux implementations. Which one is best? What if you could master the entire framework in less time, with solid foundations, without beating your head against the wall? Imagine how quickly you can get all of your work done with the right tools and best practices. Seriously, let's stop wasting time scouring Google, searching through incorrect, out-of-date, blog posts and get everything you need to be productive in one, well-organized place, complete with both simple and complex examples to get your app up and running. You'll learn what you need to know to work professionally and build solid, well-tested, optimized apps with ReactJS. This book is your definitive guide.},
booktitle = {International Journal of Computer Applications in Technology},
title = {Fullstack React: The Complete Guide to ReactJS},
year = {2018},
publisher = {Fullstack.io},
}

@book{2015GottschlingDiscovering,
author = {Peter Gottschling},
number = {Mm},
edition = {1 edition},
publisher = {Addison-Wesley Professional},
year = {2016},
pages = {474},
isbn = {9780134383583},
shorttitle = {Discovering Modern C++},
title = {Discovering Modern C++ An Intensive Course for Scientists, Engineers, and Programmers},
abstract = {469 p. il. 30 cm.},
keywords = {biologicamente ativos que s\~ao,dependentes das suas estruturas},
mendeley-tags = {biologicamente ativos que s\~ao,dependentes das suas estruturas},
}

@book{2014DineenMultivariate,
author = {Peter Saunders and Sean Dineen},
pages = {180},
series = {Springer Undergraduate Mathematics Series},
booktitle = {The Mathematical Gazette},
url = {https://www.springer.com/gp/book/9781447164180},
number = {505},
isbn = {978-1-4471-6418-0},
edition = {3},
abstract = {Third edition. Includes index. Multivariate calculus can be understood best by combining geometric insight, intuitive arguments, detailed explanations and mathematical reasoning. This textbook has successfully followed this programme. It additionally provides a solid description of the basic concepts, via familiar examples, which are then tested in technically demanding situations. In this new edition the introductory chapter and two of the chapters on the geometry of surfaces have been revised. Some exercises have been replaced and others provided with expanded solutions. Familiarity with partial derivatives and a course in linear algebra are essential prerequisites for readers of this book. Multivariate Calculus and Geometry is aimed primarily at higher level undergraduates in the mathematical sciences. The inclusion of many practical examples involving problems of several variables will appeal to mathematics, science and engineering students. Introduction to Differentiable Functions -- Level Sets and Tangent Spaces -- Lagrange Multipliers -- Maxima and Minima on Open Sets -- Curves in Rn -- Line Integrals -- The Frenet?Serret Equations -- Geometry of Curves in R3 -- Double Integration -- Parametrized Surfaces in R3 -- Surface Area -- Surface Integrals -- Stokes? Theorem -- Triple Integrals -- The Divergence Theorem -- Geometry of Surfaces in R3 -- Gaussian Curvature -- Geodesic Curvature.},
doi = {10.2307/3621630},
title = {Multivariate Calculus and Geometry},
year = {2002},
publisher = {Springer-Verlag},
volume = {86},
issn = {00255572},
}

@book{1965FinneyPrinciples,
author = {Barbara Crooker},
title = {Principles of Accounting},
doi = {10.2307/j.ctvq4c06f.17},
year = {2019},
annote = {OCLC: 799320107},
isbn = {978-0-13-702852-8},
publisher = {Prentice-Hall},
pages = {21--22},
booktitle = {Some Glad Morning},
}

@misc{2017LessardEquality,
author = {Laurent Lessard},
annote = {Introduction to Optimization},
title = {Equality constraints and tradeoffs},
url = {https://laurentlessard.com/teaching/cs524/slides/9///////%5C%5C -///////%5C%5C equality///////%5C%5C constraints///////%5C%5C and///////%5C%5C tradeoffs.pdf},
}

@article{2013SantosBalanco,
author = {Anderson Pires dos Santos and Luci\^enio Rosa e Silva J\'unior},
volume = {2},
shorttitle = {BALAN\cCO SOCIAL},
doi = {10.30681/ruc.v2i4.330},
journal = {Revista UNEMAT de Contabilidade},
number = {4},
year = {2013},
title = {Balan\cco Social: Uma An\'alise Comparativa Dos Indicadores Sociais Internos E Externos Das Institui\cc\~oes Financeiras Caixa E Banco Do Brasil 2002 a 2011},
abstract = {O objetivo do artigo \'e demonstrar os volumes e evolu\cc\~ao dos indicadores sociais internos e externos das institui\cc\~oes financeiras Caixa e Banco do Brasil. O crescente avan\cco no setor econ\^omico-financeiro e a evolu\cc\~ao da ci\^encia cont\'abil, o balan\cco social \'e uma ferramenta auxiliadora e imprescind\'ivel na divulga\cc\~ao de informa\cc\~oes sociais. Trata-se de um estudo descritivo, com abordagem qualitativa. A coleta de dados deu-se atrav\'es das web-p\'aginas das institui\cc\~oes financeiras buscando informa\cc\~oes nos seus relat\'orios de sustentabilidade. A problem\'atica que a pesquisa buscou investigar \'e o volume e a evolu\cc\~ao dos investimentos sociais realizados nos Indicadores Sociais Internos e Externos das Institui\cc\~oes Financeiras Caixa e Banco do Brasil, com base no Balan\cco Social de 2002 a 2011. As principais an\'alises sinalizam que 6,56% e 9,66% da receita l\'iquida total do per\'iodo analisado foram absorvidos pelos investimentos sociais internos para a Caixa e Banco do Brasil, respectivamente. Quanto aos investimentos sociais externos, absorveram 3,09% para a Caixa e 6,53% para o Banco do Brasil em rela\cc\~ao \`a receita l\'iquida do per\'iodo analisado. Os componentes com maiores investimentos s\~ao encargos sociais compuls\'orios, participa\cc\~ao nos lucros e resultados e alimenta\cc\~ao, isso no ambiente interno e nesta mesma ordem para a Caixa e Banco do Brasil. No ambiente externo, para a Caixa s\~ao cultura e esporte, e o Banco do Brasil, combate \`a fome e e seguran\cca alimentar e cultura, conforme o per\'iodo analisado.},
}

@book{2016LibbyResponsive,
author = {Alex Libby and Gaurav Gupta and Asoj Talesra},
pages = {155},
title = {Responsive Web Design with HTML5 and CSS3 Essentials},
year = {2016},
abstract = {Design and deliver an optimal user experience for all devices About This Book Get to grips with the core functionality of RWD through examples Discover how to make layouts, content and media flexible, and explore why a content-first approach is more effective Maximize the performance of your web pages so that they work across all browsers and devices irrespective of the screen size Who This Book Is For This book is for web designers who are familiar with HTML and CSS, and want to begin with responsive web design. Web development experience and knowledge of HTML5, CSS3 is assumed. What You Will Learn Explore various layout options Understand what can be achieved in the browser, without the use of third-party tools Executing media queries to benefit responsive designs Understand the basics of responsive workflow and boilerplate frameworks Improve performance of responsive web design Maintain compatibility across various browsers In Detail Responsive web design (RWD) is a web design approach aimed at crafting sites to provide an optimal viewing and interaction experience—providing easy reading and navigation with minimum resizing, panning, and scrolling—and all of this across a wide range of devices from desktop computer monitors to mobile phones. Responsive web design is becoming more important as the amount of mobile traffic now accounts for more than half of the Internet's total traffic. This book will give you in depth knowledge about the basics of responsive web design. You will embark on a journey of building effective responsive web pages that work across a range of devices, from mobile phones to smart TVs, with nothing more than standard markup and styling techniques. You'll begin by getting an understanding of what RWD is and its significance to the modern web. Building on the basics, you'll learn about layouts and media queries. Following this, we'll dive into creating layouts using grid based templates. We'll also cover the important topic of performance management, and discover how to tackle cross-browser challenges. Style and approach This is a practical example-based book which will delve into various elements and benefits of a responsive web design. It will help you understand the essential skills needed to create responsive web sites and guide you through the basics of building responsive web pages for any device. The topics are a blend of theoretical and practical essentials which will assist you to explore more about responsive web design.},
isbn = {978-1-78355-307-5},
publisher = {Packt Publishing - ebooks Account},
}

@book{2016HolecekDream,
author = {Andrew Holecek},
shorttitle = {Dream Yoga},
abstract = {Lucid dreaming—becoming fully conscious in the dream state—has attracted legions of those seeking to explore their vast inner worlds. Yet our states of sleep offer much more than entertainment. Combining modern lucid dreaming principles with the time-tested insights of Tibetan dream yoga makes this astonishing yet elusive experience both easier to access and profoundly life-changing. With Dream Yoga, Andrew Holecek presents a practical guide for meditators, lucid dreamers ready to go deeper, and complete beginners. Topics include: meditations and techniques for dream induction and lucidity, enhancing dream recall, dream interpretation, working with nightmares, and more.},
publisher = {Sounds True},
title = {Dream Yoga: Illuminating your life through lucid dreaming and the Tibetan Yogas of Sleep},
year = {2016},
}

@book{2017GulliDeep,
author = {Antonio Gulli},
abstract = {This book starts by introducing you to supervised learning algorithms such as simple linear regression, the classical multilayer perceptron and more sophisticated deep convolutional networks. You will also explore image processing with recognition of hand written digit images, classification of images into different categories, and advanced objects recognition with related image annotations. An example of identification of salient points for face detection is also provided. Next you will be introduced to Recurrent Networks, which are optimized for processing sequence data such as text, audio or time series. Following that, you will learn about unsupervised learning algorithms such as Autoencoders and the very popular Generative Adversarial Networks (GAN). You will also explore non-traditional uses of neural networks as Style Transfer. Finally, you will look at Reinforcement Learning and its application to AI game playing, another popular direction of research and application of neural networks.},
publisher = {Packt},
shorttitle = {Deep learning with Keras},
isbn = {978-1-78712-842-2 978-1-78712-903-0},
title = {Title Page Deep Learning with Keras Implement neural networks with Keras on Theano and TensorFlow},
keywords = {com004000 - computers / intelligence (ai) & semantics,com018000 - computers / data processing,com044000 - computers / neural networks},
mendeley-tags = {com004000 - computers / intelligence (ai) & semantics,com018000 - computers / data processing,com044000 - computers / neural networks},
}

@book{2004FeigenbaumTotal,
author = {A. Darker},
abstract = {It is considered by many that for industry to prosper Into the 1990s it must adopt the principles of Total Quality Control. These principles offer the opportunity to tap previously unused brainpower within an organization, and to achieve what our potential overseas customers expect of us, that is, a guaranteed 100% good product. This paper presents one company's Ideas and methods of implementation. TQC is very much a people thing, and requires employees- at all levels to become familiar with, and practise basic charting and problem-solving techniques. Economics do not allow us to load up our organizations with service departments. Quality must be controlled by people at the workface.},
doi = {10.4271/871263},
year = {1987},
issn = {26883627},
isbn = {978-0-07-022003-4},
booktitle = {SAE Technical Papers},
title = {Total quality control},
publisher = {McGraw-Hill Professional},
edition = {3 edition},
}

@article{1992WidrowBackpropagation,
author = {B Widrow and M Lehr},
url = {http://www-isl.stanford.edu//textasciitilde widrow/papers/c1992backpropagationand.pdf},
title = {Backpropagation and its Applications},
}

@book{2015AzadCalculus,
author = {Kahlid Azad},
year = {2015},
title = {Calculus, Better Explained: A Guide to Developing Lasting Intuition},
shorttitle = {Calculus, Better Explained},
url = {http://betterexplained.com/},
abstract = {An intuitive description of calculus},
pages = {74},
keywords = {mathematics: calculus},
mendeley-tags = {mathematics: calculus},
}

@book{1979GareyComputers,
author = {Ronald V. Book},
shorttitle = {Computers and Intractability},
edition = {1st Edition edition},
abstract = {Includes indexes. "Shows how to recognize NP-complete problems and offers proactical suggestions for dealing with them effectively. The book covers the basic theory of NP-completeness, provides an overview of alternative directions for further research, and contains and extensive list of NP-complete and NP-hard problems, with more than 300 main entries and several times as many results in total. [This book] is suitable as a supplement to courses in algorithm design, computational complexity, operations research, or combinatorial mathematics, and as a text for seminars on approximation algorithms or computational complexity. It provides not only a valuable source of information for students but also an essential reference work for professionals in computer science"--Back cover. 1. Computers, complexity, and intractability -- 2. The theory of NP-completeness -- 3. Proving NP-completeness results -- 4. Using NP-completeness to analyze problems -- 5. NP-hardness -- 6. Coping with NP-complete problems -- 7. Beyond NP-completeness -- Appendix: A list of NP-complete problems.},
number = {2},
publisher = {W. H. Freeman},
isbn = {978-0-7167-1045-5},
issn = {0273-0979},
booktitle = {Bulletin of the American Mathematical Society},
doi = {10.1090/s0273-0979-1980-14848-x},
pages = {898--905},
year = {1980},
title = {Book Review: Computers and intractability: A guide to the theory of $NP$-completeness},
volume = {3},
}

@book{1973GillespieQuantum,
author = { B and Supriyo yopadhyay and Marc Cahay},
title = {A Quantum Mechanics Primer},
publisher = {International Textbook Co},
booktitle = {Introduction to Spintronics},
isbn = {978-0-7002-2290-2},
abstract = {Book by Gillespie, Daniel T},
year = {2020},
url = {https://www.amazon.com/quantum-mechanics-primer-Daniel-Gillespie/dp/0700222901?SubscriptionId=AKIAIOBINVZYXZQZ2U3A///////%5C%5C&tag=chimbori05-20///////%5C%5C&linkCode=xm2///////%5C%5C&camp=2025///////%5C%5C&creative=165953///////%5C%5C&creativeASIN=0700222901},
pages = {477--524},
doi = {10.1201/9781420004748-18},
}

@book{1997MarcondesIniciacao,
author = {Danilo Marcondes},
abstract = {Resultado de mais de quinze anos dedicados ao ensino da filosofia, este verdadeiro guia da hist\'oria do pensamento ocidental situa pensadores e correntes filos\'oficas em seu contexto hist\'orico, discute id\'eias e conceitos e, quando necess\'ario, apresenta os textos mais relevantes dos fil\'osofos em quest\~ao, como o mito da caverna de Plat\~ao ou a tabela dos ju\'izos e categorias de Kant. Dividido cronologicamente em quatro partes - filosofia antiga, medieval, moderna e contempor\^anea -, ap\'os cada cap\'itulo o livro traz quadros sin\'oticos que recapitulam a mat\'eria estudada, uma sele\cc\~ao de leituras sugeridas, al\'em de propor quest\~oes e temas para discuss\~ao em sala de aula, o que refor\cca e traduz o car\'ater expressamente did\'atico da obra. Conta tamb\'em com \'indice remissivo.},
publisher = {Zahar},
title = {Inicia\cc\~ao \`a hist\'oria da filosofia: Dos pr\'e-socr\'aticos a Wittgenstein},
shorttitle = {Inicia\cc\~ao \`a hist\'oria da filosofia},
}

@book{ceddia_pure_nodate,
author = {Dave Ceddia},
title = {Pure React: A step-by-step guide to mastering React.},
shorttitle = {Pure React},
abstract = {Front-end development today is massively overwhelming.The React ecosystem is huge – Redux, React Router, Webpack, Babel\ldots Where do you even start?Most people begin by reading tutorials, but sifting through them to find the one that makes it 'click' is an exercise in frustration. On top of that, they dish out pages of code and leave it up to you to "learn by osmosis."If you've tried to learn React on your own, you've probably had the same experience I did: after sifting through countless tutorials and video, you still can't cobble together your own app. One second you're nodding along, sure that you understand. The next, you're staring at a blinking cursor wondering what to type.Thousands of people are already using React in their jobs or startups, and you can too -- once you figure it out.But what if you could skip straight to being as productive with React as you are with your current framework of choice?What if you were able to code as fast as you can think, using the JavaScript you know and love?Writing apps could be fun again! And fast.Teaching yourself React can be overwhelming\ldots but it doesn't have to be. You can master the fundamentals in a matter of days.Here's the thing: you need real practice. Not just nodding along to tutorials, but actually building examples and exercises. That's how you gain mastery, and this book will show you how.You'll get hands-on practice building a series of small components and micro apps – no big monolithic app here. The bite-size apps will have you reviewing concepts until they're second nature.With the included exercises you will be writing your own code right from the start – this isn't a "copy, paste, watch it run" tutorial.Don't worry, we won't build any "ToDo" apps. The world already has enough of those.Learn to turn mockups directly into code, how to "think in components," and how to handle changing state in React's world of one-way data flow.Here's what the book covers:- Easy project setup with Create React App (you'll be running code within minutes)- Debugging strategies for when things go wrong- Mastering JSX syntax, including "if"s, loops, and dynamic child components- Using props to communicate between components, and make them as reusable as possible- How PropTypes can save you time debugging and help "future you" remember how to use the components you wrote- Using the "children" prop to render dynamic content- How to write React in the modern ES6 style, with a gentle introduction to ES6 syntax (you don't need to know ES6!)- How input controls work in React (controlled and uncontrolled)- Where and how to properly use component state in a React application- Stateful vs Stateless components- The lifecycle of a component, and how to use it to your advantageThe book includes examples large and small, and 25 exercises to hone your knowledge.Buy Pure React and start learning React today!},
}

@book{2014PooleLinear,
author = {David Poole},
abstract = {David Poole's innovative LINEAR ALGEBRA: A MODERN INTRODUCTION, 4e emphasizes a vectors approach and better prepares students to make the transition from computational to theoretical mathematics. Balancing theory and applications, the book is written in a conversational style and combines a traditional presentation with a focus on student-centered learning. Theoretical, computational, and applied topics are presented in a flexible yet integrated way. Stressing geometric understanding before computational techniques, vectors and vector geometry are introduced early to help students visualize concepts and develop mathematical maturity for abstract thinking. Additionally, the book includes ample applications drawn from a variety of disciplines, which reinforce the fact that linear algebra is a valuable tool for modeling real-life problems.},
isbn = {978-1-285-46324-7},
publisher = {Cengage Learning},
shorttitle = {Linear Algebra},
edition = {4 edition},
title = {Linear Algebra: A Modern Introduction},
}

@book{2015McfarlandCss,
author = { McFarl and David Sawyer },
volume = {1},
title = {CSS: The Missing Manual (Missing Manual)},
shorttitle = {CSS},
publisher = {O'Reilly Media},
booktitle = {Online},
year = {2011},
edition = {4 edition},
pages = {538},
abstract = {You don't need programming experience to add interactive and visual effects to your web pages with JavaScript. This Missing Manual shows you how the jQuery library makes JavaScript programming fun, easy, and accessible to web designers at every level...},
url = {http://shop.oreilly.com/product/0636920015048.do},
}

@book{lazyprogrammer_deep_nodate,
author = { LazyProgrammer},
abstract = {LSTM, GRU, and more advanced recurrent neural networksLike Markov models, Recurrent Neural Networks are all about learning sequences - but whereas Markov Models are limited by the Markov assumption, Recurrent Neural Networks are not - and as a result, they are more expressive, and more powerful than anything we've seen on tasks that we haven't made progress on in decades.In the first section of the course we are going to add the concept of time to our neural networks.I'll introduce you to the Simple Recurrent Unit, also known as the Elman unit.We are going to revisit the XOR problem, but we're going to extend it so that it becomes the parity problem - you'll see that regular feedforward neural networks will have trouble solving this problem but recurrent networks will work because the key is to treat the input as a sequence.In the next section of the book, we are going to revisit one of the most popular applications of recurrent neural networks - language modeling.One popular application of neural networks for language is word vectors or word embeddings. The most common technique for this is called Word2Vec, but I'll show you how recurrent neural networks can also be used for creating word vectors.In the section after, we'll look at the very popular LSTM, or long short-term memory unit, and the more modern and efficient GRU, or gated recurrent unit, which has been proven to yield comparable performance.We'll apply these to some more practical problems, such as learning a language model from Wikipedia data and visualizing the word embeddings we get as a result.All of the materials required for this course can be downloaded and installed for FREE. We will do most of our work in Numpy, Matplotlib, and Theano. I am always available to answer your questions and help you along your data science journey.See you in class!"Hold up... what's deep learning and all this other crazy stuff you're talking about?"If you are completely new to deep learning, you might want to check out my earlier books and courses on the subject:Deep Learning in Python https://www.amazon.com/dp/B01CVJ19E8Deep Learning in Python Prerequisities https://www.amazon.com/dp/B01D7GDRQ2Much like how IBM's Deep Blue beat world champion chess player Garry Kasparov in 1996, Google's AlphaGo recently made headlines when it beat world champion Lee Sedol in March 2016.What was amazing about this win was that experts in the field didn't think it would happen for another 10 years. The search space of Go is much larger than that of chess, meaning that existing techniques for playing games with artificial intelligence were infeasible. Deep learning was the technique that enabled AlphaGo to correctly predict the outcome of its moves and defeat the world champion.Deep learning progress has accelerated in recent years due to more processing power (see: Tensor Processing Unit or TPU), larger datasets, and new algorithms like the ones discussed in this book.},
year = {2016},
shorttitle = {Deep Learning},
title = {Deep Learning Recurrent Neural Networks in Python LSTM, GRU, and more RNN machine learning architectures in Python and Theano},
}

@book{2019RaoNatural,
author = {Brian McMahan and Delip Rao},
abstract = {This book aims to bring newcomers to natural language processing (NLP) and deep learning to a tasting table covering important topics in both areas. Both of these subject areas are growing exponentially. As it introduces both deep learning and NLP with an emphasis on implementation, this book occupies an important middle ground. While writing the book, we had to make difficult, and sometimes uncomfortable, choices on what material to leave out. For a beginner reader, we hope the book will provide a strong foundation in the basics and a glimpse of what is possible. Machine learning, and deep learning in particular, is an experiential discipline, as opposed to an intellectual science. The generous end-to-end code examples in each chapter invite you to partake in that experience.},
title = {Natural Language Processing with PyTorch - Build Intelligent Language Applications Using Deep Learning},
arxivid = {arXiv:1011.1669v3},
booktitle = {O'Reilly Media},
shorttitle = {Natural Language Processing with PyTorch},
publisher = {O'Reilly Media},
pmid = {25246403},
issn = {00157120},
isbn = {9788578110796},
archiveprefix = {arXiv},
year = {2019},
edition = {1 edition},
url = {http://ebooks.cambridge.org/ref/id/CBO9781107415324A009},
pages = {210},
eprint = {arXiv:1011.1669v3},
keywords = {icle},
mendeley-tags = {icle},
}

@book{SportoElm,
author = { Sporto},
url = {https://github.com/sporto/elm-tutorial},
title = {Elm Tutorial},
}

@book{1990MooreElements,
author = {John Snell and F. Richard Moore},
edition = {1st edition},
volume = {14},
year = {1990},
title = {Elements of Computer Music},
abstract = {Includes index.},
booktitle = {Computer Music Journal},
doi = {10.2307/3680793},
issn = {01489267},
pages = {67},
publisher = {Prentice Hall},
isbn = {978-0-13-252552-7},
number = {4},
}

@thesis{2017MartinApplication,
author = {M. Martin},
type = {phdthesis},
number = {May},
url = {https://dspace.cvut.cz/bitstream/handle/10467/70078/F3-BP-2017-Muzika-Martin-Application///////%5C%5C of///////%5C%5C Game///////%5C%5C Theoretic///////%5C%5C Algorithms.pdf},
year = {2017},
title = {Application of Game Theoretic Algorithms to Gomoku},
abstract = {game Gomoku-swap2. The challenges of this domain are the size of the branching factor and the depth of the game. For this reason, the game cannot be solved exactly and so the evaluation function estimating the quality of a game state is the most important factor. Because it is impossible to solve the game exactly, we use Monte Carlo Tree Search (MCTS) where we use large number of simulations as an evaluation function. To guide the search in the MCTS we use the Neural Network learned on the human-played games. In experimental evaluation, we show that the Neural Network heuristic significantly enhances the performance of play. This leads to the first algorithm capable of human-like performance in the game Gomoku-swap2.},
institution = {Czech Technical University in Prague},
keywords = {gomoku,gomoku-swap,mcts,neural network},
mendeley-tags = {gomoku,gomoku-swap,mcts,neural network},
}

@book{2015KelleherFundamentals,
author = {John D. Kelleher and Brian Mac Namee and Aoife D'Arcy},
booktitle = {Igarss 2014},
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
number = {1},
pages = {1--691},
pmid = {15991970},
publisher = {The MIT Press},
archiveprefix = {arXiv},
shorttitle = {Fundamentals of Machine Learning for Predictive Data Analytics},
title = {Fundamentals of Machine Learning for Predictive Data Analytics},
year = {2015},
edition = {1 edition},
eprint = {arXiv:1011.1669v3},
issn = {13514180},
arxivid = {arXiv:1011.1669v3},
isbn = {9780874216561},
keywords = {high resolution images,research,risks management,sustainable reconstruction},
mendeley-tags = {high resolution images,research,risks management,sustainable reconstruction},
}

@book{2013SpanielGame,
author = {William Spaniel},
url = {https://read.amazon.com/?asin=B005L7ANWC},
year = {2011},
abstract = {Game Theory 101: The Complete Textbook is a no-nonsense, games-centered introduction to strategic form (matrix) and extensive form (game tree) games. From the first lesson to the last, this textbook introduces games of increasing complexity and then teaches the game theoretical tools necessary to solve them. Quick, efficient, and to the point, Game Theory 101: The Complete Textbook is perfect for introductory game theory, intermediate microeconomics, and political science.},
shorttitle = {Game Theory 101},
title = {Game Theory 101: The complete Textbook},
}

@book{2007BinmoreGame,
author = {Ken Binmore},
publisher = {OUP Oxford},
isbn = {978-0-19-921846-2},
edition = {1 edition},
shorttitle = {Game Theory},
abstract = {Games are everywhere: Drivers manoeuvring in heavy traffic are playing a driving game. Bargain hunters bidding on eBay are playing an auctioning game. A firm negotiating next year's wage is playing a bargaining game. The opposing candidates in an election are playing a political game. The supermarket's price for corn flakes is decided by playing an economic game.Game theory is about how to play such games in a rational way. Even when the players have not thought everything out in advance, game theory often works for the same reason that mindless animals sometimes end up behaving very cleverly: evolutionary forces eliminate irrational play because it is unfit.Game theory has seen spectacular successes in evolutionary biology and economics, and is beginning to revolutionize other disciplines from psychology to political science. This Very Short Introduction introduces the fascinating world of game theory, showing how it can be understood without mathematical equations, and revealing that everything from how to play poker optimally to the sex ratio among bees can be understood by anyone willing to think seriously about the problem.ABOUT THE SERIES: The Very Short Introductions series from Oxford University Press contains hundreds of titles in almost every subject area. These pocket-sized books are the perfect way to get ahead in a new subject quickly. Our expert authors combine facts, analysis, perspective, new ideas, and enthusiasm to make interesting and challenging topics highly readable.},
title = {Game Theory: A Very Short Introduction},
}

@book{2018LazarMastering,
author = {Guillaume Lazar and Robin Penea},
pages = {534},
year = {2018},
shorttitle = {Mastering Qt 5},
url = {http://www.arxen.com/descargas/Books/Mastering///////%5C%5C Qt///////%5C%5C 5///////%5C%5C -///////%5C%5C Guillaume///////%5C%5C Lazar,///////%5C%5C Robin///////%5C%5C Penea.pdf},
abstract = {Second edition. Includes index. Table of ContentsGET YOUR QT FEET WET DISCOVERING QMAKE SECRETS DIVIDING YOUR PROJECT AND RULING YOUR CODE CONQUERING THE DESKTOP UI DOMINATING THE MOBILE UI EVEN QT DESERVES A SLICE OF RASPBERRY PI THIRD-PARTY LIBRARIES WITHOUT A HEADACHE ANIMATIONS -- ITS ALIVE, ALIVE!KEEPING YOUR SANITY WITH MULTITHREADING NEED IPC? GET YOUR MINIONS TO WORK HAVING FUN WITH SERIALIZATIONYOU SHALL (NOT) PASS WITH QTEST ALL PACKED AND READY TO DEPLOY QT HAT TIPS AND TRICKS.},
publisher = {Packt},
isbn = {978-1788995399},
title = {Mastering Qt 5: Create stunning cross-platform applications using C++ with Qt Widgets and QML with Qt Quick},
annote = {OCLC: 1039917696},
}

@book{2004ScheyDiv,
author = {H. M. Schey},
shorttitle = {Div, Grad, Curl, and All That},
title = {Div, Grad, Curl, and All That An Informal Text on Vector Calculus, 3ed.pdf},
publisher = {W. W. Norton ////////\\\& Company},
year = {1997},
abstract = {Since the publication of the First Edition over thirty years ago, <I>Div, Grad, Curl, and All That</I> has been widely renowned for its clear and concise coverage of vector calculus, helping science and engineering students gain a thorough understanding of gradient, curl, and Laplacian operators without required knowledge of advanced mathematics. The Fourth Edition has been carefully revised and now includes updated notations and seven new example exercises.},
edition = {4th edition},
isbn = {0393925161},
pmid = {4942529},
keywords = {textbook},
mendeley-tags = {textbook},
}

@book{2015GrolemundHands,
author = {Garrett Grolemund},
volume = {53},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
url = {https://d1b10bmlvqabco.cloudfront.net/attach/ighbo26t3ua52t/igp9099yy4v10/igz7vp4w5su9/OReilly///////%5C%5C_HandsOn///////%5C%5C_Programming///////%5C%5C_with///////%5C%5C_R///////%5C%5C_2014.pdf},
booktitle = {Journal of Chemical Information and Modeling},
isbn = {9788578110796},
pmid = {25246403},
year = {2013},
publisher = {O'Reilly UK Ltd.},
title = {Hands-On Programming with R},
eprint = {arXiv:1011.1669v3},
pages = {1689--1699},
arxivid = {arXiv:1011.1669v3},
archiveprefix = {arXiv},
issn = {1098-6596},
number = {9},
keywords = {icle},
mendeley-tags = {icle},
}

@book{2017PercivalTest,
author = {Harry Percival},
edition = {2 edition},
publisher = {O'Reilly Media},
shorttitle = {Test-Driven Development with Python},
isbn = {9781491958704},
url = {http://www.obeythetestinggoat.com/pages/book.html///////%5C%5C#toc},
year = {2017},
abstract = {Second edition. Getting Django set up using a functional test -- Extending our functional test using the unittest module -- Testing a simple home page with unit tests -- What are we doing with all these tests? (And, refactoring) -- Saving user input : testing the database -- Improving functional tests : ensuring isolation and removing Voodoo sleeps -- Working incrementally -- Prettification : layout and styling, and what to test about it -- Testing deployment using a staging site -- Getting to a production-ready deployment -- Automating deployment with fabric --Splitting our tests into multiple files, and a generic wait helper --  Validation at the database layer -- A simple form -- More advanced forms -- Dipping our toes, very tentatively, into JavaScript -- Deploying our new code -- User authentication, spiking, and de-spiking -- Using mocks to test external dependencies or reduce duplication -- Test fixtures and a decorator for explicit waits -- Server-side debugging -- Finishing "my lists" : outside-in TDD -- Test isolation, and "listening to your tests" -- Continuous integration (CI) -- The token social bit, the page pattern, and an exercise for the reader -- Fast tests, slow tests, and hot lava -- Obey the testing goat! -- Appendix A: PythonAnywhere -- Appendix B: Django class-based views -- Appendix C: Provisioning with ansible -- Appendix D: Testing database migrations -- Appendix E: Behaviour-driven development (BDD) -- Appendix F: Building a REST API : JSON, Ajax, and mocking with JavaScript -- Appendix G : Django-rest-framework -- Appendix H : Cheat sheet -- Appendix I : What to do ndext -- Appendix J : Source code examples.},
title = {Test-driven development with Python : obey the testing goat: using Django, Selenium, and JavaScript},
pages = {575},
}

@book{2015EcoHow,
author = {Magdy El-Serafy},
isbn = {978-0-262-52713-2},
title = {How to write a thesis},
abstract = {Umberto Eco's wise and witty guide to researching and writing a thesis, published in English for the first time. By the time Umberto Eco published his best-selling novel The Name of the Rose, he was one of Italy's most celebrated intellectuals, a distinguished academic and the author of influential works on semiotics. Some years before that, in 1977, Eco published a little book for his students, How to Write a Thesis, in which he offered useful advice on all the steps involved in researching and writing a thesis―from choosing a topic to organizing a work schedule to writing the final draft. Now in its twenty-third edition in Italy and translated into seventeen languages, How to Write a Thesis has become a classic. Remarkably, this is its first, long overdue publication in English. Eco's approach is anything but dry and academic. He not only offers practical advice but also considers larger questions about the value of the thesis-writing exercise. How to Write a Thesis is unlike any other writing manual. It reads like a novel. It is opinionated. It is frequently irreverent, sometimes polemical, and often hilarious. Eco advises students how to avoid "thesis neurosis" and he answers the important question "Must You Read Books?" He reminds students "You are not Proust" and "Write everything that comes into your head, but only in the first draft." Of course, there was no Internet in 1977, but Eco's index card research system offers important lessons about critical thinking and information curating for students of today who may be burdened by Big Data.How to Write a Thesis belongs on the bookshelves of students, teachers, writers, and Eco fans everywhere. Already a classic, it would fit nicely between two other classics: Strunk and White and The Name of the Rose.ContentsThe Definition and Purpose of a Thesis • Choosing the Topic • Conducting Research • The Work Plan and the Index Cards • Writing the Thesis • The Final Draft},
translator = {Farina, Caterina Mongiat and Farina, Geoff},
volume = {10},
year = {2009},
pages = {73--77},
publisher = {The MIT Press},
doi = {10.1016/j.ajg.2009.07.200},
edition = {Translation edition},
booktitle = {Arab Journal of Gastroenterology},
issn = {16871979},
number = {3},
}

@book{1982MichaelsonHow,
author = {Stuart E. Jenness},
issn = {0008-3674},
doi = {10.1139/t85-061},
pages = {427--427},
publisher = {ISI Press},
url = {https://www.amazon.com/Publish-Engineering-Reports-Professional-writing/dp/0894950169?SubscriptionId=AKIAIOBINVZYXZQZ2U3A///////%5C%5C&tag=chimbori05-20///////%5C%5C&linkCode=xm2///////%5C%5C&camp=2025///////%5C%5C&creative=165953///////%5C%5C&creativeASIN=0894950169},
abstract = {3rd ed. How to define quality in engineering manuscripts -- How to match your objectives with reader interests -- How to decide questions of multiple authorship -- How to plan and organize your paper or report -- How to use the incremental method -- How to write an abstract -- How to construct the introduction -- How to prepare the body of your manuscript -- How to write an effective concluding section -- How to achieve proper emphasis in writing -- How to avoid information traps -- How to choose illustrations for visual impact -- How to construct tables for information content -- How to cite references properly in text -- How to compile a bibliography quickly -- How to write and publiish a thesis or dissertation -- How to publish your "confidential" results -- How to edit your manuscript for content and integrity -- How to submit a journal manuscript successfully -- How to deal with your critics -- How to review engineering manuscripts -- How to proofread -- How to present a paper orally -- Writing productively with a personal computer -- How to approach desktop publishing -- How to collaborate in network-based writing -- How to construct an internal proposal -- How to avoid pitfalls that lead to ethical violations -- Summary: how to avoid strategic errors in a manuscript.},
isbn = {978-0-89495-016-2},
number = {3},
year = {1985},
title = {How to write and publish engineering papers and reports: Book review},
booktitle = {Canadian Geotechnical Journal},
series = {The Professional writing series},
volume = {22},
}

@book{2017PastineIntroducing,
author = {Ivan Pastine and Tuvana Pastine},
shorttitle = {Introducing Game Theory},
abstract = {When should you adopt an aggressive business strategy? How do we make decisions when we don't have all the information? What makes international environmental cooperation possible?Game theory is the study of how we make a decision when the outcome of our moves depends on the decisions of someone else. Economists Ivan and Tuvana Pastine explain why, in these situations, we sometimes cooperate, sometimes clash, and sometimes act in a way that seems completely random.Stylishly brought to life by award-winning cartoonist Tom Humberstone, Game Theory will help readers understand behaviour in everything from our social lives to business, global politics to evolutionary biology. It provides a thrilling new perspective on the world we live in.},
publisher = {Icon Books Ltd},
title = {<Introducing Game Theory_ A Graphic Guide - Ivan Pastine & Tuvana Pastine.pdf>},
}

@book{2010MixermanZen,
author = {Michelle Francl},
number = {3},
publisher = {Hal Leonard},
abstract = {(Technical Reference). In his first book, The Daily Adventures of Mixerman , the author detailed the frustrating and often hilarious goings on during the process of recording a major-label band. Musicians, engineers, and producers laughed and cried at the crazy goings-on they'd never imagined or recognized all too well. Now Mixerman turns his razor-sharp gaze to the art of mixing and gives followers and the uninitiated reason to hope if not for logic and civility in the recording studio then at least for a good sounding record. With a firm commitment to art over technology and to maintaining a grasp of each, Mixerman outlines his own approach to recording success, based on his years mixing records in all genres of music for all kinds of artists, often under trying circumstances. As he states in his introduction to the new volume, "Even if you're not a professional mixer, even if you're a musician trying to mix your own work or a studio owner in a smaller market, you have your own set of pressures to deal with while you're mixing. Regardless of what those pressures are, it's important to identify and recognize them, if for no other reason than so you can learn to completely ignore them." But how? "That's where the Zen comes in."},
pmid = {22354415},
volume = {4},
booktitle = {Nature Chemistry},
title = {Zen and the art of molecules},
doi = {10.1038/nchem.1279},
pages = {142--144},
issn = {17554349},
year = {2012},
}

@book{2003KunderaArt,
author = {Michael Sosa and Milan Kundera and Linda Asher},
volume = {62},
booktitle = {World Literature Today},
isbn = {978-0-06-009374-7},
doi = {10.2307/40144675},
abstract = {Kundera brilliantly examines the work of such important and diverse figures as Rabelais, Cervantes, Sterne, Diderot, Flaubert, Tolstoy, and Musil. He is especially penetrating on Hermann Broch, and his exploration of the world of Kafka's novels vividly reveals the comic terror of Kafka's bureaucratized universe. Kundera's discussion of his own work includes his views on the role of historical events in fiction, the meaning of action, and the creation of character in the post-psychological novel.},
issn = {01963570},
edition = {Reprint edition},
number = {4},
year = {1988},
publisher = {Harper Perennial Modern Classics},
title = {The Art of the Novel},
pages = {685},
}

@book{2018SinghIonic,
author = {Indermohan. Singh},
abstract = {3rd ed. Introduction. Ionic has been a preferred choice for JavaScript developers to develop real time hybrid applications. This book will get you started with Ionic 3.9 and help you create Angular 5 components that interact with templates. Get the best out of Ionic through dedicated recipes which will solve issues related to it. Cover; Title Page; Copyright and Credits; Packt Upsell; Contributors; Table of Contents; Preface; Chapter 1: Creating Our First App with Ionic; Introduction; Setting up a development environment; Getting ready; How to do it ... ; There's more ... ; Creating a HelloWorld app via the CLI; How to do it ... ; How it works ... ; Creating a HelloWorld app via Ionic Creator; Getting ready; How to do it ... ; There's more ... ; Viewing the app using your web browser; Getting ready; How to do it ... ; How it works ... ; Viewing the app using the Ionic CLI; Getting Ready; How to do it ... Viewing the app using Xcode for iOSHow to do it ... ; There's more ... ; Viewing the app using Genymotion for Android; How to do it ... ; Viewing the app using Ionic View; How to do it ... ; There's more ... ; Chapter 2: Adding Ionic Components; Introduction; Adding multiple pages using tabs; Getting ready; How to do it ... ; How it works ... ; See also; Adding left and right menu navigation; Getting ready; How to do it ... ; How it works ... ; See also; Navigating multiple pages with state parameters; Getting ready; How to do it ... ; How it works ... ; See also; Using menu, tabs, and segment together in an app. Getting readyHow to do it ... ; How it works ... ; See also; Using the Ionic grid to create a complex UI; Getting ready; How to do it ... ; How it works ... ; See also; Chapter 3: Extending Ionic with Angular Building Blocks; Introduction; Creating a custom pizza ordering component; Getting ready; How to do it ... ; How it works ... ; See also; Creating a custom username input directive; Getting ready; How to do it ... ; How it works ... ; See also; Creating a custom pipe; Getting ready; How to do it ... ; How it works ... ; See also; Creating a shared service to provide data to multiple pages; Getting ready. How to do it ... How it works ... ; See also; Reusing an existing page as an HTML element; Getting ready; How to do it ... ; How it works ... ; See also; Chapter 4: Validating Forms and Making HTTP Requests; Introduction; Creating a complex form with input validation; Getting ready; How to do it ... ; How it works ... ; See also; Creating reactive forms in Ionic; Getting ready; How to do it ... ; How it works ... ; See also; Retrieving data via a mocked API using a static JSON file; Getting ready; How to do it ... ; How it works ... ; See also; Integrating with Stripe for online payment; Getting ready. How to do it ... How it works ... ; See also; Chapter 5: Adding Animation; Introduction; Embedding full screen inline video as background; Getting ready; How to do it ... ; How it works ... ; Creating physics-based animation using Dynamics.js; Getting ready; How to do it ... ; How it works ... ; See also; Animating the slide component by binding a gesture to the animation state; Getting ready; How to do it ... ; How it works ... ; See also; Adding a background CSS animation to the login page; Getting ready; How to do it ... ; How it works ... ; See also; Chapter 6: User Authentication and Push Notifications.},
edition = {3 edition},
isbn = {9781788623230},
publisher = {Packt Publishing},
pages = {383},
title = {Ionic Cookbook : Recipes to create cutting-edge, real-time hybrid mobile apps with Ionic, 3rd Edition.},
year = {2018},
shorttitle = {Ionic Cookbook},
}

@book{2017GalowiczC++17,
author = {Jacek Galowicz},
shorttitle = {C++17 STL Cookbook},
isbn = {9781787120495},
title = {C++17 STL Cookbook: Discover the latest enhancements to functional programming and lambda expressions},
abstract = {Key FeaturesLearn the latest features of C++ and how to write better code by using the Standard Library (STL). Reduce the development time for your applications.Understand the scope and power of STL features to deal with real-world problems.Compose your own algorithms without forfeiting the simplicity and elegance of the STL way.Book DescriptionC++ has come a long way and is in use in every area of the industry. Fast, efficient, and flexible, it is used to solve many problems. The upcoming version of C++ will see programmers change the way they code. If you want to grasp the practical usefulness of the C++17 STL in order to write smarter, fully portable code, then this book is for you.Beginning with new language features, this book will help you understand the language's mechanics and library features, and offers insight into how they work. Unlike other books, ours takes an implementation-specific, problem-solution approach that will help you quickly overcome hurdles. You will learn the core STL concepts, such as containers, algorithms, utility classes, lambda expressions, iterators, and more, while working on practical real-world recipes. These recipes will help you get the most from the STL and show you how to program in a better way.By the end of the book, you will be up to date with the latest C++17 features and save time and effort while solving tasks elegantly using the STL.What you will learnLearn about the new core language features and the problems they were intended to solveUnderstand the inner workings and requirements of iterators by implementing themExplore algorithms, functional programming style, and lambda expressionsLeverage the rich, portable, fast, and well-tested set of well-designed algorithms provided in the STLWork with strings the STL way instead of handcrafting C-style codeUnderstand standard support classes for concurrency and synchronization, and how to put them to workUse the filesystem library addition available with the C++17 STLAbout the AuthorJacek Galowicz obtained his master of science in electrical engineering/computer engineering at RWTH Aachen University, Germany. While at university, he enjoyed working as a student assistant in teaching and research, and he participated in several scientific publications. During and after his studies, he worked as a freelancer and implemented applications as well as kernel drivers in C and C++, touching various areas, including 3D graphics programming, databases, network communication, and physics simulation. In recent years, he has been programming performance- and security-sensitive microkernel operating systems for Intel x86 virtualization at Intel and FireEye in Braunschweig, Germany. He has a strong passion for modern C++ implementations of low-level software, and he tries hard to combine high performance with an elegant coding style. Learning purely functional programming and Haskell in recent years triggered his drive to implement generic code with the aid of meta programming.Table of ContentsThe New C++17 FeaturesSTL ContainersIteratorsLambda ExpressionsSTL Algorithm BasicsAdvanced Use of STL AlgorithmsStrings, Stream Classes, and Regular ExpressionsUtility ClasssesParallelism and ConcurrencyFilesystem},
edition = {1 edition},
year = {2017},
publisher = {Packt Publishing},
pages = {532},
}

@book{2014HorsleyUnlimited,
author = {Kevin Horsley},
title = {Unlimited Memory How to use advanced learning strategies to learn faster, remember more and be more productiive},
publisher = {TCK Publishing},
year = {2013},
pmid = {30152171},
booktitle = {TCK Publishing},
pages = {363},
shorttitle = {Unlimited Memory},
issn = {1601-6343 (Electronic)},
abstract = {The aim of this review was to evaluate available evidence on the effect of early orthodontic management and myofunctional treatment in the developing dentition children, on anterior open bite correction, as well as on normalization of patterns of mouth breathing, swallowing and tongue resting position and pressure. Electronic searches in MEDLINE, Cochrane and LILACS, without language restrictions were conducted. Additionally, unpublished literature was identified. Randomized controlled trials, or controlled clinical trials, comparing interventions applied to manage anterior open bite and other muscle functions such as breathing/swallowing pattern and tongue resting position and pressure, were considered. Quality assessment was based on the Cochrane Risk of Bias tool. Random effects meta-analyses were conducted to assess treatment effects. From the 265 initial search results, 15 articles were included in the review. Eight were randomized controlled trials (RCTs) and 7 were controlled clinical trials. Treatment outcomes comprised skeletal and dentoalveolar changes recorded cephalometrically, mouth posture and lip closure normalization, improvement of tongue resting position/pressure and modification of swallowing pattern. Quantitative synthesis was possible for only 2 of the included RCTs. There was no evidence to support bonded lingual spurs over banded fixed appliances for the correction of anterior open bite in mixed dentition children presenting nonnutritive oral habits at the onset of treatment (SMD: -0.03; 95%CI: -.81, 0.74; P = 0.94). Although early orthodontic management and myofunctional treatment in the deciduous and mixed dentition children appears to be a promising approach, the quality of the existing evidence is questionable.},
edition = {2 edition},
keywords = {breathing/swallowing pattern,mixed dentition,myofunctional,open bite,systematic review},
mendeley-tags = {breathing/swallowing pattern,mixed dentition,myofunctional,open bite,systematic review},
}

@book{2015VerouCss,
author = {Lea Verou},
publisher = {O'Reilly Media},
abstract = {1781},
pages = {354},
shorttitle = {CSS Secrets},
edition = {1 edition},
isbn = {9781449372637},
title = {CSS secrets : better solutions to everyday web design problems},
year = {2015},
}

@book{1997BieglerSystematic,
author = {L.T. Biegler and I.E. Grossmann and A.W. Westerberg},
isbn = {978-0-13-492422-9},
year = {1997},
edition = {1 edition},
title = {Systematic methods for chemical process design},
abstract = {This book brings together all the information engineers and researchers need to develop efficient, cost-effective chemical production processes. The book presents a systematic approach to chemical process design, covering both continuous and batch processes. Starting with the basics, the book then moves on to advanced topics. Among the topics covered are: flowsheet synthesis, mass and energy balances, equipment sizing and costing, economic evaluation, process simulation and optimization. The book also covers specific chemical processes such as distillation systems, reactor networks, separation, and heat exchange networks. It shows how to build more flexible processes, including multiproduct batch processes.},
publisher = {Prentice Hall},
}

@book{2017MoskalaAndroid,
author = {Marcin Moskala and Igor Wojda},
publisher = {Packt Publishing},
title = {Android Development with Kotlin: Enhance your skills for Android development using Kotlin},
abstract = {Learn how to make Android development much faster using a variety of Kotlin features, from basics to advanced, to write better quality code.Key FeaturesLeverage specific features of Kotlin to ease Android application developmentWrite code based on both object oriented and functional programming to build robust applicationsFilled with various practical examples so you can easily apply your knowledge to real world scenariosIdentify the improved way of dealing with common Java patternsBook DescriptionNowadays, improved application development does not just mean building better performing applications. It has become crucial to find improved ways of writing code. Kotlin is a language that helps developers build amazing Android applications easily and effectively. This book discusses Kotlin features in context of Android development. It demonstrates how common examples that are typical for Android development, can be simplified using Kotlin. It also shows all the benefits, improvements and new possibilities provided by this language.The book is divided in three modules that show the power of Kotlin and teach you how to use it properly. Each module present features in different levels of advancement. The first module covers Kotlin basics. This module will lay a firm foundation for the rest of the chapters so you are able to read and understand most of the Kotlin code. The next module dives deeper into the building blocks of Kotlin, such as functions, classes, and function types. You will learn how Kotlin brings many improvements to the table by improving common Java concepts and decreasing code verbosity. The last module presents features that are not present in Java. You will learn how certain tasks can be achieved in simpler ways thanks to Kotlin.Through the book, you will learn how to use Kotlin for Android development. You will get to know and understand most important Kotlin features, and how they can be used. You will be ready to start your own adventure with Android development with Kotlin.What you will learnRun a Kotlin application and understand the integration with Android StudioIncorporate Kotlin into new/existing Android Java based projectLearn about Kotlin type system to deal with null safety and immutabilityDefine various types of classes and deal with propertiesDefine collections and transform them in functional wayDefine extensions, new behaviours to existing libraries and Android framework classesUse generic type variance modifiers to define subtyping relationship between generic typesBuild a sample applicationTable of ContentsBeginning Your Kotlin AdventureLaying a FoundationPlaying with FunctionsClasses and ObjectsFunctions as First-Class CitizensGenerics Are Your FriendsExtension Functions and PropertiesDelegatesMaking Your Marvel Gallery Application},
edition = {1 edition},
shorttitle = {Android Development with Kotlin},
}

@book{2017BancilaModern,
author = {Marius Bancila},
abstract = {Over 100 recipes to help you overcome your difficulties with C++ programming and gain a deeper understanding of the working of modern C++About This BookExplore the most important language and library features of C++17, including containers, algorithms, regular expressions, threads, and more,Get going with unit testing frameworks Boost.Test, Google Test and Catch,Extend your C++ knowledge and take your development skills to new heights by making your applications fast, robust, and scalable.Who This Book Is ForIf you want to overcome difficult phases of development with C++ and leverage its features using modern programming practices, then this book is for you. The book is designed for both experienced C++ programmers as well as people with strong knowledge of OOP concepts.What You Will LearnGet to know about the new core language features and the problems they were intended to solveUnderstand the standard support for threading and concurrency and know how to put them on work for daily basic tasksLeverage C++'s features to get increased robustness and performanceExplore the widely-used testing frameworks for C++ and implement various useful patterns and idiomsWork with various types of strings and look at the various aspects of compilationExplore functions and callable objects with a focus on modern featuresLeverage the standard library and work with containers, algorithms, and iteratorsUse regular expressions for find and replace string operationsTake advantage of the new filesystem library to work with files and directories},
shorttitle = {Modern C++ Programming Cookbook},
year = {2017},
pages = {340},
title = {Modern C++ Programming Cookbook: Recipes to explore data structure, multithreading, and networking in C++17},
publisher = {Packt Publishing - ebooks Account},
isbn = {9781786465184},
}

@book{2018LapanDeep,
author = {Maxim Lapan},
booktitle = {Packt Publishing Ltd.},
title = {Deep Reinforcement Learning Hands-On. Apply modern RL methods, with deep Q-networks, value iteration, policy gradients, TRPO, AlphaGo zero and more},
abstract = {We discuss deep reinforcement learning in an overview style. We draw a big picture, filled with details. We discuss six core elements, six important mechanisms, and twelve applications, focusing on contemporary work, and in historical contexts. We start with background of artificial intelligence, machine learning, deep learning, and reinforcement learning (RL), with resources. Next we discuss RL core elements, including value function, policy, reward, model, exploration vs. exploitation, and representation. Then we discuss important mechanisms for RL, including attention and memory, unsupervised learning, hierarchical RL, multiagent RL, relational RL, and learning to learn. After that, we discuss RL applications, including games, robotics, natural language processing (NLP), computer vision, finance, business management, healthcare, education, energy, transportation, computer systems, and, science, engineering, and art. Finally we summarize briefly, discuss challenges and opportunities, and close with an epilogue. 1},
isbn = {9781788834247},
publisher = {Packt Publishing},
pages = {547},
shorttitle = {Deep Reinforcement Learning Hands-On},
year = {2018},
keywords = {algorithm,application,architecture,art,artificial intelligence,attention,business management,computer systems,computer vision,deep learning,deep reinforcement learning,deep rl,education,energy,engineering,exploration vs. exploitation,finance,games,healthcare,hierarchical rl,learning to learn,machine learning,memory,model,multiagent rl,natural language processing,policy,reinforcement learning,relational rl,representation,reward,robotics,science,transportation,unsupervised learning,value function},
mendeley-tags = {algorithm,application,architecture,art,artificial intelligence,attention,business management,computer systems,computer vision,deep learning,deep reinforcement learning,deep rl,education,energy,engineering,exploration vs. exploitation,finance,games,healthcare,hierarchical rl,learning to learn,machine learning,memory,model,multiagent rl,natural language processing,policy,reinforcement learning,relational rl,representation,reward,robotics,science,transportation,unsupervised learning,value function},
}

@book{2016CostandiNeuroplasticity,
author = { Cost and Moheb i},
abstract = {The real story of how our brains and nervous systems change throughout our lifetimes―with or without "brain training."Fifty years ago, neuroscientists thought that a mature brain was fixed like a fly in amber, unable to change. Today, we know that our brains and nervous systems change throughout our lifetimes. This concept of neuroplasticity has captured the imagination of a public eager for self-improvement―and has inspired countless Internet entrepreneurs who peddle dubious "brain training" games and apps. In this book, Moheb Costandi offers a concise and engaging overview of neuroplasticity for the general reader, describing how our brains change continuously in response to our actions and experiences.Costandi discusses key experimental findings, and describes how our thinking about the brain has evolved over time. He explains how the brain changes during development, and the "synaptic pruning" that takes place before brain maturity. He shows that adult brains can grow new cells (citing, among many other studies, research showing that sexually mature male canaries learn a new song every year). He describes the kind of brain training that can bring about improvement in brain function. It's not gadgets and games that promise to "rewire your brain" but such sustained cognitive tasks as learning a musical instrument or a new language. (Costandi also notes that London cabbies increase their gray matter after rigorous training in their city's complicated streets.) He tells how brains compensate after stroke or injury; describes addiction and pain as maladaptive forms of neuroplasticity; and considers brain changes that accompany childhood, adolescence, parenthood, and aging. Each of our brains is custom-built. Neuroplasticity is at the heart of what makes us human.},
isbn = {978-0-262-52933-4},
publisher = {The MIT Press},
title = {Neuroplasticity},
}

@book{2015NiouStrategy,
author = {Joel Watson},
pages = {1--26},
title = {Strategy: An Introduction to Game Theory},
publisher = {Routledge},
url = {http://www.r-tutor.com/},
edition = {1 edition},
isbn = {0393976483},
abstract = {The two aims of this book are suggested in the ambiguity of its title: to provide a reading of major texts by Lacan, Derrida, and Kristeva and to trace the outlines of the reading theories they propose. Lacan heralds a return to the writings of Freud in order to hear in his texts the voice of the unconscious; Derrida proposes to examine so carefully the structures of the texts he reads as to discover the deconstructive openings in those texts to structures of thought that are outside or beyond them; Kristeva extends the methods of semanalysis, a psychoanalytically enhanced semiotics, to an examination of the speaking subject and the signifying structures of social practice.},
year = {2001},
booktitle = {Graduate texts in Mathematics},
shorttitle = {Strategy and Politics},
}

@book{2016RashidMake,
author = {Tariq Rashid},
publisher = {CreateSpace Independent Publishing Platform},
edition = {1 edition},
booktitle = {Journal of Chemical Information and Modeling},
number = {9},
title = {Make Your Own Neural Network},
eprint = {arXiv:1011.1669v3},
arxivid = {arXiv:1011.1669v3},
pages = {45--50},
pmid = {25246403},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archiveprefix = {arXiv},
issn = {1098-6596},
year = {2013},
volume = {53},
isbn = {9788578110796},
keywords = {de ecuaciones no lineales,en dos variables,icle},
mendeley-tags = {de ecuaciones no lineales,en dos variables,icle},
}

@book{2014TalwalkarJoy,
author = {Presh Talwalkar},
shorttitle = {The Joy of Game Theory},
isbn = {978-1-5004-9744-6},
publisher = {CreateSpace Independent Publishing Platform},
abstract = {This book is a selection of the best articles from Game Theory Tuesdays, a column from the blog Mind Your Decisions. Articles from Game Theory Tuesdays have been referenced in The Freakonomics Blog, Yahoo Finance, and CNN.com. Game theory is the study of interactive decision making--that is, in situations where each person's action affects the outcome for the whole group. Game theory is a beautiful subject and this book will teach you how to understand the theory and practically implement solutions through a series of stories and the aid of over 30 illustrations. This book has two primary objectives. (1) To help you recognize strategic games, like the Prisoner's Dilemma, Bertrand Duopoly, Hotelling's Game, the Game of Chicken, and Mutually Assured Destruction. (2) To show you how to make better decisions and change the game, a powerful concept that can transform no-win situations into mutually beneficial outcomes. You'll learn how to negotiate better by making your threats credible, sometimes limiting options or burning bridges, and thinking about new ways to create better outcomes. As these goals indicate, game theory is about more than board games and gambling. It all seems so simple, and yet that definition belies the complexity of game theory. While it may only take seconds to get a sense of game theory, it takes a lifetime to appreciate and master it. This book will get you started.},
title = {The Joy of Game Theory - An Introduction to Strategic Thinking | 2013},
year = {2013},
}

@book{2012RamachandranTell,
author = {Peter Brugger},
pages = {351--358},
number = {4},
doi = {10.1080/13546805.2012.685295},
booktitle = {Cognitive Neuropsychiatry},
issn = {1354-6805},
isbn = {978-0-09-953759-5},
publisher = {Windmill Books},
volume = {17},
abstract = {* V.S. Ramachandran has exploded the boundaries of modern science - so much so that he has been praised by Richard Dawkins as a latter-day Marco Polo.  *A specialist in brain damage, he is famous for an instinctive, intuitive approach to neurological disorders that has led him to successfully 'amputate' phantom limbs, as well as solving the riddles of apotemnophilia (an obsession with self-amputation), and Capgrass syndrome (where patients who are in all other respects fully recovered become convinced that their loved ones are imposters).   This new book will explore why the human brain is so unique and how it became so enchantingly complex. Taking us to the frontiers of neurology, he reveals what baffling and extreme case studies can teach us about the brain and how it evolved. Along the way we hear stories that are by turns moving, funny, tragic and disturbing, but always utterly fascinating.},
shorttitle = {The Tell-Tale Brain},
title = {The tell-tale brain: Unlocking the mystery of human nature},
year = {2012},
}

@collection{2012KandelPrinciples,
author = {L Zagrean},
doi = {10.4183/aeb.2014.529},
number = {3},
isbn = {978-0-07-139011-8},
title = {Principles of Neural Science},
booktitle = {Acta Endocrinologica (Bucharest)},
issn = {18410987},
publisher = {McGraw-Hill Education / Medical},
volume = {10},
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
editor = {Kandel, Eric R and Schwartz, James H and Jessell, Thomas M and Siegelbaum, Steven A and Hudspeth, A J},
pages = {529--529},
year = {2014},
edition = {5th edition},
}

@book{Qt5,
author = {J. Thelin and J. Ryannel},
url = {https://qmlbook.github.io/},
year = {2015},
title = {Qt5 Cadaques},
}

@book{2015SusskindQuantum,
author = {Leonard Susskind and Art Friedman},
number = {01},
abstract = {From the bestselling author of The Theoretical Minimum, a DIY introduction to the math and science of quantum physicsFirst he taught you classical mechanics. Now, physicist Leonard Susskind has teamed up with data engineer Art Friedman to present the theory and associated mathematics of the strange world of quantum mechanics.In this follow-up to The Theoretical Minimum, Susskind and Friedman provide a lively introduction to this famously difficult field, which attempts to understand the behavior of sub-atomic objects through mathematical abstractions. Unlike other popularizations that shy away from quantum mechanics' weirdness, Quantum Mechanics embraces the utter strangeness of quantum logic. The authors offer crystal-clear explanations of the principles of quantum states, uncertainty and time dependence, entanglement, and particle and wave states, among other topics, and each chapter includes exercises to ensure mastery of each area. Like The Theoretical Minimum, this volume runs parallel to Susskind's eponymous Stanford University-hosted continuing education course.An approachable yet rigorous introduction to a famously difficult topic, Quantum Mechanics provides a tool kit for amateur scientists to learn physics at their own pace.},
pages = {52--0330--52--0330},
publisher = {Basic Books},
issn = {0009-4978},
volume = {52},
shorttitle = {Quantum Mechanics},
booktitle = {Choice Reviews Online},
doi = {10.5860/choice.52-0330},
isbn = {978-0-465-06290-4},
year = {2014},
title = {Quantum mechanics: the theoretical minimum},
}

@misc{WangIterated,
author = {Keven (Kedao) Wang},
pages = {1--9},
title = {Iterated Prisoners Dilemma with Reinforcement Learning},
year = {1996},
url = {http://kevenwang.com/wp-content/uploads/2017/06/psych209_paper.pdf},
abstract = {This project uses recurrent neural network based reinforcement learning to play Iterated Prisoner's Dilemma. Multiple experiments are carried out with varying strategy compositions: RL-agent vs. stationary strategies, RL-agent vs. RL-agent, more than two RL-agents, and a mix of strategies. Cooperative behavior emerged in some RL-agent vs. RL-agent scenario. Non-uniform strategies evolved in some tournaments where number of RL-agents greater than two. Q-table and markov matrix are used to analyze agents' learned strategies. A high variance is observed across trials when using Q-learning without experience replay.},
}

@report{2018Clarivate2018,
author = {Hany Kasban and Egyptian Atomic and Energy Authority},
number = {October},
type = {techreport},
publisher = {Clarivate Analytics},
url = {https://clarivate.com/wp-content/uploads/2018/06/Crv///////%5C%5C_JCR///////%5C%5C_Full-Marketing-List///////%5C%5C_A4///////%5C%5C_2018///////%5C%5C_v4.pdf},
institution = {Clarivate Analytics},
title = {2018 Journal Citation Reports},
year = {2018},
}

@book{1996HayesStatistical,
author = {Monson H Hayes},
edition = {1 edition},
isbn = {978-0-471-59431-4},
publisher = {WILEY},
abstract = {The main thrust is to provide students with a solid understanding of a number of important and related advanced topics in digital signal processing such as Wiener filters, power spectrum estimation, signal modeling and adaptive filtering. Scores of worked examples illustrate fine points, compare techniques and algorithms and facilitate comprehension of fundamental concepts. Also features an abundance of interesting and challenging problems at the end of every chapter.},
title = {STATISTICAL DSP- MONSON HAYES.pdf},
}

@article{SangamMapping,
author = {S.L. Sangam and Shivaranjini S Mogali},
title = {Mapping and Visualization Softwares tools: a review},
number = {May},
journal = {Content Management in Networked Environment},
url = {https://edisciplinas.usp.br/pluginfile.php/4131773/mod///////%5C%5C_folder/content/0/Mapping///////%5C%5C and///////%5C%5C Visualisation///////%5C%5C Software///////%5C%5C Tools///////%5C%5C A///////%5C%5C Review///////%5C%5C .pdf?forcedownload=1},
pages = {11},
year = {2012},
shorttitle = {Mapping and Visualization Softwares tools},
abstract = {The present paper aims to highlight the importance of mapping and visualization software tools viz: Bibexcel, CiteSpaceII, CoPalRed, IN-SPIRE, Leydesdorff's Software, Network Workbench Tool, Sci2 Tool, Vantage Point, and VOS Viewer. Further it covers software models, their use and operational process.},
}

@book{2007PressNumerical,
author = {Max Planitz and W. H. Press and B. P. Flannery and S. A. Teukolsky and W. T. Vetterling},
publisher = {Cambridge University Press},
volume = {71},
doi = {10.2307/3616786},
abstract = {Do you want easy access to the latest methods in scientific computing? This greatly expanded third edition of Numerical Recipes has it, with wider coverage than ever before, many new, expanded and updated sections, and two completely new chapters. The executable C++ code, now printed in color for easy reading, adopts an object-oriented style particularly suited to scientific applications. Co-authored by four leading scientists from academia and industry, Numerical Recipes starts with basic mathematics and computer science and proceeds to complete, working routines. The whole book is presented in the informal, easy-to-read style that made earlier editions so popular. Highlights of the new material include: a new chapter on classification and inference, Gaussian mixture models, HMMs, hierarchical clustering, and SVMs; a new chapter on computational geometry, covering KD trees, quad- and octrees, Delaunay triangulation, and algorithms for lines, polygons, triangles, and spheres; interior point methods for linear programming; MCMC; an expanded treatment of ODEs with completely new routines; and many new statistical distributions.},
pages = {245},
title = {Numerical Recipes: The Art of Scientific Computing},
annote = {OCLC: 212427139},
isbn = {978-0-511-33555-6},
issn = {00255572},
shorttitle = {Numerical recipes},
year = {1987},
number = {457},
booktitle = {The Mathematical Gazette},
}

@article{1996SchneiderNurb,
author = {P J Schneider},
pages = {1--11},
title = {NURB Curves: A Guide for the Uninitiated},
volume = {25},
year = {1996},
abstract = {The aim of this article is to give you an intuitive understanding of how NURB curves work. Later in the article, we'll look at some code to show you how you can start using NURB curves in your own programs -- but you really do need to understand the theory before you can start putting it to practical use. So please be patient while we slog through the mathematical concepts: I promise we'll get around to some actual programming before we're through. Note also that this article is only about NURB curves; perhaps a future article will cover NURB surfaces and how to use curves and surfaces together.},
journal = {develop, The Apple Technical Journal},
url = {http://digiitalarchfab.com/portal/wp-content/uploads/2011/03/Nurbs-Curve-A-Guide-for-the-Uninitiated.pdf},
keywords = {nurbs},
mendeley-tags = {nurbs},
}

@book{2014PirkleDesigning,
author = {Will Pirkle},
abstract = {Includes index. Synthesizer fundamentals -- Writing plug-ins -- MIDI -- Analog and digital signal processing -- Synthesizer oscillator design -- Envelope generators and controlled amplifiers -- Synthesizer filter design -- Modulation matrix, polyphony and global parametrization -- MiniSynth : analog modeling synth -- DigiSynth : sample playback synthesizer -- VectorSynth and AniSynth : vector synthesizers -- DXSynth : FM synthesizer -- Delay effects.},
publisher = {Routledge},
edition = {1 edition},
booktitle = {Focal Press},
year = {2014},
title = {Designing Software Synthesizer Plug-Ins in C++: For RackAFX, VST3, and Audio Units},
isbn = {978-1-138-78707-0},
volume = {3},
shorttitle = {Designing Software Synthesizer Plug-Ins in C++},
}

@article{1992EbdonIntroduction,
author = {J. R. Ebdon},
year = {1992},
doi = {10.1002/pi.4990270217},
number = {2},
issn = {09598103},
title = {Introduction to polymers (second edition) R. J. Young and P. A. Lovell Chapman and Hall, London, 1991. pp. 443, price \pounds16.95. ISBN 0-412-30640-9 (PB); ISBN 0–412–30630–1 (HB)},
pages = {207--208},
volume = {27},
journal = {Polymer International},
}

@book{1991YoungIntroduction,
author = {Charles E. Carraher Jr.},
booktitle = {Introduction to Polymer Chemistry},
isbn = {978-0-412-30630-3},
title = {Introduction to Polymers},
edition = {2nd ed},
publisher = {Chapman //\\\& Hall},
url = {https://www.amazon.com/Introduction-Polymers-Robert-J-Young/dp/0412306301?SubscriptionId=AKIAIOBINVZYXZQZ2U3A///////%5C%5C&tag=chimbori05-20///////%5C%5C&linkCode=xm2///////%5C%5C&camp=2025///////%5C%5C&creative=165953///////%5C%5C&creativeASIN=0412306301},
doi = {10.1201/b13684-7},
pages = {26--49},
year = {2020},
abstract = {Introduction to Polymers, Second Edition discusses the synthesis, characterization, structure, and mechanical properties of polymers in a single text, giving approximately equal emphasis to each of these major topics. It has thus been possible to show the interrelationship of the different aspects of the subject in a coherent framework. The book has been written to be self-contained, with most equations fully derived and critically discussed. It is supported by a large number of diagrams and micrographs and is fully referenced for more advanced reading. Problems have been supplied at the end of each chapter so that students can test their understanding and practice the manipulation of data.},
}

@book{2005TemamMathematical,
author = {Roger Temam and Alain Miranville},
doi = {10.1017/CBO9780511755422},
publisher = {Cambridge University Press},
title = {Mathematical modeling in continuum mechanics, second edition},
abstract = {Temam and Miranville present core topics within the general themes of fluid and solid mechanics. The brisk style allows the text to cover a wide range of topics including viscous flow, magnetohydrodynamics, atmospheric flows, shock equations, turbulence, nonlinear solid mechanics, solitons, and the nonlinear Schr\"odinger equation. This second edition will be a unique resource for those studying continuum mechanics at the advanced undergraduate and beginning graduate level whether in engineering, mathematics, physics or the applied sciences. Exercises and hints for solutions have been added to the majority of chapters, and the final part on solid mechanics has been substantially expanded. These additions have now made it appropriate for use as a textbook, but it also remains an ideal reference book for students and anyone interested in continuum mechanics.},
booktitle = {Mathematical Modeling in Continuum Mechanics, Second Edition},
volume = {9780521617239},
year = {2005},
pages = {1--342},
edition = {2 edition},
isbn = {9780511755422},
}

@book{2009NollJoint,
author = {Terrie Noll},
isbn = {155870633X},
url = {https://books.google.com/books/about/The_Joint_Book.html?id=Z7zZAAAAMAAJ},
title = {The joint book : the complete guide to wood joinery},
edition = {Edi\cc\~ao: Spi},
publisher = {Chartwell Books},
pages = {192},
shorttitle = {The Joint Book},
abstract = {"A Quarto book." Includes index. Aids to accuracy -- Designing joints -- Edge and scarf joints -- Lapped and housed joints -- Mortise-and-tenon -- Miters and bevels -- Dovetails -- Dowels and biscuits -- Fasteners, hardward, and knowdown joints.},
year = {2002},
}

@book{2018BoydIntroduction,
author = {Jessica Leung and Dmytro Matsypura},
edition = {1 edition},
title = {Introduction to Applied Linear Algebra: Vectors, Matrices, and Least Squares DRAFT},
year = {2020},
abstract = {This groundbreaking textbook combines straightforward explanations with a wealth of practical examples to offer an innovative approach to teaching linear algebra. Requiring no prior knowledge of the subject, it covers the aspects of linear algebra – vectors, matrices, and least squares – that are needed for engineering applications, discussing examples across data science, machine learning and artificial intelligence, signal and image processing, tomography, navigation, control, and finance. The numerous practical exercises throughout allow students to test their understanding and translate their knowledge into solving real-world problems, with lecture slides, additional computational exercises in Julia and MATLAB, and data sets accompanying the book online at https://web.stanford.edu//textasciitilde boyd/vmls/. Suitable for both one-semester and one-quarter courses, as well as self-study, this self-contained text provides beginning students with the foundation they need to progress to more advanced study.},
publisher = {Cambridge University Press},
shorttitle = {Introduction to Applied Linear Algebra},
}

@book{1999McclellandPsychological,
author = {David E. Rumelhart and  McClell and James L. },
title = {Psychological and Biological Models, Volume 2},
isbn = {0262631105, 9780262631105},
number = {Vol. 2},
series = {Parallel Distributed Processing. Explorations in the Microstructure of Cognition},
pages = {611},
year = {1986},
abstract = {What makes people smarter than computers? The work described in these two volumes suggests that the answer lies in the massively parallel architecture of the human mind. It is some of the most exciting work in cognitive science, unifying neural and cognitive processes in a highly computational framework, with links to artificial intelligence. Although thought and problem solving have a sequential character when viewed over a time frame of minutes or hours, the authors argue that each step in the sequence is the result of the simultaneous activity of a large number of simple computational elements, each influencing others and being influenced by them. "Parallel Distributed Processing" describes their work in developing a theoretical framework for describing this parallel distributed processing activity and in applying the framework to the development of models of aspects of perception, memory, language, and thought. Volume 2 applies to a number of specific issues in cognitive science and neuroscience. Some chapters describe models of aspects of perception, memory, language, and thought. Others discuss the relation between parallel distributed processing models and neurophysiology or describe models that are specifically addressed to neurophysiological data. The book concludes with an epilogue noting the strengths and weaknesses of the approach and directions for the future.},
annote = {OCLC: 248384622},
keywords = {memory},
mendeley-tags = {memory},
}

@book{1986RumelhartParallel,
author = {Timothy T. Rogers and  Mcclell and James L. },
pages = {1024--1077},
booktitle = {Cognitive Science},
publisher = {MIT Press},
series = {Computational models of cognition and perception},
title = {Parallel distributed processing at 25: Further explorations in the microstructure of cognition},
abstract = {This paper introduces a special issue of Cognitive Science initiated on the 25th anniversary of the publication of Parallel Distributed Processing (PDP), a two-volume work that introduced the use of neural network models as vehicles for understanding cognition. The collection surveys the core commitments of the PDP framework, the key issues the framework has addressed, and the debates the framework has spawned, and presents viewpoints on the current status of these issues. The articles focus on both historical roots and contemporary developments in learning, optimality theory, perception, memory, language, conceptual knowledge, cognitive control, and consciousness. Here we consider the approach more generally, reviewing the original motivations, the resulting framework, and the central tenets of the underlying theory. We then evaluate the impact of PDP both on the field at large and within specific subdomains of cognitive science and consider the current role of PDP models within the broader landscape of contemporary theoretical frameworks in cognitive science. Looking to the future, we consider the implications for cognitive science of the recent success of machine learning systems called "deep networks"-systems that build on key ideas presented in the PDP volumes. \textcopyright 2014 Cognitive Science Society, Inc.},
number = {6},
doi = {10.1111/cogs.12148},
shorttitle = {Parallel distributed processing},
isbn = {978-0-262-18120-4 978-0-262-13218-3},
issn = {03640213},
volume = {38},
year = {2014},
pmid = {25087578},
keywords = {cognition,cognitive control,connectionist models,language,learning,memory,neural networks,perception},
mendeley-tags = {cognition,cognitive control,connectionist models,language,learning,memory,neural networks,perception},
}

@book{2015DiezOpenintro,
author = {David M Diez and Christopher D Barr and Mine Cetinkaya-Rundel},
booktitle = {OpenIntro Statistics},
abstract = {Online Publication},
pages = {436},
pmid = {21899409},
issn = {1533-4406},
shorttitle = {OpenIntro Statistics},
isbn = {9781461062615},
edition = {3 edition},
publisher = {OpenIntro, Inc.},
volume = {1},
url = {openintro.org},
year = {2015},
title = {OpenIntro Statistics},
}

@inproceedings{2013PassonneauAutomated,
author = {Rebecca J. Passonneau and Emily Chent and Weiwei Guot and Dolores Perin},
isbn = {9781937284510},
title = {Automated pyramid scoring of summaries using distributional semantics},
url = {https://pennstate.pure.elsevier.com/en/publications/automated-pyramid-scoring-of-summaries-using-distributional-seman},
pages = {143--147},
volume = {2},
year = {2013},
abstract = {The pyramid method for content evaluation of automated summarizers produces scores that are shown to correlate well with manual scores used in educational assessment of students' summaries. This motivates the development of a more accurate automated method to compute pyramid scores. Of three methods tested here, the one that performs best relies on latent semantics. \textcopyright 2013 Association for Computational Linguistics.},
publisher = {Association for Computational Linguistics (ACL)},
booktitle = {ACL 2013 - 51st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
}

@book{noauthor_proceedings_2013,
booktitle = {ACL 2013 - 51st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
volume = {2},
title = {ACL 2013 - 51st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
url = {https://aclweb.org/anthology/P13-2000},
year = {2013},
isbn = {9781937284510},
}

@misc{farnum_review_nodate,
author = {Larissa Farnum},
url = {https://www.academia.edu/8924647/Review///////%5C%5C_of///////%5C%5C_differentiation///////%5C%5C_and///////%5C%5C_integration///////%5C%5C_rules///////%5C%5C_from///////%5C%5C_Calculus///////%5C%5C_I///////%5C%5C_and///////%5C%5C_II///////%5C%5C_for///////%5C%5C_Ordinary///////%5C%5C_Differential///////%5C%5C_Equations///////%5C%5C_3301},
abstract = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301},
pages = {2--3},
title = {Review of differentiation and integration rules from Calculus I and II for Ordinary Differential Equations, 3301 General Notation:},
volume = {2},
}

@reference{2019LearningStatistical,
author = {Harlley E. McKean},
pages = {841--842},
volume = {11},
booktitle = {Technometrics},
editor = {Learning, Hawkes},
url = {http://www.hawkeslearning.com/documents/statdatasets/stat///////%5C%5C_tables.pdf},
doi = {10.1080/00401706.1969.10490749},
year = {1969},
title = {Statistical Tables},
issn = {15372723},
number = {4},
}

@article{2011IlhanAdaptive,
author = {Taylan Lihan and Seyed M.R. Iravani and Mark S. Daskin},
abstract = {Given a set of items with associated deterministic weights and random rewards, the adaptive stochastic knapsack problem (adaptive SKP) maximizes the probability of reaching a predetermined target reward level when items are inserted sequentially into a capacitated knapsack before the reward of each item is realized. This model arises in resource allocation problems that permit or require sequential allocation decisions in a probabilistic setting. One particular application is in obsolescence inventory management. In this paper, the adaptive SKP is formulated as a dynamic programming (DP) problem for discrete random rewards. The paper also presents a heuristic that mixes adaptive and static policies to overcome the "curse of dimensionality" in the DP. The proposed heuristic is extended to problems with normally distributed random rewards. The heuristic can solve large problems quickly, and its solution always outperforms a static policy. The numerical study indicates that a near-optimal solution can be obtained by using an algorithm with limited look-ahead capabilities. \textcopyright 2011 INFORMS.},
title = {The adaptive knapsack problem with stochastic rewards},
volume = {59},
doi = {10.1287/opre.1100.0857},
journal = {Operations Research},
pages = {242--248},
year = {2011},
url = {http://users.iems.northwestern.edu//textasciitilde iravani/Stochastic///////%5C%5C_Knapsack.pdf},
number = {1},
issn = {0030364X},
keywords = {dynamic programming,sequential decision analysis},
mendeley-tags = {dynamic programming,sequential decision analysis},
}

@misc{PoczosIntroduction,
author = {Odysseas Pentakalos},
issn = {09521976},
booktitle = {Cmg Impact 2019},
title = {Introduction to machine learning},
doi = {10.4018/978-1-7998-0414-7.ch003},
year = {2019},
abstract = {Talked about what Machine Learning is - Reviewed some of the key problems machine learning solves - Reviewed some of the key algorithms - Looked at an example - Any Questions?.},
}

@article{KoernerVectors,
author = {T W K\"orner},
pages = {458},
title = {Vectors, Pure and Applied},
}

@book{2009StewartProbability,
author = {William J. Stewart},
year = {2009},
title = {Probability, Markov chains, queues, and simulation: The mathematical basis of performance modeling},
annote = {OCLC: ocn255018592},
abstract = {Probability, Markov Chains, Queues, and Simulationprovides a modern and authoritative treatment of the mathematical processes that underlie performance modeling. The detailed explanations of mathematical derivations and numerous illustrative examples make this textbook readily accessible to graduate and advanced undergraduate students taking courses in which stochastic processes play a fundamental role. The textbook is relevant to a wide variety of fields, including computer science, engineering, operations research, statistics, and mathematics.The textbook looks at the fundamentals of probability theory, from the basic concepts of set-based probability, through probability distributions, to bounds, limit theorems, and the laws of large numbers. Discrete and continuous-time Markov chains are analyzed from a theoretical and computational point of view. Topics include the Chapman-Kolmogorov equations; irreducibility; the potential, fundamental, and reachability matrices; random walk problems; reversibility; renewal processes; and the numerical computation of stationary and transient distributions. The M/M/1 queue and its extensions to more general birth-death processes are analyzed in detail, as are queues with phase-type arrival and service processes. The M/G/1 and G/M/1 queues are solved using embedded Markov chains; the busy period, residual service time, and priority scheduling are treated. Open and closed queueing networks are analyzed. The final part of the book addresses the mathematical basis of simulation.Each chapter of the textbook concludes with an extensive set of exercises. An instructor's solution manual, in which all exercises are completely worked out, is also available (to professors only).Numerous examples illuminate the mathematical theoriesCarefully detailed explanations of mathematical derivations guarantee a valuable pedagogical approachEach chapter concludes with an extensive set of exercisesProfessors: A supplementary Solutions Manual is available for this book. It is restricted to teachers using the text in courses. For information on how to obtain a copy, refer to:http://press.princeton.edu/class_use/solutions.html. \textcopyright 2009 by Princeton University Press. All Rights Reserved.},
booktitle = {Probability, Markov Chains, Queues, and Simulation: The Mathematical Basis of Performance Modeling},
shorttitle = {Probability, Markov chains, queues, and simulation},
publisher = {Princeton University Press},
isbn = {9780691140629},
keywords = {computer simulation,markov processes,probabilities,queuing theory},
mendeley-tags = {computer simulation,markov processes,probabilities,queuing theory},
}

@article{2014FowlerSequences,
author = {Nets Hawk Katz},
pages = {46--79},
year = {2020},
title = {Sequences and Series},
journal = {Calculus for Cranks},
doi = {10.2307/j.ctv1b9f4xt.5},
}

@book{2016PinedoScheduling,
author = {Michael Pinedo},
title = {Scheduling: theory, algorithms, and systems},
publisher = {Springer},
annote = {OCLC: 945375528},
shorttitle = {Scheduling},
isbn = {978-3-319-26578-0 978-3-319-26580-3},
edition = {Fifth Edition},
keywords = {production scheduling},
mendeley-tags = {production scheduling},
}

@book{2004BruceMastering,
author = {Robert Bruce and Brian Mercer},
abstract = {1st ed. Accompanying CD-ROM has 25 custom-designed trance meditation sound programs, including: daily affirmation sound files in MP3 and .WAV formats; Mastering astral projection version of the BrainWave generator shareware program; Adobe Reader version of Robert Bruce's New energy ways tutorial; dream journal template in Microsoft Word and RTF formats; Sleep programming sound files in MP3 and .WAV formats.},
title = {Mastering astral projection : 90-day guide to out-of-body experience},
edition = {1st ed},
isbn = {0738704679},
pages = {483},
publisher = {Llewellyn},
shorttitle = {Mastering astral projection},
year = {2004},
keywords = {astral projection},
mendeley-tags = {astral projection},
}

@article{2015LermanPatent,
author = {Celia Lerman},
issn = {1556-5068},
abstract = {How does a patent strategy affect a tech startup company's growth? This is a fundamental question for technology entrepreneurs, investors, lawyers and the innovation system as a whole. In this study, I shed light on this issue by conducting an empirical analysis of the patenting strategies of technology startups, examining the relationship between a company's patent applications and different events over the company's life: rounds of investment received, company acquisition and closure. I provide the first comprehensive cross-industry analysis of this question, by analyzing the patent portfolios of United States startups listed in CrunchBase, a crowd-sourced registry of tech companies used by the startup industry. By looking into these companies' public patent applications from the United States Patent and Trademark Office (USPTO) database between 2008 and 2012, I examine the patenting patterns of startups as they progress through funding rounds.  Through a quantitative analysis, I find that companies based in California tend to patent more than in other states, and that companies that are venture-backed patent more than those who are not. I also unveil that most start-ups that patent file their first application before even receiving any reported funding. Moreover, I find that there is a significant positive relationship between patent protection, and receiving investment and being acquired. I further find that the number of patents (and not merely the fact that a company has patents or not) contributes to higher total funding. I finally observe that patenting early is also associated to higher funding, and that early may be more important for start-ups than what some views in venture capital may predict. I also conclude that while more patents are associated with higher funding, patents account for a relevant but small portion of a company's success.  The study provides novel insights on startup patenting strategies. It lays empirical groundwork on key circumstances under which patents can contribute to a startup's growth, to provide important guidance to the legal and entrepreneurial communities. },
year = {2015},
title = {Patent Strategies of Technology Startups: An Empirical Study},
url = {http://www.ssrn.com/abstract=2610433},
shorttitle = {Patent Strategies of Technology Startups},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2610433},
}

@book{2018NiederstRobbinsLearning,
author = {Jennifer Niederst Robbins},
number = {12},
doi = {10.5860/choice.50-6805},
booktitle = {Choice Reviews Online},
pages = {50--6805--50--6805},
shorttitle = {Learning Web Design},
title = {Learning web design: a beginner's guide to HTML, CSS, Javascript, and web graphics},
volume = {50},
edition = {Fifth Edition},
issn = {0009-4978},
year = {2013},
abstract = {50-6805 TK5105 MARC Niederst Robbins, Jennifer. Learning web design: a beginner's guide to HTML, CSS, Javascript, and web graphics. 4th ed. O'Reilly, 2012. 602p index ISBN 1449319270 pbk, 49.99 ISBN 9781449319274 pbk, 49.99},
publisher = {O'Reilly},
isbn = {978-1-4919-6020-2},
keywords = {authoring programs,cascading style sheets,computer graphics,design,etc,handbooks,html (document markup language,javascript (computer program language,manuals,web sites},
mendeley-tags = {authoring programs,cascading style sheets,computer graphics,design,etc,handbooks,html (document markup language,javascript (computer program language,manuals,web sites},
}

@book{2012DegrootProbability,
author = {Peeyush Taori and Soumithri Mamidipudi and Deepak Agrawal},
doi = {10.1007/978-3-319-68837-4_30},
title = {Probability and Statistics},
publisher = {Addison-Wesley},
annote = {OCLC: ocn502674206},
isbn = {978-0-321-50046-5},
abstract = {This chapter is aimed at introducing and explaining some basic concepts of statistics and probability in order to aid the reader in understanding some of the more advanced concepts presented in the main text of the book. The main topics that are discussed are set theory, permutations and combinations, discrete and continuous probability distributions, descriptive statistics, and bivariate distributions.},
issn = {08848289},
pages = {945--963},
edition = {4th ed},
volume = {264},
year = {2019},
booktitle = {International Series in Operations Research and Management Science},
keywords = {mathematical statistics,probabilities,textbooks},
mendeley-tags = {mathematical statistics,probabilities,textbooks},
}

@book{2018ShoresApplied,
author = {Thomas S Shores},
doi = {10.5860/choice.44-5698},
pages = {44--5698--44--5698},
issn = {0009-4978},
number = {10},
isbn = {978-3-319-74747-7},
booktitle = {Choice Reviews Online},
abstract = {applicability for this approach.},
series = {Undergraduate Texts in Mathematics},
publisher = {Springer International Publishing},
title = {Applied linear algebra and matrix analysis},
volume = {44},
year = {2007},
}

@book{2012GreeneEconometric,
author = {William H Greene},
edition = {7th ed},
pages = {317--366},
publisher = {Prentice Hall},
year = {2005},
title = {Econometric analysis},
doi = {10.1007/3-7908-1599-3_5},
isbn = {978-0-13-139538-1},
annote = {OCLC: ocn692292382},
booktitle = {Contributions to Management Science},
issn = {2197716X},
keywords = {brand equity,european patent office,intangible asset,operating profit,world intellectual property organisation},
mendeley-tags = {brand equity,european patent office,intangible asset,operating profit,world intellectual property organisation},
}

@book{2018ImanishiSynthesis,
author = {Yoshihiro Ito},
year = {2018},
doi = {10.1201/9781351077064},
isbn = {0849367719},
edition = {1},
abstract = {Cell adhesion is a ubiquitous process that influences many aspects of cell behavior. At low concentrations of hyaluroic acid, the collagen fibers were not fully coated, and areas of both hyaluroic acid and collagen were available for cell adhesion, either directly or through any mediating protein. Vitronectin (VN) is of interest because of its roles in cell adhesion and spreading, in coagulation, in complement activation, and in three important aspects of artificial surface induced thrombosis. The RGD-BSA conjugates were used to coat tissue culture plastic surfaces which then served as substrata in cell adhesion experiments. The surfaces of solvent-cast films of this polymer were analyzed by X-ray photoelectron spectroscopy by which surface chemical composition was quantitatively measured at the outermost layer of several tenths of angstroms, which determines biological responses including cell adhesion and growth.},
editor = {Imanishi, Yukio},
publisher = {CRC Press},
shorttitle = {Synthesis of Biocomposite Materials},
url = {https://www.taylorfrancis.com/books/9781351085519},
booktitle = {Synthesis of Biocomposite Materials: Chemical and Biological Modifications of Natural Polymers},
pages = {245--284},
title = {Cell adhesion factor immobilized Materials},
}

@book{2003Buss3d,
author = {Samuel R. Buss},
publisher = {Cambridge University Press},
year = {2009},
number = {3},
doi = {10.1111/j.1949-8594.2009.tb17955.x},
title = {3 - D Computer Graphics: A Mathematical Introduction with OpenGL},
booktitle = {School Science and Mathematics},
volume = {109},
abstract = {The article reviews the book "3 - D Computer Graphics: A Mathematical Introduction With OpenGL," by Samuel R. Buss.},
issn = {0036-6803},
shorttitle = {3D Computer Graphics},
edition = {1 edition},
isbn = {978-0-521-82103-2},
pages = {183--184},
}

@book{2016GeorgeMastering,
author = {Nigel George},
shorttitle = {Mastering Django},
title = {Mastering Django: Core},
isbn = {978-1-78728-114-1},
publisher = {Packt Publishing},
}

@book{2014ChaconPro,
author = {Scott Chacon and Ben Straub},
title = {Pro Git},
booktitle = {Pro Git},
year = {2014},
edition = {2nd ed. edition},
isbn = {978-1-4842-0077-3},
doi = {10.1007/978-1-4842-0076-6},
publisher = {Apress},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
}

@book{2013PavlinaAstral,
author = {Erin Pavlina},
shorttitle = {The Astral Projection Guidebook},
title = {Astral Projection Guidebook Mastering the Art of Astral Travel by Erin Pavlina},
publisher = {CreateSpace Independent Publishing Platform},
abstract = {Learn to Master Astral Travel Would you like to walk through walls, fly around the world, reconnect with deceased loved ones, and explore time and space? Have you had a terrifying out of body encounter that left you fearful of ever exploring astral projection? Would you like to know how to travel the astral realms safely and protect yourself from unwanted projections? Whether you are a novice or an experienced astral traveler, the Astral Projection Guidebook will teach you how to master astral projection safely and effectively. In this guide, you'll learn how to: • Prepare yourself for a positive astral journey • Achieve separation from your body • Explore the astral realms – alone or with friends • Enjoy mind-blowing astral sex • Protect yourself from dark entities • Train to become an astral warrior Get ready to have fun exploring the astral realms!},
isbn = {978-1-4912-4697-9},
edition = {1 edition},
}

@book{2012BruceAstral,
author = {Robert Bruce},
abstract = {This is the fabulous FIRST EDITION of Astral DynamicsThe first edition of Astral Dynamics (the book you are now reading about) contains a great deal of content that was dropped from the 2009 second edition to save space. These are essentially two quite different books. Most people want both these amazing books, so we convinced Robert Bruce to produce an eBook version of the original First Edition of Astral Dynamics, with full color illustrations and other improvements. This First Edition went out of print in 2009. THE FIRST EDITION OF ASTRAL DYNAMICS - In one fascinating volume, Robert Bruce gathered together a personal narrative, a "how-to", a troubleshooting guide, and a theoretical perspective on the nonphysical structure underlying the strange and multidimensional life we all lead. Whether you are a skeptic, a veteran astral projector, a newbie, or an armchair traveler, there's treasure here. It's in a class by itself. What he says here rings true. In fact, it does a lot more than ring true. It opens doors. Astral Dynamics provides the intelligent and motivated reader with everything needed to put theory into practice. The book's six parts may be read each on their own, but they have been placed to build nicely one upon the other. Part One, "Elements of Projection", presents Robert's theory of what actually goes on when the projectable astral double leaves the physical body. This in itself, right out of the gate, is fascinating terrain. His theory of the consequences of the mind-split that results from projection is itself worth the price of the book. Part Two, "NEW Energy Ways", presents his stunningly practical method of raising energy and awareness by using touch, which he calls Tactile Imaging. I have tried this method on half a dozen people, selected more or less at random, each of whom obtained the desired awareness within seconds! And then, as if the new method of visualization weren't enough, Robert proceeds to describe the nature and anatomy of our energy bodies, a description firmly rooted in his own personal explorations. Part Three, "Core Skills", builds on this foundation, demonstrating how to succeed at the three tasks that are essential to success in astral projection: deep physical relaxation, taming the mind, and attaining the trance state. Part Four, "Projection Exit and Technique", tells you what you need to know to stop reading about astral projection and actually do it. Part Five, "The Akashic Connection", proceeds into the realm of the theoretical, not for the sake of getting lost in theory, but in order to make sense of things seen and heard. Particularly interesting is Robert's description of the nature and meaning of what he calls the Akashic Pulse. As to his description and analysis of the astral planes, the silver cord, the etheric body, and the Akashic record — I doubt that these have been equaled anywhere in the subject's extensive modern literature. I am confident that they have not been excelled. Part Six, "Strange Astral Phenomena", takes on a few conundrums that are worth exploring. Projection into higher realms; reality fluctuations; astral noise; what Robert calls astral wildlife, and astral combat... he covers the turf as it hasn't been covered to date. And he does it so casually, in so unpretentious a manner, his mood ranging from deepest awe to casually joking, with all the range between. If you have any interest at all in the subject of astral projection, lucid dreaming — higher consciousness in general — you're going to love this book. I predict that it will become a classic, read and valued for many years to come. Frank DeMarco - Chairman, Hampton Roads Publishing Company, Inc., VA.About the Author:Robert Bruce is the author of six groundbreaking books exploring such mysteries as the human energy body, the out-of-body experience, Kundalini, mind's-eye vision, spiritual and psychic development, metaphysics, clairvoyance, and psychi},
title = {Astral Dynamics: A NEW Approach to Out-of-Body Experience},
shorttitle = {Astral Dynamics},
edition = {Edi\cc\~ao: 1.1},
publisher = {Magic Light Press},
}

@book{1999KostekSoft,
author = {Bozena Kostek},
series = {Studies in Fuzziness and Soft Computing},
isbn = {9783790818758},
pages = {254},
abstract = {Applications of some selected soft computing methods to acoustics and sound engineering are presented in this book. The aim of this research study is the implementation of soft computing methods to musical signal analysis and to the recognition of musical sounds and phrases. Accordingly, some methods based on such learning algorithms as neural networks, rough sets and fuzzy-logic were conceived, implemented and tested. Additionally, the above-mentioned methods were applied to the analysis and verification of subjective testing results. The last problem discussed within the framework of this book was the problem of fuzzy control of the classical pipe organ instrument. The obtained results show that computational intelligence and soft computing may be used for solving some vital problems in both musical and architectural acoustics.},
booktitle = {Studies in Fuzziness and Soft Computing},
title = {Soft Computing in Acoustics: Applications of Neural Networks, Fuzzy Logic and Rough Sets to Musical Acoustics},
url = {http://link.springer.com/content/pdf/10.1007/978-3-7908-1774-4.pdf%5Cnhttp://link.springer.com/book/10.1007/978-3-7908-1875-8/page/1},
publisher = {Physica-Verlag Heidelberg},
shorttitle = {Soft Computing in Acoustics},
year = {1999},
}

@book{2017DangetiStatistics,
author = {Pratap Dangeti},
year = {2017},
isbn = {9781788295758},
booktitle = {Packt Publishing},
publisher = {Packt Publishing},
title = {Statistics for Machine Learning: Techniques for exploring supervised, unsupervised, and reinforcement learning models with Python and R},
abstract = {Key FeaturesLearn about the statistics behind powerful predictive models with p-value, ANOVA, and F- statistics.Implement statistical computations programmatically for supervised and unsupervised learning through K-means clustering.Master the statistical aspect of Machine Learning with the help of this example-rich guide to R and Python.Book DescriptionComplex statistics in Machine Learning worry a lot of developers. Knowing statistics helps you build strong Machine Learning models that are optimized for a given problem statement. This book will teach you all it takes to perform complex statistical computations required for Machine Learning. You will gain information on statistics behind supervised learning, unsupervised learning, reinforcement learning, and more. Understand the real-world examples that discuss the statistical side of Machine Learning and familiarize yourself with it. You will also design programs for performing tasks such as model, parameter fitting, regression, classification, density collection, and more.By the end of the book, you will have mastered the required statistics for Machine Learning and will be able to apply your new skills to any sort of industry problem.What you will learnUnderstand the Statistical and Machine Learning fundamentals necessary to build modelsUnderstand the major differences and parallels between the statistical way and the Machine Learning way to solve problemsLearn how to prepare data and feed models by using the appropriate Machine Learning algorithms from the more-than-adequate R and Python packagesAnalyze the results and tune the model appropriately to your own predictive goalsUnderstand the concepts of required statistics for Machine LearningIntroduce yourself to necessary fundamentals required for building supervised & unsupervised deep learning modelsLearn reinforcement learning and its application in the field of artificial intelligence domainAbout the AuthorPratap Dangeti develops machine learning and deep learning solutions for structured, image, and text data at TCS, analytics and insights, innovation lab in Bangalore. He has acquired a lot of experience in both analytics and data science. He received his master's degree from IIT Bombay in its industrial engineering and operations research program. He is an artificial intelligence enthusiast. When not working, he likes to read about next-gen technologies and innovative methodologies.Table of ContentsJourney from Statistics to Machine LearningPa\ldots},
shorttitle = {Statistics for Machine Learning},
pages = {442 / 438},
}

@book{2017BarrosFirst,
author = {La\'ecio Carvalho de Barros and Rodney Carlos Bassanezi and Weldon Alex Lodwick and  er},
title = {A First Course in Fuzzy Logic, Fuzzy Dynamical Systems, and Biomathematics},
url = {http://link.springer.com/10.1007/978-3-662-53324-6},
publisher = {Springer Berlin Heidelberg},
abstract = {LaVela SL, Evans CT, Prohaska TR, Miskevics S, Ganesh SP, Weaver FM. Males aging with a spinal cord injury: prevalence of cardiovascular and metabolic conditions. Arch Phys Med Rehabil 2012;93:90-5. Objective: To compare the prevalence of cardiovascular and metabolic conditions in male veterans aging with spinal cord injury (SCI) with that of older men comparison groups. Design: Cross-sectional survey. Setting: National community dwelling. Participants: Men 65 years and older (veterans with SCI [n=794] injured at least 20y, veterans [n=13,528], and general population [n=6105]). Interventions: Not applicable. Main Outcome Measures: Prevalence of diabetes, myocardial infarction (MI), stroke, and coronary heart disease (CHD). Results: In older adult men with SCI, prevalences of diabetes, MI, stroke, and CHD were 20.30%, 18.70%, 9.84%, and 15.47%, respectively. The odds for stroke were 1.4 times higher in veterans with SCI than general veterans (P <.05), and there was a trend to higher odds for stroke in men with SCI than in the general population (P=.06). The odds for CHD were significantly lower for veterans with SCI than both comparison groups. Being a past smoker was associated with greater odds for diabetes, MI, and CHD, and being a current smoker was associated with higher odds for stroke. High blood pressure and high cholesterol levels were associated with higher odds for all conditions examined. Conclusions: Diabetes and MI were most prevalent in older adults, but the presence was similar in men with SCI (vs other men). In older adult men, SCI appeared to be protective of CHD. Stroke was most prevalent in veterans with SCI, and controlling for demographic and risk factors, SCI was associated independently with stroke. These findings may be useful for prioritizing preventive health strategies and planning long-term care for men aging with SCI.},
volume = {347},
pages = {23--42},
isbn = {978-3-662-53322-2},
series = {Studies in Fuzziness and Soft Computing},
doi = {10.1007/978-3-662-53324-6},
year = {2017},
}

@book{2016ArgueellesMendezPractical,
author = {Luis Arg\"uelles M\'endez},
year = {2015},
doi = {10.1007/978-3-319-23186-0},
publisher = {Springer International Publishing},
isbn = {9783319231860},
series = {Studies in Fuzziness and Soft Computing},
abstract = {This book makes use of the LISP programming language to provide readers with the necessary background to understand and use fuzzy logic to solve simple to medium-complexity real-world problems. It introduces the basics of LISP required to use a Fuzzy LISP programming toolbox, which was specifically implemented by the author to "teach" the theory behind fuzzy logic and at the same time equip readers to use their newly-acquired knowledge to build fuzzy models of increasing complexity. The book fills an important gap in the literature, providing readers with a practice-oriented reference guide to fuzzy logic that offers more complexity than popular books yet is more accessible than other mathematical treatises on the topic. As such, students in first-year university courses with a basic tertiary mathematical background and no previous experience with programming should be able to easily follow the content. The book is intended for students and professionals in the fields of computer science and engineering, as well as disciplines including astronomy, biology, medicine and earth sciences. Software developers may also benefit from this book, which is intended as both an introductory textbook and self-study reference guide to fuzzy logic and its applications. The complete set of functions that make up the Fuzzy LISP programming toolbox can be downloaded from a companion book's website.},
pages = {1--370},
booktitle = {A Practical Introduction to Fuzzy Logic using LISP},
volume = {327},
title = {A practical introduction to Fuzzy logic using LISP},
}

@collection{2015TamirFifty,
author = {Christian Borgelt and Christian Braune and Marie Jeanne Lesot and Rudolf Kruse},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84930225797&partnerID=tZOtx3y1},
volume = {326},
issn = {14349922},
number = {326},
abstract = {Since it is an unsupervised data analysis approach, clustering relies solely on the location of the data points in the data space or, alternatively, on their relative distances or similarities. As a consequence, clustering can suffer from the presence of noisy data points and outliers,which can obscure the structure of the clusters in the data and thus may drive clustering algorithms to yield suboptimal or even misleading results. Fuzzy clustering is no exception in this respect, although it features an aspect of robustness, due to which outliers and generally data points that are atypical for the clusters in the data have a lesser influence on the cluster parameters. Starting from this aspect, we provide in this paper an overview of different approaches with which fuzzy clustering can be made less sensitive to noise and outliers and categorize them according to the component of standard fuzzy clustering they modify.},
publisher = {Springer},
year = {2015},
pages = {315--335},
title = {Fifty Years of Fuzzy Logic and its Applications},
annote = {OCLC: 908374518},
editor = {Tamir, Dan E and Rishe, Naphtali D and Kandel, Abraham},
booktitle = {Studies in Fuzziness and Soft Computing},
isbn = {978-3-319-19682-4},
series = {Studies in fuzziness and soft computing},
keywords = {fuzzy set theory},
mendeley-tags = {fuzzy set theory},
}

@book{2008RossFuzzy,
author = {Timothy J. Ross},
doi = {10.1002/9781119994374},
booktitle = {Fuzzy Logic with Engineering Applications: Third Edition},
publisher = {Wiley},
title = {Fuzzy Logic with Engineering Applications},
year = {2010},
abstract = {The first edition of Fuzzy Logic with Engineering Applications (1995) was the first classroom text for undergraduates in the field. Now updated for the second time, this new edition features the latest advances in the field including material on expansion of the MLFE method using genetic algorithms, cognitive mapping, fuzzy agent-based models and total uncertainty. Redundant or obsolete topics have been removed, resulting in a more concise yet inclusive text that will ensure the book retains its broad appeal at the forefront of the literature. Fuzzy Logic with Engineering Applications, 3rd Edition is oriented mainly towards methods and techniques. Every chapter has been revised, featuring new illustrations and examples throughout. Supporting MATLAB code is downloadable at www.wileyeurope.com/go/fuzzylogic. This will benefit student learning in all basic operations, the generation of membership functions, and the specialized applications in the latter chapters of the book, providing an invaluable tool for students as well as for self-study by practicing engineers. \textcopyright 2010 John Wiley & Sons, Ltd.},
isbn = {9780470743768},
edition = {2 edition},
}

@book{2002MoravcsikMusical,
author = {Michael J Moravcsik},
year = {2001},
publisher = {Kluwer Acad./Plenum},
isbn = {9780306467103},
abstract = {This text has been out of print since 1990; it was originally published by Solomon Press in 1987. Several experts in the field have verified that the information in the book remains constant; nothing has, or will, change in the basic science of musical sound. It explains the science of musical sound without the encumbrance of detailed mathematics. It will appeal to music lovers as well as students of music and students of physics. It can easily be promoted with our physics program.},
annote = {OCLC: 248884612},
shorttitle = {Musical sound},
title = {Musical sound: an introduction to the physics of music},
keywords = {history / general,music,music / general,music / history & criticism,political science / history & theory,science / acoustics & sound,science / physics,social science / reference,sound},
mendeley-tags = {history / general,music,music / general,music / history & criticism,political science / history & theory,science / acoustics & sound,science / physics,social science / reference,sound},
}

@article{1983McintyreOscillations,
author = {M. E. McIntyre and R. T. Schumacher and J. Woodhouse},
journal = {Journal of the Acoustical Society of America},
volume = {74},
doi = {10.1121/1.390157},
title = {On the oscillations of musical instruments},
abstract = {The time-domain description of musical and other nonlinear oscillators complements the more commonly used frequency-domain description, and is advantageous for some purposes. It is especially advantageous when studying large-amplitude oscillations, for which nonlinearity may be severe. It gives direct insight into the physical reasons for the variation of waveform as playing conditions vary, and into certain phenomena which may seem counter-intuitive from the frequency-domain viewpoint, such as the musically undesirable flattening in the pitch of a bowed string when the bow is pressed too hard onto the string. It is easy to set up efficient time-domain simulations on a small computer, a fact that has been surprisingly little exploited in musical acoustics. The simplest relevant model is described here. It demonstrates some of the basic nonlinear behavior of the clarinet, violin, and flute families with very little programming effort. Remarkably, a single set of model equations has relevance to all three cases, at a certain level of idealization, with appropriate choices of parameter values and of linear and nonlinear characteristics. For the flute family, this simplest model gives waveforms and phase relations closely resembling those observed at resonance in the organ-pipe experiments of Coltman [J. Acoust. Soc. Am. 60, 725–733 (1976)], including the triangular pressure and velocity waveforms. It can be shown (again using a time-domain approach) that the triangular waveform is a universal limiting form, independent of detailed acoustic loss mechanisms provided losses are small. \textcopyright 1983, Acoustical Society of America. All rights reserved.},
pages = {1325--1345},
year = {1983},
number = {5},
issn = {NA},
}

@article{1998KarjalainenPlucked,
author = {Matti Karjalainen and Vesa V\"alim\"aki and Tero Tolonen},
number = {3},
pages = {17--32},
year = {1998},
issn = {01489267},
journal = {Computer Music Journal},
shorttitle = {Plucked-String Models},
title = {Plucked-String Models: From the Karplus-Strong Algorithm to Digital Waveguides and Beyond},
url = {https://www.jstor.org/stable/3681155?origin=crossref},
doi = {10.2307/3681155},
volume = {22},
}

@book{2011VeselicDamped,
author = {Kre\vsimir Veseli\'c},
abstract = {"The theory of linear damped oscillations was originally developed more than hundred years ago and is still of vital research interest to engineers, mathematicians and physicists alike. This theory plays a central role in explaining the stability of mechanical structures in civil engineering, but it also has applications in other fields such as electrical network systems and quantum mechanics. This volume gives an introduction to linear finite dimensional damped systems as they are viewed by an applied mathematician. After a short overview of the physical principles leading to the linear systems model, a largely self-contained mathematical theory for this model is presented. this includes the geometry of the underlying indefinite eigenvalue problem. Particular attention is paid to the sensitivity issues which influence numerical computations. finally, several recent research developments are included, e.g. Lyapunov stability and the perturbation of the time evolution."--P. [4] of cover},
pages = {1--226},
annote = {OCLC: ocn747814290},
issn = {00758434},
doi = {10.1007/978-3-642-21335-9_1},
isbn = {9783642213342},
publisher = {Springer},
booktitle = {Lecture Notes in Mathematics},
shorttitle = {Damped oscillations of linear systems},
title = {Damped oscillations of linear systems: A mathematical introduction},
series = {Lecture notes in mathematics},
year = {2011},
volume = {2023},
number = {2023},
keywords = {harmonic oscillators,linear systems,textbooks},
mendeley-tags = {harmonic oscillators,linear systems,textbooks},
}

@article{Waves,
author = { Chaudhuri},
title = {Waves and Oscillations, Second Edition},
pages = {394},
}

@book{2009CorduneanuAlmost,
author = {Constantin Corduneanu},
annote = {OCLC: ocn248978163},
year = {2009},
pages = {1--308},
abstract = {This text is well designed with respect to the exposition from the preliminary to the more advanced and the applications interwoven throughout. It provides the essential foundations for the theory as well as the basic facts relating to almost periodicity. In six structured and self-contained chapters, the author unifies the treatment of various classes of almost periodic functions, while uniquely addressing oscillations and waves in the almost periodic case. The first half of the book lays the groundwork, noting the basic properties of almost periodic functions, while the second half of this work addresses applications whose main emphasis is on the solvability of ordinary or partial differential equations in the class of almost periodic functions. Key topics include: An introduction to metric spaces; Definition of several classes of almost periodic functions, including those of Bohr, Besicovitch, and Stepanov; Classical results on the mean value property; Convergence of Fourier series to any almost periodic function; Almost periodic solutions for ODEs in a linear setting; Almost periodic nonlinear oscillations; Almost periodic waves, including heat waves. The reader is taken from elementary and well-known facts through the latest results in almost periodic oscillation and waves. This is the first text to present these latest results. The presentation level and inclusion of several clearly presented proofs make this work ideal for graduate students in engineering and science. The concept of almost periodicity is widely applicable to continuuum mechanics, electromagnetic theory, plasma physics, dynamical systems, and astronomy, which makes the book a useful tool for mathematicians and physicists. \textcopyright Springer Science+Business Media, LLC 2009. All rights reserved.},
booktitle = {Almost Periodic Oscillations and Waves},
publisher = {Springer},
title = {Almost periodic oscillations and waves},
doi = {10.1007/978-0-387-09819-7},
isbn = {9780387098180},
keywords = {almost periodic functions,differential equations,oscillation theory,oscillations},
mendeley-tags = {almost periodic functions,differential equations,oscillation theory,oscillations},
}

@book{2001AnfilovPhysics,
author = {Robert E. Kelly},
number = {2},
booktitle = {The Physics Teacher},
doi = {10.1119/1.2340459},
issn = {0031-921X},
title = {Physics and music},
year = {1980},
abstract = {From the primitive reed pipe to modern music "written" by computers is quite a journey. Here, in informal text and about a score of plates, is a story that takes the teenage layman on this interesting trip. The younger reader, like a good musicologist, follows the steps in the evolution of the most important instruments that make up today's symphony orchestra, and the development of music itself (scales, modes, keys, and temperaments). Physics and music is also a source, although, of necessity a modest one, of information about the music research that has been underway in the Soviet Union, especially in the scientific manufacture of the violin, and in electrophonic and synthetic music. This why the foreign reader might think of a degree of "bias" on the part of the author. Yet, it gives him an insight into what is going on in a country that has given the world quite a number of great composers.},
volume = {18},
publisher = {University Press of the Pacific},
isbn = {978-0-89875-419-3},
pages = {164--166},
translator = {Kuznetsov, Boris},
}

@book{2010FletcherPhysics,
author = {S. Schwerman and N. Fletcher and T. Rossing},
abstract = {The Physics of Music and Color deals with two subjects, music and\ncolor - sound and light in the physically objective sense - in a\nsingle volume. The basic underlying physical principles of the two\nsubjects overlap greatly: both music and color are manifestations\nof wave phenomena, and commonalities exist as to the production,\ntransmission, and detection of sound and light. This book aids readers\nin studying both subjects, which involve nearly the entire gamut\nof the fundamental laws of classical as well as modern physics. Where\ntraditional introductory physics and courses are styled so that the\nbasic principles are introduced first and are then applied wherever\npossible, this book is based on a motivational approach: it introduces\na subject by demonstrating a set of related phenomena, challenging\nreaders by calling for a physical basis for what is observed. The\nbook is based upon a course on the physics of music and color that\nhas been taught at Tufts University since 1973, when the course was\nintroduced by Gary Goldstein and the author.\n\nTopics that are unusual for a book at this level and breadth include:\na detailed non-mathematical summary of the principles of electricity\nand magnetism with the goal of understanding the basis for various\naudio devices as well as the physical essence of light and how it\npropagates as a wave; extensive details on the calculation of color\ncoordinates from a spectral intensity with different choices of primaries;\nthe relationship between color coordinates on a computer and the\ncolor seen on a monitor. References to recent developments include\nthe connection between the blueness of the ocean and the psycho-acoustic\nperception of combination tones in a sound wave. A major goal is\nto provide an understanding of basic principles, both conceptual\nand quantitative, that will allow the reader to have increased awareness\nof audial and visual experiences and to understand phenomena not\ndiscussed in the book.\n\nThe Physics of Music and Color is written at a level suitable for\ncollege students without any scientific background, requiring only\nsimple algebra and a passing familiarity with trigonometry. It contains\nnumerous problems at the end of each chapter that help the reader\nto fully grasp the subject. The book can also serve as a reference\nof basic principles for those involved in sound production and color\nmanagement.},
publisher = {Springer},
doi = {10.2307/3680451},
annote = {OCLC: 780101082},
isbn = {978-1-4419-3120-7 978-0-387-21603-4},
edition = {2. ed., [Nachdr.]},
issn = {01489267},
booktitle = {Computer Music Journal},
number = {2},
pages = {106},
volume = {18},
year = {1994},
title = {The Physics of Musical Instruments},
}

@thesis{2004DavidssonStructure,
author = {Peter Davidsson},
year = {2004},
annote = {OCLC: 186476406},
institution = {Univ.},
abstract = {This thesis investigates structure-acoustic systems by use of finite element analysis. The systems studied here are limited to those that consist of an enclosed acoustic fluid cavity, which is coupled to a flexible structure and/or a porous sound absorbing material domain.},
type = {phdthesis},
url = {https://lup.lub.lu.se/search/publication/bdffc3e3-1b12-4b27-8483-01848d7d9fa5},
booktitle = {Bibliography of Papers},
pages = {180},
isbn = {916286176X},
title = {Structure-acoustic analysis; finite element modelling and reduction methods},
shorttitle = {Structure-acoustic analysis},
keywords = {akustik,building acoustics,finite element analysis,hydraulics,hydraulik,lightweight structures,low frequency range,maskinteknik,mechanical engineering,modal reduction,porous materials,structural acoustics,structural dynamics,substructuring,vacuum technology,vakuumteknik,vibration and acoustic engineering,vibrationer,vibroacoustics},
mendeley-tags = {akustik,building acoustics,finite element analysis,hydraulics,hydraulik,lightweight structures,low frequency range,maskinteknik,mechanical engineering,modal reduction,porous materials,structural acoustics,structural dynamics,substructuring,vacuum technology,vakuumteknik,vibration and acoustic engineering,vibrationer,vibroacoustics},
}

@article{1996HainesDetermination,
author = {D. W. Haines and J. M. Leban and C. Herb\'e},
journal = {Wood Science and Technology},
number = {4},
volume = {30},
title = {Determination of Young's modulus for spruce, fir and isotropic materials by the resonance flexure method with comparisons to static flexure and other dynamic methods},
pages = {253--263},
issn = {00437719},
doi = {10.1007/bf00229348},
year = {1996},
abstract = {Dynamic methods provide rapid and accurate means to determine Young's modulus. i.e. the modulus of elasticity, of wood. For dry, dear specimens of \'epic\'ea commun (Norway spruce, picea excelsa) and sapin pictin\'e (silver fir, abics ambailis) we present a comparison of results from tests by a resonance flexure method with results obtained from four-point static flexure tests. For a wide range of specimen size the resonance flexure method provides a simpler, more rapidly performed alternative to the classical static flexure method, giving Young's modulus values which are for the spruce and fir specimens of this study, nearly identical to those calculated from the static flexure tests. Results are also presented which show that a resonance longitudinal method yields higher values of Young's modulus and an ultrasonic method yields still higher values. We provide also a comparison of the four test methods applied to isotropic materials.},
}

@article{1997MarmarasErgonomic,
author = {Nikos Marmaras and Nikos Zarboutis},
pages = {59--67},
pmid = {9414341},
number = {1},
issn = {00036870},
year = {1997},
journal = {Applied Ergonomics},
month = {feb},
title = {Ergonomic redesign of the electric guitar},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0003687096000324},
doi = {10.1016/S0003-6870(96)00032-4},
volume = {28},
abstract = {The present study deals with the redesign of the electric guitar, considering ergonomic criteria. Difficulties met by novice musicians, neuro-muscular fatigue caused by guitar playing and occupational diseases occurring to professional guitarists, justify this study. Characteristics of existing electric guitar models which add to musician's fatigue or difficulty, were identified. A number of ergonomic requirements were then derived. The redesign process tried to satisfy these requirements, considering at the same time musical requirements and technical constraints. A comparative evaluation of the designed ergonomic guitar with three existing electric guitar models, showed that although the designed electric guitar preserves the main features of the instrument, it achieves better user fit.},
publisher = {Elsevier BV},
keywords = {equipment design,musicial instruments,redesign methodology},
mendeley-tags = {equipment design,musicial instruments,redesign methodology},
}

@article{2012TorresExperimental,
author = {J Alej Torres and  ro and J Luis Villarreal and R Ramırez},
volume = {58},
year = {2012},
number = {1},
journal = {Revista mexicana de f\'isica E},
abstract = {The focus of this paper is to describe complex theoretical concepts about vibration and acoustics, considering experimental and computational tools. Some modal behaviors of a structure were explained. First, an experiment was designed to naked eye visualization of mode shapes in a thin film. Later, simulated deflections of a guitar top plate model were explored. This exploration was done through original scientific visualization software. Moreover, the developed computational tool was essential illustrating behaviors that used to be hard to visualize: acoustic waves. Sound radiation data were calculated from the vibration of the top plate model. These data were sliced to detect acoustic wavefronts and directivity patterns. Experimental and computational procedures developed in this work were useful illustrating vibroacoustic behaviors. Mode shapes and natural frequencies in the thin film experiment were clearly detected. Scientific visualization software showed ability to display vibroacoustic information in high density, with much semantic substance and time savings. The experiment can be easily implemented in a classroom, and the software can be used to explore other kind of data in standard Visualization Tool Kit format.},
issn = {1870-3542},
title = {Experimental and simulated exploration of structural deflections and acoustic waves of guitar top plates},
pages = {1--6},
keywords = {acoustic wave,acoustics,classical mechanics,deflection,guitar,mathematics},
mendeley-tags = {acoustic wave,acoustics,classical mechanics,deflection,guitar,mathematics},
}

@article{PedgleyMaterials,
author = {Owain Pedgley and Eddie Norman and Rob Armstrong},
year = {2009},
abstract = {This paper presents a case study of research leading to a significant innovation in the acoustic guitar sector (1). The acoustic guitar is a result of centuries of design and development with wood, and has evolved into an archetypal and traditional product with a relatively conservative user base. As with many other product sectors, most acoustic guitars are now mass-produced in China, where low labour costs contribute to an average out-of-factory price of just $20 USID. This paper describes research into a dramatic shift in guitar materials, away from wood fabrication, towards the assembly of industrially moulded thermoplastic components. It is proposed that such a shift in materials can lead to competitive mass-manufacture of acoustic guitars outside of low labour cost countries, whilst invigorating the design of this popular musical instrument. Emphasis is placed on articulating the technical, aesthetic, market, and commercial requirements of a thermoplastic acoustic guitar. The crucial issue of sourcing appropriate forms of advice to aid product design is discussed. Focus is on the guitar soundboard, as the principal sound-generating component of the instrument. Three conclusions are reached, based on the patented soundboard technology that emerged from the research. First, instruments constructed. with foamed polycarbonate soundboards can rival the quality of wood counterparts, opening the way for a possible new industry of polymer musical instruments. Second, foamed polycarbonate soundboards have physical material properties surprisingly different to wood yet give equivalent acoustic performance. And third, innovation in this product sector benefits more from designerly ways of knowing and operating and less from scientific discoveries.},
title = {Materials-inspired innovation for acoustic guitar design},
pages = {157--175},
journal = {Metu Journal of the Faculty of Architecture},
volume = {26},
number = {1},
issn = {0258-5316},
keywords = {designerly ways of knowing,guitar,industrial design,material selection,plastics,product innovation},
mendeley-tags = {designerly ways of knowing,guitar,industrial design,material selection,plastics,product innovation},
}

@article{2014PaivaModal,
author = {G Paiva and J M. C. Dos Santos},
abstract = {233 The Brazilian guitar is a countryside musical instrument and presents different characteristics that vary regionally by configuring as a sparse group of string musical instruments. Basically, the instrument diversity comes from different geometries of resonance box, shapes of sound hole, types of wood, different tunings, and number and arrangement of strings. This paper intends to present the numerical and experimental modal analysis of a Brazilian guitar, without strings, in a free boundary condition. The modal analysis technique is applied in the determination of the natural frequencies and the corresponding mode shapes. The main dimensions of an actual Brazilian guitar body are used to build the computational model geometry. The numerical modal analysis uses finite element method (FEM) to determine the dynamic behavior of the vibroacoustic system, which is composed by the structural and acoustic systems coupled. The experimental modal analysis is carried out in an actual Brazilian guitar body, where the structural modal parameters (frequency and mode shape) are extracted and used to update the numerical model. Finally, numerical and experimental results are compared and discussed.},
title = {Modal analysis of a Brazilian guitar body},
year = {2014},
pages = {233--239},
number = {October 2015},
journal = {ISMA International Symposium on Music Acoustics, Le Mans, France},
}

@article{2005BecacheNumerical,
author = {Eliane B\'ecache and Antoine Chaigne and Gregoire Derveaux and Patrick Joly},
pages = {107--126},
issn = {00457949},
journal = {Computers and Structures},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0045794904002974},
abstract = {The purpose of this study is to present a time-domain numerical modeling of the guitar. The model involves the transverse displacement of the string excited by a force pulse, the flexural motion of the soundboard and the sound radiation in the air. We use a specific spectral method for solving the Kirchhoff-Love's dynamic plate model for orthotropic material, a fictitious domain method for solving the fluid-structure interaction and a conservative scheme for the time discretization. One of the originality of the proposed scheme is a stable coupling method between a continuous time resolution and a discrete one. \textcopyright 2004 Elsevier Ltd. All rights reserved.},
number = {2-3},
title = {Numerical simulation of a guitar},
volume = {83},
year = {2005},
doi = {10.1016/j.compstruc.2004.04.018},
keywords = {energy method,fictitious domain method,fluid-structure interaction,kirchhoff-love's plate model,mixed finite elements,spectral method,stability analysis},
mendeley-tags = {energy method,fictitious domain method,fluid-structure interaction,kirchhoff-love's plate model,mixed finite elements,spectral method,stability analysis},
}

@article{2007ShlychkovNumerical,
author = {S. V. Shlychkov},
number = {3},
volume = {43},
journal = {Mechanics of Composite Materials},
pages = {269--276},
year = {2007},
doi = {10.1007/s11029-007-0026-y},
issn = {01915665},
abstract = {The paper presents results of numerical and experimental investigations into the vibrations of thin-walled structures, considering such their features as the complexity of geometry, the laminated structure of walls, the anisotropy of materials, the presence of stiffeners, and the initial stresses. The object of the study is the sounding board of an acoustic guitar, the main structural material of which is a three-layer birch veneer. Based on the finite-element method, a corresponding calculation model is created, and the steady-state regimes of forced vibrations of the sounding board are investigated. A good correspondence between calculation results and experimental data is found to exist. \textcopyright 2007 Springer Science+Business Media, Inc.},
title = {Numerical-experimental investigation of resonance characteristics of a sounding board},
keywords = {dynamic characteristics,finite element,multilayered composite,spectral analysis,thin-walled structure,vibration spectrum},
mendeley-tags = {dynamic characteristics,finite element,multilayered composite,spectral analysis,thin-walled structure,vibration spectrum},
}

@article{2010HsiaoProduct,
author = {Shih Wen Hsiao and Fu Yuan Chiu and Shu Hong Lu},
volume = {40},
year = {2010},
doi = {10.1016/j.ergon.2010.01.009},
journal = {International Journal of Industrial Ergonomics},
abstract = {Industrial design attempts to enhance quality of life by designing products that meet consumer requirements. Combining concepts from various fields, including design, computer technology, aesthetics, and economics, industrial designers seek to improve quality of life by designing products that meet consumer needs. Industrial designers focus on customers' perceptions of products and their preferences for certain shapes, textures, colors, styles, linguistic variables, prices, and functions. Because new products are continuously being released, manufacturers must continually design products to satisfy customer needs to avoid displacement by market competitors. When planning strategies for marketing products to various users and consumers, managers must often consider multiple combinations of product shapes and must design products that cater to consumer tastes to minimize the risk of their products being rejected by the market. Companies with highly-skilled designers have more ideas, better and more competitive products, and shorter production times than companies with weak designers. This study analyzed product styles by applying genetic algorithms and Kansei Engineering Type II (AHP and Quantification Theory Type I). This research transforms the psychological conceptions of consumers into linguistic variables. A MATLAB program was constructed to enable designers to simulate consumer logic. The cognitive dissonance between virtual and real models was minimized by using a 3D CAD model, and the virtual model of optimum solutions in this study employed a rapid prototyping machine to generate real models efficiently. Future genetic algorithm models applying different decision theories may achieve even faster and more accurate results. Relevance to industry: Component diversification enables rapid improvement in product competitiveness. This study proposes a support model that conforms to the psychological preferences of consumers by applying a genetic algorithm method. Therefore, the model is applicable to electronic commerce websites or to other unmanned shops. \textcopyright 2010 Elsevier B.V.},
issn = {01698141},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0169814110000107},
title = {Product-form design model based on genetic algorithms},
pages = {237--246},
number = {3},
keywords = {genetic algorithms,kansei engineering,morphological analysis,product design,quantification theory type i analytical hierarchy process},
mendeley-tags = {genetic algorithms,kansei engineering,morphological analysis,product design,quantification theory type i analytical hierarchy process},
}

@article{2014ShepherdEffects,
author = {Micah R. Shepherd and Stephen A. Hambric and Dennis B. Wess},
issn = {0001-4966},
pages = {EL357--EL361},
number = {5},
abstract = {A finite element model of a bare top plate with braces and a bridge plate was created using orthotropic material properties. The natural variation of the wood properties including dependence on moisture content was also determined. The simulated modes were then compared to experimentally obtained modes from top plate prototypes. Uncertainty analysis was also performed to determine the statistical bound of natural variability between wood samples. The natural frequencies of the model fall within the computed error bound. These results reinforce the importance of obtaining accurate material properties for acoustic guitar modeling.},
volume = {136},
year = {2014},
title = {The effects of wood variability on the free vibration of an acoustic guitar top plate},
journal = {The Journal of the Acoustical Society of America},
doi = {10.1121/1.4898740},
}

@inproceedings{2008ZoranReacoustic,
author = {Amit Zoran and Pattie Maes},
isbn = {9781605584669},
url = {http://portal.acm.org/citation.cfm?doid=1400885.1400928},
booktitle = {SIGGRAPH'08 - ACM SIGGRAPH 2008 Posters},
title = {The reAcoustic eGuitar},
abstract = {We present a new approach for designing guitars making use of the digital environment. We aim to preserve the physical connection between a user and the instrument, while offering innovative sound design. The reAcoustic eGuitar is a digitally fabricated instrument to design sounds. A user shapes it by modifying six separate acoustic chambers. We contextualize the need for such an artifact within the evolution of the guitar.},
doi = {10.1145/1400885.1400928},
pages = {1},
publisher = {ACM Press},
year = {2008},
}

@article{2003DerveauxTime,
author = {Gr\'egoire Derveaux and Antoine Chaigne and Patrick Joly and Eliane B\'ecache},
abstract = {This paper presents a three-dimensional time-domain numerical model of the vibration and acoustic radiation from a guitar. The model involves the transverse displacement of the string excited by a force pulse, the flexural motion of the soundboard, and the sound radiation. A specific spectral method is used for solving the Kirchhoff-Love's dynamic top plate model for a damped, heterogeneous orthotropic material. The air-plate interaction is solved with a fictitious domain method, and a conservative scheme is used for the time discretization. Frequency analysis is performed on the simulated sound pressure and plate velocity waveforms in order to evaluate quantitatively the transfer of energy through the various components of the coupled system: from the string to the soundboard and from the soundboard to the air. The effects of some structural changes in soundboard thickness and cavity volume on the produced sounds are presented and discussed. Simulations of the same guitar in three different cases are also performed: "in vacuo," in air with a perfectly rigid top plate, and in air with an elastic top plate. This allows comparisons between structural, acoustic, and structural-acoustic modes of the instrument. Finally, attention is paid to the evolution with time of the spatial pressure field. This shows, in particular, the complex evolution of the directivity pattern in the near field of the instrument, especially during the attack.},
doi = {10.1121/1.1629302},
pages = {3368--3383},
volume = {114},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pmid = {14714817},
issn = {0001-4966},
shorttitle = {Time-domain simulation of a guitar},
year = {2003},
title = {Time-domain simulation of a guitar: Model and method},
}

@article{2012Gorrostieta-hurtadoVibration,
author = {Efren Gorrostieta-Hurtado},
title = {Vibration analysis in the design and construction of an acoustic guitar},
url = {http://www.academicjournals.org/IJPS/abstracts/abstracts/abstract2012/23Mar/Gorrostieta-Hurtado///////%5C%5C et///////%5C%5C al.htm},
number = {13},
issn = {1992-1950},
doi = {10.5897/ijps11.1603},
journal = {International Journal of the Physical Sciences},
abstract = {One of the main problems encountered in developing and building an acoustic guitar is to establish a formal methodology that allows us to observe the impact of some parameters involved in the process. This paper propose a modal analysis in the different stages of construction, and it is performed by -a finite element analysis of the soundboard of the instrument according to the relationship that that have the-frequencies and vibration modes, here, a set of certain parameters in the design are used to improve sound performance.},
volume = {7},
year = {2012},
}

@article{2011ChouGestalt–minimalism,
author = {Jyh Rong Chou},
issn = {01698141},
title = {A Gestalt-Minimalism-based decision-making model for evaluating product form design},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0169814111000886},
volume = {41},
journal = {International Journal of Industrial Ergonomics},
doi = {10.1016/j.ergon.2011.07.006},
pages = {607--616},
abstract = {This paper presents a novel methodology for dealing with decision-making problems in product design fields. The purpose of this study is to evaluate product form design in terms of the perspectives of Gestalt psychology and Minimalist principles. Unlike traditional AHP methods, the proposed decision-making model uses distinct mathematical tools to establish priorities for the criteria and synthesize the evaluation results. A case study was conducted to illustrate the practicability of this proposed model. It has shown a credible result. In addition to product form design, this model can be applied to related design fields, such as plane design and other visual design. Relevance to industry: Product form design is a creative process that involves complex visual perceptions. It is very important to develop an effective decision support system for designers to deal with problems concerning the consumers' psychological preferences toward product forms. As Gestalt psychology and Minimalist principles provide an important perspective on visual perception, it is appropriate to apply these principles in assessing the quality of product form design. \textcopyright 2011 Elsevier B.V.},
year = {2011},
number = {6},
keywords = {decision-making,evaluation,gestalt psychology,minimalism,product form design},
mendeley-tags = {decision-making,evaluation,gestalt psychology,minimalism,product form design},
}

@article{2002HsiaoNeural,
author = {Shih Wen Hsiao and H. C. Huang},
title = {A neural network based approach for product form design},
issn = {0142694X},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0142694X01000151},
pages = {67--84},
abstract = {A neural network based approach for product design is addressed in this article. Computer modeling, fuzzy set theory and semantic difference method are applied to set up an experiment. The experimental results are analyzed by applied back-propagation neural network, which establish the relationships between product-form parameters and adjective image words. A database for the connections among the design elements, product images and shape generation rules was constructed. A computer-aided system for product-form design was then developed based on this database. With the aid of this design system, a designer can generate 3D models of any product with different images by providing basic design elements and shape generation rules. Simultaneously, a rendered 3D model of the designed product and its images are also presented by this system. Therefore, changing the configuration parameter(s) until the product shape is acceptable can modify the image of a product. In this manner, the designed product can fit more closely to the consumers' desire. Chair design is taken as a case study; but this method can be used to develop other products. \textcopyright 2001 Elsevier Science Ltd. All rights reserved.},
doi = {10.1016/S0142-694X(01)00015-1},
journal = {Design Studies},
year = {2002},
number = {1},
volume = {23},
keywords = {computer-aided design,industrial design,neural network,perception,product design},
mendeley-tags = {computer-aided design,industrial design,neural network,perception,product design},
}

@article{2012ZoranPlatform,
author = {Amit Zoran and Stephen Welch and William D. Hunt},
title = {A platform for manipulation and examination of the acoustic guitar: The Chameleon Guitar},
abstract = {A platform for manipulation and examination the acoustic guitar is presented, based on a novel guitar design - the Chameleon Guitar - featuring a replaceable acoustic resonator functioning as the soundboard of the instrument. The goal of the design process is to create a tone as sonically close to that of a traditional guitar as possible, while maintaining an easily replaceable soundboard. An iterative, data driven approach was used, each design step coming under examination from one or more measurement tools: finite-element method, acoustic impulse testing, and laser vibrometry. Ideal resonator geometry, bridge location, and piezoelectric sensor positions were determined. The finished instrument was then examined with laser vibrometry to confirm earlier results, evaluate the behavior and chosen sensor positions for various tonewoods, and examine the acoustic effects of adding sensors and wax finish. The conclusions drawn are diverse and point to the significance of attention to detail in each step of instrument construction. For example, when changing instrument material from one softwood to another, ideal locations for piezoelectric sensors are subject to change. We conclude that detailed acoustic analysis can significantly aid in the construction of new instruments by quantifying the impact of instrument geometry and material properties. \textcopyright 2011 Elsevier Ltd. All rights reserved.},
shorttitle = {A platform for manipulation and examination of the acoustic guitar},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X11002738},
volume = {73},
pages = {338--347},
year = {2012},
doi = {10.1016/j.apacoust.2011.10.004},
issn = {0003682X},
number = {4},
journal = {Applied Acoustics},
keywords = {guitar resonator},
mendeley-tags = {guitar resonator},
}

@article{odonnell_study_2012,
author = {Jimmy O Donnell and Graeme Mcrobbie},
journal = {2012 COMSOL Conference},
abstract = {This study will research a modern design of acoustic guitar by analysis of the vibrational modes. The guitar that will undergo testing has been provided by Emerald Guitars and is solely constructed using Carbon Fiber Reinforced Plastic (CFRP). With the use of COMSOL Multiphysics\textcopyright the soundboard of the guitar will be simulated and analysis will be carried out to determine the first 10 eigenfrequencies and the modal shapes these create. This paper will detail the preliminary results obtained using the physical data collected through experimental testing in a previous study. The paper will demonstrate an application of the finite element method in the field of musical acoustics.},
title = {A Study Into the Acoustic and Vibrational Effects of Carbon Fiber Reinforced Plastic As a Sole Manufacturing Material for Acoustic Guitars},
year = {2012},
pages = {4},
}

@article{2015CaucaAcoustic,
author = {Ennio Hugo Idrobo-\'avila and Rubiel Vargas-Ca\~nas},
issn = {01206230},
number = {76},
abstract = {This paper presents a study relating the most commonly used materials in manufacturing the top plate of the Spanish guitar and some sound characteristics such as timbre, volume, and duration. Theoretically, the wood infl uences the quality of the sound and the vibrations of the membranes. Based upon these facts, an acoustic and vibrational study was carried out in order to establish the relationship between the physical properties of the wood and the resulting sound quality. To do this, digital signal processing techniques were implemented. It was found that volume and sound duration were higher in guitars with German spruce soundboard, whereas guitars with Canadian cedar soundboard presented more homogeneous sounds.},
pages = {30--38},
shorttitle = {Acoustic and mechanic characterization of materials used in manufacturing the soundboard of the spanish guitar},
title = {Acoustic and mechanic characterization of materials used in manufacturing the soundboard of the spanish guitar: Influence in the sonority},
url = {http://aprendeenlinea.udea.edu.co/revistas/index.php/ingenieria/article/view/21021},
doi = {10.17533/udea.redin.n76a04},
journal = {Revista Facultad de Ingenieria},
volume = {2015},
year = {2015},
keywords = {digital signal processing,duration,physical properties,soundboard,timbre,volume},
mendeley-tags = {digital signal processing,duration,physical properties,soundboard,timbre,volume},
}

@misc{2013GualandriAnalysis,
author = {I Introduction},
url = {https://courses.physics.illinois.edu/phys406/sp2017/Student///////%5C%5C_Projects/Spring13/Dan///////%5C%5C_Gualandri///////%5C%5C_P406///////%5C%5C_Final///////%5C%5C_Project///////%5C%5C_Report///////%5C%5C_Sp13.pdf},
pages = {1--12},
year = {1969},
title = {Analysis of an Acoustic Guitar},
}

@article{2005HsiaoApplying,
author = {Shih Wen Hsiao and Hung Cheng Tsai},
issn = {01698141},
volume = {35},
title = {Applying a hybrid approach based on fuzzy neural network and genetic algorithm to product form design},
journal = {International Journal of Industrial Ergonomics},
pages = {411--428},
number = {5},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0169814104002070},
doi = {10.1016/j.ergon.2004.10.007},
abstract = {When generating new design concepts, most industrial designers tend to draw upon stereotypical images and their own personal design experiences. The evaluation of each individual design candidate in terms of its ability to meet the demands of the marketplace is a crucial step within the conceptual design stage. Consequently, this paper proposes a method which enables an automatic product form search or product image evaluation by means of fuzzy neural network and genetic algorithm. Initially, a feature-based hierarchical computer-aided design (CAD) model is constructed, in which the related form parameters are thoroughly defined in applicable domains to facilitate the automatic generation of new product forms. A fuzzy neural network algorithm is then applied to establish the relationships between the input form parameters and a series of adjectival image words. In a reverse process, genetic algorithm is employed to search for a near-optimal design which satisfies the designer's required product image by using the trained neural network as a fitness function. The proposed method provides an automatic design system, which gives designers the ability to rapidly obtain a product form and its corresponding image, or to search for the ideal form which fits a required image in a shorter lead-time. An electronic door lock design is chosen as the subject of the current investigation. However, the proposed method is equally applicable to the design of other products. \textcopyright 2004 Elsevier B.V. All rights reserved.},
year = {2005},
keywords = {computer-aided design,fuzzy neural network,genetic algorithm,industrial design,optimum design},
mendeley-tags = {computer-aided design,fuzzy neural network,genetic algorithm,industrial design,optimum design},
}

@article{2008HsiaoApplying,
author = {Shih Wen Hsiao and Fu Yuan Chiu and Chong Shian Chen},
abstract = {In the highly competitive market, varying product color to change its image is one of the best solutions to improve the product competitiveness. In this paper, the relationships among the product image, color area, and aesthetic measurement of the product are studied. The pixels of an area of color are used to obtain the proportionate relationship between different colored areas in a given solid visual angle. Based on the relationship among the Hue, Value, Chroma and colored area proposed by Munsell, the other factors are integrated to set up one formula for evaluating the aesthetic degree of color matching. The aesthetics measurement is considered to be influenced by the color environments, color areas, component colors and display angles of the product. The color planning for developing a cell phone was performed based on this model. The experimental results verified this model can be used for color planning in product design. \textcopyright 2008 Elsevier B.V. All rights reserved.},
doi = {10.1016/j.ergon.2008.02.009},
issn = {01698141},
volume = {38},
url = {https://linkinghub.elsevier.com/retrieve/pii/S016981410800036X},
journal = {International Journal of Industrial Ergonomics},
pages = {910--920},
number = {11-12},
title = {Applying aesthetics measurement to product design},
year = {2008},
keywords = {aesthetic measurement,color area,color combination,color harmony,color image},
mendeley-tags = {aesthetic measurement,color area,color combination,color harmony,color image},
}

@book{1999LavilleConstrucao,
author = {Christian Laville and Jean Dionne},
shorttitle = {A constru\cc\~ao do saber},
publisher = {Ed. da UFMG : ARTMED},
isbn = {978-85-7307-489-5},
annote = {OCLC: 817592435},
title = {A constru\cc\~ao do saber: manual de metodologia da pesquisa em ci\^encias humanas},
}

@article{2006AssisMetodologia,
author = {Orl Pontes and o Domingues de Ara\'ujo and Rilva Lopes de Sousa-Mu\~noz},
journal = {Revista Brasileira de Educa\cc\~ao M\'edica},
abstract = {OBJETIVOS: Avaliar a satisfa\cc\~ao dos estudantes do internato do curso de gradua\cc\~ao em Medicina da Universidade Federal da Para\'iba (UFPB) sobre seu \'ultimo rod\'izio. M\'ETODOS: Estudo transversal e observacional realizado no curso de Medicina da UFPB, envolvendo estudantes do novo curr\'iculo. Foi aplicado um question\'ario elaborado pelos autores e pr\'e-testado. RESULTADOS: Foram inclu\'idos 124 estudantes (91,2% dos internos). A m\'edia dos percentuais de estudantes satisfeitos foi de 49,6%, correlacionando-se inversamente com o n\'umero de rod\'izios cursados. O maior grau de satisfa\cc\~ao foi observado no rod\'izio de Sa\'ude Coletiva (76%), e o mais baixo, no de Cl\'inica M\'edica (23,1%) em todos os aspectos avaliados. Revelaram-se inexist\^encia de preceptoria nos hospitais conveniados, excesso de atividades burocr\'aticas, relacionamento conflituoso com residentes, pr\'atica insuficiente e enfoque em problemas muito espec\'ificos. CONCLUS\~OES: A satisfa\cc\~ao dos estudantes com o internato m\'edico da UFPB foi baixa. O rod\'izio de Cl\'inica M\'edica atingiu os percentuais mais baixos em todos os aspectos avaliados, enquanto o de Sa\'ude Coletiva, os melhores. Constatou-se que o Regimento do internato n\~ao est\'a sendo cumprido adequadamente.OBJECTIVES: To evaluate undergraduate medical students' satisfaction with their last internship rotation of Internship at Universidade Federal da Para\'iba (UFPB). METHODS: Observational and cross-sectional study, developed at the UFPB Medical School, involving interns enrolled under the new medical course curriculum. A pretested questionnaire prepared by the authors was applied. RESULTS: The sample population was of 124 students (91.2% of the total number of interns). The average percentage of satisfied students was 49.6%, inversely correlated to the number of rotations already attended. The highest degree of satisfaction was observed in the Family Medicine rotation (76%), and the lowest in the Internal Medicine rotation (23.1%), when all aspects were evaluated. Other findings included: a lack of preceptors in associated hospitals, excessive administrative activities, conflicting relationship with residents, insufficient practice and focus on very specific problems. CONCLUSION: The study demonstrated that UFPB medical students' satisfaction with the internship program was low. The Internal Medicine rotation reported the lowest percentage in all aspects evaluated, while the Family Medicine rotation reported the highest. Furthermore, it was found that the Internship regulations were not being upheld adequately.},
year = {2014},
isbn = {8522431698},
pages = {519--531},
volume = {38},
title = {Metodologia do trabalho},
number = {4},
}

@book{2012AbreuArte,
author = {Anthony Weston},
pages = {43--48},
volume = {8},
abstract = {"Este trabalho ... \'e endere\ccado a todos aqueles que desejam melhorar seu relacionamento porfissional, aumentado, cirativamente, dua capacidade apra o  trabalho em equipe e para a resolu\cc\~ao de conflitos. Nesse sentido, \'e estremamente \'util para execituvos, professores, psic\'ologos, advogados, administradores e pessoal de venda. Mas \'e tamb\'em endere\ccado \`aqueles que desejam simplesmente aumentar sua qualidade de vida, em uma dimens\~ao intelectual e emocional, pro meio de uma mudan\cca positiva em seus relacionamentos pessoais." [contra capa]"},
booktitle = {A Arte de Argumentar},
year = {1998},
isbn = {972662441x},
title = {A Arte de Argumentar},
}

@book{2009GilComo,
author = {Antonio Carlos Gil},
number = {61},
pages = {16--17},
volume = {5},
year = {2002},
abstract = {Como encaminhar uma pesquisa; Como formular um problema de pesquisa; Como construir hip\'oteses; Como classificar as pesquisas; Como delinear uma pesquisa bibliogr\'afica; Como delinear uma pesquisa documental; Como delinear uma pesquisa experimental; Como delinear um ensaio cl\'inico; Como delinear um estudo de coorte; Como delinear um estudo caso-controle; Como delinear um levantamento; Como delinear um estudo de caso; Como delinear uma pesquisa etnogr\'afica; Como delinear uma pesquisa fenomenol\'ogica; Como delinear uma pesquisa para desenvolver teoria fundamentada (grounded theory); Como delinear uma pesquisa-a\cc\~ao;Como delinear uma pesquisa participante; Como calcular o tempo e o custo do projeto; Como redigir o projeto de pesquisa.},
isbn = {978-85-224-3169-4},
title = {Como elaborar projetos de pesquisa},
booktitle = {S\~ao Paulo},
publisher = {Atlas},
annote = {OCLC: 422878585},
keywords = {methodology,research},
mendeley-tags = {methodology,research},
}

@article{ZanonO,
author = {F\'abio ZANON},
title = {O Viol\~ao no Brasil depois de Villa-Lobos},
url = {http//p2.forumforfree.com/1-vt1436-violaoerudito.html?start=0},
year = {2006},
journal = {Forum Viol\~ao Erudito},
pages = {7},
}

@article{2002HeijinkComplexity,
author = {Hank Heijink and Ruud G.J. Meulenbroek},
shorttitle = {On the Complexity of Classical Guitar Playing},
abstract = {The authors performed a behavioral study of the complexity of left-hand finger movements in classical guitar playing. Six professional guitarists played movement sequences in a fixed tempo. Left-hand finger movements were recorded in 3 dimensions, and the guitar sound was recorded synchronously. Assuming that performers prefer to avoid extreme joint angles when moving, the authors hypothesized 3 complexity factors. The results showed differential effects of the complexity factors on the performance measures and on participants' judgments of complexity. The results demonstrated that keeping the joints in the middle of their range is an important principle in guitar playing, and players exploit the available tolerance in timing and placement of the left-hand fingers to control the acoustic output variability. \textcopyright 2002 Taylor & Francis Group, LLC.},
pages = {339--351},
journal = {Journal of Motor Behavior},
title = {On the complexity of classical guitar playing: Functional adaptations to task constraints},
year = {2002},
issn = {19401027},
doi = {10.1080/00222890209601952},
pmid = {12446249},
volume = {34},
number = {4},
keywords = {degrees of freedom,guitar fingering,music performance,skilled motor behavior},
mendeley-tags = {degrees of freedom,guitar fingering,music performance,skilled motor behavior},
}

@article{balleste_organizacao_2009,
author = {Adriana Olinto Ballest\'e},
abstract = {On the musicology, in particular in the organology, terminological problems often occur. A typical example can be observed in the plunked musical instruments universe in Brazil. This paper demonstrates the importance of the application of knowledge organization methodologies in the musical domain, especially in the plunked musical instruments domain.},
pages = {11},
title = {ORGANIZA\cC\~AO DO CONHECIMENTO E SUA APLICA\cC\~AO AO UNIVERSO DE CORDAS DEDILHADAS NO RIO DE JANEIRO OITOCENTISTA},
}

@article{2012RichardsonThree,
author = {Bernard Richardson and Helen Johnson and Alex Joslin and  ra and Ian Perry and Bernard Richardson and Helen Johnson and Alex Joslin and  ra and Ian Perry},
pages = {7},
title = {The three-mass model for the classical guitar revisited To cite this version :},
year = {2012},
}

@article{2013HeemskerkEye,
author = {Jacques Heemskerk},
pages = {21--24},
volume = {44},
number = {6},
year = {2013},
issn = {05317479},
title = {An eye-witness report on how the CD came about},
abstract = {The Compact Disc was a smashing success. It pushed the traditional 45 and 33 RPM vinyl records off the market in an astonishingly short period of time. But the struggle to develop the CD and to get it on the market was just as fascinating. \textcopyright European Physical Society, EDP Sciences, 2013.},
journal = {Europhysics News},
doi = {10.1051/epn/2013601},
}

@article{2002ElejabarrietaCoupled,
author = {M. J. Elejabarrieta and A. Ezcurra and C. Santamarı́a},
pmid = {12051448},
doi = {10.1121/1.1470163},
journal = {The Journal of the Acoustical Society of America},
number = {5},
issn = {00014966},
volume = {111},
abstract = {Vibrations of the resonance box of the guitar have been studied by means of the modal analysis technique and the finite-element method. An expert craftsman constructed the guitar box with all the structures, internal and external, characteristic of a real instrument for the experimental measurements. The boundary conditions were chosen in order to clarify the soundboard-back interaction only via the internal air coupling. The numerical model allows one to study the influence of each component on the whole box, and the contribution of the modes of the components (wooden box and its parts, and air), to the coupled modes by calculating their participation factors. The coupled modes of the guitar box are discussed taking into account both the finite-element and modal analysis results. \textcopyright 2002 Acoustical Society of America.},
title = {Coupled modes of the resonance box of the guitar},
pages = {2283},
year = {2002},
}

@article{probert_design_nodate,
author = {Stephen M Probert},
pages = {173},
title = {Design, Manufacture and Analysis of a Carbon Fiber Epoxy Composite Acoustic Guitar},
year = {2007},
}

@article{GreenMechanical,
author = {David W Green and  Win and Jerrold E y and David E Kretschmann},
title = {Mechanical properties of wood determined},
doi = {10.1126/science.46.1195.516-a},
year = {1917},
journal = {Science},
number = {1195},
pages = {516--517},
pmid = {17818245},
volume = {46},
issn = {00368075},
}

@article{2012ZillDifferential,
author = {Dennis G Zill},
pages = {673},
title = {Differential Equations with Boundary-Value Problems},
}

@book{2005SerwayModern,
author = {Robert Ehrlich},
pages = {179--192},
booktitle = {Why Toast Lands Jelly-Side Down},
title = {Modern Physics},
isbn = {978-0-534-49339-4 978-0-534-40624-0},
doi = {10.2307/j.ctv173f18x.15},
publisher = {Thomson Brooks/Cole},
year = {2020},
edition = {3rd ed},
keywords = {physics,textbooks},
mendeley-tags = {physics,textbooks},
}

@book{2018ShabanaComputational,
author = {Ahmed A. Shabana},
title = {Computational continuum mechanics},
volume = {9780521885690},
year = {2008},
isbn = {9780511611469},
pages = {1--335},
edition = {Third edition},
abstract = {This book presents the nonlinear theory of continuum mechanics and demonstrates its use in developing nonlinear computer formulations for large displacement dynamic analysis. Basic concepts used in continuum mechanics are presented and used to develop nonlinear general finite element formulations that can be effectively used in large displacement analysis. The book considers two nonlinear finite element dynamic formulations: a general large deformation finite element formulation and a formulation that can efficiently solve small deformation problems that characterize very stiff structures. The book presents material clearly and systematically, assuming the reader has only basic knowledge in matrix and vector algebra and dynamics. The book is designed for use by advanced undergraduates and first-year graduate students. It is also a reference for researchers, practicing engineers, and scientists working in computational mechanics, bio-mechanics, computational biology, multibody system dynamics, and other fields of science and engineering using the general continuum mechanics theory.},
publisher = {Wiley},
booktitle = {Computational Continuum Mechanics},
doi = {10.1017/CBO9780511611469},
keywords = {continuum mechanics,engineering mathematics},
mendeley-tags = {continuum mechanics,engineering mathematics},
}

@book{1981GurtinIntroduction,
author = {El\'ias Cueto and David Gonz\'alez},
url = {https://www.ebook.de/de/product/3659321/morton///////%5C%5C_e///////%5C%5C_gurtin///////%5C%5C_an///////%5C%5C_introduction///////%5C%5C_to///////%5C%5C_continuum///////%5C%5C_mechanics.html},
publisher = {Academic Press},
issn = {25225618},
abstract = {This chapter revisits the basics of the theory of elasticity upon which strength of materials is based. The level is kept to the minimum that will enable reader to understand subsequent chapters.},
volume = {4},
year = {2018},
booktitle = {Structural Integrity},
doi = {10.1007/978-3-319-72935-0_1},
edition = {1 edition},
pages = {1--31},
isbn = {978-0-12-309750-7},
title = {An introduction to continuum mechanics},
}

@book{2016HastieElements,
author = {Jerome Hastie, Trevor, Tibshirani, Robert, Friedman},
booktitle = {Springer series in statistics},
pmid = {12377617},
isbn = {978-0-387-84858-7},
abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.},
archiveprefix = {arXiv},
edition = {2nd edition},
issn = {00111287},
url = {http://www.worldcat.org/oclc/405547558%5CnHastie, Tibshirani et al - The elements of statistical learning.pdf%5Cnhttp://www.springer.com.libproxy1.nus.edu.sg/statistics/statistical+theory+and+methods/book/978-0-387-84857-0%5Cnhttp://statweb.stanford.edu/$\sim$tibs/E},
title = {The Elements of Statistical Learning The Elements of Statistical LearningData Mining, Inference, and Prediction, Second Edition},
year = {2009},
eprint = {arXiv:1011.1669v3},
publisher = {Springer},
shorttitle = {The Elements of Statistical Learning},
pages = {282},
arxivid = {arXiv:1011.1669v3},
keywords = {data mining,inference,neural nets,prediction,statistical learning},
mendeley-tags = {data mining,inference,neural nets,prediction,statistical learning},
}

@article{2016TuMapping,
author = {Enmei Tu and Nikola Kasabov and Jie Yang},
title = {Mapping Temporal Variables Into the NeuCube for Improved Pattern Recognition, Predictive Modeling, and Understanding of Stream Data},
number = {6},
url = {http://arxiv.org/abs/1603.05594},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
eprint = {1603.05594},
year = {2017},
issn = {21622388},
pmid = {26992179},
pages = {1305--1317},
volume = {28},
abstract = {This paper proposes a new method for an optimized mapping of temporal variables, describing a temporal stream data, into the recently proposed NeuCube spiking neural network (SNN) architecture. This optimized mapping extends the use of the NeuCube, which was initially designed for spatiotemporal brain data, to work on arbitrary stream data and to achieve a better accuracy of temporal pattern recognition, a better and earlier event prediction, and a better understanding of complex temporal stream data through visualization of the NeuCube connectivity. The effect of the new mapping is demonstrated on three benchmark problems. The first one is the early prediction of patient sleep stage event from temporal physiological data. The second one is the pattern recognition of dynamic temporal patterns of traffic in the Bay Area of California and the last one is the Challenge 2012 contest data set. In all the cases, the use of the proposed mapping leads to an improved accuracy of pattern recognition and event prediction and a better understanding of the data when compared with traditional machine learning techniques or SNN reservoirs with an arbitrary mapping of the variables.},
arxivid = {1603.05594},
doi = {10.1109/TNNLS.2016.2536742},
archiveprefix = {arXiv},
keywords = {early event prediction,neucube architecture,spatiotemporal data,spiking neural network (snn},
mendeley-tags = {early event prediction,neucube architecture,spatiotemporal data,spiking neural network (snn},
}

@article{2010KeshavarzPolyhydroxyalkanoates,
author = {Tajalli Keshavarz and Ipsita Roy},
title = {Polyhydroxyalkanoates: bioplastics with a green agenda},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1369527410000275},
issn = {13695274},
journal = {Current Opinion in Microbiology},
pmid = {20227907},
pages = {321--326},
volume = {13},
year = {2010},
abstract = {Production of polyhydroxyalkanoates (PHAs) has been investigated for more than eighty years but recently a number of factors including increase in the price of crude oil and public awareness of the environmental issues have become a notable driving force for extended research on biopolymers. The versatility of PHAs has made them good candidates for the study of their potential in a variety of areas from biomedical/medical fields to food, packaging, textile and household material. While production costs are still a drawback to wider usage of these biopolymers, their application as low volume high cost items is becoming a reality. The future trend is to focus on the development of more efficient and economical processes for PHA production, isolation, purification and improvement of PHA material properties. \textcopyright 2010 Elsevier Ltd. All rights reserved.},
doi = {10.1016/j.mib.2010.02.006},
number = {3},
shorttitle = {Polyhydroxyalkanoates},
}

@misc{2012HintonLecture,
author = {Geoffrey Hinton and Srivastava Nitish and Kevin Swersky},
year = {2017},
abstract = {Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012},
booktitle = {Neural Networks for Machine Learning},
title = {Lecture 6a: Overview of mini‐batch gradient descent},
}

@article{RoebelNeural,
author = {Axel R\"obel},
issn = {10495258},
abstract = {Time prediction is one of the major applications of neural networks. After a short introduction into the basic theoretical foundations we argue that the iterated prediction of a dynamical system may be interpreted as a model of the system dynamics. By means of RBF neural networks we describe a modeling approach and extend it to be able to model instationary systems. As a practical test for the capabilities of the method we investigate the modeling of musical and speech signals and demonstrate that the model may be used for synthesis of musical and speech signals.},
title = {Neural network modeling of speech and music signals},
year = {1997},
isbn = {0262100657},
journal = {Advances in Neural Information Processing Systems},
pages = {779--785},
}

@article{2016MehriSamplernn,
author = {Soroush Mehri and Kundan Kumar and Ishaan Gulrajani and Rithesh Kumar and Shubham Jain and Jose Sotelo and Aaron Courville and Yoshua Bengio},
arxivid = {1612.07837},
archiveprefix = {arXiv},
eprint = {1612.07837},
year = {2017},
url = {http://arxiv.org/abs/1612.07837},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
shorttitle = {SampleRNN},
title = {Samplernn: An unconditional end-to-end neural audio generation model},
abstract = {In this paper we propose a novel model for unconditional audio generation based on generating one audio sample at a time. We show that our model, which profits from combining memory-less modules, namely autoregressive multilayer percep-trons, and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans, on three datasets of different nature. Human evaluation on the generated samples indicate that our model is preferred over competing models. We also show how each component of the model contributes to the exhibited performance.},
}

@book{2010GrahameWind,
author = {Kenneth Grahame},
year = {2005},
title = {The Wind in the Willows},
edition = {New ed},
doi = {10.5117/9781904919513},
annote = {OCLC: ocn619552325},
publisher = {Oxford University Press},
booktitle = {The Wind in the Willows},
isbn = {978-0-19-956756-0},
keywords = {country life,england,fiction,friendship,of toad hall,pastoral fiction,river life,toad},
mendeley-tags = {country life,england,fiction,friendship,of toad hall,pastoral fiction,river life,toad},
}

@collection{2012AtkinsonManagement,
author = {Anthony a Atkinson and Robert S Kaplan and S Mark Young},
edition = {6th ed},
shorttitle = {Management accounting},
publisher = {Pearson},
abstract = {An approach to management accounting from the perspective of a business manager. Management Accounting: Information for Decision-Making and Strategy Execution explains how business managers can estimate and manage the cost and profitability of their products and customers. This text also covers how managers use financial and nonfinancial information to improve processes, design and develop new products, and motivate employee performance.},
annote = {OCLC: ocn639166510},
editor = {Atkinson, Anthony A},
isbn = {978-0-13-702497-1},
pages = {550},
title = {MANAGEMENT Information for Decision-Making and Strategy Execution},
year = {2012},
keywords = {managerial accounting},
mendeley-tags = {managerial accounting},
}

@book{2005BrownStrategic,
author = {Steve Brown and John Bessant and Fu Jia and Steve Brown and John Bessant and Fu Jia},
doi = {10.4324/9781315123370-2},
isbn = {978-0-7506-6319-9},
title = {Strategic Operations Management},
annote = {OCLC: 249641155},
editor = {Brown, Steve},
year = {2020},
abstract = {'Strategic Operations Management' examines the latest thinking in this fast-moving area. Businesses constantly face ongoing and increased amounts of competition. Coping with this competition demands that strategies must be already in place which can deal with key questions such as: what business is the firm really in? what does the firm do best, and why, where, and how can it outsource some of its activities? how can opportunities become quickly exploited and how can the firm's capabilities help to ward off external threats from new and existing players? This text believes that successful operations management depends on having strategies in place which combine both manufacturing and service areas into an overall customer offering. This means that strategic relations must be established with other players - operations management is no longer a firm-specific matter. 'Strategic Operations Management' combines four themes; strategy, services, innovation and management of relationships both in the supply chain and with other players. This is done by dividing chapters into a past/present/future scenario approach which illustrates how these strategies affect business. Strong team of writers of international standing Content is thought provoking and challenging - excellent in terms of stimulating debates New issues explored as well as old - contrasting mass production versus mass customisation and innovation},
pages = {43--99},
edition = {2. ed},
publisher = {Elsevier, Butterworth-Heinemann},
booktitle = {Strategic Operations Management},
}

@article{2014LongFully,
author = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
year = {2017},
archiveprefix = {arXiv},
abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build 'fully convolutional' networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {Fully Convolutional Networks for Semantic Segmentation},
arxivid = {1411.4038},
pages = {640--651},
url = {http://arxiv.org/abs/1411.4038},
volume = {39},
number = {4},
doi = {10.1109/TPAMI.2016.2572683},
eprint = {1411.4038},
pmid = {27244717},
keywords = {convolutional networks,deep learning,semantic segmentation,transfer learning},
mendeley-tags = {convolutional networks,deep learning,semantic segmentation,transfer learning},
}

@article{2015RadfordUnsupervised,
author = {Alec Radford and Luke Metz and Soumith Chintala},
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
url = {http://arxiv.org/abs/1511.06434},
eprint = {1511.06434},
archiveprefix = {arXiv},
year = {2016},
title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
arxivid = {1511.06434},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
}

@article{2017ZhuUnpaired,
author = {Jun Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G: X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F: Y → X and introduce a cycle consistency loss to enforce F(G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
issn = {23318422},
journal = {arXiv},
title = {Unpaired image-to-image translation using cycle-consistent adversarial networks},
url = {http://arxiv.org/abs/1703.10593},
year = {2017},
}

@article{2019EngelGansynth,
author = {Jesse Engel and Kumar Krishna Agrawal and Shuo Chen and Ishaan Gulrajani and Chris Donahue and Adam Roberts},
arxivid = {1902.08710},
journal = {arXiv},
title = {Gansynth: Adversarial neural audio synthesis},
year = {2019},
archiveprefix = {arXiv},
eprint = {1902.08710},
issn = {23318422},
shorttitle = {GANSynth},
url = {http://arxiv.org/abs/1902.08710},
abstract = {Efficient audio synthesis is an inherently difficult machine learning task, as human perception is sensitive to both global structure and fine-scale waveform coherence. Autoregressive models, such as WaveNet, model local structure but have slow iterative sampling and lack global latent structure. In contrast, Generative Adversarial Networks (GANs) have global latent conditioning and efficient parallel sampling, but struggle to generate locally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact generate high-fidelity and locally-coherent audio by modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Through extensive empirical investigations on the NSynth dataset, we demonstrate that GANs are able to outperform strong WaveNet baselines on automated and human evaluation metrics, and efficiently generate audio several orders of magnitude faster than their autoregressive counterparts.1},
}

@book{2018SpizhevoiOpencv,
author = {Alexey Spizhevoy and Aleks Rybnikov and  r},
year = {2018},
isbn = {978-1788474443},
annote = {OCLC: 1030817073},
abstract = {Annotation Recipe-based approach to tackle the most common problems in Computer Vision by leveraging the functionality of OpenCV using Python APIsKey FeaturesBuild computer vision applications with OpenCV functionality via Python APIGet to grips with image processing, multiple view geometry, and machine learningLearn to use deep learning models for image classification, object detection, and face recognitionBook DescriptionOpenCV 3 is a native cross-platform library for computer vision, machine learning, and image processing. OpenCV's convenient high-level APIs hide very powerful internals designed for computational efficiency that can take advantage of multicore and GPU processing. This book will help you tackle increasingly challenging computer vision problems by providing a number of recipes that you can use to improve your applications.In this book, you will learn how to process an image by manipulating pixels and analyze an image using histograms. Then, we'll show you how to apply image filters to enhance image content and exploit the image geometry in order to relay different views of a pictured scene. We'll explore techniques to achieve camera calibration and perform a multiple-view analysis.Later, you'll work on reconstructing a 3D scene from images, converting low-level pixel information to high-level concepts for applications such as object detection and recognition. You'll also discover how to process video from files or cameras and how to detect and track moving objects. Finally, you'll get acquainted with recent approaches in deep learning and neural networks.By the end of the book, you'll be able to apply your skills in OpenCV to create computer vision applications in various domains.What you will learnGet familiar with low-level image processing methodsSee the common linear algebra tools needed in computer visionWork with different camera models and epipolar geometryFind out how to detect interesting points in images and compare themBinarize images and mask out regions of interestDetect objects and track them in videosWho this book is forThis book is for developers who have a basic knowledge of Python. If you are aware of the basics of OpenCV and are ready to build computer vision systems that are smarter, faster, more complex, and more practical than the competition, then this book is for you.},
shorttitle = {OpenCV 3 Computer Vision with Python Cookbook},
url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=5332144},
title = {OpenCV 3 computer vision with Python cookbook: Leverage the power of OpenCV 3 and Python to build computer vision applications},
pages = {385},
publisher = {Packt Publishing},
}

@book{1997LockeConduct,
author = {John Locke and John Locke},
doi = {10.1037/13729-001},
publisher = {Thoemmes Pr},
isbn = {978-1-85506-225-2},
pages = {3--144},
abstract = {[Brackets] enclose editorial explanations. Small \textperiodcentereddots\textperiodcentered enclose material that has been added, but can be read as though it were part of the original text. Occasional •bullets, and also indenting of passages that are not quotations, are meant as aids to grasping the structure of a sentence or a thought. Every four-point ellipsis. .. . indicates the omission of a brief passage that seems to present more difficulty than it is worth. Longer omissions are reported between brackets in normal-sized type.-Locke wrote this in 1697, seven years before his death, but he didn't revise or publish it, and in a few places the text is evidently jumbled. The present version will omit some of those passages and will sort out the others as best it can. Most of the section-headings are Locke's.},
title = {Of the conduct of the understanding.},
booktitle = {Locke's conduct of the understanding (5th ed.).},
edition = {Facsimile edition},
year = {2012},
}

@book{2010LuptonThinking,
author = {S Goldstein},
publisher = {Princeton Architectural Press},
isbn = {978-1-56898-969-3},
pages = {67--68},
edition = {2nd rev. and expanded ed},
abstract = {\ldots This book is about thinking with typography—in the end, the emphasis falls on with. Typography is a tool for doing things with: shaping content, giving language a physical body, enabling the social flow of messages. Typography \ldots},
annote = {OCLC: ocn528665832},
shorttitle = {Thinking with type},
url = {https://books.google.com/books?hl=en&lr=&id=oz1FAwAAQBAJ&oi=fnd&pg=PA7&dq=simulation+%22social+flow%22%7C%22educational+flow%22&ots=i8CDTZoZSW&sig=YCdn-NLW21N0Z_nOcTJOERLzA4w},
issn = {0049-3155},
title = {Thinking with Type. A Critical Guide for Designers, Writers, Editors, & Students, 2nd edition},
volume = {60},
year = {2013},
booktitle = {Technical Communication},
number = {1},
keywords = {graphic design (typography,type and type-founding},
mendeley-tags = {graphic design (typography,type and type-founding},
}

@book{2006DevoreModern,
author = {Jay Devore},
abstract = {Probability and Statistics are studied by most science students, usually as a second- or third-year course. Many current texts in the area are just cookbooks and, as a result, students do not know why they perform the methods they are taught, or why the methods work. The strength of this book is that it readdresses these shortcomings; by using examples, often from real-life and using real data, the authors can show how the fundamentals of probabilistic and statistical theories arise intuitively. It provides a tried and tested, self-contained course, that can also be used for self-study.  A Modern Introduction to Probability and Statistics has numerous quick exercises to give direct feedback to the students. In addition the book contains over 350 exercises, half of which have answers, of which half have full solutions. A website at www.springeronline.com/1-85233-896-2 gives access to the data files used in the text, and, for instructors, the remaining solutions. The only pre-requisite for the book is a first course in calculus; the text covers standard statistics and probability material, and develops beyond traditional parametric models to the Poisson process, and on to useful modern methods such as the bootstrap.  This will be a key text for undergraduates in Computer Science, Physics, Mathematics, Chemistry, Biology and Business Studies who are studying a mathematical statistics course, and also for more intensive engineering statistics courses for undergraduates in all engineering subjects.},
shorttitle = {A Modern Introduction to Probability and Statistics},
booktitle = {Journal of the American Statistical Association},
doi = {10.1198/jasa.2006.s72},
title = {A Modern Introduction to Probability and Statistics: Understanding Why and How},
year = {2006},
volume = {101},
issn = {0162-1459},
number = {473},
pages = {393--394},
}

@book{2006LawsonHow,
author = {Bryan Lawson},
number = {January 2006},
url = {https://www.researchgate.net/publication/30872105},
abstract = {applicability for this approach.},
publisher = {Elsevier/Architectural Press},
isbn = {0750660775},
shorttitle = {How designers think},
edition = {4. ed},
title = {How designers think : the design process demystified - Loughborough University Library},
year = {2006},
annote = {OCLC: 254426229},
keywords = {bryan lawwon},
mendeley-tags = {bryan lawwon},
}

@book{2015HortonAndroid,
author = {John Horton},
shorttitle = {Android programming for beginners},
isbn = {978-1-78588-326-2},
pages = {660},
annote = {OCLC: 1011380341},
abstract = {Includes index. Annotation Learn all the Java and Android skills you need to start making powerful mobile applicationsAbout This Book Kick-start your Android programming career, or just have fun publishing apps to the Google Play marketplace A first-principles introduction to Java, via Android, which means you'll be able to start building your own applications from scratch Learn by example and build three real-world apps and over 40 mini apps throughout the bookWho This Book Is ForAre you trying to start a career in programming, but haven't found the right way in? Do you have a great idea for an app, but don't know how to make it a reality? Or maybe you're just frustrated that to learn Android, you must know java. If so, Android Programming for Beginners is for you. You don't need any programming experience to follow along with this book, just a computer and a sense of adventure. What You Will Learn Master the fundamentals of coding Java for Android Install and set up your Android development environment Build functional user interfaces with the Android Studio visual designer Add user interaction, data captures, sound, and animation to your apps Manage your apps' data using the built-in Android SQLite database Find out about the design patterns used by professionals to make top-grade applications Build, deploy, and publish real Android applications to the Google Play marketplaceIn DetailAndroid is the most popular OS in the world. There are millions of devices accessing tens of thousands of applications. It is many people's entry point into the world of technology; it is an operating system for everyone. Despite this, the entry-fee to actually make Android applications is usually a computer science degree, or five years' worth of Java experience. Android Programming for Beginners will be your companion to create Android applications from scratchwhether you're looking to start your programming career, make an application for work, be reintroduced to mobile development, or are just looking to program for fun. We will introduce you to all the fundamental concepts of programming in an Android context, from the Java basics to working with the Android API. All examples are created from within Android Studio, the official Android development environment that helps supercharge your application development process. After this crash-course, we'll dive deeper into Android programming and you'll learn how to create applications with a professional-standard UI through fragments, make location-aware apps with Google Maps integration, and store your user's data with SQLite. In addition, you'll see how to make your apps multilingual, capture images from a device's camera, and work with graphics, sound, and animations too. By the end of this book, you'll be ready to start building your own custom applications in Android and Java. Style and approachWith more than 40 mini apps to code and run, Android Programming for Beginners is a hands-on guide to learning Android and Java. Each example application demonstrates a different aspect of Android programming. Alongside these mini apps, we push your abilities by building three larger applications to demonstrate Android application development in context. Cover; Copyright; Credits; About the Author; About the Reviewers; www.PacktPub.com; Table of Contents; Preface; Chapter 1: The First App; How Java and Android work together; The Android API; Java is object-oriented; What exactly is Android?; The development environment; A note to the existing developers who use Eclipse; The JDK; What if I already have Java?; Installing the JDK; Setting up Android Studio; What makes an Android app; Android resources; The structure of Android's Java code; Android packages; Our first Android app; Creating the project; A note on version controlling. Deploying and testing the appDeploying to an emulator; Deploying to a real Android device; FAQ; Summary; Chapter 2: Java -- First Contact; Examining the log output; Exploring the project assets and code; Examining the layout file; Improving our app and deploying again; Modifying the UI; Meet Java; Java comments; Sending messages; Writing our first Java code; Writing our own Java methods; Examining the log output; FAQ; Summary; Chapter 3: Exploring Android Studio; The Android Studio guided tour; Parts of the UI; The console; More console features; The project explorer. Transforming the editor into a design studioE1 -- the Preview toolbar; E2 -- exploring the palette; E3 -- the layout preview; E4 -- the Component Tree; E5 -- the Properties window; E6 -- text and design view tabs; The project folder and file structure; FAQ; Summary; Chapter 4: Designing Layouts; Exploring Android UI design; Structure of a UI design; Configuring and using widgets; Widget properties; Experimenting with widgets; Containing widgets in layouts; RelativeLayout; Using LinearLayout; Summary; Chapter 5: Real-World Layouts; Building a real-world UI; Creating a tablet emulator. List-detail layout with scrollView and LinearLayoutDesigning a form with RelativeLayout; Summary; Chapter 6: The Life and Times of an Android App; Introduction to the Android lifecycle; A simplified explanation of the Android lifecycle; Lifecycle phases -- what we need to know; Lifecycle phases -- what we need to do; The lifecycle demonstration app; Some other overridden methods; The structure of Java code -- revisited; Summary; Chapter 7: Coding in Java Part 1 -- Variables, Decisions, and Loops; Java is everywhere; Syntax and jargon; More code comments; Storing and using data with variables. Types of variablesPrimitive types; Reference types; Variable declaration; Variable initialization; Changing values in variables with operators; Expressing yourself demo app; Decisions; Indenting our code; More operators; If they come over the bridge, shoot them; Else do this instead; Switching to make decisions; The Switch Demo app; Repeating code with loops; While loops; Breaking out of a loop; Continue; Do while loops; For loops; Loops demo app; Summary; Chapter 8: Coding in Java Part 2 -- Methods; Methods revisited; The method structure; Modifiers; Return types; The name of a method.},
edition = {First published},
publisher = {Packt Publishing},
url = {https://books.google.co.in/books/about/Android_Programming_for_Beginners.html?id=wTzlCwAAQBAJ&printsec=frontcover&source=kp_read_button&redir_esc=y#v=onepage&q&f=false},
year = {2015},
title = {Android programming for beginners: learn all the Java and Android skills you need to start making powerful mobile applications},
}

@book{2004MccorduckMachines,
author = {Michael J. Apter and Pamela McCorduck},
booktitle = {Leonardo},
isbn = {978-1-56881-205-2},
abstract = {first truly successful AI software},
pages = {242},
number = {3},
publisher = {A.K. Peters},
shorttitle = {Machines who think},
issn = {0024094X},
doi = {10.2307/1574702},
title = {Machines Who Think: A Personal Inquiry into the History and Prospects of Artificial Intelligence},
volume = {15},
edition = {25th anniversary update},
year = {1982},
keywords = {artificial intelligence,history},
mendeley-tags = {artificial intelligence,history},
}

@book{2010RumseyStatistics,
author = {Deborah Rumsey-Johnson},
pages = {192},
url = {http://www.amazon.com/Statistics-Essentials-Dummies-Lifestyles-Paperback/dp/0470618396%3FSubscriptionId%3D1V7VTJ4HA4MFT9XBJ1R2%26tag%3Dmekentosjcom-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0470618396},
title = {Statistics Essentials For Dummies (For Dummies (Lifestyles Paperback))},
publisher = {Wiley Pub., Inc},
isbn = {978-0-470-61839-4},
year = {2010},
abstract = {Statistics Essentials For Dummies not only provides students enrolled in Statistics I with an excellent high-level overview of key concepts, but it also serves as a reference or refresher for students in upper-level statistics courses. Free of review and ramp-up material, Statistics Essentials For Dummies sticks to the point, with content focused on key course topics only. It provides discrete explanations of essential concepts taught in a typical first semester college-level statistics course, from odds and error margins to confidence intervals and conclusions. This guide is also a perfect reference for parents who need to review critical statistics concepts as they help high school students with homework assignments, as well as for adult learners headed back into the classroom who just need a refresher of the core concepts.The Essentials For Dummies SeriesDummies is proud to present our new series, The Essentials For Dummies. Now students who are prepping for exams, preparing to study new material, or who just need a refresher can have a concise, easy-to-understand review guide that covers an entire course by concentrating solely on the most important concepts. From algebra and chemistry to grammar and Spanish, our expert authors focus on the skills students most need to succeed in a subject.},
series = {For dummies},
keywords = {statistics},
mendeley-tags = {statistics},
}

@book{2018LoderWeb,
author = {Wolfgang Loder},
publisher = {Apress},
title = {Web Applications with Elm},
shorttitle = {Web Applications with Elm},
booktitle = {Web Applications with Elm},
year = {2018},
isbn = {978-1-4842-2609-4 978-1-4842-2610-0},
doi = {10.1007/978-1-4842-2610-0},
}

@book{noauthor_portugues_nodate,
title = {PORTUGU\^ES Cesgranrio},
isbn = {978-85-352-5911-7},
}

@book{2011DefantClassical,
author = {Andreas Defant},
pages = {1--181},
doi = {10.1007/978-3-642-20438-8_1},
publisher = {Springer},
isbn = {9783642204371},
year = {2011},
number = {2021},
volume = {2021},
annote = {OCLC: ocn746846973},
issn = {00758434},
title = {Classical summation in commutative and noncommutative Lp-spaces},
series = {Lecture notes in mathematics},
booktitle = {Lecture Notes in Mathematics},
keywords = {lp spaces},
mendeley-tags = {lp spaces},
}

@book{2017GeronHands,
author = {Aur\'elien G\'eron},
shorttitle = {Hands-on machine learning with Scikit-Learn and TensorFlow},
url = {https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/},
abstract = {Second edition. "2nd edition updated for TensorFlow 2"--Page 1 of cover. Includes index. Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. The updated edition of this best-selling book uses concrete examples, minimal theory, and two production-ready Python frameworks-Scikit-Learn and TensorFlow 2-to help you gain an intuitive understanding of the concepts and tools for building intelligent systems. Practitioners will learn a range of techniques that they can quickly put to use on the job. Part 1 employs Scikit-Learn to introduce fundamental machine learning tasks, such as simple linear regression. Part 2, which has been significantly updated, employs Keras and TensorFlow 2 to guide the reader through more advanced machine learning methods using deep neural networks. With exercises in each chapter to help you apply what you've learned, all you need is programming experience to get started. NEW FOR THE SECOND EDITION:Updated all code to TensorFlow 2 ; Introduced the high-level Keras API ; New and expanded coverage including TensorFlow's Data API, Eager Execution, Estimators API, deploying on Google Cloud ML, handling time series, embeddings and more With Early Release ebooks, you get books in their earliest form-the author's raw and unedited content as he or she writes-so you can take advantage of these technologies long before the official release of these titles. You'll also receive updates when significant changes are made, new chapters are available, and the final ebook bundle is released. Part I, The fundamentals of machine learning. The machine learning landscape ; End-to-end machine learning project ; Classification ; Training models ; Support vector machines ; Decision trees ; Ensemble learning and random forests ; Dimensionality reduction ; Unsupervised learning techniques -- Part II, Neural networks and deep learning. Introduction to artificial neural networks with Keras ; Training deep neural networks ; Custom models and training with TensorFlow ; Loading and preprocessing data with TensorFlow ; Deep computer vision using convolutional neural networks ; Processing sequences using RNNs and CNNs ; Natural language processing with RNNs and attention ; Representation learning and generative learning using autoencoders and GANs ; Reinforcement learning ; Training and deploying TensorFlow models at scale ; Exercise solutions ; Machine learning project checklist ; SVM dual problem ; Autodiff ; Other popular ANN architectures ; Special data structures ; TensorFlow graphs.},
isbn = {9781492032649},
publisher = {O'Reilly Media},
year = {2019},
booktitle = {O'Reilly Media},
edition = {First edition},
title = {Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems},
annote = {OCLC: ocn953432302},
pages = {851},
keywords = {artificial intelligence,machine learning,neural networks -- artificial intelligence -- comp},
mendeley-tags = {artificial intelligence,machine learning,neural networks -- artificial intelligence -- comp},
}

@book{2015TallaridaPocket,
author = {Steve Abbott and Ronald J. Tallarida},
number = {500},
year = {2000},
booktitle = {The Mathematical Gazette},
volume = {84},
title = {Pocket Book of Integrals and Mathematical Formulas},
annote = {OCLC: 946827504},
isbn = {978-1-4987-0476-2},
abstract = {Convenient Organization of Essential Material so You Can Look up Formulas\nFast\n\nContaining a careful selection of standard and timely topics, the\nPocket Book of Integrals and Mathematical Formulas, Fourth Edition\npresents many numerical and statistical tables, scores of worked\nexamples, and the most useful mathematical formulas for engineering\nand scientific applications. This fourth edition of a bestseller\nprovides even more comprehensive coverage with the inclusion of several\nadditional topics, all while maintaining its accessible, clear style\nand handy size.\n\nNew to the Fourth Edition\n\n- An expanded chapter on series that covers many fascinating properties\nof the natural numbers that follow from number theory\n\n- New applications such as geostationary satellite orbits and drug\nkinetics\n\n- An expanded statistics section that discusses nonlinear regression\nas well as the normal approximation of the binomial distribution\n\n- Revised format of the table of integrals for easier use of the forms\nand functions\n\nThe book addresses a range of areas, from elementary algebra, geometry,\nmatrices, and trigonometry to calculus, vector analysis, differential\nequations, and statistics. Featuring a convenient, portable size,\nit is sure to remain in the pockets or on the desks of all who use\nmathematical formulas and tables of integrals and derivatives.},
pages = {352},
doi = {10.2307/3621709},
issn = {00255572},
}

@book{1995BaxterProduct,
author = {K.L. Edwards},
booktitle = {Materials & Design},
volume = {16},
shorttitle = {Product Design},
year = {1995},
isbn = {978-0-7487-4197-7},
publisher = {Routledge},
pages = {301},
doi = {10.1016/0261-3069(96)84967-3},
number = {5},
abstract = {The discovery of market needs and the manufacture of a product to meet those needs are integral parts of the same process. Since most textbooks on new product development are written from either a marketing or an engineering perspective, it is important for students to encounter these two aspects of product development together in a single text.Product Design: Practical Methods for the Systematic Development of New Products covers the entire new product development process, from market research through concept design, embodiment design, design for manufacture, and product launch. Systematic and practical in its approach, the text offers both a structured management framework for product development and an extensive range of specific design methods. Chapters feature "Design Toolkits" that provide detailed guidance on systematic design methods, present examples with familiar products, and conclude with reviews of key concepts.This major text aims to turn the often haphazard and unstructured product design process into a quality-controlled, streamlined, and manageable procedure. It is ideal for students of engineering, design, and technology on their path to designing new products.},
title = {Product design: Practical methods for the systematic development of new products},
issn = {02613069},
edition = {1 edition},
}

@article{gandhi_central_nodate,
author = {Gico Central and Degrau Cultural},
pages = {2--17},
title = {Central de Concursos / Degrau Cultural},
}

@book{2011JamesStudents,
author = {J. F. James},
edition = {3rd ed},
abstract = {Fourier transform theory is of central importance in a vast range of applications in physical science, engineering and applied mathematics. Providing a concise introduction to the theory and practice of Fourier transforms, this book is invaluable to students of physics, electrical and electronic engineering, and computer science. After a brief description of the basic ideas and theorems, the power of the technique is illustrated through applications in optics, spectroscopy, electronics and telecommunications. The rarely discussed but important field of multi-dimensional Fourier theory is covered, including a description of Computer Axial Tomography (CAT scanning). The book concludes by discussing digital methods, with particular attention to the Fast Fourier Transform and its implementation. This new edition has been revised to include new and interesting material, such as convolution with a sinusoid, coherence, the Michelson stellar interferometer and the van Cittert-Zernike theorem, Babinet's principle and dipole arrays.},
year = {2011},
isbn = {9780511762307},
title = {A student's guide to fourier transforms: With applications in physics and engineering, third edition},
volume = {9780521176835},
pages = {1--146},
doi = {10.1017/CBO9780511762307},
booktitle = {A Student's Guide to Fourier Transforms: With Applications in Physics and Engineering, Third Edition},
publisher = {Cambridge University Press},
shorttitle = {A student's guide to Fourier transforms},
}

@book{2011TzengMultiple,
author = {Gwo Hshiung Tzeng and Jih Jeng Huang},
series = {A Chapman ////////\\\& Hall book},
publisher = {CRC Press},
annote = {OCLC: 746841344},
isbn = {9781439861585},
abstract = {Decision makers are often faced with several conflicting alternatives. How do they evaluate trade-offs when there are more than three criteria? To help people make optimal decisions, scholars in the discipline of multiple criteria decision making (MCDM) continue to develop new methods for structuring preferences and determining the correct relative weights for criteria. A compilation of modern decision-making techniques, Multiple Attribute Decision Making: Methods and Applications focuses on the fuzzy set approach to multiple attribute decision making (MADM). Drawing on their experience, the authors bring together current methods and real-life applications of MADM techniques for decision analysis. They also propose a novel hybrid MADM model that combines DEMATEL and analytic network process (ANP) with VIKOR procedures. The first part of the book focuses on the theory of each method and includes examples that can be calculated without a computer, providing a complete understanding of the procedures. Methods include the analytic hierarchy process (AHP), ANP, simple additive weighting method, ELECTRE, PROMETHEE, the gray relational model, fuzzy integral technique, rough sets, and the structural model. Integrating theory and practice, the second part of the book illustrates how methods can be used to solve real-world MADM problems. Applications covered in the book include: • AHP to select planning and design services for a construction project • TOPSIS and VIKOR to evaluate the best alternative-fuel vehicles for urban areas • ELECTRE to solve network design problems in urban transportation planning • PROMETEE to set priorities for the development of new energy systems, from solar thermal to hydrogen energy • Fuzzy integrals to evaluate enterprise intranet web sites • Rough sets to make decisions in insurance marketing Helping readers understand how to apply MADM techniques to their decision making, this book is suitable for undergraduate and graduate students as well as practitioners.},
year = {2011},
booktitle = {Multiple Attribute Decision Making: Methods and Applications},
pages = {1--333},
title = {Multiple attribute decision making: Methods and applications},
shorttitle = {Multiple attribute decision making},
}

@book{martins_lingua_nodate,
author = {Andr\'ea Martins},
publisher = {Central de Concursos / Degrau Cultural},
title = {L\'INGUA PORTUGUESA 1.000 Exerc\'icios Quest\~oes simuladas e quest\~oes de concursos anteriores com os gabaritos},
}

@book{2017HeizerOperations,
author = {F. Schotanus},
abstract = {Operations management (OM) is the set of activities that creates value in the form of goods and services by transforming inputs into outputs.},
edition = {12},
pages = {276--276},
publisher = {Pearson},
isbn = {978-0-13-413042-2},
number = {4 (Dec.)},
shorttitle = {Operations management},
title = {Operations management: sustainability and supply chain management},
booktitle = {Journal of purchasing and supply management},
volume = {19},
year = {2013},
issn = {1478-4092},
keywords = {production management},
mendeley-tags = {production management},
}

@book{2015FrazierOperations,
author = {Gaither Frazier},
title = {Operations Management},
isbn = {978-81-315-0048-4},
publisher = {Thomson Press},
edition = {9th edition},
abstract = {Printed in Asia - Carries Same Contents as of US edition - Opt Expedited Shipping for 3 to 4 day delivery - - Includes CD-ROM - Printed in COLORS},
}

@book{2016SlackOperations,
author = {Prof Nigel Slack and  Br and Prof Alistair on-Jones and Prof Robert Johnston},
publisher = {Pearson},
abstract = {Were you looking for the book with access to MyOMLab? This product is the book alone and does NOT come with access to MyOMLab. Buy Operations Management, 8th edition with MyOMLab access card (ISBN 9781292098777) if you need access to MyOMLab as well, and save money on this resource. You will also need a course ID from your instructor to access MyOMLab. Operations management is important, exciting, challenging \ldots and everywhere you look! Important, because it enables organizations to provide services and products that we all need Exciting, because it is central to constant changes in customer preference, networks of supply and demand, and developments in technology Challenging, because solutions must be must be financially sound, resource-efficient, as well as environmentally and socially responsible And everywhere, because in our daily lives, whether at work or at home, we all experience and manage processes and operations. New features: There are now more than 110 of the popular ‘Operations in Practice' examples throughout the book, over 40 /\\% of which are new. The importance of sustainability and Corporate Social Responsibility (CSR) has been emphasized further, and included throughout the book. We have even further strengthened the emphasis on the idea that ‘operations management' is relevant to every type of business and all functional areas of the organization. Many new ideas in operations management have been incorporated, including the ‘three level' approach to performance, the relationship between innovation, creativity and design, crowdsourcing, ideas management, business ecosystems, triadic relationships, office layout, telecommuting and organisational ‘ambidexterity'. However, we have retained the emphasis on the foundations of the subject. Six of the 19 cases at the end of the chapter are new (but the old ones are still available on the web site), and provide an up-to-date selection of operations issues. Operations Management focuses on the sustainable and socially responsible imperatives of operations management, using over 120 cases and illustrations of real-life operations around the world, including Apple, M\'edecins Sans Fronti\`eres, Amazon, Ecover, Dyson, Disneyland Paris, Google, The North Face, and many more. This is 24-carat excellence'Par \AAhlstr\"om, Torsten and Ragnar S\"oderberg Chair of Business Administration, Stockholm School of Economics 'Operations Management is engaging and accessible, but it never dumbs-down. The book is comprehensive, but not overwhelming. Students hold on to this one; it's a ‘keeper'.'Michael Shulver, Birmingham Business School 'This continues to be the definitive operations Management text \ldots written by the masters of the field!'Dr Ross Ritchie, Lecturer in Operations Management, Loughborough University 'An essential text packed full of up-to-date examples that really bring the subject to life'Claire Moxham, University of Liverpool Management School 'An excellent book for those studying operations management. This book provides great illustrations to seamlessly link theory with practice' Frank Wiengarten, ESADE Business School Operations Management by Nigel Slack and Alistair Brandon-Jones is quite simply the best text on operations management. Comprehensive, engaging and insightful, I cannot recommend this book highly enough'Professor Andy Neely, Head, Institute for Manufacturing, Cambridge University Carrie Queenan, University of South Carolina Peter Race, Henley Business School, University of Reading},
title = {Operations Management},
edition = {8},
isbn = {978-1-292-09867-8},
}

@book{2013OliveiraNocoes,
author = {Michelle Silva and D E Oliveira and Sherley Cabral and Moreira Michelle and Silva De},
isbn = {978-85-64124-17-2},
title = {No\cc\~oes De Contabilidade B\'asica Para Cursos T\'ecnicos},
}

@book{2017WalpoleProbability,
author = {Ronald E. Walpole and Raymond H. Myers and Sharon L. Myers and Keying Ye},
abstract = {Ninth edition.},
url = {https://books.google.com/books?id=aOKHrgEACAAJ},
annote = {OCLC: 1014366070},
pages = {791},
shorttitle = {Probability ///////\\& statistics for engineers ///////\\& scientists},
isbn = {0134115856},
title = {Probability & statistics for engineers & scientists : MyStatLab update},
}

@collection{2008GowersPrinceton,
author = {Timothy Gowers and June Barrow-Green and Imre Leader},
publisher = {Princeton University Press},
year = {2010},
booktitle = {The Princeton Companion to Mathematics},
abstract = {This is a one-of-a-kind reference for anyone with a serious interest in mathematics. Edited by Timothy Gowers, a recipient of the Fields Medal, it presents nearly two hundred entries, written especially for this book by some of the world's leading mathematicians, that introduce basic mathematical tools and vocabulary; trace the development of modern mathematics; explain essential terms and concepts; examine core ideas in major areas of mathematics; describe the achievements of scores of famous mathematicians; explore the impact of mathematics on other disciplines such as biology, finance, and music--and much, much more. Unparalleled in its depth of coverage, The Princeton Companion to Mathematics surveys the most active and exciting branches of pure mathematics, providing the context and broad perspective that are vital at a time of increasing specialization in the field. Packed with information and presented in an accessible style, this is an indispensable resource for undergraduate and graduate students in mathematics as well as for researchers and scholars seeking to understand areas outside their specialties. Features nearly 200 entries, organized thematically and written by an international team of distinguished contributors: Presents major ideas and branches of pure mathematics in a clear, accessible style; Defines and explains important mathematical concepts, methods, theorems, and open problems; Introduces the language of mathematics and the goals of mathematical research; Covers number theory, algebra, analysis, geometry, logic, probability, and more; Traces the history and development of modern mathematics; Profiles more than ninety-five mathematicians who influenced those working today; Explores the influence of mathematics on other disciplines; Includes bibliographies, cross-references, and a comprehensive index.},
issn = {0009-4978},
title = {The Princeton companion to mathematics},
isbn = {9781400830398},
pages = {1--1034},
doi = {10.5860/choice.46-3606},
editor = {Gowers, Timothy and Barrow-Green, June and Leader, Imre},
keywords = {mathematics},
mendeley-tags = {mathematics},
}

@book{2012GitmanPrinciples,
author = {Will Unwin},
issn = {08908389},
isbn = {0030558832},
annote = {OCLC: 991834493},
pages = {106--107},
number = {1},
abstract = {The article reviews the book "Managerial Finance," by J. Fred Weston.},
volume = {21},
booktitle = {The British Accounting Review},
title = {Principles of Managerial finance},
year = {1989},
publisher = {Prentice Hall},
}

@book{2003BilaniukProblem,
author = {Stefan Bilaniuk},
abstract = {This is a text for a problem-oriented course on math- ematical logic and computability.},
pages = {1--166},
booktitle = {Language},
url = {http://www.trentu.ca/academic/math/sb/416H/pcml-ii-15b.pdf},
title = {A Problem Course in Mathematical Logic},
year = {2003},
keywords = {a problem oriented course,a text,abstract,bilaniuk,computability,copyright c 1994 2003 stefan,ematical logic computability,incompleteness,logic,math,phrases},
mendeley-tags = {a problem oriented course,a text,abstract,bilaniuk,computability,copyright c 1994 2003 stefan,ematical logic computability,incompleteness,logic,math,phrases},
}

@book{2009FlajoletAnalytic,
author = {Philippe Flajolet and Robert Sedgewick},
abstract = {Analytic Combinatorics is a self-contained treatment of the mathematics underlying the analysis of discrete structures, which has emerged over the past several decades as an essential tool in the understanding of properties of computer programs and scientific models with applications in physics, biology and chemistry. Thorough treatment of a large number of classical applications is an essential aspect of the presentation. Written by the leaders in the field of analytic combinatorics, this text is certain to become the definitive reference on the topic. The text is complemented with exercises, examples, appendices and notes to aid understanding therefore, it can be used as the basis for an advanced undergraduate or a graduate course on the subject, or for self-study.},
year = {2009},
publisher = {Cambridge University Press},
doi = {10.1017/CBO9780511801655},
pages = {1--810},
isbn = {9780511801655},
annote = {OCLC: ocn244767782},
title = {Analytic combinatorics},
booktitle = {Analytic Combinatorics},
keywords = {combinatieleer,combinatorial analysis},
mendeley-tags = {combinatieleer,combinatorial analysis},
}

@book{2016GastelHow,
author = {Vernon Booth},
number = {3},
pages = {102--102},
title = {How to write and publish a scientific paper},
volume = {12},
issn = {18791468},
booktitle = {Biochemical Education},
doi = {10.1016/0307-4412(84)90089-X},
edition = {Eighth edition},
publisher = {Greenwood, an imprint of ABC-CLIO, LLC},
isbn = {978-1-4408-4262-7 978-1-4408-4280-1},
year = {1984},
keywords = {technical writing},
mendeley-tags = {technical writing},
}

@book{2009DeKlerkIllustrated,
author = {Judith De Klerk},
annote = {OCLC: 937425073},
isbn = {978-0-7339-8661-1},
title = {Illustrated Maths Dictionary 4th Edition},
publisher = {Pearson},
year = {2007},
abstract = {Presenting the Illustrated Maths Dictionary 4th Edition, the revised and improved edition of Australia's best-selling mathematics dictionary by Judith De Klerk. New features in this fourth edition: new, cleaner design; computer terms with mathematical connotations; conversion tables; over fifty new entries; a bonus electronic version of the dictionary on CD-ROM. Together with the best features of previous editions: definitions written in simple language that children can understand but without losing accuracy; clear, precise and concise explanations of difficult terms; definitions that are supported by hundreds of examples and illustrations; a Useful Information section providing symbols, formulae and other supporting mathematical terms. The Illustrated Maths Dictionary 4th edition is an essential resource for primary and lower secondary students, teachers, student teachers and parents.},
}

@book{2012GarrisonManagerial,
author = {Charles Wankel and David G. Woodward},
annote = {OCLC: ocn674938871},
edition = {14th ed},
booktitle = {Encyclopedia of Business in Today's World},
publisher = {McGraw-Hill/Irwin},
doi = {10.4135/9781412964289.n608},
year = {2012},
isbn = {978-0-07-811100-6},
title = {Managerial Accounting},
keywords = {managerial accounting},
mendeley-tags = {managerial accounting},
}

@book{2009ClaphamConcise,
author = {Susan T. Sommer and Harold Rosenthal and John Warrack},
year = {1980},
isbn = {978-0-19-923594-0},
publisher = {Oxford University Press},
annote = {OCLC: ocn299242316},
doi = {10.2307/939825},
edition = {4},
pages = {660},
series = {Oxford paperback reference},
volume = {36},
issn = {00274380},
abstract = {Derived from the full Oxford Dictionary of Opera, this is the most authoritative and up-to-date dictionary of opera available in paperback. Fully revised for this new edition with over 3,500 entries, it is designed to be accessible to all those who enjoy opera, whether at the opera-house or at home. Here opera buffs will have at their fingertips plot synopses and first performance details, bibliographies of works about opera, entries on singers (including their debuts and career highlights, with notes on voice type, style, and reputation), definitions and discussions of technical terms and operatic styles, and surveys of the history of opera worldwide. Included also are separate entries for well-known roles, arias, and choruses.},
booktitle = {Notes},
number = {3},
title = {The Concise Oxford Dictionary of Opera},
}

@collection{2012WieringReinforcement,
series = {Adaptation, learning, and optimization},
publisher = {Springer},
isbn = {978-3-642-27644-6 978-3-642-27645-3},
title = {Reinforcement learning: state-of-the-art},
annote = {OCLC: ocn768170254},
editor = {Wiering, Marco and van Otterlo, Martijn},
shorttitle = {Reinforcement learning},
volume = {12},
}

@article{2013ChadeganiComparison,
author = {Arezoo Aghaei Chadegani and Hadi Salehi and Melor M. Md Yunus and Hadi Farhadi and Masood Fooladi and Maryam Farhadi and Nader Ale Ebrahim},
url = {http://www.ccsenet.org/journal/index.php/ass/article/view/26960},
volume = {9},
year = {2013},
journal = {Asian Social Science},
arxivid = {1305.0377},
shorttitle = {A Comparison between Two Main Academic Literature Collections},
doi = {10.5539/ass.v9n5p18},
eprint = {1305.0377},
title = {A comparison between two main academic literature collections: Web of science and scopus databases},
issn = {19112017},
archiveprefix = {arXiv},
number = {5},
pages = {18--26},
abstract = {Nowadays, the world's scientific community has been publishing an enormous number of papers in different scientific fields. In such environment, it is essential to know which databases are equally efficient and objective for literature searches. It seems that two most extensive databases are Web of Science and Scopus. Besides searching the literature, these two databases used to rank journals in terms of their productivity and the total citations received to indicate the journals impact, prestige or influence. This article attempts to provide a comprehensive comparison of these databases to answer frequent questions which researchers ask, such as: How Web of Science and Scopus are different? In which aspects these two databases are similar? Or, if the researchers are forced to choose one of them, which one should they prefer? For answering these questions, these two databases will be compared based on their qualitative and quantitative characteristics.},
keywords = {citation tracking,citations,coverage,database,h-index,impact factor,indexing,provenance,researcher id,researcher profile,scopus,searching,web of science},
mendeley-tags = {citation tracking,citations,coverage,database,h-index,impact factor,indexing,provenance,researcher id,researcher profile,scopus,searching,web of science},
}

@article{2016SinghChawlaUnsung,
author = {Dalmeet Singh Chawla},
year = {2016},
pages = {115--116},
volume = {529},
doi = {10.1038/529115a},
number = {7584},
journal = {Nature},
title = {The unsung heroes of scientific software},
issn = {14764687},
pmid = {26738597},
}

@article{1972GarfieldCitation,
author = {Haseeb F. Rashid},
abstract = {A new formula for establishing the relationship between the number of papers (n) published in a journal of physics, chemistry or biology and the rank (R) of the journal concerned is proposed. The new formula is straightforward and simple, and appears to lead to a reasonably accurate prediction of the number of published source items in a journal, provided the rank of the journal is known. The proposed formula may be considered as a modification of or alternative to Bradford's law. \textcopyright 1991 by The Haworth Press, Inc.},
issn = {15411095},
number = {2-3},
doi = {10.1300/J123v20n02_05},
journal = {Serials Librarian},
volume = {20},
pages = {55--64},
year = {1991},
title = {Bibliometric analysis as a tool in journal evaluation},
}

@article{2018KumarIs,
author = {Gopalakrishnan Sundaram and Theyagarajan Ramakrishnan and Harinath Parthasarathy and Manoj Raja and Samuel Raj},
pages = {113--118},
doi = {10.4103/jisp.jisp},
shorttitle = {Is "Impact" the "Factor" that matters\ldots?},
title = {disease : A cross ‑ link of sorts !},
volume = {22},
year = {2018},
issn = {0972-124X},
number = {May},
url = {http://www.jisponline.com/text.asp?2018/22/2/95/230828},
keywords = {access this article online,chronic generalized periodontitis,density lipoprotein,fenugreek,glycosylated hemoglobin,low,total cholesterol,triglycerides,type 2 diabetes mellitus},
mendeley-tags = {access this article online,chronic generalized periodontitis,density lipoprotein,fenugreek,glycosylated hemoglobin,low,total cholesterol,triglycerides,type 2 diabetes mellitus},
}

@article{2005JacsoAs,
author = {Peter Jacso},
volume = {89},
issn = {00113891},
title = {As we may search - Comparison of major features of the Web of Science, Scopus, and Google Scholar citation-based and citation-enhanced databases},
year = {2005},
number = {9},
pages = {1537--1547},
journal = {Current Science},
keywords = {google scholar,scopus,web of science},
mendeley-tags = {google scholar,scopus,web of science},
}

@article{2006EditorsImpact,
author = {The PLoS Medicine Editors},
year = {2006},
issn = {15491277},
journal = {PLoS Medicine},
pages = {0707--0708},
doi = {10.1371/journal.pmed.0030291},
volume = {3},
pmid = {16749869},
number = {6},
title = {The impact factor game: It is time to find a better way to assess the scientific literature},
}

@article{meho_impact_nodate,
author = {Lokman I. Meho and Kiduk Yang},
number = {13},
pages = {2105--2125},
title = {Impact of data sources on citation counts and rankings of LIS faculty: Web of science versus scopus and google scholar},
year = {2007},
issn = {15322882},
doi = {10.1002/asi.20677},
abstract = {The Institute for Scientific Information's (ISI, now Thomson Scientific, Philadelphia, PA) citation databases have been used for decades as a starting point and often as the only tools for locating citations and/or conducting citation analyses. The ISI databases (or Web of Science [WoS]), however, may no longer be sufficient because new databases and tools that allow citation searching are now available. Using citations to the work of 25 library and information science (LIS) faculty members as a case study, the authors examine the effects of using Scopus and Google Scholar (GS) on the citation counts and rankings of scholars as measured by WoS. Overall, more than 10,000 citing and purportedly citing documents were examined. Results show that Scopus significantly alters the relative ranking of those scholars that appear in the middle of the rankings and that GS stands out in its coverage of conference proceedings as well as international, non-English language journals. The use of Scopus and GS, in addition to WoS, helps reveal a more accurate and comprehensive picture of the scholarly impact of authors. The WoS data took about 100 hours of collecting and processing time, Scopus consumed 200 hours, and GS a grueling 3,000 hours.},
journal = {Journal of the American Society for Information Science and Technology},
volume = {58},
}

@article{2008FalagasComparison,
author = {Matthew E. Falagas and Eleni I. Pitsouni and George A. Malietzis and Georgios Pappas},
title = {Comparison of PubMed, Scopus, Web of Science, and Google Scholar: strengths and weaknesses},
pmid = {17884971},
doi = {10.1096/fj.07-9492lsf},
abstract = {The evolution of the electronic age has led to the development of numerous medical databases on the World Wide Web, offering search facilities on a particular subject and the ability to perform citation analysis. We compared the content coverage and practical utility of PubMed, Scopus, Web of Science, and Google Scholar. The official Web pages of the databases were used to extract information on the range of journals covered, search facilities and restrictions, and update frequency. We used the example of a keyword search to evaluate the usefulness of these databases in biomedical information retrieval and a specific published article to evaluate their utility in performing citation analysis. All databases were practical in use and offered numerous search facilities. PubMed and Google Scholar are accessed for free. The keyword search with PubMed offers optimal update frequency and includes online early articles; other databases can rate articles by number of citations, as an index of importance. For citation analysis, Scopus offers about 20% more coverage than Web of Science, whereas Google Scholar offers results of inconsistent accuracy. PubMed remains an optimal tool in biomedical electronic research. Scopus covers a wider journal range, of help both in keyword searching and citation analysis, but it is currently limited to recent articles (published after 1995) compared with Web of Science. Google Scholar, as for the Web in general, can help in the retrieval of even the most obscure information but its use is marred by inadequate, less often updated, citation information.},
journal = {The FASEB Journal},
issn = {0892-6638},
shorttitle = {Comparison of PubMed, Scopus, Web of Science, and Google Scholar},
volume = {22},
pages = {338--342},
year = {2008},
number = {2},
}

@article{rossner_irreproducible_nodate,
author = {Mike Rossner and Heather Van Epps and Emma Hill},
year = {2008},
doi = {10.1084/jem.20080053},
title = {Irreproducible results: A response to Thomson Scientific},
number = {2},
issn = {00221007},
journal = {Journal of Experimental Medicine},
pmid = {18187691},
pages = {260--261},
volume = {205},
}

@article{2009BrumbackImpact,
author = {Roger A. Brumback},
volume = {24},
number = {3},
pmid = {19258283},
year = {2009},
pages = {260--262},
shorttitle = {Impact Factor Wars},
doi = {10.1177/0883073808331366},
title = {Impact factor wars: Episode V - The empire strikes back},
issn = {08830738},
journal = {Journal of Child Neurology},
}

@article{2007RossnerShow,
author = {Mike Rossner and Heather Van Epps and Emma Hill},
pmid = {18086910},
title = {Show me the data},
doi = {10.1083/jcb.200711140},
number = {6},
journal = {Journal of Cell Biology},
volume = {179},
year = {2007},
pages = {1091--1092},
issn = {00219525},
}

@inproceedings{2009AlvesPre,
author = {Ivan Alves and Atila Aragao and Braulio-Luis Bastos and JOSE FALCAO and E Fartes},
title = {Pre-Salt Santos Basin—Well Construction Learning Curve Acceleration},
abstract = {Drilling and completing either exploratory or development wells in Pre-Salt prospects present several challenges. The wells are located in very deep waters, beyond 2,000 m WD and they are also deep wells, with more than 5,000 m TVD. Pressure and temperature is normal, but contaminants such as H2S and CO2 represent an additional difficulty. Most of all, drilling through salt layers as thick as 2,000 m presents the most challenging aspect of these wells. Directional, extended reach (ERW), horizontal and multilateral wells will be evaluated for production development, but the reservoir is a carbonate horizon just below the salt, meaning that high angle navigation and multilateral joints will be located inside the salt layers. These wells measured depths will reach 8,000 m or more. The salt geo-mechanical loads on the casing and cementing will require high strength materials and high capacity rig equipment. The competency of the salt formations and, most of all, of the carbonate reservoir, totaling more than 3,000 m to be drilled, will require special BHA and bit design to increase penetration rates, thus reducing rig time. Carbonate reservoir will require production liner, perforations/slots and stimulation treatments designed to maximize production. Although these challenges could be overcome today, with existing technology, due to the current high costs scenario, well construction time and risks must be minimized. Some technology development is already underway to address these issues, but most of the gains can be materialized without new technology, by proper engineering design, risk management and learning curve acceleration. After 8 wells drilled in Pre-Salt prospects, Petrobras has already gained important know-how in these projects, but there is still a long way ahead. In the following years, well construction campaign for an Extended Well Testing (EWT) and a Pilot Production System in the Tupi Pre-Salt area, plus additional exploration wells, will provide field test opportunities for development and optimization of well engineering techniques and equipment. This paper will present the highlights of Petrobras E&P program to make the best use of these opportunities to leverage the well construction learning curve.},
booktitle = {Proceedings of Offshore Technology Conference},
year = {2009},
doi = {10.4043/otc-20177-ms},
publisher = {The Offshore Technology Conference},
url = {http://www.onepetro.org/mslib/servlet/onepetropreview?id=OTC-20177-MS///////%5C%5C&soc=OTC},
}

@article{2010VaccaroProspective,
author = {Guilherme Lu\'is Roehe Vaccaro and Christopher Pohlmann and Andr\'e Cirne Lima and Manoela Silveira dos Santos and Cristina Botti de Souza and Debora Azevedo},
pages = {1263--1272},
volume = {14},
journal = {Renewable and Sustainable Energy Reviews},
abstract = {This paper presents a study based on the Systems Thinking and Scenario Planning (STSP) method, focusing the biodiesel production chain of Rio Grande do Sul State. The aim of the study was to identify key elements to comprehend the systemic structure of interaction among the ties of this chain. The study was held by a team of specialists over five months, including 15 meetings. Discussions were based on quantitative and qualitative data and a systemic map was constructed and refined. Based on this modeling, four different prospective scenarios were comparatively analyzed in order to propose strategic actions to promote the sustainability and competitiveness of the chain. The results were then presented to two different groups of external specialists in order to validate the conclusions drawn and the proposals. Both groups agreed with the ideas presented. The paper is constructed as follows: a brief introduction focusing on contextual elements of the biodiesel production in Brazil and in Rio Grande do Sul; some background material regarding agroindustrial production chains and an overview of the biodiesel production chain of interest; a description of the method used to perform the research; main results and discussion; and conclusions. With this paper the authors also hope to contribute to the discussion regarding competitiveness and sustainability of biofuel chains in Brazil. \textcopyright 2009 Elsevier Ltd. All rights reserved.},
year = {2010},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364032109002883},
issn = {13640321},
title = {Prospective scenarios for the biodiesel chain of a Brazilian state},
number = {4},
doi = {10.1016/j.rser.2009.12.008},
keywords = {biodiesel,competitiveness,scenario planning,sustainability,systems thinking},
mendeley-tags = {biodiesel,competitiveness,scenario planning,sustainability,systems thinking},
}

@article{gouveia_tecnologia_nodate,
author = {Fl\'avia Gouveia},
title = {Tecnologia nacional para extrair petr\'oleo e g\'as do pr\'e-sal},
volume = {6},
pages = {30--35},
url = {http://inovacao.scielo.br/pdf/cinov/v6n1/10.pdf},
year = {2010},
issn = {1984-4395},
journal = {Conhecimento & Inova\cc\~ao},
}

@article{2013AmerReview,
author = {Muhammad Amer and Tugrul U. Daim and Antonie Jetter},
pages = {23--40},
issn = {00163287},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328712001978},
title = {A review of scenario planning},
volume = {46},
year = {2013},
doi = {10.1016/j.futures.2012.10.003},
journal = {Futures},
abstract = {This paper reviews the scenario planning literature looking for answers for the following questions: How do qualitative and quantitative scenario methods differ and what are the advantages and disadvantages? What methods exist for quantitative scenario planning? Particularly quantitative scenario methods often lead to a large number of so-called "raw" scenarios that need to be further refined, discussed, and verbally described. How do scenario planners select raw scenarios for further exploration and how many should they choose? How is the problem of validation addressed in scenario studies?. \textcopyright 2012 Elsevier Ltd.},
}

@inproceedings{2012PizarroChallenges,
author = {Jorge Oscar De Sant Anna Pizarro and Celso Cesar Moreira Branco},
publisher = {Society of Petroleum Engineers},
abstract = {Carbonate reservoirs contain expressive part of the world oil reserves. The exploitation of these resources, however, presents several challenges mainly associated with their complex pore geometry, large scale variation in permeability and sometimes unfavorable wettability. These challenges can become more significant when we move to a deep offshore environment. As offshore projects need to be planned well in advance, due to the lack of room in the platforms for future expansion, the pioneer application of EOR methods needs to be considered from the conceptual stage of the development. This paper addresses the approach used to design the development basis for Lula field, formerly known as Tupi area, in the Pre-Salt Cluster (SBPSC) in Santos Basin, offshore Brazil. It focuses on the strategy of phased development, dynamic data acquisition and actions to add flexibility to the production system and how to manage uncertainties. A comprehensive analysis of the existing uncertainties, such as the reservoir characterization, early water and gas breakthrough, bypassed oil saturation, flow assurance in deep water flowlines and CaCO 3 scale possibility in production wells, favored a phased development concept aiming to mitigate risks.. The approach used to cope with these uncertainties in a Pilot Project as well as in the future development scenarios is presented. Most of the discussion is focused on how to consider feasible Enhanced Oil Recovery techniques through Pilot testing and future implementation in large scale in the field. It comprises the investigation of different recovery processes and first field results, including miscible processes using hydrocarbon gas and CO2. To optimize the oil displacement, a water alternating gas (WAG) injection process is also being designed. After one and a half year of extended well test production and the implementation of the first Pilot project in January, 2011, results confirm the decision of providing additional flexibility to the project. Dynamic appraisal proved essential to assess reservoir connectivity, evaluate stimulation methods, support reservoir characterization studies and define aspects related to flow in subsea lines. The first results of the injection of the CO2 stream, separated from the associated gas in the Pilot project, indicate that the chosen strategy has potential to be a successful one. The continuing production and pressure data monitoring of the WAG implementation in the Pilot, from 2012 on, will provide a more definitive conclusion about the feasibility. Good responses will translate in the EOR expansion to field scale. Copyright 2012, Society of Petroleum Engineers.},
doi = {10.2118/155665-ms},
pages = {954--966},
year = {2012},
isbn = {9781622760473},
title = {Challenges in implementing an EOR project in the Pre-Salt province in deep offshore Brasil},
volume = {2},
booktitle = {Society of Petroleum Engineers - SPE EOR Conference at Oil and Gas West Asia 2012, OGWA - EOR: Building Towards Sustainable Growth},
}

@article{2012RiccominiPre,
author = {Claudio Riccomini and Lucy Gomes Sant´Anna and Colombo Celso Gaeta Tassinari},
abstract = {O pr\'e-sal \'e a maior descoberta petrol\'ifera mundial dos \'ultimos cinquenta anos. O petr\'oleo do pr\'e-sal est\'a alojado em reservat\'orios situados abaixo de extensa e espessa camada de sal que ocorre na regi\~ao costa-afora do Esp\'irito Santo at\'e Santa Catarina, em \'aguas profundas e ultraprofundas, localizados sob 3 a 4 km de rochas abaixo do fundo marinho. As investiga- \cc\~oes j\'a realizadas em algumas \'areas do pr\'e-sal revelaram prov\'aveis campos gigantes e supergigantes com volumes recuper\'aveis de at\'e 16 bilh\~oes de barris de \'oleo equivalente – boe (somat\'orio de petr\'oleo e g\'as natural), e potencial de ocorr\^encia de 70 a 100 bilh\~oes de barris de \'oleo equivalente, o que colocaria o Brasil entre os principais pa\'ises produtores. Este artigo aborda as condi\cc\~oes geol\'ogicas e o cen\'ario do passado no qual foram formadas as reservas do pr\'e-sal, as caracter\'isticas do sistema petrol\'ifero, reservas projetadas, explora\cc\~ao e produ\cc\~ao.},
journal = {Revista USP},
year = {2012},
shorttitle = {Pr\'e-sal},
issn = {0103-9989},
title = {Pr\'e-sal: geologia e explora\cc\~ao},
url = {http://www.revistas.usp.br/revusp/article/view/52236},
volume = {0},
pages = {33},
doi = {10.11606/issn.2316-9036.v0i95p33-42},
number = {95},
}

@inproceedings{2012MoczydlowerDevelopment,
author = {B. Moczydlower and M. C. Salom\~ao and C. C.M. Branco and R. K. Romeu and T. R. Homem and L. C.S. Freitas and H. A.T.S. Lima},
booktitle = {SPE Latin American and Caribbean Petroleum Engineering Conference Proceedings},
title = {Development of the Brazilian pre-salt fields - When to pay for information and when to pay for flexibility},
pages = {872--882},
volume = {1},
year = {2012},
isbn = {9781622760466},
abstract = {The Santos Basin Pre-Salt Cluster (SBPSC), Offshore Southeast Brazil, is a unique scenario, posing great development challenges. The microbial carbonate reservoir is unusual regarding its origin and petrophysical properties; the fluids have a variable CO2 content; the few analogue reservoirs around the world do not compare in terms of volumes, water depth and distance to the coast; and there are also flow assurance issues. Considering the importance of these reserves for the Brazilian economy and the opportunity to accelerate cash flow, Petrobras and its partners have opted for a fast track development, including extended well tests (EWTs) and production pilots. The current Petrobras Business Plan (2011-15) foresees mat the SBPSC areas alone will produce over 500,000 boe/d in 2015 and over 1,100,000 boe/d in 2020. These numbers refer only to Petrobras share and do not include me transfer of rights with economic compensation from the Brazilian government to Petrobras. Therefore, the initial development phase will have to cope with several uncertainties, mainly the subsurface ones. Some of the most relevant are the quality and the heterogeneity degree of each reservoir zone; the compositional grading of the fluids; the performance of different EOR methods; and the presence of fractures affecting the flow. How to specify and anticipate the acquisition of expensive equipment, such as FPSOs and subsea devices, with uncertainties to be clarified? When is it worth to invest in more data acquisition, such as EWTs, core and fluid sampling, extensive lab analysis or even more appraisal wells? The timing and the uncertainty reduction foreseen for each initiative must be taken into account. On the other hand, when is it better to pay for extra flexibilities, accepting the inevitable CAPEX increase? Some examples would be: smart completions and possibility to inject different chemical products in the wells; gas and water separated lines for each satellite injector; flexible subsea layout, allowing multiples strategies and the addition of more wells; FPSO plants designed to inject desulphated water, or to export, import or reinject me gas, and also to separate variable CO2 contents in the produced fluids. This paper aims to discuss the influence of the main subsurface uncertainties in the selection of alternatives to develop the giant fields in the SBPSC, in a fast track way. Copyright 2012, Society of Petroleum Engineers.},
doi = {10.2118/152860-ms},
publisher = {Society of Petroleum Engineers},
}

@article{2013PardoProspective,
author = {Nicol\'as Pardo and Jos\'e Antonio Moya},
journal = {Energy},
year = {2013},
doi = {10.1016/j.energy.2013.03.015},
abstract = {The Iron & Steel industry is one of the biggest industrial CO2 emitters in the European Union. The present work analyzes the potential for the improvement of the energy efficiency and CO2 emission reduction for this sector up to 2030. Three scenarios are analyzed: baseline scenario (BS) representing the current evolution of this sector and two alternative scenarios (AS1 and AS2) to study the sensitivity of fuel and resource prices and CO2 emission prices. In the integrated production route all the scenarios highlight the importance of breakthrough technologies, such as Top Gas Recycling, to obtain performance improvement in energy consumption and CO2 emissions. In the secondary production route conditions under BS scenario are enough for a suitable incorporation of the best technologies in this route making insensitive the possible incentives due to higher prices in fuel and resources or CO2 emissions. \textcopyright 2013 Elsevier Ltd.},
title = {Prospective scenarios on energy efficiency and CO2 emissions in the European Iron & Steel industry},
pages = {113--128},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544213001928},
volume = {54},
issn = {03605442},
keywords = {iron and steel industry,technology innovation},
mendeley-tags = {iron and steel industry,technology innovation},
}

@inproceedings{2015CostaFragaBrazilian,
author = {Carlos Tadeu Da Costa Fraga and Antonio Carlos Capeleiro Pinto and Celso Cesar Moreira Branco and Jorge Oscar De Sant'Anna Pizarro and Cezar Augusto Da Silva Paulo},
volume = {1},
abstract = {In the early 2000s the context of the pre-salt formations was conceptual geological models of possible oil bearing reservoirs underneath a thick salt layer, many technical challenges, uncertainties and risks. Past only eight years from first discovery (2006), there are nine production systems, FPSOs, in operation, reaching an average oil rate of more than 700 thousand barrels per day and a cumulative production greater than 400 million barrels of oil, through 34 production wells. To optimize recovery, the first desulfated sea water and gas injectors were started. But these impressive numbers cannot be taken from granted: although nature has revealed prolific reservoirs, much experience, talent, planning and perseverance were necessary. The first articles addressing the pre-salt fields had a focus on the technical challenges faced on first years: the heterogeneous nature of the microbial carbonate reservoir, the 2,000 m salt layer and drilling concerns associated, the variable CO2 content and compositional grading in the reservoir fluids, flow assurance issues and special demands concerning subsea engineering, well construction and processing plant. The main drivers and development strategies were also established: staged development, based on extended well tests (EWTs), multi well production pilots and definitive systems prioritizing the standardization of well projects and production systems. Now, challenges and plans are rewarding the efforts, as depicted by the concrete production numbers achieved to date. In this text, a historical perspective of the pre-salt exploration and development is presented, emphasizing the previous unknowns and uncertainties and how they were treated in order to attain the results. As we still have a lot to learn, since we are just on the beginning of the development of this extraordinary petroleum province, a look to the future and the present efforts on optimization are also commented.},
shorttitle = {Brazilian Pre-Salt},
issn = {01603663},
doi = {10.4043/25710-ms},
isbn = {9781510803527},
booktitle = {Proceedings of the Annual Offshore Technology Conference},
pages = {746--760},
publisher = {Offshore Technology Conference},
year = {2015},
title = {Brazilian pre-salt: An impressive journey from plans and challenges to concrete results},
}

@inproceedings{2016CaoData,
author = {Q. Cao and R. Banerjee and S. Gupta and J. Li and W. Zhou and  Jeyach and B. ra},
isbn = {9781613994740},
abstract = {Forecasting of production in unconventional prospects has gained a lot of attention in the recent years. The key challenges in unconventional reservoirs have been the requirement to put online a) a large number of wells in a short period of time, b) well productivity significantly driven by completion characteristics and that c) the physics of fluid flow in these prospects still remain uncertain. In this paper, machine learning algorithms are used to forecast production for existing and new wells in unconventional assets using inputs like geological maps, production history, pressure data and operational constraints. One of the most popular Machine Learning methods - Artificial Neural Network (ANN) is employed for this purpose. ANN can learn from large volume of data points without assuming a predetermined model and can adapt to newer data as and when it becomes available. The workflow involves using these data sets to train and optimize the ANN model which, subsequently, is used to predict the well production performance of both existing wells using their own history and new wells by using the history of nearby wells which were drilled in analogous geological locations. The proposed technique requires users to do less data conditioning and model building and focus more on analyzing what-if scenarios and determining the well performance.},
doi = {10.2118/180984-ms},
booktitle = {Society of Petroleum Engineers - SPE Argentina Exploration and Production of Unconventional Resources Symposium},
publisher = {Society of Petroleum Engineers},
title = {Data driven production forecasting using machine learning},
year = {2016},
}

@inproceedings{2016MoraesCruzLula,
author = {Rafael Oscar De Moraes Cruz and Marcelo Becher Rosa and Celso Cesar Moreira Branco and Jorge Oscar De Sant'anna Pizarro and Celso Tarcisio De Souza Silva},
booktitle = {Proceedings of the Annual Offshore Technology Conference},
year = {2016},
pages = {4673--4693},
publisher = {Offshore Technology Conference},
isbn = {9781510824294},
abstract = {This paper presents the successful history of Lula NE Pilot Project, a challenging megaproject with an aggressive time-driven schedule, faster than industry average, that demanded new technology development in a scenario of uncertainty. The area is part of the supergiant Lula field, located in the pre-salt region of Santos Basin, Southeast Brazil, 300 km off the coast of Rio de Janeiro state, in 2000 m water depth. It is a joint venture with Petrobras as the Operator, and BG E&P Brasil and Petrogal Brasil as partners. The project was designed as a Pilot aiming to test some new concepts for the production development in the pre-salt area. In terms of subsea gathering system, an innovative concept was deployed, combining flexible flowlines lying on sea floor, with rigid steel catenary risers (SCR) supported by a buoy positioned 250 m below sea level. The drainage plan considered eight oil producers, some of them with intelligent completion, one gas/CO2 injection well and five water alternating gas (WAG) injectors (two subsea WAG manifolds were also installed). A balanced approach between data acquisition and facilities flexibility made possible to face the many reservoir and production uncertainties. Details of the development concept will be discussed, as well as the main results obtained so far, highlighting the strategies adopted in order to mitigate risks and the influence of the acquired information to the following projects in the area. The chartered FPSO Cidade de Paraty started production in June 2013, with an oil capacity of 120,0 bpd, and a gas plant able to process up to 5 million m3/d of gas with 35% content of CO2. Despite all challenges faced, the project was delivered on time, with plateau attained in September 2014.},
issn = {01603663},
doi = {10.4043/27297-ms},
volume = {5},
title = {Lula NE Pilot Project - An ultra-deep success in the Brazilian pre-salt},
}

@book{2016KowsmannGeology,
author = {Renato Oscar Kowsmann Leopoldo},
annote = {OCLC: 965386433},
url = {http://www.sciencedirect.com/science/book/9788535284447},
title = {Regional Environmental Characterization of the Campos Basin, Southwest Atlantic},
year = {2016},
isbn = {9788535284430},
pages = {143},
shorttitle = {Geology and geomorphology},
}

@article{2016DiasSustainability,
author = {Maria Amelia de Paula Dias and Jo\~ao Nildo de Souza Vianna and Claus Felby},
shorttitle = {Sustainability in the prospective scenarios methods},
doi = {10.1016/j.futures.2016.06.005},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328716300167},
year = {2016},
title = {Sustainability in the prospective scenarios methods: A case study of scenarios for biodiesel industry in Brazil, for 2030},
abstract = {In order to build prospective scenarios for biodiesel industry in Brazil, with a sustainable perspective, it was necessary to develop a cross-disciplinary work to include Sachs' dimensions of sustainability into the scenarios method. This meant linking concepts from different disciplines, without transforming it in a new discipline. In order to support the proposition for the new method, a study case is presented, the framework for the biodiesel scenarios in Brazil, by 2030. An in-depth interview was used to test the proposition of having the sustainability dimensions as driving forces. The result was the identification of a critical uncertainty composed of various aspects related the response to climate change and environmental conservation. The scenario storylines that were developed based on the critical uncertainties showed that sustainable options for the future are possible if the mental maps are enlarged to see beyond the business as usual. The results show that the scenarios storylines go through social, environmental and economic aspects, supported by other aspects like the territorial and political. Also it showed that sustainable options are possible if the mental maps are enlarged to see beyond the business as usual.},
journal = {Futures},
volume = {82},
issn = {00163287},
pages = {1--14},
keywords = {biodiesel,critical uncertainties,mental maps,methodology,sustainability},
mendeley-tags = {biodiesel,critical uncertainties,mental maps,methodology,sustainability},
}

@article{2017GomesSensibility,
author = {Carlos Francisco Sim\~oes Gomes and Helder Gomes Costa and Alex de Barros and re P.},
journal = {Journal of Modelling in Management},
volume = {12},
number = {3},
doi = {10.1108/JM2-01-2016-0005},
pages = {475--497},
title = {Sensibility analysis of MCDA using prospective in Brazilian energy sector},
issn = {17465672},
year = {2017},
abstract = {Purpose: The purpose of this paper is to present a hybrid modelling that combines concepts and techniques for scenario building together with a Multi-criteria Decision Aid (MCDA) outranking approach. The paper presents a case to illustrate the proposed methodology. Design/methodology/approach: The research method is a qualitative and quantitative mixture and it is presented as a study case. Bibliographic research is used to construct the theoretical framework. There are a number of studies that develop a sensibility analysis in MCDA modelling; however, none of them explore the robustness of the MCDA solution with use of scenarios variation. Findings: The methodology allows the criteria that must be taken into account, according to the decision makers' values and preferences. It is interesting to note that, depending on the scenario, different weights were applied for each criterion, and the performances of alternatives under each criterion has changed as well. Practical implications: This need arises in decision problems that are susceptible to the influence of scenario variation. Originality/value: This proposal was applied to a real case that has taken into account six alternatives, with a prospective analysis of three scenarios, evaluated by four criteria. The authors use prospective scenarios to choose the criterion weights and alternatives evaluation.},
editor = {Huang, Zhimin and Shi, Xunpeng},
keywords = {decision analysis,mcda,multiple criteria,scenario analysis},
mendeley-tags = {decision analysis,mcda,multiple criteria,scenario analysis},
}

@inproceedings{2018PankajApplication,
author = {Piyush Pankaj and Steve Geetan and Richard MacDonald and Priyavrat Shukla and Abhishek Sharma and Samir Menasria and Han Xue and Tobias Judd},
isbn = {9781510862531},
issn = {01603663},
volume = {6},
booktitle = {Proceedings of the Annual Offshore Technology Conference},
pages = {4186--4201},
doi = {10.4043/28632-ms},
publisher = {Offshore Technology Conference},
abstract = {In today's data-driven economy, operators that integrate vast stores of fundamental reservoir and production data with the highperformance predictive analytics solutions can emerge as winners in the contest of maximizing estimated ultimate recovery (EUR). The scope of this study is to demonstrate a new workflow coupling earth sciences with data analytics to operationalize well completion optimization. The workflow aims to build a robust predictive model that allows users to perform sensitivity analysis on completion designs within a few hours. Current workflows for well completion and production optimization in unconventional reservoirs require extensive earth modeling, fracture simulation, and production simulations. With considerable effort and wide scale of sensitivity, studies could enable optimized well completion design parameters such as optimal cluster spacing, optimal proppant loading, optimal well spacing, etc. Yet, today, less than 5% of the wells fractured in North America are designed using advanced simulation due to the required level of data, skillset, and long computing times. Breaking these limitations through parallel fracture and reservoir simulations in the cloud and combining such simulation with data analytics and artificial intelligence algorithms helped in the development of a powerful solution that creates models for fast, yet effective, completion design. The approach was executed on Eagle Ford wells as a case study in 2016. Over 2000 data points were collected with completion sensitivity performed on a multithreaded cluster environment on these wells. Advanced machine learning and data mining algorithms of data analytics such as random forest, gradient boost, linear regression, etc. were applied on the data points to create a proxy model for the fracturing and numerical production simulator. With the gradient boost technique, over 90% accuracy was achieved between the proxy model and the actual results. Hence, the proxy model could predict the wellbore productivity accurately for any given change in completion design. The operators now had a much simpler model, which served as a plug-and-play tool for the completion engineers to evaluate the impact of changes in completion parameters on the future well performance and making fast-tracked economic decisions almost in real time. The approach can be replicated for varying geological and geomechanical properties as operations move from pad to pad. Although the need for heavy computing resource, simulation skillset, and long run times was eliminated with this new approach, regular QA/QC of the model through manual simulations makes the process more robust and reliable. The methodology provides an integrated approach to bridge the traditional reservoir understanding and simulation approach to the new big data approach to create proxies, which allows operators to make quicker decisions for completion optimization. The technique presented in this paper can be extended for other domains of wellsite operations such as well drilling, artificial lift, etc. and help operators evaluate the most economical scenario in close to real time.},
year = {2018},
title = {Application of data science and machine learning for well completion optimization},
}

@inproceedings{2018PollockMachine,
author = {Jacob Pollock and Zachary Stoecker-Sylvia and Vinod Veedu and Neil Panchal and Hani Elshahawi},
title = {Machine learning for improved directional drilling},
abstract = {Directional drilling is a complex process involving the remote control of tool alignment and force application to a very long drill string subject to variable external forces. Controlling bit tool face orientation while ensuring adequate rate of penetration (ROP) is quite challenging, with aspects that have been described as more art than science. Improving this control helps preserve proper well trajectory and eliminate deviations that require corrective measures and add to well costs. An artificial intelligence system was developed to learn from the actions of expert directional drillers and the mechanics of drilling simulations. Machine learning algorithms were employed to improve the efficiency of directional drilling: optimized ROP, less tortuous borehole, less personnel on board (POB), and consistency across operations. The system ingests historical and simulation data corresponding to the information used and actions taken by expert directional drillers and uses that data to generate decisions that result in efficient slide drilling. To create a system for controlling tool face angle and guiding drill bit sliding during directional drilling, relevant historical data from directional drilling operations was gathered. Much of this data was recorded in the drilling logs, which the drilling operator traditionally uses to control drilling parameters. The collected data was then filtered and used to structure and train artificial neural networks and select appropriate hyperparameters. Reinforcement learning methods were used to refine the neural networks trained on historical data. A computational model for drill string physics was used to simulate the mechanics of directional drilling. A successfully trained network was considered one that minimized deviation from planned wellbore trajectory, minimized tortuosity, and maximized ROP. The neural network developed could replicate the decisions of expert directional drillers within a small error (<3%). Reinforcement learning was then successfully used to improve network performance, particularly for conditions not previously considered. Since the algorithm has demonstrated competence in the historical and simulated realms, it will be further tested as a real-time advisory system for control of directional drilling operations. The system will be tested in simulation with an expert directional driller before use in a field drilling operation. Ultimately, the algorithm can be directly integrated into drilling operations, enabling fully automated directional drilling.},
isbn = {9781510862531},
year = {2018},
publisher = {Offshore Technology Conference},
pages = {2496--2504},
doi = {10.4043/28633-ms},
volume = {4},
issn = {01603663},
booktitle = {Proceedings of the Annual Offshore Technology Conference},
}

@inproceedings{2018PankajNeed,
author = {Piyush Pankaj and Steve Geetan and Richard MacDonald and Priyavrat Shukla and Abhishek Sharma and Samir Menasria and Tobias Judd},
isbn = {9781613995822},
year = {2018},
publisher = {Society of Petroleum Engineers},
title = {Need for speed: Data analytics coupled to reservoir characterization fast tracks well completion optimization},
volume = {2018-March},
booktitle = {Society of Petroleum Engineers - SPE Canada Unconventional Resources Conference, URC 2018},
doi = {10.2118/189790-ms},
abstract = {In today's data-driven economy, operators that integrate vast stores of fundamental reservoir and production data with the high-performance predictive analytics solutions can emerge as winners in the contest of maximizing estimated ultimate recovery (EUR). The scope of this study is to demonstrate a new workflow coupling earth sciences with data analytics to operationalize well completion optimization. The workflow aims to build a robust predictive model that allows users to perform sensitivity analysis on completion designs within a few hours. Current workflows for well completion and production optimization in unconventional reservoirs require extensive earth modeling, fracture simulation, and production simulations. With considerable effort and wide scale of sensitivity, studies could enable optimized well completion design parameters such as optimal cluster spacing, optimal proppant loading, optimal well spacing, etc. Yet, today, less than 5% of the wells fractured in North America are designed using advanced simulation due to the required level of data, skillset, and long computing times. Breaking these limitations through parallel fracture and reservoir simulations in the cloud and combining such simulation with data analytics and artificial intelligence algorithms helped in the development of a powerful solution that creates models for fast, yet effective, completion design. As a case study, the approach was executed on Eagle Ford wells. Over 2000 data points were collected with completion sensitivity performed on a multithreaded cluster environment on these wells. Advanced machine learning and data mining algorithms of data analytics such as random forest, gradient boost, linear regression, etc. were applied on the data points to create a proxy model for the fracturing and numerical production simulator. With the gradient boost technique, over 90% accuracy was achieved between the proxy model and the actual results. Hence, the proxy model could predict the wellbore productivity accurately for any given change in completion design. The operators now had a much simpler model, which served as a plug-and-play tool for the completion engineers to evaluate the impact of changes in completion parameters on the future well performance and making fast-tracked economic decisions almost in real time. The approach can be replicated for varying geological and geomechanical properties as operations move from pad to pad. Although the need for heavy computing resource, simulation skillset, and long run times was eliminated with this new approach, regular QA/QC of the model through manual simulations makes the process more robust and reliable. The methodology provides an integrated approach to bridge the traditional reservoir understanding and simulation approach to the new big data approach to create proxies, which allows operators to make quicker decisions for completion optimization. The technique presented in this paper can be extended for other domains of wellsite operations such as well drilling, artificial lift, etc. and help operators evaluate the most economical scenario in close to real time.},
shorttitle = {Need for Speed},
}

@inproceedings{2018NoshiRole,
author = {Christine I. Noshi and Jerome J. Schubert},
year = {2018},
booktitle = {SPE Eastern Regional Meeting},
isbn = {9781613996386},
publisher = {Society of Petroleum Engineers},
title = {The role of machine learning in drilling operations; a review},
doi = {10.2118/191823-18erm-ms},
volume = {2018-October},
abstract = {Drilling problems such as stick slip vibration/hole cleaning, pipe failures, loss of circulation, BHA whirl, stuck pipe incidents, excessive torque and drag, low ROP, bit wear, formation damage and borehole instability, and the drilling of highly tortuous wells have only been tackled using physics-based models. Despite the mammoth generation of real-time metadata, there is a tremendous gap between statistical based models and empirical, mathematical, and physical-based models. Data mining techniques have made prominent contributions across a broad spectrum of industries. Its value is widely appreciated in a variety of applications, but its potential has not been fully tapped in the oil and gas industry. This paper presents a review compiling several years of Data Analytics applications in the drilling operations. This review discusses the benefits, deficiencies of the present practices, challenges, and novel applications under development to overcome industry deficiencies. This study encompasses a comprehensive compilation of data mining algorithms and industry applications from a predictive analytics standpoint using supervised and unsupervised advanced analytics algorithms to identify hidden patterns and help mitigate drilling challenges. Traditional data preparation and analysis methods are not sufficiently capable of rapid information extraction and clear visualization of big complicated data sets. Due to the petroleum industry's unfulfilled demand, Machine Learning (ML)-assisted industry workflow in the fields of drilling optimization and real time parameter analysis and mitigation is presented. This paper summarizes data analytics case studies, workflows, and lessons learnt that would allow field personnel, engineers, and management to quickly interpret trends, detect failure patterns in operations, diagnose problems, and execute remedial actions to monitor and safeguard operations. The presence of such a comprehensive workflow can minimize tool failure, save millions in replacement costs and maintenance, NPV, lost production, minimize industry bias, and drive intelligent business decisions. This study will identify areas of improvement and opportunities to mitigate malpractices. Data exploitation via the proposed platform is based on well-established ML and data mining algorithms in computer sciences and statistical literature. This approach enables safe operations and handling of extremely large data bases, hence, facilitating tough decision-making processes.},
}

@article{1980EnzerInterax—an,
author = {Selwyn Enzer},
doi = {10.1016/0040-1625(80)90049-9},
year = {1980},
volume = {17},
journal = {Technological Forecasting and Social Change},
url = {http://linkinghub.elsevier.com/retrieve/pii/0040162580900499},
title = {INTERAX-An interactive model for studying future business environments: Part I},
issn = {00401625},
abstract = {In exploring alternative futures, strategic planners are frequently forced into making simplifying assumptions because of time and methodological limitations. These assumptions typically reduce the interdisciplinary perspective, limit the range of policy choices, and restrict the investigation to only the "most likely" future changes. By so doing, many sources of future surprise are eliminated from the analysis. This article describes INTERAX, a method for generating alternative future scenarios which requires very few simplifying assumptions. To accelerate the time required for the analysis, INTERAX includes a large multidisciplinary data base, which is of immediate use in a broad range of long-range strategic issues. INTERAX is described in two articles. This article describes the method and its philosophy and presents the data base. The second part, which will appear in the next issue of Technological Forecasting and Social Change, describes how INTERAX generates scenarios and their use in exploring a variety of strategic issues. \textcopyright 1980.},
pages = {141--159},
number = {2},
shorttitle = {INTERAX—An interactive model for studying future business environments},
}

@article{1980EnzerInterax—ana,
author = {Selwyn Enzer and o̊Associate Director},
abstract = {In exploring alternative futures, strategic planners are frequently forced into making simplifying assumptions because of time and methodological limitations. These assumptions typically reduce the interdisciplinary perspective, limit the range of policy choices, and restrict the investigation to only the "most likely" future changes. By so doing, many sources of future surprise are eliminated from the analysis. This article describes INTERAX, a method for generating alternative future scenarios which requires very few simplifying assumptions. To accelerate the time required for the analysis, INTERAX includes a large multidisciplinary data base, which is of immediate use in a broad range of long-range strategic issues. INTERAX is described in two parts. The previous issue of Technological Forecasting and Social Change contained a description of the method and its philosophy and presented the data base. This article describes how INTERAX generates scenarios and uses them in exploring a variety of strategic issues. \textcopyright 1980.},
pages = {211--242},
journal = {Technological Forecasting and Social Change},
issn = {00401625},
title = {INTERAX-An interactive model for studying future business environments: Part II},
volume = {17},
year = {1980},
shorttitle = {INTERAX—An interactive model for studying future business environments},
doi = {10.1016/0040-1625(80)90064-5},
number = {3},
url = {http://linkinghub.elsevier.com/retrieve/pii/0040162580900645},
}

@article{corsano_drilling_nodate,
author = {J. F. Brett and K. K. Millheim},
doi = {10.2523/15362-ms},
isbn = {9781555636074},
title = {The drilling performance curve: A yardstick for judging drilling Performance},
abstract = {The Drilling Performance Curve (DPC) is a simple yet powerful tool to assess the drilling performance in any given area where a consecutive series of similar wells have been drilled. All the information that is needed to perform the analysis is the sequence numbers of the well and the time it takes to reach a given depth. This paper presents some typical examples of DPC's covering a study of over 30 different areas (onshore and offshore) including over 2000 wells. From the data, a simple model for the overall drilling performance was derived. Three constants Ci, C2 and C3 are unique to the DPC. From the numerical value of the constants, the drilling performance can be derived. For example, the Ci constant indicates how well an operation is prepared to drill a given location and/or how difficult the area is to drill. The C2 constant directly reflects the rate of learning. The C3 constant indicates the level of technology and organization for drilling in a particular area. This paper will present cases from poor to excellent drilling with the associated coefficients. It will be shown that the DPC can dictate the strategy for a drilling program and what the economics of drilling a sequence of wells should be in a given area. It is suggested that the DPC become the yardstick for evaluating drilling, much as the decline curve is for production.},
year = {1986},
journal = {Proceedings - SPE Annual Technical Conference and Exhibition},
pages = {12},
}

@article{2005MietznerAdvantages,
author = {Dana Mietzner and Guido Reger},
abstract = {Scenarios, as a prime technique of future studies, have long been used by government planners, corporate managers and military analysts as powerful tools to aid in decision making in the face of uncertainty. The idea behind them is to establish thinking about possible futures which can minimise surprises and broaden the span of managers' thinking about different possibilities. Today the question of what scenarios are is unclear except with regard to one point - they have become extremely popular. This paper attempts to shed light on differences in scenario approaches. It will describe the origin of scenarios and the development of different understandings and purposes for managers. Categories are developed to compare the different ways scenarios are performed. Finally, the advantages and disadvantages of scenario approaches are analysed. \textcopyright 2005 Inderscience Enterprises Ltd.},
issn = {17402840},
pages = {220--239},
journal = {International Journal of Technology Intelligence and Planning},
title = {Advantages and disadvantages of scenario approaches for strategic foresight},
doi = {10.1504/IJTIP.2005.006516},
year = {2005},
volume = {1},
url = {http://www.inderscience.com/link.php?id=6516},
number = {2},
keywords = {innovation strategy,scenario building,scenario technique,technology planning},
mendeley-tags = {innovation strategy,scenario building,scenario technique,technology planning},
}

@article{lima_os_nodate,
author = {Paulo C\'esar Ribeiro Lima},
pages = {1--25},
url = {http://large.stanford.edu/courses/2011/ph240/waisberg1/docs/desafios_presal_lima.pdf},
title = {Os Desafios , Os Impactos E a Gest\~ao Da Explora\cc\~ao Do Pr\'e-Sal},
journal = {Biblioteca Digital - C\^amara dos Deputados - Bras\'ilia/DF},
year = {2008},
}

@inproceedings{2009BeltraoChallenges,
author = {Ricardo L. Beltrao and Cristiano Sombra and Antonio Lage and Jose Fagundes Netto and Carlos Henriques},
url = {http://www.onepetro.org/mslib/servlet/onepetropreview?id=OTC-19880-MS///////%5C%5C&soc=OTC},
publisher = {The Offshore Technology Conference},
booktitle = {Proceedings of Offshore Technology Conference},
doi = {10.4043/otc-19880-ms},
title = {Challenges and New Technologies for the Development of the Pre-Salt Cluster, Santos Basin, Brazil},
year = {2009},
abstract = {Abstract Pre-salt carbonate reservoirs from Santos Basin represent a great opportunity and probably the most important recent oil discovery. Tupi area (estimated to have recoverable volume of 5 to 8 bboe), which is the most known amongst several other leads in the cluster, is going to be a great insight for the production project. From the production point of view, this new frontier has technological challenges that are being addressed by PETROBRAS and partners. Special attention is being dedicated to anticipate solutions to potential problems. This will require a balance between innovative and field proven solutions. This paper addresses the most critical points, where Petrobras is making a great R&D effort, which are: Well technology, where casing stability, well cost and productivity are addressed, in a scenario of water depths beyond 2,200m, target depths greater than 5,000m, crossing salt layers that can reach 2,000m in thickness. Poorly known microbial carbonate reservoir, heterogeneous in vertical profile, spread over very large areas, with wettability concerns, requiring careful evaluation of the performance of the waterflooding method and EOR. Wax deposition, due to low temperature in the ocean bottom, imposing limitations to the subsea layout. Gas processing and exporting technologies concerning environmental issues: CO2 compact removal units aiming the minimization of emissions to the atmosphere. Production units placed in more than 2,000m water depth, with oceanic conditions quite severe and dealing with high CO2 content stream. These challenges deserve all Petrobras attention, but also count with the confidence in achieving good technological solutions, supported by the history of successful developments of the company. Introduction The history of success built by Petrobras in deep water Brazilian coast - mainly Campos Basin - was largely supported by successive discoveries of heavy oil in turbidite sandstones, step by step towards gradually deeper and deeper water depths (Carminatti et al., 2009). The Pre-salt discoveries of Santos Basin represent discovery of huge volumes of light oil (28 to 30 degrees API), with high gas content, in a very short time span, close the most important consuming centers in Southeastern Brazil, and formation tests in the first wells have presented very high flow rates with no indication of barriers. All are excellent news, although PETROBRAS and partners recognize that the Pre-salt of Santos Basin represents a challenging scenario: ultra-deep water (greater then 2,000 meters), deep carbonate reservoirs (deeper than 5,000 meters), spread over very large areas, with high gas-oil ratio (GOR in Tupi area greater than 200 m3/m3), CO2 content (8-12% in Tupi), high-pressure and low temperature, laying immediately bellow a thick salt layer (more than 2,000 meters of salt), located around 300 km from the coast, with oceanic conditions more severe than Campos Basin. This scenario demands using sometimes present day technology in the limit, and other times, adaption and development of technologies specific for such conditions. This paper addresses the most critical points to the development of production in the Pre-salt of Santos Basin, where Petrobras is making an R&D effort to develop and qualify new technologies, including well technology, reservoir technology, flow assurance, gas processing and exporting technologies, and production units. Additionally, the paper discusses briefly how PETROBRAS has organized its structure to face these technological challenges, including the creation of a technological program - PROSAL - focused on Pre-salt objectives.},
}

@article{2002BerkhoutForesight,
author = {Frans Berkhout and Julia Hertin},
number = {37},
journal = {Greener Management International},
abstract = {This paper presents the Foresight Futures, a participative planning tool developed by SPRU-Science and Technology Policy Research for the UK Foresight Programme. It describes the process of developing the scenario framework, sets out the key dimensions and basic storylines and summarises different ways in which the Foresight Futures have been applied by government, researchers and industry. Focusing on practical ways of using the scenarios, the final part of the paper provides guidance on their use and discusses the potential of the approach.},
title = {Foresight futures scenarios: Developing and applying a participative strategic planning tool},
pages = {37--52},
year = {2002},
doi = {10.9774/GLEAF.3062.2002.sp.00005},
issn = {09669671},
shorttitle = {Foresight futures scenarios},
}

@article{1995SchoemakerScenario,
author = {Paul J H Schoemaker},
journal = {Long Range Planning},
issn = {00246301},
abstract = {Among the many tools a manager can use for strategic planning, scenario planning stands out for its ability to capture a whole range of possibilities in rich detail. By identifying basic trends and uncertainties, a manager can construct a series of scenarios that will help to compensate for the usual errors in decision makingoverconfidence and tunnel vision. Through case studies of Interpublic, an international advertising agency, and Anglo-American Corporation in South Africa, the author describes how to build scenarios in a step-by-step process and how to use the resulting stories to plan a company's future. INSETS: They believed it.;Three scenarios for the advertising industry.. ABSTRACT FROM AUTHOR Copyright of Sloan Management Review is the property of Sloan Management Review and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
number = {3},
volume = {28},
doi = {10.1016/0024-6301(95)91604-0},
pages = {117},
title = {Scenario planning: a tool for strategic thinking},
shorttitle = {Scenario planning},
year = {1995},
}

@collection{2010ChenPlastics,
author = {Guo-Qiang Chen},
isbn = {9783642032868},
annote = {OCLC: ocn428029360},
publisher = {Springer},
year = {2010},
editor = {Chen, Guo-Qiang},
title = {Plastics from Bacteria Natural Functions and Applications (Microbiology Monographs Volume 14)},
series = {Microbiology monographs ; v. 14},
pages = {10--30},
shorttitle = {Plastics from bacteria},
keywords = {isbn},
mendeley-tags = {isbn},
}

@article{1993SwansonStarch,
author = {C. L. Swanson and R. L. Shogren and G. F. Fanta and S. H. Imam},
shorttitle = {Starch-plastic materials?},
title = {Starch-plastic materials-Preparation, physical properties, and biodegradability (a review of recent USDA research)},
year = {1993},
pages = {155--166},
issn = {10647564},
abstract = {Recent starch-plastic research at the National Center for Agricultural Utilization Research is reviewed and related worldwide efforts are noted. Properties of starch that influence its formulation and performance in plastics are discussed. Methods are given for preparation of starch-poly(methyl acrylate) graft copolymer, starch-poly(ethylene-co-acrylic acid), and starch-poly(ethylene-co-acrylic acid)-polyethylene plastics. Their physical properties are discussed, as is degradability by enzymes or amylolytic organisms from soil, ponds, and streams. \textcopyright 1993 Plenum Publishing Corporation.},
doi = {10.1007/BF01418208},
journal = {Journal of Environmental Polymer Degradation},
number = {2},
volume = {1},
keywords = {amylovorus,arthrobacter,biodegradation,graft copolymer,lactobacillus,plastic,starch},
mendeley-tags = {amylovorus,arthrobacter,biodegradation,graft copolymer,lactobacillus,plastic,starch},
}

@article{1997VanSoestInfluence,
author = {J. J.G. Van Soest and N. Knooren},
abstract = {The properties of starch plastic sheets were investigated by stress-strain measurements in relation with starch crystallinity. Granular potato starch was plasticized with different amounts of glycerol and water by extrusion. The materials were amorphous directly after processing. During aging above the glass transition temperature at various humidities single helical (V and E-type) and double helical (B-type) crystallinity was formed. The rate of crystallization is a function of water and glycerol content. The amorphous rubbery materials were soft and weak with high elongations. During aging the materials became less flexible with higher elastic modulus and tensile stress. The changes are related to changes in water content and glass transition temperature and to changes in B-type crystallinity. The changes in stress-strain properties are explained by the formation of helical structures and crystals, which results in a reinforcement of the starch network by physical crosslinking. \textcopyright 1997 John Wiley & Sons, Inc.},
pages = {1411--1422},
doi = {10.1002/(SICI)1097-4628(19970516)64:7<1411::AID-APP21>3.0.CO;2-Y},
volume = {64},
year = {1997},
title = {Influence of glycerol and water content on the structure and properties of extruded starch plastic sheets during aging},
number = {7},
journal = {Journal of Applied Polymer Science},
issn = {00218995},
keywords = {bioplastic,crystallinity,extrusion,mechanical properties,potato starch},
mendeley-tags = {bioplastic,crystallinity,extrusion,mechanical properties,potato starch},
}

@article{1998LuntLarge,
author = {James Lunt},
journal = {Polymer Degradation and Stability},
abstract = {Polylactic acids (PLA) are not new polymers. However, recent developments in the capability to manufacture the monomer economically from renewable feedstocks have placed these materials at the forefront of the emerging biodegradable plastics industry. Increasing realisation of the intrinsic properties of these polymers, coupled with a knowledge of how such properties can be manipulated to achieve compatibility with thermoplastics processing, manufacturing, and end-use requirements has fuelled technological and commercial interest in PLA products. This paper discusses the various technologies being used to produce polylactic acids. In addition, attention is drawn to how monomer stereochemistry can be controlled to impart targeted utility in the final polymers. Specific applications are described to illustrate further the range of properties that can be developed by utilising both the basic monomer/polymer chemistries in combination with post-modification techniques. Finally, the biodegradation mechanism of polylactic acids will be discussed and contrasted with other biodegradable polymers. \textcopyright 1998 Elsevier Science Limited. All rights reserved.},
issn = {01413910},
title = {Large-scale production, properties and commercial applications of poly lactic acid polymers},
pages = {145--152},
number = {1-3},
volume = {59},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0141391097001481},
year = {1998},
doi = {10.1016/s0141-3910(97)00148-1},
}

@article{2000DrumrightPolylactic,
author = {Ray E. Drumright and Patrick R. Gruber and David E. Henton},
abstract = {Polylactic acid is proving to be a viable alternative to petrochemical-based plastics for many applications. It is produced from renewable resources and is biodegradable, decomposing to give H2O, CO2, and humus, the black material in soil. In addition, it has unique physical properties that make it useful in diverse applications including paper coating, fibers, films, and packaging.},
doi = {10.1002/1521-4095(200012)12:23<1841::AID-ADMA1841>3.0.CO;2-E},
issn = {09359648},
number = {23},
pages = {1841--1846},
year = {2000},
title = {Polylactic acid technology},
volume = {12},
journal = {Advanced Materials},
}

@article{2003LuengoBioplastics,
author = {Jos\'e M. Luengo and Bel\'en Garc\'ia and  S and Angel oval and Germ\'an Naharro and El\'ias R. Olivera},
abstract = {The term 'biomaterials' includes chemically unrelated products that are synthesised by microorganisms (or part of them) under different environmental conditions. One important family of biomaterials is bioplastics. These are polyesters that are widely distributed in nature and accumulate intracellularly in microorganisms in the form of storage granules, with physico-chemical properties resembling petrochemical plastics. These polymers are usually built from hydroxy-acyl-CoA derivatives via different metabolic pathways. Depending on their microbial origin, bioplastics differ in their monomer composition, macromolecular structure and physical properties. Most of them are biodegradable and biocompatible, which makes them extremely interesting from the biotechnological point of view.},
issn = {13695274},
number = {3},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1369527403000407},
volume = {6},
year = {2003},
title = {Bioplastics from microorganisms},
pmid = {12831901},
doi = {10.1016/S1369-5274(03)00040-7},
journal = {Current Opinion in Microbiology},
pages = {251--260},
}

@article{2004DomenekBiodegradability,
author = {S Domenek and  ra and Pierre Feuilloley and Jean Gratraud and Marie H\'el\`ene Morel and St\'ephane Guilbert},
pages = {551--559},
issn = {00456535},
pmid = {14581057},
doi = {10.1016/S0045-6535(03)00760-4},
title = {Biodegradability of wheat gluten based bioplastics},
number = {4},
year = {2004},
volume = {54},
journal = {Chemosphere},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0045653503007604},
abstract = {A large variety of wheat gluten based bioplastics, which were plasticized with glycerol, were subjected to biodegradation. The materials covered the total range available for the biochemical control parameter Fi, which expresses the percentage of aggregated proteins. This quantity can be related to the density of covalent crosslinks in the wheat gluten network, which are induced by technological treatments. The biodegradability tests were performed in liquid medium (modified Sturm test) and in farmland soil. All gluten materials were fully degraded after 36 days in aerobic fermentation and within 50 days in farmland soil. No significant differences were observed between the samples. The mineralization half-life time of 3.8 days in the modified Sturm test situated gluten materials among fast degrading polymers. The tests of microbial inhibition experiments revealed no toxic effects of the modified gluten or of its metabolites. Thus, the protein bulk of wheat gluten materials is non-toxic and fully biodegradable, whatever the technological process applied. \textcopyright 2003 Elsevier Ltd. All rights reserved.},
keywords = {biodegradable polymer,farmland soil,microbial inhibition,protein network,rheology sturm test},
mendeley-tags = {biodegradable polymer,farmland soil,microbial inhibition,protein network,rheology sturm test},
}

@article{2008JacquelIsolation,
author = {Nicolas Jacquel and Chi Wei Lo and Yu Hong Wei and Ho Shing Wu and Shaw S. Wang},
doi = {10.1016/j.bej.2007.11.029},
journal = {Biochemical Engineering Journal},
pages = {15--27},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1369703X07004433},
volume = {39},
year = {2008},
issn = {1369703X},
abstract = {The isolation and the purification of bacterial polyhydroxyalkanoates are the key step of the process profitability in the fermentation system. That is why many scientists have studied this field for the production of this biodegradable polymer. The ideal method should lead to a high purity and recovery level at a low production cost. This paper reviews four isolation methods, i.e. solvent extraction of halosolvent and nonhalosolvent, digestion of non-polyhydroxyalkanoate cell material involving surfactants, sodium hypochlorite or enzyme, mechanical cell disruption methods like using bead mills and high pressure homogenization, and new methods like spontaneous liberation of poly(3-hydroxybutyrate), dissolved air flotation, air classification, or by using supercritical CO2. The pretreatment of cell disruption and the purification methods and analytical methods of polyhydroxyalkanoates are also presented. \textcopyright 2007 Elsevier B.V. All rights reserved.},
title = {Isolation and purification of bacterial poly(3-hydroxyalkanoates)},
number = {1},
keywords = {bacteria,biopolymers,isolation,polyhydroxyalkanoates,purification,recovery},
mendeley-tags = {bacteria,biopolymers,isolation,polyhydroxyalkanoates,purification,recovery},
}

@article{2009SatyanarayanaBiodegradable,
author = {Kestur G. Satyanarayana and Gregorio G.C. Arizaga and Fern Wypych and  o},
issn = {00796700},
title = {Biodegradable composites based on lignocellulosic fibers-An overview},
number = {9},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0079670008001214},
abstract = {The development of commercially viable "green products" based on natural resources for both matrices and reinforcements for a wide range of applications is on the rise. This effort includes new pathways to produce natural polymers with better mechanical properties and thermal stability using nanotechnology and use of natural polymers to make biodegradable plastics and their composites with lignocellulosic fibers. This paper presents an overview of the developments made in the area of biodegradable composites, in terms of market, processing methods, matrix-reinforcement systems, morphology, properties and product development. Some critical issues and suggestions for future work are discussed, underscoring the roles of materials scientists and textile engineers for the future of these new "green" materials through value addition to enhance their use. \textcopyright 2009 Elsevier Ltd. All rights reserved.},
doi = {10.1016/j.progpolymsci.2008.12.002},
volume = {34},
pages = {982--1021},
year = {2009},
journal = {Progress in Polymer Science (Oxford)},
keywords = {biodegradability,biopolymers,composite processing,lignocellulosic fibers,mechanical properties,societal applications},
mendeley-tags = {biodegradability,biopolymers,composite processing,lignocellulosic fibers,mechanical properties,societal applications},
}

@article{chee_bacterially_2010,
author = {Jiun-yee Chee and Sugama-salim Yoga and Nyok-sean Lau and Siew-chen Ling and Raeid M M Abed},
year = {2010},
abstract = {Dependence on conventional plastics and their boundless usage have resulted in waste accumulation and greenhouse gas emissions. Recent technologies are directed towards the development of bio-green materials that exert negligible side- effects on the environment. A biologically-synthesized plastic, polyhydroxyalkanoate (PHA), has been attracting major interests due to its similar physical properties to synthetic plastics. Unlike synthetic plastics, PHA is produced from renewable resources and is degraded aerobically by microorganisms to CO2 and H2O upon disposal. The selections of suitable bacterial strains, inexpensive carbon sources, efficient fermentation and recovery processes are important aspects that should be taken into consideration for the commercialization of PHA. This chapter discusses economical strategies to reduce production costs of PHA as well as its applications in various fields.},
pages = {1395--1404},
title = {Bacterially Produced Polyhydroxyalkanoate ( PHA ): Converting Renewable Resources into Bioplastics},
keywords = {bioplastics,downstream processing,pha,pha-producing bacteria,renewable resources},
mendeley-tags = {bioplastics,downstream processing,pha,pha-producing bacteria,renewable resources},
}

@article{2010AkaraonyeProduction,
author = {Everest Akaraonye and Tajalli Keshavarz and Ipsita Roy},
issn = {02682575},
doi = {10.1002/jctb.2392},
pages = {732--743},
number = {6},
abstract = {Polyhydroxyalkanoates (PHAs) have recently been the focus of attention as a biodegradable and biocompatible substitute for conventional non degradable plastics. The cost of large-scale production of these polymers has inhibited its widespread use. Thus, economical, large-scale production of PHAs is currently being studied intensively. Various bacterial strains, either wild-type or recombinant have been utilized with a wide spectrum of utilizable carbon sources. New fermentation strategies have been developed for the efficient production of PHAs at high concentration and productivity. With the current advances, PHAs can now be produced to a concentration of 80 g L-1 with productivities greater than 4 g PHA L-1 h-1. These advanceswill further lower the production cost of PHAs and allow this family of polymers to become a leading biodegradable polymer in the near future. This review describes the properties of PHAs, their uses, the various attempts towards the production of PHAs, focusing on the utilization of cheap substrates and the development of different fermentation strategies for the production of these polymers, an essential step forward towards their widespread use. \textcopyright2010 Society of Chemical Industry.},
volume = {85},
journal = {Journal of Chemical Technology and Biotechnology},
year = {2010},
shorttitle = {Production of polyhydroxyalkanoates},
title = {Production of polyhydroxyalkanoates: The future green materials of choice},
keywords = {bacteria,batch culture,cheap carbon sources,continuous culture,fed-batch culture,mixed culture,polyhydroxyalkanoates},
mendeley-tags = {bacteria,batch culture,cheap carbon sources,continuous culture,fed-batch culture,mixed culture,polyhydroxyalkanoates},
}

@incollection{2012KollerWhey,
author = {Martin Koller and Anna Salerno and Alex Muhr and  er and Angelika Reiterer and Emo Chiellini and Sergio Casella and Predrag Horvat and Gerhart Braunegg},
doi = {10.5772/48737},
editor = {Saleh, Hosam El-Din},
publisher = {InTech},
url = {http://www.intechopen.com/books/polyester/whey-lactose-as-a-raw-material-for-microbial-production-of-biodegradable-polyesters},
isbn = {978-953-51-0770-5},
year = {2012},
abstract = {Abstract Long-haul travel does not constitute an obstacle for tourists to travel and is fast gaining the attention of tourists in new and unique experiences. This study was conducted to identify the long-haul travel motivation by international tourists to Penang. A total of 400 respondents participated in this survey, conducted around the tourist attractions in Penang, using cluster random sampling. However, only 370 questionnaires were only used for this research. Data were analysed using SPSS software 22 version. The findings, ‘knowledge and novelty seeking' were the main push factors that drove long-haul travel by international tourists to Penang. Meanwhile, the main pull factor that attracts long- haul travel by international tourists to Penang was its ‘culture and history'. Additionally, there were partly direct and significant relationships between socio-demographic, trip characteristics and travel motivation (push factors and pull factors). Overall, this study identified the long-haul travel motivations by international tourists to Penang based on socio-demographic, trip characteristics and travel motivation and has indirectly helped in understanding the long-haul travel market particularly for Penang and Southeast Asia. This research also suggested for an effective marketing and promotion strategy in pro- viding useful information that is the key to attract international tourists to travel long distances. Keywords:},
booktitle = {Polyester},
title = {Whey Lactose as a Raw Material for Microbial Production of Biodegradable Polyesters},
}

@article{2016Mozejko-ciesielskaBacterial,
author = {Justyna Mo\.zejko-Ciesielska and Robert Kiewisz},
shorttitle = {Bacterial polyhydroxyalkanoates},
pmid = {27664746},
year = {2016},
pages = {271--282},
abstract = {Bacterial polyhydroxyalkanoates (PHA) are polyesters accumulated as carbon and energy storage materials under limited growth conditions in the presence of excess carbon sources. They have been developed as biomaterials with unique properties for the past many years being considered as a potential substitute for conventional non-degradable plastics. Due to the increasing concern towards global climate change, depleting petroleum resource and problems with an utilization of a growing number of synthetic plastics, PHAs have gained much more attention from industry and research. These environmentally friendly microbial polymers have great potential in biomedical, agricultural, and industrial applications. However, their production on a large scale is still limited. This paper describes the backgrounds of PHAs and discussed the current state of knowledge on the polyhydroxyalkanoates. Ability of bacteria to convert different carbon sources to PHAs, the opportunities and challenges of their introduction to global market as valuable renewable products have been also discussed.},
issn = {09445013},
url = {https://linkinghub.elsevier.com/retrieve/pii/S094450131630043X},
journal = {Microbiological Research},
title = {Bacterial polyhydroxyalkanoates: Still fabulous?},
doi = {10.1016/j.micres.2016.07.010},
volume = {192},
keywords = {bacteria,bacterial polyesters,biopolymers,polyhydroxyalkanoates},
mendeley-tags = {bacteria,bacterial polyesters,biopolymers,polyhydroxyalkanoates},
}

@article{2018RazaPolyhydroxyalkanoates,
author = {Zulfiqar Ali Raza and Sharjeel Abid and Ibrahim M. Banat},
year = {2018},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0964830517300276},
title = {Polyhydroxyalkanoates: Characteristics, production, recent developments and applications},
doi = {10.1016/j.ibiod.2017.10.001},
abstract = {Polyhydroxyalkanoates (PHAs) are biopolyesters, stored within cells as energy storage materials by various microorganisms. Due to their biocompatibility and biodegradability, PHAs have a wide range of applications in various industries such as biomedical sector including tissue engineering, bio-implant patches, drug delivery, surgery and wound dressing. PHAs are green plastics and they have positive social and environmental impact when compared with conventional plastics in terms of production and recycling. Moreover, PHAs do not possess acute and chronic health effects when used in vivo. These bioplastics represent a renewable and sustainable resource to reduce landfill requirements without being persistence or causing pollution. A wide range of carbon sources, bacterial strains, fermentation conditions and recovery methods have been purposed by various researchers for better yield and economical perspectives. Recent advancements in synthetic biology and genetic engineering has led to the production of PHAs from non-PHAs producing strains with no toxins. Progression in recovery techniques has improved the extraction efficacy from biomass with high purity. This review outlines production and characteristics of PHAs, developments in their production, and applications in various industries including nanotechnology.},
journal = {International Biodeterioration and Biodegradation},
pages = {45--56},
issn = {09648305},
volume = {126},
shorttitle = {Polyhydroxyalkanoates},
keywords = {bioplastic,biopolyester,nanotechnology,polyester,polyhydroxyalkanoates},
mendeley-tags = {bioplastic,biopolyester,nanotechnology,polyester,polyhydroxyalkanoates},
}

@misc{2017RosenheimFrequently,
author = {Limbless Association},
year = {2011},
pages = {1--6},
title = {Frequently Asked Questions on :},
booktitle = {Health Care},
abstract = {Advocacy: the voice of small business in government},
number = {202},
}

@misc{2011BajpaiDurable,
author = {Pratima Bajpai},
editor = {IntertechPira},
pages = {74},
year = {2011},
title = {Durable Bioplastics},
}

@article{2014AgustinBioplastic,
author = {Melissa B. Agustin and Bashir Ahmmad and Shanna Marie M. Alonzo and Famille M. Patriana},
journal = {Journal of Reinforced Plastics and Composites},
volume = {33},
issn = {15307964},
title = {Bioplastic based on starch and cellulose nanocrystals from rice straw},
abstract = {Bioplastic based on starch as the matrix and cellulose nanocrystals from rice straw as reinforcing filler were prepared in this study. The isolation of cellulose nanocrystal (CNC) followed a series of steps: delignification, sulfuric acid hydrolysis, and sonication. The process afforded short, rod-like CNCs with particle diameter ranging from 10 to 12nm and crystallinity index of 76.1%. Fourier transform infrared analysis of the CNCs also confirmed absorption patterns typical of cellulose and the removal of silica. Bioplastic with different starch-to-CNC ratios were prepared by solution casting and evaporation method. Scanning electron micrographs of the films showed uniform dispersion of CNC in the starch matrix. Mechanical tests revealed that both tensile strength and modulus significantly increased with increasing CNC load while percent elongation decreased. The moisture uptake of the films reinforced with CNC also decreased an indication of improvement in water resistance. However, the thermal stability of the films decreased by the addition of CNC.},
pages = {2205--2213},
doi = {10.1177/0731684414558325},
number = {24},
year = {2014},
keywords = {cellulose nanocrystals,rice straw,starch-based bioplastic},
mendeley-tags = {cellulose nanocrystals,rice straw,starch-based bioplastic},
}

@article{2015LiewEffect,
author = {Kang Chiang Liew and Lian Kim Khor},
journal = {Journal of King Saud University - Engineering Sciences},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1018363913000408},
volume = {27},
pages = {137--141},
issn = {10183639},
abstract = {Nowadays, industry is searching for an alternative to reduce the usage of petroleum-based non-degradable conventional seedling plant pots. In this study, three different types of bioplastic pots incorporated with newspaper pulp fibres (the ratio of B75%:N25%, B50%:N50% and B25%:N75% denotes percentage of bioplastic to percentage of newspaper pulp fibres) were produced while B0%:N100% acted as the control. All cylinder square shape moulded bioplastic pots with 100 mm height and 2 mm thickness were planted with Leucaena leucocephala seedlings for 60 days in two ground levels (below ground and above ground). Weight loss for bioplastic pots was evaluated. Results showed that bioplastic pots tested below ground had a higher percentage of weight loss than those planted above ground. For percentage of weight loss of bioplastic pots, most bioplastic pots that were tested in both ground levels only showed a significant difference at p ⩽ 0.05 after 30 days. Bioplastic pots B75%:N25% that were tested below ground have the highest percentage of weight loss with 77.93%. As conclusion, B50%:N50% is the most suitable ratio for the production of bioplastic pot.},
doi = {10.1016/j.jksues.2013.08.001},
title = {Effect of different ratios of bioplastic to newspaper pulp fibres on the weight loss of bioplastic pot},
year = {2015},
number = {2},
keywords = {bioplastic pot,newspaper pulp,weight loss},
mendeley-tags = {bioplastic pot,newspaper pulp,weight loss},
}

@collection{2005MohantyNatural,
publisher = {Taylor //\\\& Francis},
title = {Natural fibers, biopolymers, and biocomposites},
editor = {Mohanty, Amar K and Misra, Manjusri and Drzal, Lawrence T},
isbn = {978-0-8493-1741-5},
keywords = {biopolymers,fibers,plant fibers,polymeric composites},
mendeley-tags = {biopolymers,fibers,plant fibers,polymeric composites},
}

@misc{2017EuropePlastics,
author = { PlasticsEurope},
issn = {1879-3363},
pages = {37},
title = {Plastic - The Facts 2017},
isbn = {9788578110796},
arxivid = {arXiv:1011.1669v3},
abstract = {Analysis of European plastics production, demand and waste data.},
archiveprefix = {arXiv},
publisher = {PlasticsEurope},
pmid = {23499538},
booktitle = {European Association Of Plastics Recycling},
year = {2017},
eprint = {arXiv:1011.1669v3},
}

@unpublished{2018BioplasticsBioplastics,
author = { EUBP},
title = {European Bioplastics Fact Sheet},
url = {http://www.bancodealimentos.es/bancos/aprende/queson},
number = {January},
publisher = {European Bioplastics},
year = {2016},
keywords = {activismo,alimento,alimentos,bancos de alimentos,c\'aritas,federacion bancos de alimentos,fesbal,kilo,ong,voluntariado,voluntario},
mendeley-tags = {activismo,alimento,alimentos,bancos de alimentos,c\'aritas,federacion bancos de alimentos,fesbal,kilo,ong,voluntariado,voluntario},
}

@article{mohanty_sustainable_2002,
author = {A. K. Mohanty and M. Misra and L. T. Drzal},
volume = {10},
year = {2002},
issn = {15662543},
journal = {Journal of Polymers and the Environment},
pages = {19--26},
abstract = {Sustainability, industrial ecology, eco-efficiency, and green chemistry are guiding the development of the next generation of materials, products, and processes. Biodegradable plastics and bio-based polymer products based on annually renewable agricultural and biomass feedstock can form the basis for a portfolio of sustainable, eco-efficient products that can compete and capture markets currently dominated by products based exclusively on petroleum feedstock. Natural/Biofiber composites (Bio-Composites) are emerging as a viable alternative to glass fiber reinforced composites especially in automotive and building product applications. The combination of biofibers such as kenaf, hemp, flax, jute, henequen, pineapple leaf fiber, and sisal with polymer matrices from both nonrenewable and renewable resources to produce composite materials that are competitive with synthetic composites requires special attention, i.e., biofiber-matrix interface and novel processing. Natural fiber-reinforced polypropylene composites have attained commercial attraction in automotive industries. Natural fiber - polypropylene or natural fiber - polyester composites are not sufficiently eco-friendly because of the petroleum-based source and the nonbiodegradable nature of the polymer matrix. Using natural fibers with polymers based on renewable resources will allow many environmental issues to be solved. By embedding biofibers with renewable resource-based biopolymers such as cellulosic plastics; polylactides; starch plastics; polyhydroxyalkanoates (bacterial polyesters); and soy-based plastics, the so-called green bio-composites are continuously being developed. \textcopyright 2002 Plenum Publishing Corporation.},
title = {Sustainable Bio-Composites from renewable resources: Opportunities and challenges in the green materials world},
number = {1-2},
doi = {10.1023/A:1021013921916},
keywords = {bioplastic,cellulosic plastic,fiber-matrix interface,natural fiber,polyhydroxyalkanoates,polylactides,soybean-based plastic,sustamable bio-composites},
mendeley-tags = {bioplastic,cellulosic plastic,fiber-matrix interface,natural fiber,polyhydroxyalkanoates,polylactides,soybean-based plastic,sustamable bio-composites},
}

@article{2008SudeshSustainability,
author = {Kumar Sudesh and Tadahisa Iwata},
doi = {10.1002/clen.200700183},
title = {Sustainability of biobased and biodegradable plastics},
year = {2008},
journal = {Clean - Soil, Air, Water},
number = {5-6},
volume = {36},
pages = {433--442},
issn = {18630650},
abstract = {Advances in science and technology have resulted in the rapid development of modern society, which is clearly unsustainable because of the strain it places on current resources. The energy and materials needed to sustain the present society are derived primarily from non-renewable fossil resources, which will be depleted at some point. Plastics are one example of an important commodity in the modern lifestyle. While plastics are undoubtedly superior materials in terms of their costs, processability and functional properties, they are currently derived from fossil resources and they are not readily assimilated by the various ecosystems upon disposal. The search for biodegradable plastics that are derived from renewable resources has been ongoing since the 1970s. Two of the most promising biobased plastics, i.e., polylactic acid and polyhydroxyalkanoates, have received much attention as potential alternatives to existing processes. This article will discuss the current status and sustainability of these two next generation biobased plastics by taking into consideration the raw materials required, as well as the post-consumption effects of these materials on the environment. In addition, important issues surrounding the development and sustainability of biobased and biodegradable plastics will be highlighted. \textcopyright 2008 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim.},
keywords = {biobased content,biodegradable polymers,poly(lacticacid) (pla,polyhydroxyalkanoate (pha,sustainability},
mendeley-tags = {biobased content,biodegradable polymers,poly(lacticacid) (pla,polyhydroxyalkanoate (pha,sustainability},
}

@article{2009ThompsonPlastics,
author = {Richard C. Thompson and Charles J. Moore and Frederick S.Votn Saal and Shanna H. Swan},
year = {2009},
pages = {2153--2166},
abstract = {Plastics have transformed everyday life; usage is increasing and annual production is likely to exceed 300 million tonnes by 2010. In this concluding paper to the Theme Issue on Plastics, the Environment and Human Health, we synthesize current understanding of the benefits and concerns surrounding the use of plastics and look to future priorities, challenges and opportunities. It is evident that plastics bring many societal benefits and offer future technological and medical advances. However, concerns about usage and disposal are diverse and include accumulation of waste in landfills and in natural habitats, physical problems for wildlife resulting from ingestion or entanglement in plastic, the leaching of chemicals from plastic products and the potential for plastics to transfer chemicals to wildlife and humans. However, perhaps the most important overriding concern, which is implicit throughout this volume, is that our current usage is not sustainable. Around 4 per cent of world oil production is used as a feedstock to make plastics and a similar amount is used as energy in the process. Yet over a third of current production is used to make items of packaging, which are then rapidly discarded. Given our declining reserves of fossil fuels, and finite capacity for disposal of waste to landfill, this linear use of hydrocarbons, via packaging and other short-lived applications of plastic, is simply not sustainable. There are solutions, including material reduction, design for end-of-life recyclability, increased recycling capacity, development of bio-based feedstocks, strategies to reduce littering, the application of green chemistry life-cycle analyses and revised risk assessment approaches. Such measures will be most effective through the combined actions of the public, industry, scientists and policymakers. There is some urgency, as the quantity of plastics produced in the first 10 years of the current century is likely to approach the quantity produced in the entire century that preceded. \textcopyright 2009 The Royal Society.},
pmid = {19528062},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
issn = {14712970},
volume = {364},
number = {1526},
title = {Plastics, the environment and human health: Current consensus and future trends},
shorttitle = {Plastics, the environment and human health},
doi = {10.1098/rstb.2009.0053},
keywords = {debris,endocrine disruption,phthalates,plastic,polymer,waste management},
mendeley-tags = {debris,endocrine disruption,phthalates,plastic,polymer,waste management},
}

@article{2010TaboneSustainability,
author = {Michaelangelo D. Tabone and James J. Cregg and Eric J. Beckman and  L and Amy E. is},
issn = {0013936X},
journal = {Environmental Science and Technology},
number = {21},
shorttitle = {Sustainability Metrics},
volume = {44},
title = {Sustainability metrics: Life cycle assessment and green design in polymers},
pmid = {20866068},
year = {2010},
abstract = {This study evaluates the efficacy of green design principles such as the "12 Principles of Green Chemistry," and the "12 Principles of Green Engineering" with respect to environmental impacts found using life cycle assessment (LCA) methodology. A case study of 12 polymers is presented, seven derived from petroleum, four derived from biological sources, and one derived from both. The environmental impacts of each polymer's production are assessed using LCA methodology standardized by the International Organization for Standardization (ISO). Each polymer is also assessed for its adherence to green design principles using metrics generated specifically for this paper. Metrics include atom economy, mass from renewable sources, biodegradability, percent recycled, distance of furthest feedstock, price, life cycle health hazards and life cycle energy use. A decision matrix is used to generate single value metrics for each polymer evaluating either adherence to green design principles or life-cycle environmental impacts. Results from this study show a qualified positive correlation between adherence to green design principles and a reduction of the environmental impacts of production. The qualification results from a disparity between biopolymers and petroleum polymers. While biopolymers rank highly in terms of green design, they exhibit relatively large environmental impacts from production. Biopolymers rank 1, 2, 3, and 4 based on green design metrics; however they rank in the middle of the LCA rankings. Polyolefins rank 1, 2, and 3 in the LCA rankings, whereas complex polymers, such as PET, PVC, and PC place at the bottom of both ranking systems. \textcopyright 2010 American Chemical Society.},
pages = {8264--8269},
doi = {10.1021/es101640n},
}

@article{2012KaranaCharacterization,
author = {Elvin Karana},
volume = {37},
issn = {09596526},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652612003721},
doi = {10.1016/j.jclepro.2012.07.034},
pages = {316--325},
abstract = {Over the past decade, the deployment of sustainable product design has led to a dramatic increase in the use of bio-plastics as an environmentally sensitive substitute to regular petroleum-based ones. Published literature has explored the environmental performance and their suitability as an alternative for regular plastics. However, the reception of these materials by users, who come into contact with these materials embodied in consumer products, has not been researched and published. Even though the principle of using such materials with improved environmental credentials is sound, it is down to the users' appreciation of those materials that ultimately determine their commercial success. A significant challenge faced by material developers and product designers is to facilitate the appraisal of bio-plastics as a natural alternative to regular plastics, whilst at the same time meeting users' perceptions of quality. Drawing on the results of an empirical study this paper discusses when a material is perceived as 'natural' and/or 'high- quality'. The study concludes that there are more contradictory aspects than congruent aspects when evoking these two meanings. Imposition of new aesthetic values and uniqueness are discussed as critical strategies to elicit the desired meanings. \textcopyright 2012 Elsevier Ltd. All rights reserved.},
title = {Characterization of 'natural' and 'high-quality' materials to improve perception of bio-plastics},
journal = {Journal of Cleaner Production},
year = {2012},
keywords = {bio-plastics,high-quality,material acceptance,meaning attribution,natural},
mendeley-tags = {bio-plastics,high-quality,material acceptance,meaning attribution,natural},
}

@article{2013PhilpBioplastics,
author = {Jim C. Philp and Alex Bartsev and  re and Rachael J. Ritchie and Marie Ange Baucher and K. Guy},
issn = {18716784},
journal = {New Biotechnology},
volume = {30},
doi = {10.1016/j.nbt.2012.11.021},
pages = {635--646},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1871678412008783},
abstract = {Society is fundamentally ambivalent to the use of plastics. On the one hand, plastics are uniquely flexible materials that have seen them occupy a huge range of functions, from simple packing materials to complex engineering components. On the other hand, their durability has raised concerns about their end-of-life disposal. When that disposal route is landfill, their invulnerability to microbial decomposition, combined with relatively low density and high bulk, means that plastics will occupy increasing amounts of landfill space in a world where available suitable landfill sites is shrinking.The search for biodegradable plastics and their introduction to the marketplace would appear to be a suitable amelioration strategy for such a problem. And yet the uptake of biodegradable plastics has been slow. The term biodegradable itself has entered public controversy, with accidental and intended misuse of the term; the intended misuse has led to accusations and instances of 'greenwashing'. For this and other reasons standards for biodegradability and compostability testing of plastics have been sought.An environmental dilemma with more far-reaching implications is climate change. The need for rapid and deep greenhouse gas (GHG) emissions cuts is one of the drivers for the resurgence of industrial biotechnology generally, and the search for bio-based plastics more specifically. Bio-based has come to mean plastics based on renewable resources, but this need not necessarily imply biodegradability. If the primary purpose is GHG emissions savings, then once again plastics durability can be a virtue, if the end-of-life solution can be energy recovery during incineration or recycling. The pattern of production is shifting from the true biodegradable plastics to the bio-based plastics, and that trend is likely to persist into the future.This paper looks at aspects of the science of biodegradable and bio-based plastics from the perspective of policy advisers and makers. It is often said that the bioplastics suffer from a lack of a favourable policy regime when compared to the wide-ranging set of policy instruments that are available on both the supply and demand side of biofuels production. Some possible policy measures are discussed. \textcopyright 2012 Elsevier B.V.},
year = {2013},
number = {6},
title = {Bioplastics science from a policy vantage point},
pmid = {23220474},
}

@article{2014VanCauwenbergheMicroplastics,
author = {Lisbeth Van Cauwenberghe and Colin R. Janssen},
issn = {18736424},
pages = {65--70},
doi = {10.1016/j.envpol.2014.06.010},
journal = {Environmental Pollution},
pmid = {25005888},
title = {Microplastics in bivalves cultured for human consumption},
volume = {193},
year = {2014},
abstract = {Microplastics are present throughout the marine environment and ingestion of these plastic particles (<1 mm) has been demonstrated in a laboratory setting for a wide array of marine organisms. Here, we investigate the presence of microplastics in two species of commercially grown bivalves: Mytilus edulis and Crassostrea gigas. Microplastics were recovered from the soft tissues of both species. At time of human consumption, M. edulis contains on average 0.36 ± 0.07 particles g-1 (wet weight), while a plastic load of 0.47 ± 0.16 particles g-1 ww was detected in C. gigas. As a result, the annual dietary exposure for European shellfish consumers can amount to 11,000 microplastics per year. The presence of marine microplastics in seafood could pose a threat to food safety, however, due to the complexity of estimating microplastic toxicity, estimations of the potential risks for human health posed by microplastics in food stuffs is not (yet) possible. \textcopyright 2014 Elsevier Ltd. All rights reserved.},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0269749114002425},
keywords = {crassostrea gigas,human food chain,ingestion,microplastics,mytilus edulis},
mendeley-tags = {crassostrea gigas,human food chain,ingestion,microplastics,mytilus edulis},
}

@article{2014LawMicroplastics,
author = {Kara Lavender Law and Richard C. Thompson},
title = {Microplastics in the seas},
pmid = {25013051},
year = {2014},
number = {6193},
volume = {345},
pages = {144--145},
journal = {Science},
issn = {10959203},
doi = {10.1126/science.1254065},
}

@article{2015LiMicroplastics,
author = {Jiana Li and Dongqi Yang and Lan Li and Khalida Jabeen and Huahong Shi},
abstract = {We investigated microplastic pollution in 9 commercial bivalves from a fishery market in China. Multiple types of microplastics, including fibers, fragments and pellets, occurred in the tissue of all bivalves. The number of total microplastics varied from 2.1 to 10.5 items/g and from 4.3 to 57.2 items/individual for bivalves. Scapharca subcrenata contained on average 10.5 items/g and exhibited the highest levels of microplastics by weight. Fibers were the most common microplastics and consisted of more than half of the total microplastics in each of the 8 species. In Alectryonella plicatula, pellets accounted for 60% of the total microplastics. The most common size class was less than 250 $\mu$m and accounted for 33-84% of the total microplastics calculated by species. Our results suggest that microplastic pollution was widespread and exhibited a relatively high level in commercial bivalves from China. More intensive investigations on microplastics should be conducted in seafood.},
doi = {10.1016/j.envpol.2015.09.018},
journal = {Environmental Pollution},
pmid = {26386204},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0269749115300658},
year = {2015},
pages = {190--195},
volume = {207},
title = {Microplastics in commercial bivalves from China},
issn = {18736424},
keywords = {bivalves,human health,microplastic,seafood},
mendeley-tags = {bivalves,human health,microplastic,seafood},
}

@article{2016Costananoplastics,
author = {Jo\~ao Pinto da Costa and Patr\'icia S.M. Santos and Arm Duarte and o C. and Teresa Rocha-Santos},
abstract = {There has been a considerable increase on research of the ecological consequences of microplastics released into the environment, but only a handful of works have focused on the nano-sized particles of polymer-based materials. Though their presence has been difficult to adequately ascertain, due to the inherent technical difficulties for isolating and quantifying them, there is an overall consensus that these are not only present in the environment - either directly released or as the result of weathering of larger fragments - but that they also pose a significant threat to the environment and human health, as well. The reduced size of these particulates (<1 $\mu$m) makes them susceptible of ingestion by organisms that are at the base of the food-chain. Moreover, the characteristic high surface area-to-volume ratio of nanoparticles may add to their potential hazardous effects, as other contaminants, such as persistent organic pollutants, could be adsorbed and undergo bioaccumulation and bioamplification phenomena. In this review, we describe the most relevant sources of nanoplastics and offer some insights into their fate once released into the environment. Furthermore, we overviewthemost prominent effects of these small particulates, while identifying the key challenges scientists currently face in the research of nanoplastics in the environment. Lastly, we give a brief summary of the economic impacts of the pollution caused by plastic litter - a potential key source of nanoplastics - in the oceans, the most common destination of these contaminants.},
issn = {18791026},
doi = {10.1016/j.scitotenv.2016.05.041},
journal = {Science of the Total Environment},
pages = {15--26},
pmid = {27213666},
title = {(Nano)plastics in the environment - Sources, fates and effects},
year = {2016},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0048969716309731},
volume = {566-567},
keywords = {environment,nanoplastics,pollution,polymer},
mendeley-tags = {environment,nanoplastics,pollution,polymer},
}

@article{2016BrockhausCrossroads,
author = {Sebastian Brockhaus and Moritz Petersen and Wolfgang Kersten},
abstract = {Bioplastics play an increasingly important role for consumer products. These new materials might increase product sustainability but they are currently confined to niche markets. While research has gained important insight into the technical challenges, few studies to date explore the behavioral aspects for product developers as they move to employ bioplastics in their development efforts. This manuscript reports the findings of a grounded inductive study based on interview data with 32 product developers in the consumer goods industry. The Theory of Planned Behavior is employed to guide the research and provide a theoretical background to derive implications. The study finds that behavioral challenges impede the increased use of bioplastics. Product developers experience a lack of perceived behavioral control and struggle with doubts about the environmental benefits and incurring trade-offs of bioplastics with respect to the Triple Bottom Line. While product developers are intrinsically motivated to make more use of bioplastics, they often refrain from bringing products to the mass market due to uncertainties of customer receptiveness and fears of greenwashing allegations. Implications for industry and research are detailed.},
shorttitle = {A crossroads for bioplastics},
title = {A crossroads for bioplastics: exploring product developers' challenges to move beyond petroleum-based plastics},
year = {2016},
issn = {09596526},
journal = {Journal of Cleaner Production},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652616302414},
pages = {84--95},
volume = {127},
doi = {10.1016/j.jclepro.2016.04.003},
keywords = {behavioral research,bioplastics,consumer goods,product development,sustainability,theory of planned behavior},
mendeley-tags = {behavioral research,bioplastics,consumer goods,product development,sustainability,theory of planned behavior},
}

@article{2016SijtsemaConsumer,
author = {Siet J. Sijtsema and Marleen C. Onwezen and MacHiel J. Reinders and Hans Dagevos and Asta Partanen and Marieke Meeusen},
title = {Consumer perception of bio-based products - An exploratory study in 5 European countries},
volume = {77},
pages = {61--69},
year = {2016},
doi = {10.1016/j.njas.2016.03.007},
issn = {22121307},
journal = {NJAS - Wageningen Journal of Life Sciences},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1573521416300070},
abstract = {This study explores people's perceptions (i.e., positive and negative associations, mixed feelings) regarding the concept of 'bio-based' in general and specific bio-based products. This exploratory study is one of the first consumer studies in the field of bio-based research. Three focus group discussions were organized in the Czech Republic, Denmark, Germany, Italy, and The Netherlands (with 89 participants in total) in which projective techniques were applied. Results of these group discussions indicate that participants are unfamiliar with 'bio-based' as a concept. 'Bio-based' is most often associated with positive environmental issues as "naturalness" and "environmental friendly" but also with negative environmental associations and to a lesser extent with technological and health issues. Associations with 'bio-based' as a general concept and with particular bio-based products can be simultaneously positive and negative, which caused uncertainty and mixed feelings by the respondents. This idea highlights both the complexity of and a lack of familiarity with the concept of 'bio-based'. Consumers have a holistic perception of bio-based products, i.e., they combine their perception of different aspects of the product in an evaluation of the whole product concept (e.g., their perception of the original product, usability, production method, proportion of bio-based materials used, price, packaging material, and appearance). Discussions on 'bio-based' as a concept are more general and abstract, while discussions and associations related to bio-based products are more specific. This study's qualitative approach illustrates in detail the great variety in consumers' perceptions, which can be both cognitive and affective (including positive, negative and mixed feelings towards 'bio-based' as a concept as well as bio-based products).},
keywords = {associations,bio-based products,consumers' perception,feelings and emotions,focus group discussions},
mendeley-tags = {associations,bio-based products,consumers' perception,feelings and emotions,focus group discussions},
}

@article{2017CecchiniBioplastics,
author = {Cecilia Cecchini},
pages = {S1596--S1610},
volume = {20},
title = {Bioplastics made from upcycled food waste. Prospects for their use in the field of design},
issn = {14606925},
number = {sup1},
doi = {10.1080/14606925.2017.1352684},
year = {2017},
journal = {Design Journal},
abstract = {The negative effects on the environment of the intensive use of synthetic, oil-derived plastics to make products have given renewed impetus to the search for biopolymers derived from vegetable, animal or microbial matter that could prove to be a sound alternative in a number of applications. However, the real challenge is to create new materials from food waste and not from specially grown crops, whose production in any case comes at an environmental cost. In recent years, the testing of substances made from food waste has increased significantly; the sheer abundance of raw materials that can be used to make them has encouraged institutional research, as well as an approach to project development that has been widely embraced by the many young designers who craft these materials. This paper considers all aspects of these materials, starting from a historical overview. It presents interesting experiments underway and envisages possible future scenarios.},
keywords = {agroindustrial design,bioplastics,design for sustainability,thecnological transfer,upcycled food waste},
mendeley-tags = {agroindustrial design,bioplastics,design for sustainability,thecnological transfer,upcycled food waste},
}

@article{2018LebretonEvidence,
author = {L. Lebreton and B. Slat and F. Ferrari and B. Sainte-Rose and J. Aitken and R. Marthouse and S. Hajbane and S. Cunsolo and A. Schwarz and A. Levivier and K. Noble and P. Debeljak and H. Maral and R. Schoeneich-Argent and R. Brambini and J. Reisser},
year = {2018},
number = {1},
journal = {Scientific Reports},
issn = {20452322},
abstract = {Ocean plastic can persist in sea surface waters, eventually accumulating in remote areas of the world's oceans. Here we characterise and quantify a major ocean plastic accumulation zone formed in subtropical waters between California and Hawaii: The Great Pacific Garbage Patch (GPGP). Our model, calibrated with data from multi-vessel and aircraft surveys, predicted at least 79 (45-129) thousand tonnes of ocean plastic are floating inside an area of 1.6 million km2; a figure four to sixteen times higher than previously reported. We explain this difference through the use of more robust methods to quantify larger debris. Over three-quarters of the GPGP mass was carried by debris larger than 5 cm and at least 46% was comprised of fishing nets. Microplastics accounted for 8% of the total mass but 94% of the estimated 1.8 (1.1-3.6) trillion pieces floating in the area. Plastic collected during our study has specific characteristics such as small surface-to-volume ratio, indicating that only certain types of debris have the capacity to persist and accumulate at the surface of the GPGP. Finally, our results suggest that ocean plastic pollution within the GPGP is increasing exponentially and at a faster rate than in surrounding waters.},
title = {Evidence that the Great Pacific Garbage Patch is rapidly accumulating plastic},
doi = {10.1038/s41598-018-22939-w},
pmid = {29568057},
url = {http://www.nature.com/articles/s41598-018-22939-w},
volume = {8},
}

@article{2015RognoliDiy,
author = {Valentina Rognoli and Massimo Bianchini and Stefano Maffei and Elvin Karana},
title = {DIY materials},
doi = {10.1016/j.matdes.2015.07.020},
year = {2015},
journal = {Materials and Design},
volume = {86},
pages = {692--702},
abstract = {The democratization of personal fabrication technologies in parallel to the rising desire of individuals for personalizing their products offers great opportunities to experiment with advanced, distributed and shared production processes as well as design new materials. In this article, we introduce the notion of Do-It-Yourself (DIY) Materials, which are created through individual or collective self-production practices, often by techniques and processes of the designer's own invention. They can be totally new materials, modified, or further developed versions of existing materials. In order to provide an operational vocabulary to discuss DIY materials, we have collected 27 DIY material cases developed in the last five years. We group the collected cases under two main categories: (1) DIY new materials: which focus on creative material ingredients (e.g. a material made of dried, blended waste citrus peel combined with natural binders); and (2) DIY new identities for conventional materials: which focus on new production techniques, giving new expressions to existing materials (i.e. they do not necessarily contain new ingredients, such as 3D printed metal). Grounded on the commonalities of collected cases, we discuss the design opportunities, including new aesthetic impressions offered through DIY material design practices.},
issn = {18734197},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0264127515300964},
keywords = {diy materials,imperfection,personalisation,self-production},
mendeley-tags = {diy materials,imperfection,personalisation,self-production},
}

@article{2015KaranaMethod,
author = {Karana Elvin and Barati Bahareh and Rognoli Valentina and Zeeuw van der Laan Anouk},
volume = {9},
number = {2},
journal = {International Journal of Design},
title = {Material Driven Design (MDD): A Method to Design for Material Experiences},
year = {2015},
pages = {35--54},
}

@article{2016RognoliMaterial,
author = {Valentina Rognoli and Stefano Parisi and Ayala G. Camilo},
pages = {1--10},
journal = {ResearchGate},
abstract = {This paper presents the growing phenomena of self-produced materials, namely ‘Do-It-Yourself (DIY) Materials', and illustrates the pattern of conditions and circumstances which led to the emergence of this approach to materials. The DIY Materials phenomena is derived from a broader concept defined as ‘emerging materials experiences' and through their definition we think in new and meaningful interaction between users and these new materials qualities derived by a self-production process. Through the presentation of a case study, NeWool, a bio composite made of starch and wool fibres, we outline a design practice based on direct experimentation, tinkering and envisioning for designer.},
title = {The material experiences as DIY-Materials : self The material experiences as DIY-Materials :},
volume = {4},
number = {June},
year = {2016},
keywords = {bio-based materials,diy materials,materials experience,natural fibers composites,self-production},
mendeley-tags = {bio-based materials,diy materials,materials experience,natural fibers composites,self-production},
}

@article{2017KaranaGrowing,
author = {Serena Camere and Elvin Karana},
pages = {101--115},
title = {Growing materials for product design},
abstract = {The possibility to fabricate materials from living organisms offers appealing advantages for product design, such as higher sustainability and an interesting novel aesthetics. Several designers are now 'growing' their own materials. Despite the large interest shown, this emerging material practice is still scarcely understood in design literature. The aim of this paper is to shed light on what it means to design with growing organisms as collaborators, identifying the defining traits of this novel, designerly way of 'doing materials'. To do so, we first compare this specific approach to the approaches of others working in the intersections of biology and design. In this way, we outline the boundaries of Growing Design, defining its unique characteristics. We then provide detailed descriptions of three classes of Growing Materials: fungal, bacterial and algal materials. For each class, we bring two examples of designers utilizing these materials for industrial design purposes. This helps to further explain what truly distinguishes Growing Materials from other conventional materials and to understand the challenges in working with them. Finally, this discussion enables us to set out a research agenda for Growing Design, supporting the development of these materials for industrial production.},
year = {2017},
journal = {Alive. Active. Adaptive: International Conference on Experiential Knowledge and Emerging Materials, EKSIG 2017},
isbn = {9788790775902},
keywords = {algae,alive materials,bacterial cellulose,materials experience,mycelium},
mendeley-tags = {algae,alive materials,bacterial cellulose,materials experience,mycelium},
}

@article{2018CamereFabricating,
author = {Serena Camere and Elvin Karana},
abstract = {Biotechnology offers exciting opportunities for novel and more sustainable alternatives for the design and manufacturing of products. One of the most promising approaches is the fabrication of materials from living organisms, such as fungi and bacteria. An increasing number of designers are engaging in this Growing Design practice, exploring the unique potentials of the grown materials for product design. In Growing Design, designers operate in interdisciplinary contexts, engaging in early stage material developments. Despite the widespread interest towards Growing Design, no systematic study has been conducted so far to understand how this practice unfolds and its contribution to the progression towards cleaner production. To this end, eight recognized professionals in the field were interviewed. The results illustrate how the conception of materials in design evolves when designers co-perform with biological organisms. This alters how the design process unfolds and the mindset adopted in design practice, shaping a novel, systemic vision on production and consumption practices. The paper further discusses the need for developing new sensibilities to face complex interdisciplinary problems in Growing Design and highlights the role designers can take in developing new materials for sustainable production.},
journal = {Journal of Cleaner Production},
issn = {09596526},
shorttitle = {Fabricating materials from living organisms},
pages = {570--584},
year = {2018},
doi = {10.1016/j.jclepro.2018.03.081},
title = {Fabricating materials from living organisms: An emerging design practice},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652618307388},
volume = {186},
keywords = {algae,bacteria,biotechnology,design for sustainability,materials experience,mycelium},
mendeley-tags = {algae,bacteria,biotechnology,design for sustainability,materials experience,mycelium},
}

@article{2017BridgensDesign,
author = {Ben Bridgens and Debra Lilley},
year = {2017},
abstract = {From the moment of purchase, pristine objects are subjected to an array of stimuli including wear, impact, heat, light, water and air which alter their tactile and aesthetic properties. Material change is often regarded as ‘damage' or ‘degradation', but has potential to be used as a tool to engender emotional engagement to an object. We present a framework for designers to better understand how materials change with use, and in turn how people respond to materials as they change. Key challenges are identified which must be overcome to use this framework in design practice–people's physical interaction with objects is poorly understood, it is difficult to simulate material change, materials resources for designers do not provide information about material change, and people's responses to aged materials depend on a complex web of interacting factors.},
number = {sup1},
pages = {S160--S171},
journal = {Design Journal},
volume = {20},
issn = {14606925},
doi = {10.1080/14606925.2017.1352715},
title = {Design for Next\ldots Year. The Challenge of Designing for Material Change},
keywords = {cosmetic obsolescence,degradation,graceful ageing,material change,patina},
mendeley-tags = {cosmetic obsolescence,degradation,graceful ageing,material change,patina},
}

@article{2008JohnBiofibres,
author = {Maya Jacob John and Sabu Thomas},
abstract = {This review deals with a recent study of the literature on the various aspects of cellulosic fibres and biocomposites. Cellulosic fibre reinforced polymeric composites are finding applications in many fields ranging from construction industry to automotive industry. The pros and cons of using these fibres are enumerated in this review. The classification of composites into green composites, hybrid biocomposites and textile biocomposites are discussed. New developments dealing with cellulose based nanocomposites and electrospinning of nanofibres have also been presented. Recent studies pertaining to the above topics have also been cited. Finally, the applications of cellulosic fibre reinforced polymeric composites have been highlighted. \textcopyright 2007 Elsevier Ltd. All rights reserved.},
journal = {Carbohydrate Polymers},
number = {3},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0144861707002974},
volume = {71},
year = {2008},
issn = {01448617},
doi = {10.1016/j.carbpol.2007.05.040},
pages = {343--364},
title = {Biofibres and biocomposites},
keywords = {biocomposite,biofiber,green composite,hybrid,textile},
mendeley-tags = {biocomposite,biofiber,green composite,hybrid,textile},
}

@article{2014ThakurReview,
author = {Vijay Kumar Thakur and Manju Kumari Thakur and Raju Kumar Gupta},
journal = {International Journal of Polymer Analysis and Characterization},
abstract = {The effective utilization of raw natural fibers as indispensable component in polymers for developing novel low-cost eco-friendly composites with properties such as acceptable specific strength, low density, high toughness, good thermal properties, and biodegradability is one of the most rapidly emerging fields of research in polymer engineering and science. In fact, raw natural fiber-reinforced composites are the subject of numerous scientific and research projects, as well as many commercial programs. Keeping in mind the immense advantages of raw natural fibers, in the present article we concisely review raw natural fiber/polymer matrix composites with particular focus on their mechanical properties. \textcopyright 2014 Copyright Taylor & Francis Group, LLC.},
year = {2014},
pages = {256--271},
doi = {10.1080/1023666X.2014.880016},
title = {Review: Raw Natural Fiber-Based Polymer Composites},
volume = {19},
issn = {1023666X},
shorttitle = {Review},
number = {3},
keywords = {composites,mechanical properties,natural fibers,polymers},
mendeley-tags = {composites,mechanical properties,natural fibers,polymers},
}

@article{2016PickeringReview,
author = {K. L. Pickering and M. G.Aruan Efendy and T. M. Le},
volume = {83},
title = {A review of recent developments in natural fibre composites and their mechanical performance},
pages = {98--112},
issn = {1359835X},
year = {2016},
abstract = {Recently, there has been a rapid growth in research and innovation in the natural fibre composite (NFC) area. Interest is warranted due to the advantages of these materials compared to others, such as synthetic fibre composites, including low environmental impact and low cost and support their potential across a wide range of applications. Much effort has gone into increasing their mechanical performance to extend the capabilities and applications of this group of materials. This review aims to provide an overview of the factors that affect the mechanical performance of NFCs and details achievements made with them.},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1359835X15003115},
doi = {10.1016/j.compositesa.2015.08.038},
journal = {Composites Part A: Applied Science and Manufacturing},
keywords = {b. mechanical properties},
mendeley-tags = {b. mechanical properties},
}

@article{2016OmraniState,
author = {Emad Omrani and Pradeep L. Menezes and Pradeep K. Rohatgi},
pages = {717--736},
year = {2016},
title = {State of the art on tribological behavior of polymer matrix composites reinforced with natural fibers in the green materials world},
doi = {10.1016/j.jestch.2015.10.007},
volume = {19},
issn = {22150986},
number = {2},
abstract = {Natural fiber reinforced polymer composites have emerged as a potential environmentally friendly and cost-effective alternative to synthetic fiber reinforced composites. Therefore, in the past decade, a number of major industries, such as the automotive, construction and packaging industries, have shown a considerable interest in the progress of new natural fiber reinforced composite materials. The availability of natural fibers and the ease of manufacturing have tempted researchers to study their feasibility of their application as reinforcement and the extent to which they satisfy the required specifications in tribological applications. However, less information concerning the tribological performance of natural fiber reinforced composite material is available in the literature. Hence, the aim of this bibliographic review is to demonstrate the tribological behavior of natural fiber reinforced composites and find a knowledge about their usability for various applications that tribology plays a dominant role. This review presents the reported work on natural fiber reinforced composites with special reference to the type of fibers, matrix polymers, treatment of fibers and test parameters. The results show that composites reinforced with natural fibers have an improvement in tribological properties and their properties are comparable with conventional fibers. In addition, fiber treatment and fiber orientation are two important factors can affect tribological properties where treated fibers and normal oriented fibers exhibit better friction and wear behavior. This review is trying to evaluate the effect of test parameter including normal load and sliding speed on tribological properties, and the results vary based on type of reinforcement. Generally, due to their positive economic and environmental aspects, as well as their good tribological properties, natural composites are showing a good potential for employing in several applications.},
journal = {Engineering Science and Technology, an International Journal},
url = {https://linkinghub.elsevier.com/retrieve/pii/S221509861500172X},
keywords = {biodegradability,friction,green materials,natural fiber,polymer composite,tribology,wear},
mendeley-tags = {biodegradability,friction,green materials,natural fiber,polymer composite,tribology,wear},
}

@article{2018SanjayCharacterization,
author = {M. R. Sanjay and P. Madhu and Mohammad Jawaid and P. Senthamaraikannan and S. Senthil and S. Pradeep},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652617323946},
pages = {566--581},
title = {Characterization and properties of natural fiber polymer composites: A comprehensive review},
journal = {Journal of Cleaner Production},
shorttitle = {Characterization and properties of natural fiber polymer composites},
issn = {09596526},
year = {2018},
abstract = {The world is in need of more eco-friendly material, therefore researchers around the globe focus on developing new materials that would improve the environmental quality of products. This need for new green materials has led to the utilization of composites made from raw natural fibers and polymer matrices, and this has become one of the most widely investigated research topics in recent times. Natural fiber composites are an alternative for replacing environmentally harmful synthetic materials and help control pollution problems. In addition, they are low cost, have better mechanical properties and require low production energy consumption. Also, using such materials in construction works, it is possible to improve the sustainability by eliminating construction wastes. Keeping in view all the benefits of natural fiber reinforced polymer composites, this paper first discusses various fabrication techniques employed for the production of these composites and then presents a detailed review of the research devoted to the analysis of their structure and properties by a variety of characterization techniques.},
doi = {10.1016/j.jclepro.2017.10.101},
volume = {172},
keywords = {ftir,natural fiber,properties,sem,xrd},
mendeley-tags = {ftir,natural fiber,properties,sem,xrd},
}

@article{2018ElanchezhianReview,
author = {C. Elanchezhian and B. Vijaya Ramnath and G. Ramakrishnan and M. Rajendrakumar and V. Naveenkumar and M. K. Saravanakumar},
title = {Review on mechanical properties of natural fiber composites.},
abstract = {The present experimental study aims at learning the mechanical behavior of natural fiber composites. Natural fibers have an attracting the interest to engineers, researchers, professionals and scientists all over the world as an alternative reinforcement, because of its superior properties such as high specific strength, low weight, low cost, fairly good mechanical properties, non-abrasive, eco-friendly and bio-degradable characteristics. A brief review has been carried out to make use of natural fibers (such as abaca, jute, sisal, banana, cotton, coir, hemp, etc) abundantly available in India. This paper presents a review on the mechanical properties of Abaca, Jute, Sisal.},
number = {1},
volume = {5},
year = {2018},
journal = {Materials Today: Proceedings},
doi = {10.1016/j.matpr.2017.11.276},
issn = {22147853},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2214785317325440},
pages = {1785--1790},
keywords = {composite materials,epoxy,glass fibers,hybrid composites,jute fiber,natural rubber,silicon carbide,sisal fiber},
mendeley-tags = {composite materials,epoxy,glass fibers,hybrid composites,jute fiber,natural rubber,silicon carbide,sisal fiber},
}

@article{2007NeillHow,
author = {Ushma S. Neill},
year = {2007},
number = {12},
abstract = {I've been asked several times to give talks about various aspects of the scientific publishing enterprise, and sometimes to comment specifically on how to write a manuscript that will have maximal impact. While many in my audiences have felt that my presentations are designed for students and trainees, I hope everyone listens, as sometimes even established scientists are prone to making mistakes. I hope here to outline a few pointers that will help your manuscripts skate through the submission and peer review process. Some points may be elementary, but all bear repeating.},
pages = {3599--3602},
volume = {117},
journal = {Journal of Clinical Investigation},
title = {How to write a scientific masterpiece},
doi = {10.1172/JCI34288},
issn = {00219738},
pmid = {18060016},
url = {http://www.jci.org/articles/view/34288},
}

@article{2011AndradeHow,
author = {Chittaranjan Andrade},
doi = {10.4103/0019-5545.82558},
issn = {00195545},
number = {2},
pages = {172--175},
url = {http://www.indianjpsychiatry.org/text.asp?2011/53/2/172/82558},
title = {How to write a good abstract for a scientific paper or conference presentation},
year = {2011},
abstract = {Abstracts of scientific papers are sometimes poorly written, often lack important information, and occasionally convey a biased picture. This paper provides detailed suggestions, with examples, for writing the background, methods, results, and conclusions sections of a good abstract. The primary target of this paper is the young researcher; however, authors with all levels of experience may find useful ideas in the paper.},
volume = {53},
journal = {Indian Journal of Psychiatry},
keywords = {abstract,preparing a manuscript,writing skills},
mendeley-tags = {abstract,preparing a manuscript,writing skills},
}

@article{2014DerntlBasics,
author = {Michael Derntl},
doi = {10.1504/IJTEL.2014.066856},
journal = {International Journal of Technology Enhanced Learning},
title = {Basics of research paper writing and publishing},
pages = {105--123},
abstract = {Publishing research results is an integral part of a researcher's professional life. However, writing is not every researcher's favourite activity, and getting a paper published can be a very tedious and time-consuming process. Fortunately, many of the obstacles along the writing and publishing path can be avoided by following some simple guidelines and practices. This paper presents a synthesis of guidelines found in literature about structuring and writing scientific papers. The paper outlines the process of publishing research papers in journals and conference proceedings, aiming to provide early-stage researchers with a handy introduction to essential issues. The paper takes an interdisciplinary stance by giving examples from technology-enhanced learning research and borrowing from literature in social, natural and computing sciences.},
volume = {6},
number = {2},
year = {2014},
issn = {17535263},
url = {http://www.inderscience.com/link.php?id=66856},
keywords = {conference publications,journal publications,paper structure,paper writing,publication process,scientific practice,writing tips},
mendeley-tags = {conference publications,journal publications,paper structure,paper writing,publication process,scientific practice,writing tips},
}

@article{hanauer_one_nodate,
author = {Barbara Lantz and Nancy Brannon},
doi = {10.1080/00039896.1962.10663298},
title = {One picture is worth a thousand words},
issn = {00039896},
year = {1962},
number = {4},
pages = {394--395},
volume = {5},
journal = {Archives of Environmental Health},
}

@misc{2018ElsevierElsevier,
author = { Elsevier},
url = {https://www.elsevier.com/__data/assets/pdf_file/0003/91173/Brochure_UPP_April2015.pdf},
title = {Elsevier - how to publish in scholarly journals},
}

@book{2013TurabianManual,
author = {Kate L. Turabian and Wayne C. Booth and Gregory G. Colomb and Joseph M. Williams and Wayne C. University of Chicago Press Staff},
year = {2013},
doi = {10.7208/chicago/9780226823386.001.0001},
editor = {Booth, Wayne C and Colomb, Gregory G and Williams, Joseph M and Staff, University of Chicago Press},
shorttitle = {A Manual for Writers of Research Papers, Theses, and Dissertations, Eighth Edition},
isbn = {978-0-226-81638-8},
publisher = {University of Chicago Press},
title = {A Manual for Writers of Research Papers, Theses, and Dissertations, Seventh Edition},
booktitle = {A Manual for Writers of Research Papers, Theses, and Dissertations, Seventh Edition},
edition = {8},
abstract = {This is a highly technical equivalent manual to the APA but the style is Chicago. Unlikely to be very useful.},
}

@book{2013O′learyEssential,
author = {Zina O'Leary},
title = {The Essential Guide to Doing Your Research Project | SAGE Publications Ltd},
year = {2017},
url = {https://uk.sagepub.com/en-gb/eur/the-essential-guide-to-doing-your-research-project/book249279},
booktitle = {SAGE Publications Ltd},
publisher = {SAGE Publications Ltd},
edition = {Second edition},
abstract = {The Essential Guide to Doing Your Research Project 2e is the ultimate companion to successfully completing your research project. Warm and pragmatic, it gives you the skills and the confidence needed to succeed no matter what happens along the way. The book guides you through every step of your research project, from getting started to analysing data and writing up. Each stage is clearly set out, highlighting best practice and providing practical tips and down-to-earth advice for actually doing research. Key features include: Fully developed companion website including podcasts, worksheets, examples of real projects and links to journal articles Chapter summaries Boxed definitions of key terms Full glossary Suggestions for further reading Bursting with real world examples and multidisciplinary case studies, this book addresses the key questions posed by anyone hoping to complete a research project. It is the must-have textbook every student needs. Available with Perusall―an eBook that makes it easier to prepare for class Perusall is an award-winning eBook platform featuring social annotation tools that allow students and instructors to collaboratively mark up and discuss their SAGE textbook. Backed by research and supported by technological innovations developed at Harvard University, this process of learning through collaborative annotation keeps your students engaged and makes teaching easier and more effective. Learn more.},
isbn = {978-1-4462-5897-2},
pages = {1--415},
}

@article{2015SanyangEffect,
author = {Muhammed L. Sanyang and Salit M. Sapuan and Mohammad Jawaid and Mohamad R. Ishak and Japar Sahari},
volume = {7},
pages = {1106--1124},
issn = {20734360},
number = {6},
journal = {Polymers},
abstract = {The use of starch based films as a potential alternative choice to petroleum derived plastics is imperative for environmental waste management. This study presents a new biopolymer (sugar palm starch) for the preparation of biodegradable packaging films using a solution casting technique. The effect of different plasticizer types (glycerol (G), sorbitol (S) and glycerol-sorbitol (GS) combination) with varying concentrations (0, 15, 30 and 45, w/w%) on the tensile, thermal and barrier properties of sugar palm starch (SPS) films was evaluated. Regardless of plasticizer types, the tensile strength of plasticized SPS films decreased, whereas their elongation at break (E%) increased as the plasticizer concentrations were raised. However, the E% for G and GS-plasticized films significantly decreased at a higher plasticizer concentration (45% w/w) due to the anti-plasticization effect of plasticizers. Change in plasticizer concentration showed an insignificant effect on the thermal properties of S-plasticized films. The glass transition temperature of SPS films slightly decreased as the plasticizer concentration increased from 15% to 45%. The plasticized films exhibited increased water vapor permeability values from 4.855 × 10<sup>-10</sup> to 8.70 × 10<sup>-10</sup> g\textperiodcenteredm<sup>-1</sup>\textperiodcentereds<sup>-1</sup>\textperiodcenteredPa<sup>-1</sup>, irrespective of plasticizer types. Overall, the current study manifested that plasticized sugar palm starch can be regarded as a promising biopolymer for biodegradable films.},
title = {Effect of plasticizer type and concentration on tensile, thermal and barrier properties of biodegradable films based on sugar palm (Arenga pinnata) starch},
doi = {10.3390/polym7061106},
url = {http://www.mdpi.com/2073-4360/7/6/1106},
year = {2015},
keywords = {barrier properties,biodegradable polymer,glycerol,sugar palm starch,tensile properties,thermal properties},
mendeley-tags = {barrier properties,biodegradable polymer,glycerol,sugar palm starch,tensile properties,thermal properties},
}

@article{2016MendesBiodegradable,
author = {J. F. Mendes and R. T. Paschoalin and V. B. Carmona and Alfredo R. Sena Neto and A. C.P. Marques and J. M. Marconcini and L. H.C. Mattoso and E. S. Medeiros and J. E. Oliveira},
abstract = {Blends of thermoplastic cornstarch (TPS) and chitosan (TPC) were obtained by melt extrusion. The effect of TPC incorporation in TPS matrix and polymer interaction on morphology and thermal and mechanical properties were investigated. Possible interactions between the starch molecules and thermoplastic chitosan were assessed by XRD and FTIR techniques. Scanning Electron Microscopy (SEM) analyses showed a homogeneous fracture surface without the presence of starch granules or chitosan aggregates. Although the incorporation of thermoplastic chitosan caused a decrease in both tensile strength and stiffness, films with better extensibility and thermal stability were produced.},
doi = {10.1016/j.carbpol.2015.10.093},
issn = {01448617},
pages = {452--458},
title = {Biodegradable polymer blends based on corn starch and thermoplastic chitosan processed by extrusion},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0144861715010735},
journal = {Carbohydrate Polymers},
year = {2016},
volume = {137},
pmid = {26686150},
keywords = {biodegradable polymers,extrusion,thermoplastic chitosan,thermoplastic starch},
mendeley-tags = {biodegradable polymers,extrusion,thermoplastic chitosan,thermoplastic starch},
}

@article{2018WahyuningtiyasProperties,
author = {Nanang Eko Wahyuningtiyas and Heru Suryanto},
abstract = {Synthetic Synthetic plastic is chemical materials which cause severe environmental problems. Incinerating plastic waste leads to release of hazardous gases, which is not good for humans. Bioplastic can help reduce the dependence on fossil fuels and petroleum, that bioplastic can solve the problem of synthetic plastic use. This research aims to define the properties of the cassava starch-based bioplastic reinforced by nanoclay. Methods were experimental with bioplastic component of cassava starch, glycerol as plasticizer and nanoclay as reinforcement. The bioplastic was analyzed using XRD, tensile test, moisture absorption, biodegradability, and compared with another bioplastic. The results show that the addition of nanoclay into bioplastic results increasing the tensile strength of bioplastic also increases from 5.2 MPa to 6.3 MPa. This research revealed that complete degradation of nanoclay reinforced bioplastic could be achieved on the 6th day.},
doi = {10.17977/um016v2i12018p020},
pages = {20--26},
year = {2018},
title = {Properties of Cassava Starch based Bioplastic Reinforced by Nanoclay},
journal = {Journal of Mechanical Engineering Science and Technology},
issn = {25800817},
url = {http://journal2.um.ac.id/index.php/jmest/article/view/5066},
volume = {2},
number = {1},
}

@article{2006HuangHigh,
author = {Mingfu Huang and Jiugao Yu and Xiaofei Ma},
number = {3},
abstract = {Biodegradable nanocomposites have been successfully fabricated from the thermoplastic cornstarch (TPCS) and activated-montmorillonite (MMT) by melt-intercalation. TPCS was plasticized with novel plasticizers urea and formamide, and the activated-montmorillonites were obtained using citric acid as the activated solvent. Compared with urea and formamide-plasticized thermoplastic cornstarch (UFTPCS), the mechanical properties of nanocomposites were very good. The thermal analysis was investigated by Differential Scanning Calorimetry (DSC). The effect of water content on the mechanical properties of nanocomposites was studied. Dynamic Mechanical Thermal Analysis (DMTA) was also carried out. The structure and morphology of biodegradable nanocomposites were characterized by wide-angle X-ray diffraction (WAXD), scanning electron microscope (SEM) and transmission electron microscope (TEM). It was revealed that UFTPCS were intercalated into the layers of MMT successfully, and layers of MMT were fully exfoliated and so formed the exfoliated nanocomposites with MMT. This manufacturing process is simple and environmentally friendly.},
title = {High mechanical performance MMT-urea and formamide-plasticized thermoplastic cornstarch biodegradable nanocomposites},
volume = {63},
journal = {Carbohydrate Polymers},
doi = {10.1016/j.carbpol.2005.09.006},
pages = {393--399},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0144861705004406},
issn = {01448617},
year = {2006},
keywords = {biodegradable,citric acid,corn starch,nanocomposites},
mendeley-tags = {biodegradable,citric acid,corn starch,nanocomposites},
}

@article{2011VieiraNatural,
author = {Melissa Gurgel Adeodato Vieira and Mariana Altenhofen Da Silva and Lucielen Oliveira Dos Santos and Marisa Masumi Beppu},
pages = {254--263},
doi = {10.1016/j.eurpolymj.2010.12.011},
issn = {00143057},
year = {2011},
journal = {European Polymer Journal},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0014305710004763},
title = {Natural-based plasticizers and biopolymer films: A review},
volume = {47},
abstract = {In recent years, much attention has been focused on research to replace petroleum-based commodity plastics, in a cost-effective manner, with biodegradable materials offering competitive mechanical properties. Biopolymers have been considered as the most promising materials for this purpose. However, they generally present poor mechanical properties regarding processability and end-use application, since the fragility and brittleness exhibited during thermoformation can limit their potential for application. In order to overcome this problem, plasticizers are added to provide the necessary workability to biopolymers. This class of products became more visible when biodegradable additives and plasticizers also became the focus of material scientists. The use of natural and/or biodegradable plasticizers, with low toxicity and good compatibility with several plastics, resins, rubber and elastomers in substitution of conventional plasticizers, such as phthalates and other synthetic conventional plasticizers attracted the market along with the increasing worldwide trend towards use of biopolymers. Here we discuss the main results and developments in natural plasticizer/synthetic and biopolymer-based films during the last decades. \textcopyright 2011 Elsevier Ltd. All rights reserved.},
number = {3},
shorttitle = {Natural-based plasticizers and biopolymer films},
keywords = {additives,biodegradable,biopolymers,films,plasticizer},
mendeley-tags = {additives,biodegradable,biopolymers,films,plasticizer},
}

@article{rahmatiah_al_faruqy_properties_2016,
author = {M Sujuthi and & Liew},
year = {2016},
number = {2},
url = {http://transectscience.org/},
title = {Properties of Bioplastic Sheets Made from Different Types of Starch Incorporated With Recycled Newspaper Pulp},
volume = {3},
journal = {Transactions on Science and Technology},
pages = {257--264},
abstract = {The use of biodegradable material based on natural polysaccharides, particularly starch helps to reduce the usage of non-degradable materials. In this study, three types of starch were used to produce the bioplastic sheets (cassava, corn and potato). The sheets were produced with the mixture of bioplastic (B) incorporated with recycled newspaper pulp fibre (N) at four different ratios (newspaper pulp fibres:bioplastic) N50%:B50%, N30%: B70%, N10%:B90% and N0%:B100%. Water absorption and tensile properties were investigated for these bioplastic sheets which were done in room temperature. Cassava-based bioplastic sheet had the worst water repellent while corn starch-based bioplastic sheets had the lowest water absorption percentage. Based on the ratios, bioplastic sheet N30%:B70% shows the lowest percentage of water absorption. Result also showed that as the amount of bioplastic ratio increase, the tensile strength decrease. The optimum mixture of fibres/bioplastic was N50%:B50% which obtained highest percentage of tensile strength. Elongation at break was increased as the bioplastic increased.},
keywords = {biodegradable,bioplastic,elongation at break,starch,tensile strength,water absorption},
mendeley-tags = {biodegradable,bioplastic,elongation at break,starch,tensile strength,water absorption},
}

@article{2011YunosEffect,
author = {M. Z.B. Yunos and W. A.W.A. Rahman},
title = {Effect of glycerol on performance rice straw/starch based polymer},
abstract = {The effect of glycerol on the mechanical, thermal and water absorption properties of thermoplastic tapioca starch reinforced rice straw fiber grinded in the range below 100 um was investigated. Compound formulation was done on twin screw extrusion and the extrudates were pelletized. The compounded samples were processed using compression moulding to form sheet at 150°C for tensile and thermal gravimetric. SEM studies were investigated on fracture surface of composites. Tensile test was done in accordance to ASTM D638. Thermal analysis was used to determine the degradation temperature of composite. Increasing the amount of glycerol increased the tensile strength of composite up to 30 phr of glycerol, however, increasing to 40 and 50 phr glycerol was decrease the strength but elongation at break of composites was increased with increasing glycerol content. Thermal Gravimetric Analysis (TGA) result showed that increased amount of glycerol content lead to decrease in degradation temperature of the composite and SEM micrograph showed that good dispersion and adhesion between rice straw fiber and starch. \textcopyright 2011 Asian Network for Scientific Information.},
year = {2011},
pages = {2456--2459},
doi = {10.3923/jas.2011.2456.2459},
number = {13},
volume = {11},
journal = {Journal of Applied Sciences},
issn = {18125654},
keywords = {biodegradable,compression,glycerol,rice straw,thermoplastic starch},
mendeley-tags = {biodegradable,compression,glycerol,rice straw,thermoplastic starch},
}

@incollection{2004VilpouxStarch,
author = {Olivier Vilpoux and Luc Averous},
booktitle = {Technology, use and potentialities of Latin American starchy tubers},
pages = {33},
title = {Starch-based plastics},
}

@thesis{2014NazriProduction,
author = {N U R Syazana and B T Nazri},
year = {2014},
institution = {UNIVERSITI MALAYSIA PAHANG},
type = {candthesis},
abstract = {Nowadays, the demand for fossil fuels is quite high. But, the extensive use of fossil fuels is causing the gradual decrease of fossil fuels. Therefore, a way to get rid of widespread of using fossil fuels is by developing a new renewable source that can benefit our environment. Resin is one of the important polymeric in the chemical industry. Resins such as alkyd resins are widely used in coatings and paint industry. There are many researches about producing a resin from renewable sources such as vegetable oils. The naturally used vegetable oils in producing resin are soyabean, rapeseed, coconut, castor or linseed oils. Other than that, there are many potential vegetable oils such as karawila, nahar, rubber or safflower oil. Scientist and engineers are dedicated to find another alternative to replace using fossil fuels as the main components in resin making. This study was inspired to do a research by using palm oil as the main components in making renewable resin or bio resin. In this study, waste cooking oil was used as the main component in making bio resin. The synthesis of resin begins with alcoholysis of waste cooking oil with glycerol followed by esterification process. Then, the monoglyceride was reacted with anhydride to obtain bio resin. The resulting product which is bio resin was characterized for physiochemical properties, thermogravimetric analysis (TGA), the infrared spectrum using Fourier Transform Infrared Spectroscopy (FTIR), melting point using Differential Scanning Calorimeter (DSC). The result was compared with previous literature about producing resin from renewable material such as karawila seed oil. The expected resin is feasible in replacing synthetic resin. Thus, improvements and more research need to be made as to market the resin.},
number = {Bio-resin},
pages = {1--24},
title = {Production of Bio Resin From Palm Oil},
}

@article{2017XiongMicrosoft,
author = {W. Xiong and L. Wu and F. Alleva and J. Droppo and X. Huang and A. Stolcke},
url = {http://arxiv.org/abs/1708.06073},
year = {2017},
journal = {arXiv},
issn = {23318422},
abstract = {We describe the 2017 version of Microsoft's conversational speech recognition system, in which we update our 2016 system with recent developments in neural-network-based acoustic and language modeling to further advance the state of the art on the Switchboard speech recognition task. The system adds a CNN-BLSTM acoustic model to the set of model architectures we combined previously, and includes character-based and dialog session aware LSTM language models in rescoring. For system combination we adopt a two-stage approach, whereby subsets of acoustic models are first combined at the senone/frame level, followed by a word-level voting via confusion networks. We also added a confusion network rescoring step after system combination. The resulting system yields a 5.1% word error rate on the 2000 Switchboard evaluation set.},
title = {The microsoft 2017 conversational speech recognition system},
}

@inproceedings{2017LiAcoustic,
author = {Bo Li and Tara N. Sainath and Arun Narayanan and Joe Caroselli and Michiel Bacchiani and Ananya Misra and Izhak Shafran and Hasim Sak and Golan Pundak and Kean Chin and Khe Chai Sim and Ron J. Weiss and Kevin W. Wilson and Ehsan Variani and Chanwoo Kim and Olivier Siohan and Mitchel Weintraub and Erik McDermott and Richard Rose and Matt Shannon},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
url = {http://www.isca-speech.org/archive/Interspeech///////%5C%5C_2017/abstracts/0234.html},
doi = {10.21437/Interspeech.2017-234},
pages = {399--403},
volume = {2017-August},
title = {Acoustic modeling for Google home},
issn = {19909772},
publisher = {ISCA},
abstract = {This paper describes the technical and system building advances made to the Google Home multichannel speech recognition system, which was launched in November 2016. Technical advances include an adaptive dereverberation frontend, the use of neural network models that do multichannel processing jointly with acoustic modeling, and Grid-LSTMs to model frequency variations. On the system level, improvements include adapting the model using Google Home specific data. We present results on a variety of multichannel sets. The combination of technical and system advances result in a reduction of WER of 8-28% relative compared to the current production system.},
year = {2017},
}

@inproceedings{2017DhamdhereAnalyza,
author = {Kedar Dhamdhere and Kevin S. McCurley and Ralfi Nahmias and Mukund Sundararajan and Qiqi Yan},
doi = {10.1145/3025171.3025227},
abstract = {We describe Analyza, a system that helps lay users explore data. Analyza has been used within two large real world systems. The first is a question-And-Answer feature in a spreadsheet product. The second provides convenient access to a revenue/inventory database for a large sales force. Both user bases consist of users who do not necessarily have coding skills, demonstrating Analyza's ability to democratize access to data. We discuss the key design decisions in implementing this system. For instance, how to mix structured and natural language modalities, how to use conversation to disambiguate and simplify querying, how to rely on the "semantics" of the data to compensate for the lack of syntactic structure, and how to efficiently curate the data.},
year = {2017},
booktitle = {International Conference on Intelligent User Interfaces, Proceedings IUI},
publisher = {ACM Press},
shorttitle = {Analyza},
pages = {493--504},
isbn = {9781450343480},
url = {http://dl.acm.org/citation.cfm?doid=3025171.3025227},
title = {Analyza: Exploring data with conversation},
keywords = {exploratory data analysis,natural language},
mendeley-tags = {exploratory data analysis,natural language},
}

@article{2017SeeGet,
author = {Abigail See and Peter J. Liu and Christopher D. Manning},
title = {Get To The Point: Summarization with Pointer-Generator Networks},
year = {2017},
shorttitle = {Get To The Point},
journal = {arXiv},
issn = {23318422},
url = {http://arxiv.org/abs/1704.04368},
abstract = {Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.},
}

@article{2017YuLearning,
author = {Adams Wei Yu and Hongrae Lee and Quoc V. Le},
issn = {23318422},
abstract = {Recurrent Neural Networks are showing much promise in many sub-areas of natural language processing, ranging from document classification to machine translation to automatic question answering. Despite their promise, many recurrent models have to read the whole text word by word, making it slow to handle long documents. For example, it is difficult to use a recurrent network to read a book and answer questions about it. In this paper, we present an approach of reading text while skipping irrelevant information if needed. The underlying model is a recurrent network that learns how far to jump after reading a few words of the input text. We employ a standard policy gradient method to train the model to make discrete jumping decisions. In our benchmarks on four different tasks, including number prediction, sentiment analysis, news article classification and automatic Q&A, our proposed model, a modified LSTM with jumping, is up to 6 times faster than the standard sequential LSTM, while maintaining the same or even better accuracy.},
url = {http://arxiv.org/abs/1704.06877},
year = {2017},
journal = {arXiv},
title = {Learning to skim text},
}

@article{2016NallapatiAbstractive,
author = {Ramesh Nallapati and Bowen Zhou and Cicero dos Santos and \cCaglar Gul\ccehre and Bing Xiang},
abstract = {In this work, we model abstractive text summarization using Attentional Encoder-Decoder Recurrent Neural Networks, and show that they achieve state-of-the-art performance on two different corpora. We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture, such as modeling key-words, capturing the hierarchy of sentence-to-word structure, and emitting words that are rare or unseen at training time. Our work shows that many of our proposed models contribute to further improvement in performance. We also propose a new dataset consisting of multi-sentence summaries, and establish performance benchmarks for further research.},
doi = {10.18653/v1/k16-1028},
isbn = {9781945626197},
pages = {280--290},
journal = {CoNLL 2016 - 20th SIGNLL Conference on Computational Natural Language Learning, Proceedings},
archiveprefix = {arXiv},
title = {Abstractive text summarization using sequence-to-sequence RNNs and beyond},
url = {http://arxiv.org/abs/1602.06023},
year = {2016},
arxivid = {1602.06023},
eprint = {1602.06023},
}

@article{2016MiyatoAdversarial,
author = {Takeru Miyato and Andrew M. Dai and Ian Goodfellow},
title = {Adversarial training methods for semi-supervised text classification},
year = {2017},
arxivid = {1605.07725},
eprint = {1605.07725},
archiveprefix = {arXiv},
url = {http://arxiv.org/abs/1605.07725},
abstract = {Adversarial training provides a means of regularizing supervised learning algorithms while virtual adversarial training is able to extend supervised learning algorithms to the semi-supervised setting. However, both methods require making small perturbations to numerous entries of the input vector, which is inappropriate for sparse high-dimensional inputs such as one-hot word representations. We extend adversarial and virtual adversarial training to the text domain by applying perturbations to the word embeddings in a recurrent neural network rather than to the original input itself. The proposed method achieves state of the art results on multiple benchmark semi-supervised and purely supervised tasks. We provide visualizations and analysis showing that the learned word embeddings have improved in quality and that while training, the model is less prone to overfitting.},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
}

@article{lu_best_2017,
author = {Jiasen Lu and Anitha Kannan and Jianwei Yang and Devi Parikh and Dhruv Batra},
issn = {23318422},
abstract = {We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce 'safe' and generic responses ('I don't know', 'I can't tell'). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, D is not useful in practice since it can not be deployed to have real conversations with users. Our work aims to achieve the best of both worlds - the practical usefulness of G and the strong performance of D - via knowledge transfer from D to G. Our primary contribution is an end-to-end trainable generative visual dialog model, where G receives gradients from D as a perceptual (not adversarial) loss of the sequence sampled from G. We leverage the recently proposed Gumbel-Softmax (GS) approximation to the discrete distribution - specifically, a RNN augmented with a sequence of GS samplers, coupled with the straight-through gradient estimator to enable end-to-end differentiability. We also introduce a stronger encoder for visual dialog, and employ a self-attention mechanism for answer encoding along with a metric learning loss to aid D in better capturing semantic similarities in answer responses. Overall, our proposed model outperforms state-of-the-art on the VisDial dataset by a significant margin (2.67% on recall@10). The source code can be downloaded from https://github.com/jiasenlu/visDial.pytorch.},
journal = {arXiv},
title = {Best of both worlds: Transferring knowledge from discriminative learning to a generative visual dialog model},
year = {2017},
pages = {11},
}

@online{noauthor_deep_2017,
author = {Siri Team},
volume = {1},
url = {https://machinelearning.apple.com/2017/08/06/siri-voices.html},
number = {4},
pages = {1--18},
title = {Deep Learning for Siri's Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis},
abstract = {Siri is a personal assistant that communicates using speech synthesis. Starting in iOS 10 and continuing with new features in iOS 11, we base Siri voices on deep learning. The resulting voices are more natural, smoother, and allow Siri's personality to shine through. This article presents more details about the deep learning based technology behind Siri's voice.},
booktitle = {Apple Machine Learning Journal},
shorttitle = {Deep Learning for Siri's Voice},
year = {2017},
}

@online{2017Improving,
author = {Issue July},
pages = {1--15},
abstract = {Most successful examples of neural nets today are trained with supervision. However, to achieve high accuracy, the training sets need to be large, diverse, and accurately annotated, which is costly. An alternative to labelling huge amounts of data is to use synthetic images from a simulator. This is cheap as there is no labeling cost, but the synthetic images may not be realistic enough, resulting in poor generalization on real test images. To help close this performance gap, we've developed a method for refining synthetic images to make them look more realistic. We show that training models on these refined images leads to significant improvements in accuracy on various machine learning tasks.},
url = {https://machinelearning.apple.com/2017/07/07/GAN.html},
number = {1},
volume = {1},
title = {Improving the Realism of Synthetic Images - Apple},
year = {2017},
booktitle = {Apple Machine Learning Journal},
}

@article{2014HussainAffective,
author = {Amir Hussain and Erik Cambria and Bj\"orn Schuller and Newton Howard},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608014001762},
journal = {Neural Networks},
pmid = {25131153},
volume = {58},
issn = {18792782},
doi = {10.1016/j.neunet.2014.07.010},
pages = {1--3},
year = {2014},
title = {Affective neural networks and cognitive learning systems for big data analysis},
keywords = {affective neural networks,big data analysis,cognitive learning systems},
mendeley-tags = {affective neural networks,big data analysis,cognitive learning systems},
}

@inproceedings{raza_disjunctive_2018,
author = {Mohammad Raza and Sumit Gulwani},
isbn = {9781577358008},
title = {Disjunctive program synthesis: A robust approach to programming by example},
year = {2018},
abstract = {Programming by example (PBE) systems allow end users to easily create programs by providing a few input-output examples to specify their intended task. The system attempts to generate a program in a domain specific language (DSL) that satisfies the given examples. However, a key challenge faced by existing PBE techniques is to ensure the robustness of the programs that are synthesized from a small number of examples, as these programs often fail when applied to new inputs. This is because there can be many possible programs satisfying a small number of examples, and the PBE system has to somehow rank between these candidates and choose the correct one without any further information from the user. In this work we present a different approach to PBE in which the system avoids making a ranking decision at the synthesis stage, by instead synthesizing a disjunctive program that includes the many possible top-ranked programs as possible alternatives and selects between these different choices upon execution on a new input. This delayed choice brings the important benefit of comparing the possible outputs produced by the different disjuncts on a given input at execution time. We present a generic framework for synthesizing such disjunctive programs in arbitrary DSLs, and describe two concrete implementations of disjunctive synthesis in the practical domains of data extraction from plain text and HTML documents. We present an evaluation showing the significant increase in robustness achieved with our disjunctive approach, as illustrated by an increase from 59% to 93% of tasks for which correct programs can be learnt from a single example.},
booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
pages = {1403--1412},
}

@inproceedings{wang_show_2018,
author = {Jing Wang and Jianlong Fu and Jinhui Tang and Zechao Li and Tao Mei},
pages = {7396--7403},
booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
title = {Show, reward and tell: Automatic generation of narrative paragraph from photo stream by adversarial training},
abstract = {Impressive image captioning results (i.e., an objective description for an image) are achieved with plenty of training pairs. In this paper, we take one step further to investigate the creation of narrative paragraph for a photo stream. This task is even more challenging due to the difficulty in modeling an ordered photo sequence and in generating a relevant paragraph with expressive language style for storytelling. The difficulty can even be exacerbated by the limited training data, so that existing approaches almost focus on search-based solutions. To deal with these challenges, we propose a sequence-to-sequence modeling approach with reinforcement learning and adversarial training. First, to model the ordered photo stream, we propose a hierarchical recurrent neural network as story generator, which is optimized by reinforcement learning with rewards. Second, to generate relevant and story-style paragraphs, we design the rewards with two critic networks, including a multi-modal and a language-style discriminator. Third, we further consider the story generator and reward critics as adversaries. The generator aims to create indistinguishable paragraphs to human-level stories, whereas the critics aim at distinguishing them and further improving the generator by policy gradient. Experiments on three widely-used datasets show the effectiveness, against state-of-the-art methods with relative increase of 20.2% by METEOR. We also show the subjective preference for the proposed approach over the baselines through a user study with 30 human subjects.},
isbn = {9781577358008},
year = {2018},
}

@article{2014GraefeMemory,
author = {Goetz Graefe and Haris Volos and Hideaki Kimura and Harumi Kuno and Joseph Tucek and Mark Lillibridge and Alistair Veitch},
url = {http://dl.acm.org/citation.cfm?doid=2735461.2735465},
journal = {Proceedings of the VLDB Endowment},
abstract = {When a working set fits into memory, the overhead imposed by the buffer pool renders traditional databases noncompetitive with in-memory designs that sacrifice the benefits of a buffer pool. However, despite the large memory available with modern hardware, data skew, shifting workloads, and complex mixed workloads make it diffcult to guarantee that a working set will fit in memory. Hence, some recent work has focused on enabling in-memory databases to protect performance when the working data set almost fits in memory. Contrary to those prior efforts, we enable buffer pool designs to match in-memory performance while supporting the "big data" workloads that continue to require secondary storage, thus providing the best of both worlds. We introduce here a novel buffer pool design that adapts pointer swizzling for references between system objects (as opposed to application objects), and uses it to practically eliminate buffer pool overheads for memoryresident data. Our implementation and experimental evaluation demonstrate that we achieve graceful performance degradation when the working set grows to exceed the buffer pool size, and graceful improvement when the working set shrinks towards and below the memory and buffer pool sizes. \textcopyright 2014 VLDB Endowment.},
number = {1},
year = {2014},
title = {In-memory performance for big data},
volume = {8},
pages = {37--48},
doi = {10.14778/2735461.2735465},
issn = {21508097},
}

@article{2014GiannakisSignal,
author = {Georgios B. Giannakis and Francis Bach and Raphael Cendrillon and Michael Mahoney and Jennifer Neville},
pages = {15--16},
number = {5},
title = {Signal processing for big data [From the Guest Editors]},
journal = {IEEE Signal Processing Magazine},
issn = {10535888},
doi = {10.1109/MSP.2014.2330054},
abstract = {The articles in this special section delineate the theoretical and algorithmic nderpinnings along with the relevance of signal processing tools to the emerging field of big data and introduce readers to the challenges and opportunities for SP research on (massive-scale) data analytics. The latter entails an extended and continuously refined technological wish list, which is envisioned to encompass high-dimensional, decentralized, parallel, online, and robust statistical signal processing as well as large, distributed, fault-tolerant, and intelligent systems engineering. The goal is to selectively sample a diverse gamut of big data challenges and opportunities through surveys of methodological advances, as well as more focused-and application-oriented contributions chosen on the basis of timeliness, importance, and relevance to signal processing. \textcopyright 2014 IEEE.},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6879633},
year = {2014},
volume = {31},
}

@book{2011WittenData,
author = {Ian H. Witten and Eibe Frank and Mark A. Hall and Christopher J. Pal},
publisher = {Morgan Kaufmann},
booktitle = {Data Mining: Practical Machine Learning Tools and Techniques},
edition = {3 edition},
doi = {10.1016/c2009-0-19715-5},
title = {Data Mining: Practical Machine Learning Tools and Techniques},
year = {2016},
pages = {1--621},
shorttitle = {Data Mining},
isbn = {9780128042915},
abstract = {Data Mining: Practical Machine Learning Tools and Techniques, Fourth Edition, offers a thorough grounding in machine learning concepts, along with practical advice on applying these tools and techniques in real-world data mining situations. This highly anticipated fourth edition of the most acclaimed work on data mining and machine learning teaches readers everything they need to know to get going, from preparing inputs, interpreting outputs, evaluating results, to the algorithmic methods at the heart of successful data mining approaches. Extensive updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including substantial new chapters on probabilistic methods and on deep learning. Accompanying the book is a new version of the popular WEKA machine learning software from the University of Waikato. Authors Witten, Frank, Hall, and Pal include today's techniques coupled with the methods at the leading edge of contemporary research. Please visit the book companion website at http://www.cs.waikato.ac.nz/ml/weka/book.html It contains Powerpoint slides for Chapters 1-12. This is a very comprehensive teaching resource, with many PPT slides covering each chapter of the book Online Appendix on the Weka workbench; again a very comprehensive learning aid for the open source software that goes with the book Table of contents, highlighting the many new sections in the 4th edition, along with reviews of the 1st edition, errata, etc. Provides a thorough grounding in machine learning concepts, as well as practical advice on applying the tools and techniques to data mining projects Presents concrete tips and techniques for performance improvement that work by transforming the input or output in machine learning methods Includes a downloadable WEKA software toolkit, a comprehensive collection of machine learning algorithms for data mining tasks-in an easy-to-use interactive interface Includes open-access online courses that introduce practical applications of the material in the book.},
}

@article{2011ArnoldNefarious,
author = {Douglas N. Arnold and Kristine K. Fowler},
archiveprefix = {arXiv},
abstract = {We investigate the journal impact factor, focusing on the applied mathematics category. We discuss impact factor manipulation and demonstrate that the impact factor gives an inaccurate view of journal quality, which is poorly correlated with expert opinion.},
arxivid = {1010.0278},
eprint = {1010.0278},
pages = {434--437},
title = {Nefarious Numbers},
number = {3},
volume = {58},
url = {http://arxiv.org/abs/1010.0278},
year = {2010},
}

@article{2018OliveiraProspective,
author = {Altina Silva Oliveira and Marta Duarte de Barros and Fern de Carvalho Pereira and  a and Carlos Francisco Sim\~oes Gomes and Helder Gomes da Costa},
volume = {100},
pages = {20--33},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328716302476},
issn = {00163287},
year = {2018},
journal = {Futures},
doi = {10.1016/j.futures.2018.03.005},
abstract = {The use of prospective scenarios has been discussed by companies in different sectors. As such, this work seeks to study the literature on the prospection of scenarios, permitting different types of analyses and applications. A bibliometric study was performed on the Scopus database, accessed from the CAPES portal in April 2015 and updated in June 2017 in order to identify how the articles about the term prospective scenarios are presented in the literature. 87 articles on the subject were found indexed on Scopus, of which only 17 were from Brazil. It is expected, therefore, that this work will contribute to the construction of an overview of the existing literature on prospective scenarios in order to stimulate the interest of more researchers for the subject.},
title = {Prospective scenarios: A literature review on the Scopus database},
shorttitle = {Prospective scenarios},
keywords = {bibliometric study,prospective scenarios,scopus},
mendeley-tags = {bibliometric study,prospective scenarios,scopus},
}

@book{2017KaehlerLearning,
author = {Adrian Kaehler and Gary Bradski},
issn = {1098-6596},
year = {2013},
abstract = {applicability for this approach.},
pmid = {25246403},
pages = {1689--1699},
edition = {1 edition},
archiveprefix = {arXiv},
title = {Learning OpenCV - computer vision in c++ with the opencv Library},
volume = {53},
number = {9},
shorttitle = {Learning OpenCV 3},
isbn = {9788578110796},
arxivid = {arXiv:1011.1669v3},
publisher = {O'Reilly Media},
eprint = {arXiv:1011.1669v3},
booktitle = {Journal of Chemical Information and Modeling},
keywords = {icle},
mendeley-tags = {icle},
}

@book{2018TazehkandiComputer,
author = { Tazehk and Amin Ahmadi i},
year = {2018},
isbn = {9781788472395},
abstract = {Blend the power of Qt with OpenCV to build cross-platform computer vision applications Key Features ● Start creating robust applications with the power of OpenCV and Qt combined ● Learn from scratch how to develop cross-platform computer vision applications ● Accentuate your OpenCV applications by developing them with Qt Book Description Developers have been using OpenCV library to develop computer vision applications for a long time. However, they now need a more effective tool to get the job done and in a much better and modern way. Qt is one of the major frameworks available for this task at the moment. This book will teach you to develop applications with the combination of OpenCV 3 and Qt5, and how to create cross-platform computer vision applications. We'll begin by introducing Qt, its IDE, and its SDK. Next you'll learn how to use the OpenCV API to integrate both tools, and see how to configure Qt to use OpenCV. You'll go on to build a full-fledged computer vision application throughout the book. Later, you'll create a stunning UI application using the Qt widgets technology, where you'll display the images after they are processed in an efficient way. At the end of the book, you'll learn how to convert OpenCV Mat to Qt QImage. You'll also see how to efficiently process images to filter them, transform them, detect or track objects as well as analyze video. You'll become better at developing OpenCV applications. What you will learn ● Get an introduction to Qt IDE and SDK ● Be introduced to OpenCV and see how to communicate between OpenCV and Qt ● Understand how to create UI using Qt Widgets ● Learn to develop cross-platform applications using OpenCV 3 and Qt 5 ● Explore the multithreaded application development features of Qt5 ● Improve OpenCV 3 application development using Qt5 ● Build, test, and deploy Qt and OpenCV apps, either dynamically or statically ● See Computer Vision technologies such as filtering and transformation of images, detecting and matching objects, template matching, object tracking, video and motion analysis, and much more ● Be introduced to QML and Qt Quick for iOS and Android application development Who this book is for This book is for readers interested in building computer vision applications. Intermediate knowledge of C++ programming is expected. Even though no knowledge of Qt5 and OpenCV 3 is assumed, if you're familiar with these frameworks, you'll benefit. Table of Contents Introduction to Qt and OpenCV Creating our first Qt and OpenCV project Creating a comprehensive Qt+OpenCV project Mat and Qimage The Graphics View Framework Image Processing in OpenCV Features and Descriptors Multi-Threading Video Analysis Debugging and Testing Static Linking and Deployment Computer Vision Apps for Android and iOS},
edition = {Edi\cc\~ao: 1},
shorttitle = {Computer Vision with OpenCV 3 and Qt5},
publisher = {Packt Publishing},
title = {Computer Vision with OpenCV 3 and Qt5: Build visually appealing, multithreaded, cross-platform computer vision applications},
}

@book{2018JohnsonHands,
author = {Andrew Johnson},
title = {Hands-On Functional Programming in Rust: Build modular and reactive applications with functional programming techniques in Rust 2018},
abstract = {Explore the support Rust offers for creating functional applications in Rust. Learn about various design patterns, implementing concurrency, metaprogramming, and so on in the processKey FeaturesLearn generics, organization, and design patterns in functional programmingModularize your applications and make them highly reusable and testable using functional design patternsGet familiar with complex concepts such as metaprogramming, concurrency, and immutabilityBook DescriptionFunctional programming allows developers to divide programs into smaller, reusable components that ease the creation, testing, and maintenance of software as a whole. Combined with the power of Rust, you can develop robust and scalable applications that fulfill modern day software requirements. This book will help you discover all the Rust features that can be used to build software in a functional way.We begin with a brief comparison of the functional and object-oriented approach to different problems and patterns. We then quickly look at the patterns of control flow, data the abstractions of these unique to functional programming. The next part covers how to create functional apps in Rust; mutability and ownership, which are exclusive to Rust, are also discussed. Pure functions are examined next and you'll master closures, their various types, and currying. We also look at implementing concurrency through functional design principles and metaprogramming using macros. Finally, we look at best practices for debugging and optimization.By the end of the book, you will be familiar with the functional approach of programming and will be able to use these techniques on a daily basis.What you will learnHow Rust supports the use of basic functional programming principlesUse functional programming to handle concurrency with eleganceRead and interpret complex type signatures for types and functionsImplement powerful abstractions using meta programming in RustCreate quality code formulaically using Rust's functional design patternsMaster Rust's complex ownership mechanisms particularly for mutabilityWho This Book Is ForThis book is for Rust developers who are comfortable with the language and now want to improve their coding abilities by learning advanced functional techniques to enhance their skillset and create robust and testable apps.Table of ContentsFunctional Programming - a comparisonFunctional Control FlowFunctional Data StructuresGenerics and PolymorphismCode Organization and Application ArchitectureMutability, Ownership, and Pure FunctionsDesign PatternsImplementing ConcurrencyMetaprogramming,Debugging, and Performance},
isbn = {978-1-78883-935-8},
publisher = {Packt Publishing},
shorttitle = {Hands-On Functional Programming in Rust},
}

@book{noauthor_proceedings_2008,
title = {Proceedings of the 7th International Conference on New Interfaces for Musical Expression, NIME '07},
isbn = {13-978-88-901344-6-3},
year = {2007},
booktitle = {Proceedings of the 7th International Conference on New Interfaces for Musical Expression, NIME '07},
}

@book{2015AllenGetting,
author = {Shawn Blau},
abstract = {Shawn Blau reviews David Allen's Getting Things Done: The Art of Stress-Free Productivity},
edition = {Revised edition},
doi = {10.1108/neje-04-02-2001-b008},
booktitle = {New England Journal of Entrepreneurship},
year = {2001},
pages = {81--82},
publisher = {Penguin Books},
title = {Getting Things Done: The Art of Stress-Free Productivity},
volume = {4},
number = {2},
issn = {2574-8904},
shorttitle = {Getting Things Done},
}

@mvbook{2016HallidayFundamentos,
author = {Jearl Halliday, David, Resnick, Robert e Walker},
title = {Fundamentos de f\'isica 2: Gravita\cc\~ao, Ondas e Termodin\^amica},
year = {1996},
edition = {Edi\cc\~ao: 10},
abstract = {A nova edi\cc\~ao do maior cl\'assico de F\'isica traz o melhor para voc\^e! Raspe o c\'odigo promocional que aparece na "orelha" do livro, entre no site www.grupogen.com.br/halliday-vol2 e ganhe o e-book de Fundamentos de F\'isica - Vol. 2 - Gravita\cc\~ao, Ondas e Termodin\^amica + v\'ideos exclusivos de F\'isica Experimental. Sucesso h\'a mais de quatro d\'ecadas em todo o mundo, Fundamentos de F\'isica continua cumprindo o desafio de apresentar a F\'isica de maneira clara, unindo a teoria e os exerc\'icios \`as aplica\cc\~oes pr\'aticas do mundo real. Novidades da 10\textordfeminine edi\cc\~ao: • M\'odulos e Objetivos de Aprendizado - Os cap\'itulos v\^em agora divididos em m\'odulos conceituais, dedicados a temas b\'asicos, com uma lista de objetivos do aprendizado para que o estudante identifique, de antem\~ao, todos os conceitos e as defini\cc\~oes que ver\'a naquele m\'odulo. • Cap\'itulos Reformulados - Para facilitar o aprendizado, alguns cap\'itulos foram reformulados, como o que aborda a lei de Gauss e o potencial el\'etrico. Houve tamb\'em a preocupa\cc\~ao de estabelecer uma liga\cc\~ao mais clara e direta com os conceitos-chave apresentados. • Novos Exemplos, Perguntas e Problemas - 250 novos problemas, 50 perguntas in\'editas e 16 novos exemplos foram acrescentados a esta edi\cc\~ao. Permanecem como destaques desta 10a edi\cc\~ao os materiais suplementares, todos traduzidos e dispon\'iveis no site www.grupogen.com.br/halliday-vol2 (LTC Editora – GEN | Grupo Editorial Nacional), mediante cadastro.},
publisher = {LTC},
volume = {2},
}

@mvbook{2016HallidayFundamentosa,
author = {David Halliday and Robert Resnick and Jearl Walker},
publisher = {LTC},
title = {Fundamentos de F\'isica - Vol. 1 - Mec\^anica},
edition = {Edi\cc\~ao: 10},
volume = {1},
abstract = {A nova edi\cc\~ao do maior cl\'assico de F\'isica traz o melhor para voc\^e! Raspe o c\'odigo promocional que aparece na "orelha" do livro, entre no site www.grupogen.com.br/halliday-vol1 e ganhe o e-book de Fundamentos de F\'isica - Vol. 1 - Mec\^anica + v\'ideos exclusivos de F\'isica Experimental. Sucesso h\'a mais de quatro d\'ecadas em todo o mundo, Fundamentos de F\'isica continua cumprindo o desafio de apresentar a F\'isica de maneira clara, unindo a teoria e os exerc\'icios \`as aplica\cc\~oes pr\'aticas do mundo real. Novidades da 10\textordfeminine edi\cc\~ao: • M\'odulos e Objetivos de Aprendizado - Os cap\'itulos v\^em agora divididos em m\'odulos conceituais, dedicados a temas b\'asicos, com uma lista de objetivos do aprendizado para que o estudante identifique, de antem\~ao, todos os conceitos e as defini\cc\~oes que ver\'a naquele m\'odulo. • Cap\'itulos Reformulados - Para facilitar o aprendizado, alguns cap\'itulos foram reformulados, como o que aborda a lei de Gauss e o potencial el\'etrico. Houve tamb\'em a preocupa\cc\~ao de estabelecer uma liga\cc\~ao mais clara e direta com os conceitos-chave apresentados. • Novos Exemplos, Perguntas e Problemas - 250 novos problemas, 50 perguntas in\'editas e 16 novos exemplos foram acrescentados a esta edi\cc\~ao. Permanecem como destaques desta 10a edi\cc\~ao os materiais suplementares, todos traduzidos e dispon\'iveis no site www.grupogen.com.br/halliday-vol1 (LTC Editora – GEN | Grupo Editorial Nacional), mediante cadastro.},
}

@mvbook{2016HallidayFundamentosb,
author = {David Halliday and Robert Resnick and Jearl Walker},
title = {Fundamentos de F\'isica - Vol. 4 - \'Optica e F\'isica Moderna},
edition = {Edi\cc\~ao: 10},
publisher = {LTC},
volume = {4},
abstract = {A nova edi\cc\~ao do maior cl\'assico de F\'isica traz o melhor para voc\^e! Raspe o c\'odigo promocional que aparece na "orelha" do livro, entre no site www.grupogen.com.br/halliday-vol1 e ganhe o e-book de Fundamentos de F\'isica - Vol. 4 - \'Optica e F\'isica Moderna + v\'ideos exclusivos de F\'isica Experimental. Sucesso h\'a mais de quatro d\'ecadas em todo o mundo, Fundamentos de F\'isica continua cumprindo o desafio de apresentar a F\'isica de maneira clara, unindo a teoria e os exerc\'icios \`as aplica\cc\~oes pr\'aticas do mundo real. Novidades da 10\textordfeminine edi\cc\~ao: • M\'odulos e Objetivos de Aprendizado - Os cap\'itulos v\^em agora divididos em m\'odulos conceituais, dedicados a temas b\'asicos, com uma lista de objetivos do aprendizado para que o estudante identifique, de antem\~ao, todos os conceitos e as defini\cc\~oes que ver\'a naquele m\'odulo. • Cap\'itulos Reformulados - Para facilitar o aprendizado, alguns cap\'itulos foram reformulados, como o que aborda a lei de Gauss e o potencial el\'etrico. Houve tamb\'em a preocupa\cc\~ao de estabelecer uma liga\cc\~ao mais clara e direta com os conceitos-chave apresentados. • Novos Exemplos, Perguntas e Problemas - 250 novos problemas, 50 perguntas in\'editas e 16 novos exemplos foram acrescentados a esta edi\cc\~ao. Permanecem como destaques desta 10a edi\cc\~ao os materiais suplementares, todos traduzidos e dispon\'iveis no site www.grupogen.com.br/halliday-vol4 (LTC Editora – GEN | Grupo Editorial Nacional), mediante cadastro.},
}

@mvbook{2016ResnickFundamentos,
author = {Robert Resnick and Jearl Walker and David Halliday},
isbn = {978-85-216-3037-1},
publisher = {LTC},
title = {Fundamentos de F\'isica - Vol. 3 - Eletromagnetismo},
abstract = {A nova edi\cc\~ao do maior cl\'assico de F\'isica traz o melhor para voc\^e!Na compra do exemplar impresso, raspe o c\'odigo promocional (PIN) da etiqueta que aparece na "orelha" do livro, entre no site www.grupogen.com.br/halliday-volume-3 e acesse 30 v\'ideos exclusivos de F\'isica Experimental. E com o mesmo c\'odigo PIN, oferecemos uma oferta exclusiva! Por apenas R$ 20,00, voc\^e poder\'a adquirir o e-book do volume de "Fundamentos de F\'isica - Vol. 3 - Eletromagnetismo" e mais os v\'ideos completos (140 v\'ideos) de F\'isica Experimental que acompanham o livro! Saiba mais em www.halliday.com.br ---------- Sucesso h\'a mais de quatro d\'ecadas em todo o mundo, Fundamentos de F\'isica continua cumprindo o desafio de apresentar a F\'isica de maneira clara, unindo a teoria e os exerc\'icios \`as aplica\cc\~oes pr\'aticas do mundo real. Novidades da 10a edi\cc\~ao:- M\'odulos e Objetivos de AprendizadoOs cap\'itulos v\^em agora divididos em m\'odulos conceituais, dedicados a temas b\'asicos, com uma lista de objetivos do aprendizado para que o estudante identifique, de antem\~ao, todos os conceitos e as defini\cc\~oes que ver\'a naquele m\'odulo. - Cap\'itulos ReformuladosPara facilitar o aprendizado, alguns cap\'itulos foram reformulados, como o que aborda a lei de Gauss e o potencial el\'etrico. Houve tamb\'em a preocupa\cc\~ao de estabelecer uma liga\cc\~ao mais clara e direta com os conceitos-chave apresentados. - Novos Exemplos, Perguntas e Problemas250 novos problemas, 50 perguntas in\'editas e 16 novos exemplos foram acrescentados a esta edi\cc\~ao. Permanecem como destaques desta 10a edi\cc\~ao os materiais suplementares, todos traduzidos e dispon\'iveis no site www.grupogen.com.br/halliday-volume-3 (LTC Editora – GEN | Grupo Editorial Nacional), mediante cadastro.},
volume = {3},
edition = {Edi\cc\~ao: 10\textordfeminine, Nova Edi\cc\~ao},
}

@book{1979AlexanderTimeless,
author = { Alex and Christopher er},
year = {1979},
publisher = {Oxford University Press},
issn = {15403602},
pages = {Alexander, C., Ishikawa, S., & Silverstein, M. (19},
title = {The Timeless Way of Building},
isbn = {0195024028},
pmid = {3653177},
booktitle = {New York Oxford University Press},
abstract = {This volume provides the opening work in Christopher Alexander's seminal trilogy on architecture (continued in A Pattern Language and The Oregon Experiment). Here he provides a fascinating introduction to the ideas behind the succeeding two books.},
}

@book{2016SeverinoMetodologia,
author = {Ant\^onio Joaquim Severino},
abstract = {Metodologia -\'e uma palavra derivada de " m\'etodo " , do Latim " methodus " cujo significado \'e " caminho ou a via para a realiza\cc\~ao de algo " . Ci\^encia -etimologicamente, o termo ci\^encia prov\'em do verbo em latim Scire, que significa aprender, conhecer. Ent\~ao metodologia do trabalho cient\'ifico \'e entendida como uma disciplina que consiste em estudar, compreender e avaliar os v\'arios m\'etodos dispon\'iveis para a realiza\cc\~ao de uma pesquisa acad\'emica. Conhecimento cient\'ifico -\'e o conhecimento racional, sistem\'atico, exato e verific\'avel da realidade. Sua origem est\'a nos procedimentos de verifica\cc\~ao baseados na metodologia cient\'ifica. Podemos ent\~ao dizer que o conhecimento cient\'ifico: -\'E racional e objectivo. -At\'em-se aos fatos. -Transcende aos fatos. -\'E anal\'itico. -Requer exatid\~ao e clareza. -\'E comunic\'avel. -\'E verific\'avel. -Depende de investiga\cc\~ao met\'odica. -Busca e aplica leis. -\'E explicativo. -Pode fazer predi\cc\~oes. -\'E aberto. -\'E \'util. Exemplo: Descobrir uma vacina que evite uma doen\cca; Descobrir como se d\'a a respira\cc\~ao dos batr\'aquios; Outros tipos de conhecimento: Conhecimento que deriva da autoridade -do latim auctorĭtas, a autoridade \'e o poder, a legitimidade ou a faculdade. Em geral, o termo refere-se \`as pessoas que governam ou que exercem o comando. Temos como por exemplo a religi\~ao. Os adventistas do s\'etimo dia guardam o S\'abado como sendo o dia de descanso, pois na b\'iblia esta escrito " lembra – te do dia do S\'abado para o santificar (G\^enesis 20:4).},
publisher = {Cortez},
year = {2007},
pages = {304},
title = {Metodologia do trabalho cientifico},
isbn = {978-85-249-1311-2},
}

@misc{2006HillerCarbon,
author = {Jonathan Hiller},
title = {Carbon fiber vs. wood as an acoustic guitar soundboard},
}

@misc{2006HillerComposite,
author = {Burke Andrejko and Mustafa Mohammed},
title = {Composite Acoustic Guitar},
year = {2008},
booktitle = {Group},
}

@book{2016StrangIntroduction,
author = {Charles W. Curtis},
title = {Introduction to Linear Algebra},
edition = {Fifth Edition edition},
doi = {10.1007/978-1-4612-1136-5_1},
publisher = {Wellesley-Cambridge Press},
isbn = {978-0-9802327-7-6},
pages = {1--15},
abstract = {Gilbert Strang's textbooks have changed the entire approach to learning linear algebra -- away from abstract vector spaces to specific examples of the four fundamental subspaces: the column space and nullspace of A and A'. This new fifth edition has become more than a textbook for the basic linear algebra course. That is its first purpose and always will be. The new chapters about applications of the SVD, probability and statistics, and Principal Component Analysis in finance and genetics, make it also a textbook for a second course, plus a resource at work. Linear algebra has become central in modern applied mathematics. This book supports the value of understanding linear algebra. Introduction to Linear Algebra, Fifth Edition includes challenge problems to complement the review problems that have been highly praised in previous editions. The basic course is followed by eight applications: differential equations in engineering, graphs and networks, statistics, Fourier methods and the FFT, linear programming, computer graphics, cryptography, Principal Component Analysis, and singular values. Audience: Thousands of teachers in colleges and universities and now high schools are using this book, which truly explains this crucial subject. This text is for readers everywhere, with support from the websites and video lectures. Every chapter begins with a summary for efficient review. Contents: Chap. 1: Introduction to Vectors; Chap. 2: Solving Linear Equations; Chap. 3: Vector Spaces and Subspaces; Chap. 4: Orthogonality; Chap. 5: Determinants; Chap. 6: Eigenvalues and Eigenvectors; Chap. 7: Singular Value Decomposition; Chap. 8: Linear Transformations; Chap. 9: Complex Vectors and Matrices; Chap. 10: Applications; Chap. 11: Numerical Linear Algebra; Chap. 12: Linear Algebra in Probability and Statistics; Matrix Factorizations; Index; Six Great Theorems.},
year = {1984},
}

@book{2013HallidayFundamentals,
author = { Halliday and  Resnick and  Walker},
publisher = {Wiley},
abstract = {Market_Desc: \textperiodcentered Physicists\textperiodcentered Physics Students \textperiodcentered Instructors Special Features: \textperiodcentered A new edition of the book that has been the market leader for 30 years! \textperiodcentered Problem-solving tactics are provided to help the reader solve problems and avoid common errors\textperiodcentered This new edition features several thousand end of chapter problems that were rewritten to streamline both the presentations and answers\textperiodcentered Chapter Puzzlers open each chapter with an intriguing application or question that is explained or answered in the chapterAbout The Book: In a breezy, easy-to-understand style this book offers a solid understanding of fundamental physics concepts, and helps readers apply this conceptual understanding to quantitative problem solving. It offers a unique combination of authoritative content and stimulating applications.},
url = {http://books.google.com/books?id=RVCE4EUjDCgC&pgis=1},
pages = {1224},
title = {Fundamentals of Physics Extended, 8Th Ed},
isbn = {8126514426},
edition = {10 edition},
year = {2008},
}

@book{2010BurnetteHello,
author = {Ed Burnette},
abstract = {Google's Android is shaking up the mobile market in a big way. With Android, you can write programs that run on any compatible cell phone or tablet in the world. It's a mobile platform you can't afford not to learn, and this book gets you started. Hello, Android has been updated to Android 2.3.3, with revised code throughout to reflect this updated version. That means that the book is now up-to-date for tablets such as the Kindle Fire. All examples were tested for forwards and backwards compatibility on a variety of devices and versions of Android from 1.5 to 4.0. (Note: the Kindle Fire does not support home screen widgets or wallpaper, so those samples couldn't be tested on the Fire.)Android is an operating system for mobile phones and tablets. It's inside millions of cell phones and other devices, including the hugely popular Amazon Kindle Fire, making Android the foremost platform for mobile application developers. That could be your own program running on all those devices.Within minutes, Hello, Android will get you started creating your first working application: Android's version of "Hello, World." From there, you'll build up a more substantial example: an Android Sudoku game. By gradually adding features to the game, you'll learn the basics of Android programming. You'll also see how to build in audio and video support, add graphics using 2D and 3D OpenGL, network with web pages and web services, and store data with SQLite. You'll also learn how to publish your applications to the Android Market.The ///////\\#1 book for learning Android is now in its third edition. Every page and example was reviewed and updated for compatibility with the latest versions. Freshly added material covers installing applications to the SD card, supporting multi-touch, and creating live wallpaper. You'll also find plenty of real-world advice on how to support all major Android versions in use today.If you'd rather be coding than reading about coding, this book is for you.},
isbn = {978-1-934356-56-2},
edition = {Third edition},
publisher = {Pragmatic Bookshelf},
shorttitle = {Hello, Android},
title = {Hello, Android: Introducing Google's Mobile Development Platform},
}

@book{2009KothariResearch,
author = {Cr Kothari},
publisher = {New Age International Publishers},
abstract = {This Second Edition Has Been Thoroughly Revised And Updated And Efforts Have Been Made To Enhance The Usefulness Of The Book. In This Edition A New Chapter The Computer : Its Role In Research Have Been Added Keeping In View Of The Fact That Computers By Now Become A Indispensable Part Of Research Equipment. The Other Salient Feature Of This Revised Edition, Subject Contents Have Been Developed And Restructured At Several Places. New Problems Have Also Been Added In Various Chapters.Adoption Of Appropriate Methodology Is An Essential Characteristic Of Quality Research Studies Irrespective Of The Discipline With Which They Are Related. The Present Book Provides The Basic Tenets Of Methodological Research So That Researchers May Become Familiar With The Art Of Using Research Methods And Techniques.The Book Contains Introductory Explanations Of Several Quantitative Methods Enjoying Wide Use In Social Sciences. It Covers A Fairly Wide Range, Related To Research Methodology. The Presentations Are Uniformly Economical And Cogent. Illustrations Given Are Meaningful And Relevant. The Book Can Be Taken As A Well-Organised Guide For Researchers Whose Methodological Background Is Not Extensive.The Book Is Primarily Intended To Serve As A Textbook For Social Science Students Of All Indian Universities. It Will Also Serve As A Text For The Students Of M.Phil, Management, And Students Of Various Institutes. It Will Serve All Practitioners Doing Research Of One Form Or Other In A General Way.},
doi = {http://196.29.172.66:8080/jspui/bitstream/123456789/2574/1/Research%20Methodology.pdf},
isbn = {9788122424881},
title = {Research methodology: methods and techniques},
year = {2004},
pages = {418},
booktitle = {New Age International},
edition = {2nd revised edition edition},
url = {http://books.google.com/books?hl=en&lr=&id=8c6gkbKi-F4C&oi=fnd&pg=PR7&dq=Research+Methodology:+Methods+and+Techniques&ots=iGnHoSUbpN&sig=MCLUW6fq3hl5GDq0RanXjegF9Gg},
}

@book{2000DudaPattern,
author = {Thierry Den?ux},
booktitle = {Handbook of Neural Computation},
doi = {10.1887/0750303123/b365c83},
publisher = {Wiley-Interscience},
edition = {2 edition},
abstract = {... Estimation, 161 4.3 Parzen Windows, 164 4.3.1 Convergence of the Mean, 167 4.3.2 Convergence of the Variance, 167 4.3.3 Illustrations, 168 4.3.4 Classification Example, 168 4.3.5 Probabilistic Neural Networks (PNNs), 172 4.3.6 Choosing the Window Function , 174 4.4 kn ...},
isbn = {978-0-471-05669-0},
title = {Pattern classification},
year = {2004},
}

@book{2018GriffithsIntroduction,
author = {Eduardo J.S. Villase\~nor},
edition = {3 edition},
doi = {10.1063/1.2958160},
title = {Introduction to Quantum Mechanics},
volume = {1023},
isbn = {9780735405462},
pages = {107--117},
year = {2008},
issn = {0094243X},
abstract = {The purpose of this contribution is to give a very brief introduction to Quantum Mechanics for an audience of mathematicians. I will follow Segal's approach to Quantum Mechanics paying special attention to algebraic issues. The usual representation of Quantum Mechanics on Hilbert spaces is also discussed. \textcopyright 2008 American Institute of Physics.},
publisher = {Cambridge University Press},
booktitle = {AIP Conference Proceedings},
keywords = {quantum mechanics},
mendeley-tags = {quantum mechanics},
}

@book{2012AndersonStatistics,
author = {Neville Davies and Paul Newbold},
doi = {10.2307/3615710},
abstract = {applicability for this approach.},
title = {Statistics for Business and Economics},
booktitle = {The Mathematical Gazette},
number = {453},
publisher = {Cengage Learning},
isbn = {978-1-285-02755-5},
pages = {243},
volume = {70},
year = {1986},
issn = {00255572},
}

@book{2014WhitePhysics,
author = {Larry Beach},
pages = {261--262},
volume = {8},
shorttitle = {Physics and Music},
abstract = {This foundational text is written for students who want to go beyond the perceptual stage of music to learn how musical sound is created and perceived. It surveys a wide range of topics related to acoustics, beginning with a brief history of the art and science of music. Succeeding chapters explore the general principles of sound, musical scales, the primary ways in which sound can be generated, the characteristics of instruments, the use of mechanical and electronic recording devices, hi-fi stereophonic and quadraphonic sound, the design of electronic musical instruments, and architectural acoustics.Comprehensive yet accessible, Physics and Music includes over 300 diagrams, photographs, and tables. Each chapter concludes with questions, problems, and projects, in addition to references for further study. 1980 edition.},
issn = {1522-8541},
isbn = {978-0-486-77934-8},
number = {2},
booktitle = {Medical Physics},
publisher = {Dover Publications},
title = { Physics and Music: The Science of Musical Sound , by H. E. White and D. H. White },
doi = {10.1118/1.594956},
year = {1981},
edition = {Reprint edition},
}

@book{2005SurowieckiWisdom,
author = {Ellen Teesdale},
abstract = {In this fascinating book, New Yorker business columnist James Surowiecki explores a deceptively simple idea: Large groups of people are smarter than an elite few, no matter how brilliant—better at solving problems, fostering innovation, coming to wise decisions, even predicting the future. With boundless erudition and in delightfully clear prose, Surowiecki ranges across fields as diverse as popular culture, psychology, ant biology, behavioral economics, artificial intelligence, military history, and politics to show how this simple idea offers important lessons for how we live our lives, select our leaders, run our companies, and think about our world.},
number = {10042},
publisher = {Anchor},
title = {The wisdom of crowds},
pages = {321},
doi = {10.1016/S0140-6736(16)31130-8},
booktitle = {The Lancet},
isbn = {978-0-385-72170-7},
edition = {Reprint edition},
issn = {1474547X},
pmid = {27477150},
volume = {388},
year = {2016},
}

@book{2011KotlerPrinciples,
author = {J. G. Smith and Fred. E. Clark},
issn = {00130133},
title = {Principles of Marketing.},
volume = {38},
edition = {14 edition},
number = {151},
booktitle = {The Economic Journal},
publisher = {Prentice Hall},
year = {1928},
pages = {450},
abstract = {15th ed. Marketing : creating and capturing customer value -- Company and marketing strategy : partnering to build customer relationships -- Analyzing the marketing environment -- Managing marketing information to gain customer insights -- Consumer markets and consumer buyer behavior -- Business markets and business buyer behavior -- Customer-driven marketing strategy : creating value for target customers -- Products, services, and brands : building customer value -- New-product development and product life-cycle strategies -- Pricing products : understanding and capturing customer value -- Pricing strategies : additional considerations -- Marketing channels : delivering customer value -- Retailing and wholesaling -- Communicating customer value : integrated marketing communication strategy -- Advertising and public relations -- Personal selling and sales promotion -- Direct and online marketing : building direct customer relationships -- Creating competitive advantage -- The global marketplace -- Sustainable marketing : social responsibility and ethics.},
isbn = {978-0-13-216712-3},
doi = {10.2307/2224326},
}

@article{norman_innovation_2003,
author = {Eddie Norman},
pages = {91--97},
title = {Innovation in design and technology : the polymer acoustic guitar and the case for the relegation of ‘ the design process '},
abstract = {Innovation and creativity are key aspects of design and technological activity. The development of the polymer acoustic guitar at Loughborough University has been recognised as a highly innovative project having received three innovation awards from major bodies. This paper describes three key aspects of the development, in particular the capability to imagine future possibilities, the role of knowledge and appropriate prototyping. These aspects lie at the heart of the innovation, although, of course, the whole activity was supported by key design skills, such as drawing and CAD. Some aspects of design epistemology (ways of knowing that facilitate designing) are discussed using evidence from this project, for example, the roles of ‘knowing that' and ‘knowing how' and the supposed tension between ‘craft skills' and ‘modern technology'. The importance of fitness for purpose when prototyping is emphasised and the link to the problems associated with product outcomes and innovation noted. A model of design and technological activity is discussed which emphasises the role of knowledge in realising design possibilities. This model was first presented at DATA's Millennium Conference (Norman 2000) and is a modification of one discussed by Roberts (1992). It incorporates the idea of technology for design as the summation of knowledge, skills and values (Norman, 1998) and provides an alternative way of thinking about design and technological activity. It is argued that existing ideas surrounding ‘the design process', as represented by a series of stages derived from systems analysis, are a significant stumbling block to promoting innovation.},
url = {https://dspace.lboro.ac.uk/2134/2799%0Ahttp://hdl.handle.net/2134/2799},
year = {2003},
journal = {DATA International Research Conference},
shorttitle = {Innovation in design and technology},
}

@book{1999KotlerMarketing,
author = {Philip Kotler},
edition = {10 edition},
isbn = {978-0-13-012217-9},
publisher = {Prentice Hall},
shorttitle = {Marketing Management},
title = {Marketing Management: Millennium Edition},
abstract = {This world-wide best-selling book highlights the most recent trends and developments in global marketingwith an emphasis on the importance of teamwork between marketing and all the other functions of the business. It introduces new perspectives in successful strategic market planning, and presents additional company examples of creative, market-focused, and customer-driven action. Coverage includes a focus on marketing in the 21st Century that introduces the new ideas, tools and practices companies will need to successfully operate in the New Millenium. Chapter topics discuss building customer satisfaction, market-oriented strategic planning, analyzing consumer markets and buyer behavior, dealing with the competition, designing pricing strategies and programs, and managing the sales force. For marketing managers who want to increase their understanding of the major issues of strategic, tactical, and administrative marketingalong with the opportunities and needs of the marketplace in the years ahead.},
}

@book{JolleySummation,
author = {L. Short},
year = {1991},
pages = {985--996},
abstract = {Three approaches are considered to the summation of some 'standard' series: An elementary analysis, an approach based on residues, and a technique employing the digamma function and partial fractions. This last procedure is the most convenient to use, but all three techniques have their limitations. \textcopyright 1991 Taylor & Francis Ltd.},
booktitle = {International Journal of Mathematical Education in Science and Technology},
publisher = {Dover Publications Inc.},
volume = {22},
issn = {14645211},
doi = {10.1080/0020739910220617},
edition = {Second Revised Edition edition},
isbn = {978-0-486-60023-9},
title = {Summation of series},
number = {6},
}

@article{arcanjo_o_2013,
author = {Loque Arcanjo},
volume = {6},
number = {1},
year = {2013},
pages = {25--35},
url = {https://www.academia.edu/4924894/O///////%5C%5C_Violao///////%5C%5C_de///////%5C%5C_Heitor///////%5C%5C_Villa-Lobos///////%5C%5C_entre///////%5C%5C_a///////%5C%5C_Belle///////%5C%5C_Epoque///////%5C%5C_e///////%5C%5C_as///////%5C%5C_rodas///////%5C%5C_de///////%5C%5C_choro},
issn = {1984-767X},
journal = {E-Hum},
abstract = {Mestre em pr\'aticas interpretativas, o violonista, pesquisador e professor Humberto Amorim dedica-se neste livro a explorar uma das mais importantes facetas da obra de Villa-Lobos: suas composi\cc\~oes para viol\~ao. Dentro desse repert\'orio, Villa \'e o autor mais tocado do s\'eculo XX em todo o mundo. Com seus conhecimentos t\'ecnicos sobre o instrumento, escreveu obras que alargaram as possibilidades do viol\~ao e o trouxeram \`a modernidade. \'E surpreendente, portanto, que at\'e o momento n\~ao existisse um estudo minucioso que se debru\ccasse sobre esse repert\'orio e nos ajudasse a desvendar as circunst\^ancias de sua composi\cc\~ao, bem como suas especificidades. \'E o que Amorim faz agora, em um importante estudo que faz um levantamento cr\'itico da obra para viol\~ao do compositor. Para F\'abio Zanon, trata-se de "um trabalho excepcional de musicologia, que junta os pontos e preenche as lacunas, em um equil\'ibrio raro entre o trabalho de investigador, a sensatez na interpreta\cc\~ao dos dados, a isen\cc\~ao e a admira\cc\~ao pelo objeto de estudo".},
title = {O viol\~ao de Heitor Villa-Lobos: entre a Belle \'Epoque carioca e as rodas de choro},
keywords = {art,art history,modern art,modernism,musical},
mendeley-tags = {art,art history,modern art,modernism,musical},
}

@inproceedings{2013RibeiroNumerical,
author = {Roseli Ribeiro},
title = {Numerical Analysis of Acoustic Guitars Soundboards},
booktitle = {22nd International Congress of Mechanical Engineering},
}

@article{2016LeeMathematical,
author = {Meng Koon Lee and Mohammad Hosseini Fouladi and Satesh Narayana Namasivayam},
journal = {Advances in Acoustics and Vibration},
url = {https://www.hindawi.com/journals/aav/2016/6084230/},
volume = {2016},
year = {2016},
title = {Mathematical modelling and acoustical analysis of classical guitars and their soundboards},
doi = {10.1155/2016/6084230},
abstract = {Research has shown that the soundboard plays an increasingly important role compared to the sound hole, back plate, and the bridge at high frequencies.The frequency spectrum of investigation can be extended to 5 kHz. Design of bracings and their placements on the soundboard increase its structural stiffness as well as redistributing its deflection to nonbraced regions and affecting its loudness as well as its response at low and high frequencies.This paper attempts to present a review of the current state of the art in guitar research and to propose viable alternatives that will ultimately result in a louder and better sounding instrument. Current research is an attempt to increase the sound level with bracing designs and their placements, control of natural frequencies using scalloped braces, aswell as improve the acoustic radiation of this instrument at higher frequencies by deliberately inducing asymmetricmodes in the soundboard using the concept of "splitting board." Variousmathematicalmethods are available for analysing the soundboard based on the theory of thin plates. Discrete models of the instrument up to 4 degrees of freedom are also presented. Results from finite element analysis can be utilized for the evaluation of acoustic radiation.},
issn = {1687627X},
pages = {1--10},
}

@collection{2007BottouLarge,
annote = {OCLC: ocm79002103},
publisher = {The MIT Press},
editor = {Bottou, L\'eon},
series = {Neural information processing series},
isbn = {978-0-262-02625-3},
title = {Large-scale kernel machines},
}

@article{yau_is_2013,
author = {Alex Yau and Christian Murphy},
title = {Is a Rigorous Agile Methodology the Best Development Strategy for Small Scale Tech Startups ?},
number = {Paper 980},
journal = {University of Pennsylvania Department of Computer and Information Science Technical Report No. MS-CIS.13-01},
abstract = {Recently, Agile development processes have become popular in the software development community, and have been shown to be effective in large organizations. However, given that the communication and cooperation dynamics in startup companies are very different from that of larger, more established companies, and the fact that the initial focus of a startup might be significantly different from its ultimate goal, it is questionable whether a rigid process model that works for larger companies is appropriate in tackling the problems faced by a startup. When we scale down even further and observe the small scale startup with only a few members, many of the same problems that Agile methodology sets out to solve do not even exist. Then, for a small scale startup, is it still worth putting the resources into establishing a process model? Do the benefits of adopting an Agile methodology outweigh the opportunity cost of spending the resources elsewhere? This paper examines the advantages and disadvantages of adopting an Agile methodology in a small scale tech startup and compares it to other process models, such as the Waterfall model and Lean Startup. In determining whether a rigorous agile methodology is the best development strategy for small scale tech startups, we consider the metrics of cost, time, quality, and scope in light of the particular needs of small startup organizations, and present a case study of a company that has needed to answer this very question.},
pages = {9},
year = {2013},
keywords = {agile methodology,lean startup,small scale tech startup},
mendeley-tags = {agile methodology,lean startup,small scale tech startup},
}

@article{2018GhezziAgile,
author = {Antonio Ghezzi and Angelo Cavallo},
doi = {10.1016/j.jbusres.2018.06.013},
journal = {Journal of Business Research},
title = {Agile Business Model Innovation in Digital Entrepreneurship: Lean Startup Approaches},
pages = {519--537},
shorttitle = {Agile Business Model Innovation in Digital Entrepreneurship},
issn = {01482963},
abstract = {Digital startups in the early stages of their development frequently undergo innovation to their value architecture and Business Model. A set of pragmatic methods drawing on lean and agile principles has recently been proposed to support digital entrepreneurs facing Business Model Innovation (BMI), known as Lean Startup Approaches (LSAs). However, the theoretical and practical relationship between BMI and LSAs in dynamic digital environments has seldom been investigated. To fill this gap, our study draws on an exploratory multiple-case study based on three digital multisided platform startups to craft a unified framework that can disclose the relationship between BMI, LSAs and Agile Development (AD), within the context of Strategic Agility. Our findings, which emerge from the unified framework, show that LSAs can be employed as agile methods to enable Business Model Innovation in Digital Entrepreneurship. These findings are then organized around a set of propositions, with the aim of developing a research agenda directed towards integrating BMI, LSAs and AD processes and methods.},
url = {https://linkinghub.elsevier.com/retrieve/pii/S014829631830300X},
year = {2020},
volume = {110},
keywords = {agile development,business model innovation,customer development,digital startups,lean startup approaches,multisided platform,strategic agility},
mendeley-tags = {agile development,business model innovation,customer development,digital startups,lean startup approaches,multisided platform,strategic agility},
}

@incollection{2016DucMinimum,
author = {Anh Nguyen Duc and Pekka Abrahamsson},
booktitle = {Lecture Notes in Business Information Processing},
editor = {Sharp, Helen and Hall, Tracy},
volume = {251},
year = {2016},
isbn = {9783319335148},
doi = {10.1007/978-3-319-33515-5_10},
shorttitle = {Minimum Viable Product or Multiple Facet Product?},
abstract = {Minimum viable product (MVP) is the main focus of both business and product development activities in software startups. We empirically explored five early stage software startups to understand how MVP are used in early stages. Data was collected from interviews, observation and documents. We looked at the MVP usage from two angles, software prototyping and boundary spanning theory. We found that roles of MVPs in startups were not fully aware by entrepreneurs. Besides supporting validated learning, MVPs are used to facilitate product design, to bridge communication gaps and to facilitate cost-effective product development activities. Entrepreneurs should consider a systematic approach to fully explore the value of MVP, as a multiple facet product (MFP). The work also implies several research directions about prototyping practices and patterns in software startups.},
pages = {118--130},
issn = {18651348},
publisher = {Springer International Publishing},
title = {Minimum viable product or multiple facet product? The role of MVP in software startups},
keywords = {empirical study,exploratory case study,mfp,mvp,prototype,software development,software startups},
mendeley-tags = {empirical study,exploratory case study,mfp,mvp,prototype,software development,software startups},
}

@article{2014FlyvbjergWhat,
author = {Bent Flyvbjerg},
doi = {10.1002/pmj.21409},
journal = {Project Management Journal},
shorttitle = {What You Should Know About Megaprojects and Why},
abstract = {This paper takes stock of megaproject management, an emerging and hugely costly field of study, by first answering the question of how large megaprojects are by measuring them in the units of mega, giga, and tera, and concluding with how we are presently entering a new "tera era" of trillion-dollar projects. Second, total global megaproject spending is assessed, at US$6 to US$9 trillion annually, or 8% of the total global gross domestic product (GDP), which denotes the biggest investment boom in human history. Third, four "sublimes" - political, technological, economic, and aesthetic - are identified and used to explain the increased size and frequency of megaprojects. Fourth, the "iron law of megaprojects" is laid out and documented: Over budget, over time, over and over again. Moreover, the "break-fix model" of megaproject management is introduced as an explanation of the iron law. Fifth, Albert O. Hirschman's theory of the "Hiding Hand" is revisited and critiqued as unfounded and corrupting for megaproject thinking in both the academy and policy. Sixth, it is shown how megaprojects are systematically subject to "survival of the unfittest," which explains why the worst projects get built rather than the best. Finally, it is argued that the conventional way of managing megaprojects has reached a "tension point," in which tradition is being challenged and reform is emerging. \textcopyright 2014 by the Project Management Institute.},
year = {2014},
title = {What you should know about megaprojects and why: An overview},
volume = {45},
number = {2},
pages = {6--19},
issn = {87569728},
keywords = {break-fix model of megaprojects,four sublimes,hirschman's principle of the hiding hand,iron law of megaprojects,megaproject management,scale,survival of the unfittest,tension points},
mendeley-tags = {break-fix model of megaprojects,four sublimes,hirschman's principle of the hiding hand,iron law of megaprojects,megaproject management,scale,survival of the unfittest,tension points},
}

@article{2008OruetaNew,
author = {Fern Orueta and o Diaz and Susan S. Fainstein},
issn = {03091317},
title = {The new mega-projects: Genesis and impacts},
journal = {International Journal of Urban and Regional Research},
volume = {32},
abstract = {Critiques of urban renewal and large-scale developments were prominent in the period 1960-80. In particular, they emphasized the negative environmental and social consequences of these schemes and especially attacked them for displacing low-income and ethnically different populations. In the 1980s and 1990s, we saw a decline in such projects in many places, responding to popular protest and intellectual dissent, along with a new emphasis on preservation. More recently, however, we see the revival of mega-projects, often connected with tourism and sports development and incorporating the designs of world-famous architects. Frequently these are on landfill or abandoned industrial sites. The symposium for which this is an introduction shows the growing convergence of North American and European projects. This convergence is visible in their physical form, their financing, and in the role played by the state in a world marked by neoliberalism. At the same time, the new projects do display a greater environmental sensitivity and commitment to urbanity than the modernist schemes of an earlier epoch. \textcopyright 2009 The Authors. Journal Compilation \textcopyright 2009 Joint Editors and Blackwell Publishing Ltd.},
pages = {759--767},
shorttitle = {The New Mega-Projects},
doi = {10.1111/j.1468-2427.2008.00829.x},
number = {4},
year = {2008},
keywords = {local government,mega-projects,property,real estate,spatial processes,urban redevelopment},
mendeley-tags = {local government,mega-projects,property,real estate,spatial processes,urban redevelopment},
}

@book{2013GreimanMegaproject,
author = {Virginia Greiman},
shorttitle = {Megaproject Management},
publisher = {John Wiley ////////\\\& Sons, Inc.},
title = {Megaproject management [Recurso electr\'onico] : lessons on risk and project management from the Big Dig / Virginia A. Greiman},
doi = {10.1002/9781118671092},
isbn = {978-1-118-67109-2 978-1-118-11547-3},
year = {2013},
url = {http://encore.fama.us.es/iii/encore/record/C__Rb2619627__Smegaproject__Orightresult__U__X6?lang=spi&suite=cobalt},
}

@online{2008DoriaO,
author = {Pedro Doria},
abstract = {Uma negocia\cc\~ao a portas fechadas, no tempo dos militares, volta para assombrar o Brasil},
title = {O verdadeiro pre\cco de Itaipu},
url = {https://alias.estadao.com.br/noticias/geral,o-verdadeiro-preco-de-itaipu,163784},
}

@online{2013JeronimoPonte,
author = {Josie Jeronimo},
abstract = {H\'a muitas d\'uvidas sobre a necessidade da obra que ligar\'a Salvador a Itaparica. A certeza \'e que o valor pago pelo governo da Bahia est\'a superdimensionado},
title = {A ponte de R$ 7 bilh\~oes},
url = {https://istoe.com.br/274208///////%5C%5C_A+PONTE+DE+R+7+BILHOES/},
}

@online{2014OtavioO,
author = {Chico Ot\'avio and Bruno G\'oes},
title = {O Globo - Ponte Rio Niter\'oi},
url = {http://infograficos.oglobo.globo.com/pais/ponte-rio-niteroi.html},
}

@online{2018PrestesPrestes,
author = {Fabiano Maisonnave and Lalo de Almeida},
title = {Prestes a Ser Conclu\'ida, Belo Monte \'e Criticada por Atingidos e Especialistas},
year = {2018},
booktitle = {Folha de S\~ao Paulo},
abstract = {Mudan\cca na vaz\~ao dos rios para abastecer usina muda fauna e h\'abitos da popula\cc\~ao local},
url = {https://temas.folha.uol.com.br/projeto-amazonia/hidreletricas/prestes-a-ser-concluida-belo-monte-e-criticada-por-atingidos-e-especialistas.shtml},
}

@online{noauthor_em_2010,
abstract = {Valor equivale a quase seis vezes o que o Brasil pretende investir nos Jogos Ol\'impicos de 2016},
title = {Em dinheiro de hoje, Bras\'ilia custaria US$ 83 bilh\~oes - Bras\'ilia 50 anos - iG},
url = {https://ultimosegundo.ig.com.br/brasilia50anos/em-dinheiro-de-hoje-brasilia-custaria-us-83-bilhoes/n1237588758783.html},
}

@inreference{noauthor_estadio_2019,
booktitle = {Wikip\'edia, a enciclop\'edia livre},
annote = {Page Version ID: 54720810},
title = {Est\'adio do Maracan\~a},
abstract = {Est\'adio Jornalista M\'ario Filho, mais conhecido como Maracan\~a, o popular Maraca ("semelhante a um chocalho" em tupi-guarani, devido ao som de p\'assaros que viviam por ali), \'e um est\'adio de futebol localizado na Zona Norte do Rio de Janeiro e inaugurado em 1950, durante o mandato do ent\~ao General de Divis\~ao e Prefeito do Distrito Federal do Rio de Janeiro Marechal \^Angelo Mendes de Moraes, tendo sido utilizado na Copa do Mundo de Futebol daquele ano. Desde ent\~ao, o Maracan\~a foi palco de grandes momentos do futebol brasileiro e mundial, como o mil\'esimo gol de Pel\'e, finais do Campeonato Brasileiro, Carioca de Futebol, Ta\cca Libertadores da Am\'erica e do primeiro Campeonato Mundial de Clubes da FIFA, al\'em de competi\cc\~oes internacionais e partidas da Sele\cc\~ao Brasileira. O est\'adio foi um dos locais de competi\cc\~ao dos Jogos Pan-Americanos de 2007, recebendo o futebol, as cerim\^onias de abertura e de encerramento. Sediou futebol e as cerim\^onias de abertura e encerramento dos Jogos Ol\'impicos de 2016, que foram realizados na cidade do Rio de Janeiro. Foi tamb\'em o palco da partida final da Copa das Confedera\cc\~oes de 2013 e da Copa do Mundo FIFA de 2014Ao longo do tempo, no entanto, o est\'adio passou a assumir car\'ater de espa\cco multi\'uso ao receber outros eventos como espet\'aculos e partidas de outros esportes, como o voleibol em uma oportunidade. Ap\'os diversas obras de moderniza\cc\~ao, a capacidade do est\'adio \'e de 78 838 espectadores, sendo o maior est\'adio do Brasil.},
url = {https://pt.wikipedia.org/w/index.php?title=Est///////%5C%5C%C3///////%5C%5C%A1dio///////%5C%5C_do///////%5C%5C_Maracan///////%5C%5C%C3///////%5C%5C%A3///////%5C%5C&oldid=54720810},
}

@online{noauthor_maracana:_2013,
abstract = {Governo afirma que n\~ao haver\'a outras surpresas indesejadas para contribuinte},
url = {https://veja.abril.com.br/esporte/maracana-preco-final-e-r-119-bi-69-acima-do-previsto/},
title = {Maracan\~a: ‘pre\cco final' \'e R$ 1,19 bi, 69///////\\% acima do previsto},
shorttitle = {Maracan\~a},
}

@online{2018OttaTransposicao,
author = {Lu Otta},
abstract = {Minist\'erio da Transpar\^encia diz que se projeto de transposi\cc\~ao do Rio S\~ao Francisco n\~ao se autossustentar conta ser\'a paga pelo Tesouro},
title = {Transposi\cc\~ao custar\'a R$ 800 milh\~oes ao ano - Economia},
url = {https://economia.estadao.com.br/noticias/geral,transposicao-custara-r-800-milhoes-ao-ano,70002268817},
}

@online{noauthor_projeto_2018,
title = {Projeto de Integra\cc\~ao do Rio S\~ao Francisco: uma obra que j\'a entrou para a hist\'oria},
url = {https://www.huffpostbrasil.com/2018/12/18/projeto-de-integracao-do-rio-sao-francisco-uma-obra-que-ja-entrou-para-a-historia///////%5C%5C_a///////%5C%5C_23621697/},
abstract = {O projeto de integra\cc\~ao do Rio S\~ao Franscisco \'e a mais importante iniciativa do governo federal em temos da Pol\'itica Nacional de Recursos H\'idricos.},
shorttitle = {Projeto de Integra\cc\~ao do Rio S\~ao Francisco},
}

@online{noauthor_brasil_2015,
url = {//www.brasil247.com/pt/247/brasil/167233/Brasil-tem-6-das-100-obras-mais-importantes-do-mundo.htm},
abstract = {Seis grandes obras de infraestrutura do Brasil est\~ao entre as 100 mais importantes do mundo, de acordo com lista feita pela consultoria internacional KPMG; quatro delas t\^em o carimbo do Programa de Acelera\cc\~ao do Crescimento (PAC), do governo federal, Seis grandes obras de infraestrutura do Brasil est\~ao entre as 100 mais importantes do mundo, de acordo com lista feita pela consultoria internacional KPMG; quatro delas t\^em o carimbo do Programa de Acelera\cc\~ao do Crescimento (PAC), do governo federal},
title = {Brasil tem 6 das 100 obras mais importantes do mundo},
}

@inreference{noauthor_ef-354_2019,
annote = {Page Version ID: 54416427},
abstract = {A Ferrovia Transcontinental - EF-354 (tamb\'em referida como Ferrovia Transoce\^anica), \'e o projeto de uma ferrovia firmado entre os governos do Brasil e Peru, que busca conectar o Oceano Atl\^antico, no litoral brasileiro ao Oceano Pac\'ifico no litoral peruano, atravessando de Leste a Oeste o continente Sul-americano. A extens\~ao total \'e estimada em 4.400 km em solo brasileiro.},
booktitle = {Wikip\'edia, a enciclop\'edia livre},
title = {EF-354},
url = {https://pt.wikipedia.org/w/index.php?title=EF-354///////%5C%5C&oldid=54416427},
}

@online{2018MaiaFerrovia,
author = {Ti\~ao Maia},
title = {Ferrovia Transoce\^anica come\cca a sair do papel},
url = {https://www.expressoamazonia.com.br/index.php/economia/413-ferrovia-transoceanica-comeca-a-sair-do-papel.html},
}

@online{2013NederCusto,
author = {Vin\'icius Neder},
abstract = {Valor foi estimado por consultoria internacional e \'e quatro vezes superior \`a proje\cc\~ao da ANP},
title = {Custo para explorar pr\'e-sal de Libra pode chegar a US$ 400 bilh\~oes - Economia},
url = {https://economia.estadao.com.br/noticias/geral,custo-para-explorar-pre-sal-de-libra-pode-chegar-a-us-400-bilhoes,169408e},
}

@online{noauthor_angra_2000,
title = {Angra 2 come\cca a funcionar ap\'os gastar R$ 12 bilh\~oes},
url = {https://www1.folha.uol.com.br/fsp/dinheiro/fi2307200009.htm},
}

@inreference{noauthor_usina_2019,
booktitle = {Wikip\'edia, a enciclop\'edia livre},
title = {Usina Hidrel\'etrica Santo Ant\^onio},
url = {https://pt.wikipedia.org/w/index.php?title=Usina///////%5C%5C_Hidrel///////%5C%5C%C3///////%5C%5C%A9trica///////%5C%5C_Santo///////%5C%5C_Ant///////%5C%5C%C3///////%5C%5C%B4nio///////%5C%5C&oldid=54490770},
annote = {Page Version ID: 54490770},
abstract = {A Hidrel\'etrica Santo Ant\^onio est\'a localizada no Rio Madeira, na cidade de Porto Velho, capital de Rond\^onia. Possui 50 turbinas do tipo Bulbo para gera\cc\~ao de energia el\'etrica com pot\^encia de cerca de 71,6 megawatts (MW) cada uma, totalizando 3.568,3 MW de pot\^encia instalada e 2.424 MW de energia assegurada. \'E a quarta maior hidrel\'etrica em opera\cc\~ao no Brasil e uma das maiores do mundo. A concession\'aria respons\'avel pela hidrel\'etrica \'e a Santo Ant\^onio Energia, atualmente quarta maior geradora h\'idrica do pa\'is, formada pelas empresas Odebrecht Energia do Brasil, SAAG Investimentos, Furnas Centrais El\'etricas, Cemig e Caixa FIP Amaz\^onia Energia. A hidrel\'etrica, juntamente com a de Jirau, no mesmo rio, s\~ao consideradas fundamentais para o suprimento de energia el\'etrica no Brasil e estiveram entre as obras mais importantes do Governo Federal entre 2008 e 2016.O leil\~ao de concess\~ao foi realizado em dezembro de 2007. Os estudos de invent\'ario e viabilidade aconteceram previamente entre os anos de 2001 e 2006. Em 2008 as obras foram iniciadas. Em 30 de mar\cco a hidrel\'etrica recebeu autoriza\cc\~ao da Ag\^encia Nacional de Energia El\'etrica (Aneel) para iniciar sua opera\cc\~ao. As obras de constru\cc\~ao foram conclu\'ias em dezembro de 2016.},
}

@article{2012Wang"leagile",
author = {Xiaofeng Wang and Kieran Conboy and Oisin Cawley},
journal = {Journal of Systems and Software},
title = {"Leagile" software development: An experience report analysis of the application of lean approaches in agile software development},
abstract = {In recent years there has been a noticeable shift in attention from those who use agile software development toward lean software development, often labelled as a shift "from agile to lean". However, the reality may not be as simple or linear as this label implies. To provide a better understanding of lean software development approaches and how they are applied in agile software development, we have examined 30 experience reports published in past agile software conferences in which experiences of applying lean approaches in agile software development were reported. The analysis identified six types of lean application. The results of our study show that lean can be applied in agile processes in different manners for different purposes. Lean concepts, principles and practices are most often used for continuous agile process improvement, with the most recent introduction being the kanban approach, introducing a continuous, flow-based substitute to time-boxed agile processes. \textcopyright 2012 Elsevier Inc. All rights reserved.},
doi = {10.1016/j.jss.2012.01.061},
issn = {01641212},
number = {6},
pages = {1287--1299},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121212000404},
volume = {85},
year = {2012},
shorttitle = {"Leagile" software development},
keywords = {agile software development,experience report,kanban,leagile,lean software development,scrum,software engineering},
mendeley-tags = {agile software development,experience report,kanban,leagile,lean software development,scrum,software engineering},
}

@misc{2013SirkiaeLean,
author = {Rami Sirki\"a and Maarit Laanti},
url = {http://www.scrummaster.dk/lib/AgileLeanLibrary/Topics////////%5C%5C_ScalingScrumAgile/Whitepaper///////%5C%5C_///////%5C%5C Lean-Agile///////%5C%5C Financial///////%5C%5C Planning///////%5C%5C (Dec///////%5C%5C 2013).pdf},
pages = {14},
abstract = {Enterprises that approach uncertainty and risk in software development based on lean and agile methods often do experience financial control as a restriction. Traditional budgeting and cost reporting is a system based on rigid frames, and it – along with the process of project cost accounting – burdens the lean and agile enterprise with unnecessary and counterproductive overhead and friction. The traditional system provides, at best, a false sense of cost control to any enterprise. In this paper we share insights related to how project-?‐based cost accounting can be transformed to a structure based on agile and lean finance and control. Our insights and examples are intended to remove a key impediment to transforming the finance function of your enterprise to something measurably more lean and agile. This work is based both on an actual case completed with our employer and on our knowledge of financial processes at major Finnish companies},
title = {Lean and agile financial planning},
keywords = {agile,agile software development,beyond budgeting,budgeting,cost center,cost center accounting,cost management,lean,lean enterprise,lean finance,management accounting,project costing,rolling forecast,safe,scaled agile framework,traditional budgeting},
mendeley-tags = {agile,agile software development,beyond budgeting,budgeting,cost center,cost center accounting,cost management,lean,lean enterprise,lean finance,management accounting,project costing,rolling forecast,safe,scaled agile framework,traditional budgeting},
}

@book{1994DudequeHistoria,
author = {Norton Dudeque},
title = {Hist\'oria do viol\~ao},
isbn = {85-85132-85-X},
}

@book{2012CostaIntroducao,
author = {S F Costa},
isbn = {978-85-294-0419-6},
edition = {Edi\cc\~ao: 1\textordfeminine},
abstract = {No Brasil, poucos livros, principalmente de Estat\'istica, passam da 2\textordfeminine ou 3\textordfeminine edi\cc\~ao. O sucesso desta obra, agora em 5.\textordfeminine edi\cc\~ao, totalmente revista, deve-se, indiscutivelmente, \`a preocupa\cc\~ao do autor com a organiza\cc\~ao e apresenta\cc\~ao da mat\'eria e \`a calorosa acolhida que a obra vem recebendo por parte dos usu\'arios desde seu lan\ccamento em 1988. Continua dispon\'ivel, aos usu\'arios que contatem a Editora por meio de formul\'ario incluso no livro, o gabarito da Curva Normal, instrumento grandemente facilitador na resolu\cc\~ao de alguns exerc\'icios e problemas que dependam da visualiza\cc\~ao do gr\'afico, al\'em das respostas aos exerc\'icios propostos no livro. Aos professores est\~ao dispon\'iveis as solu\cc\~oes dos exerc\'icios propostos no livro do aluno, al\'em de exerc\'icios e problemas adicionais. O gabarito com a Curva Normal tamb\'em faz parte desse material. Sem d\'uvida, uma obra que prioriza a compreens\~ao por parte dos alunos.},
title = {Introdu\cc\~ao Ilustrada \`a Estat\'istica},
publisher = {Harbra},
}

@inproceedings{2018KarrasProgressive,
author = {Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
archiveprefix = {arXiv},
abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 10242. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8:80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.},
eprint = {1710.10196},
arxivid = {1710.10196},
booktitle = {arXiv},
pages = {26},
year = {2017},
issn = {23318422},
title = {Progressive growing of gans for improved quality, stability, and variation},
}

@article{2018EslamiNeural,
author = {S. M. Ali Eslami and Danilo Jimenez Rezende and Frederic Besse and Fabio Viola and Ari S. Morcos and Marta Garnelo and Avraham Ruderman and Andrei A. Rusu and Ivo Danihelka and Karol Gregor and David P. Reichert and Lars Buesing and Theophane Weber and Oriol Vinyals and Dan Rosenbaum and Neil Rabinowitz and Helen King and Chloe Hillier and Matt Botvinick and Daan Wierstra and Koray Kavukcuoglu and Demis Hassabis},
issn = {10959203},
title = {Neural scene representation and rendering},
number = {6394},
abstract = {Scene representation—the process of converting visual sensory data into concise descriptions—is a requirement for intelligent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (GQN), a framework within which machines learn to represent scenes using only their own sensors. The GQN takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The GQN demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.},
pages = {1204--1210},
volume = {360},
doi = {10.1126/science.aar6170},
journal = {Science},
pmid = {29903970},
year = {2018},
}

@inproceedings{2017ChivukulaAdversarial,
author = {Aneesh Sreevallabh Chivukula and Wei Liu},
abstract = {Deep learning has been found to be vulnerable to changes in the data distribution. This means that inputs that have an imperceptibly and immeasurably small difference from training data correspond to a completely different class label in deep learning. Thus an existing deep learning network like a Convolutional Neural Network (CNN) is vulnerable to adversarial examples. We design an adversarial learning algorithm for supervised learning in general and CNNs in particular. Adversarial examples are generated by a game theoretic formulation on the performance of deep learning. In the game, the interaction between an intelligent adversary and deep learning model is a two-person sequential noncooperative Stackelberg game with stochastic payoff functions. The Stackelberg game is solved by the Nash equilibrium which is a pair of strategies (learner weights and genetic operations) from which there is no incentive for either learner or adversary to deviate. The algorithm performance is evaluated under different strategy spaces on MNIST handwritten digits data. We show that the Nash equilibrium leads to solutions robust to subsequent adversarial data manipulations. Results suggest that game theory and stochastic optimization algorithms can be used to study performance vulnerabilities in deep learning models.},
year = {2017},
title = {Adversarial learning games with deep learning models},
isbn = {9781509061815},
doi = {10.1109/IJCNN.2017.7966196},
publisher = {IEEE},
pages = {2758--2767},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
url = {http://ieeexplore.ieee.org/document/7966196/},
volume = {2017-May},
keywords = {adversarial learning,data mining and knowledge discovery,deep learning,evolutionary learning,game theory,genetic algorithms,supervised learning},
mendeley-tags = {adversarial learning,data mining and knowledge discovery,deep learning,evolutionary learning,game theory,genetic algorithms,supervised learning},
}

@article{2018TuylsSymmetric,
author = {Karl Tuyls and Julien P\'erolat and Marc Lanctot and Georg Ostrovski and Rahul Savani and Joel Z. Leibo and Toby Ord and Thore Graepel and Shane Legg},
title = {Symmetric Decomposition of Asymmetric Games},
year = {2018},
volume = {8},
issn = {20452322},
journal = {Scientific Reports},
url = {http://www.nature.com/articles/s41598-018-19194-4},
pages = {1015},
pmid = {29343692},
number = {1},
doi = {10.1038/s41598-018-19194-4},
abstract = {We introduce new theoretical insights into two-population asymmetric games allowing for an elegant symmetric decomposition into two single population symmetric games. Specifically, we show how an asymmetric bimatrix game (A,B) can be decomposed into its symmetric counterparts by envisioning and investigating the payoff tables (A and B) that constitute the asymmetric game, as two independent, single population, symmetric games. We reveal several surprising formal relationships between an asymmetric two-population game and its symmetric single population counterparts, which facilitate a convenient analysis of the original asymmetric game due to the dimensionality reduction of the decomposition. The main finding reveals that if (x,y) is a Nash equilibrium of an asymmetric game (A,B), this implies that y is a Nash equilibrium of the symmetric counterpart game determined by payoff table A, and x is a Nash equilibrium of the symmetric counterpart game determined by payoff table B. Also the reverse holds and combinations of Nash equilibria of the counterpart games form Nash equilibria of the asymmetric game. We illustrate how these formal relationships aid in identifying and analysing the Nash structure of asymmetric games, by examining the evolutionary dynamics of the simpler counterpart games in several canonical examples.},
}

@article{2019ParkSemantic,
author = {Taesung Park and Ming Yu Liu and Ting Chun Wang and Jun Yan Zhu},
issn = {23318422},
title = {Semantic image synthesis with spatially-adaptive normalization},
journal = {arXiv},
year = {2019},
url = {http://arxiv.org/abs/1903.07291},
abstract = {We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the deep network, which is then processed through stacks of convolution, normalization, and nonlinearity layers. We show that this is suboptimal as the normalization layers tend to "wash away" semantic information. To address the issue, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned transformation. Experiments on several challenging datasets demonstrate the advantage of the proposed method over existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows user control over both semantic and style. Code is available at https://github.com/NVlabs/SPADE.},
}

@book{1984CremerPhysics,
author = {Erik V. Jansson},
booktitle = {The Journal of the Acoustical Society of America},
abstract = {This major work covers almost all that has been learned about the acoustics of stringed instruments from Helmholtz's 19th-century theoretical elaborations to recent electroacoustic and holographic measurements. Many of the results presented here were uncovered by the author himself (and by his associates and students) over a 20-year period of research on the physics of instruments in the violin family. Lothar Cremer is one of the world's most respected authorities on architectural acoustics and, not incidentally, an avid avocational violinist and violist.The book―which was published in German in 1981―first of all meets the rigorous technical standards of specialists in musical acoustics. But it also serves the needs and interests of two broader groups: makers and players of stringed instruments are expressly addressed, since the implications of the mathematical formulations are fully outlined and explained; and acousticians in general will find that the work represents a textbook illustration of the application of fundamental principles and up-to-date techniques to a specific problem. The first―and longest―of the book's three parts investigates the oscillatory responses of bowed (and plucked) strings. The natural nonlinearities that derive from considerations of string torsion and bending stiffness are deftly handled and concisely modeled. The second part deals with the body of the instrument. Special attention is given to the bridge, which transmits the oscillations of the strings to the wooden body and its air cavity. In this case, linear modeling proves serviceable for the most part―a simplification that would not be possible with lute―like instruments such as the guitar. The radiation of sound from the body into the listener's space, which is treated as an extension of the instrument itself, is the subject of the book's final part.},
publisher = {The MIT Press},
volume = {114},
isbn = {978-0-262-52707-1},
issn = {0001-4966},
number = {4},
pages = {2437--2437},
doi = {10.1121/1.4779130},
edition = {UK ed. edition},
title = {Physics of the violin},
translator = {Allen, John S},
year = {2003},
}

@article{2016FriedPerspective,
author = {Ohad Fried and Eli Shechtman and Dan B. Goldman and Adam Finkelstein},
volume = {35},
pages = {1--10},
issn = {15577368},
doi = {10.1145/2897824.2925933},
abstract = {This paper introduces a method to modify the apparent relative pose and distance between camera and subject given a single portrait photo. Our approach fits a full perspective camera and a parametric 3D head model to the portrait, and then builds a 2D warp in the image plane to approximate the effect of a desired change in 3D. We show that this model is capable of correcting objectionable artifacts such as the large noses sometimes seen in "selfies," or to deliberately bring a distant camera closer to the subject. This framework can also be used to re-pose the subject, as well as to create stereo pairs from an input portrait. We show convincing results on both an existing dataset as well as a new dataset we captured to validate our method.},
number = {4},
journal = {ACM Transactions on Graphics},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925933},
year = {2016},
title = {Perspective-aware manipulation of portrait photos},
keywords = {faces,image enhancement,perspective,portraits},
mendeley-tags = {faces,image enhancement,perspective,portraits},
}

@article{tahvanainen_modelling_nodate,
author = {Henna Tahvanainen},
title = {Modelling Body Vibration and Sound Radiation of a Modified Kantele},
pages = {73},
year = {2012},
abstract = {In this thesis, it is shown that the modiﬁed kantele includes vibrational modes of both the freely vibrating top plate and the enclosed air. Thus, it has a higher mode density than the traditional kanteles. Because of the coupling of the enclosed air modes to the body, the modiﬁed kantele radiates more omni-directionally than the traditional kanteles. Consequently, the modiﬁed kantele has a higher radiation eﬃciency than the traditional kanteles when the size of the air gap is small (1-3 mm).},
}

@software{2019VdumoulinTechnical,
author = { Vdumoulin},
title = {A technical report on convolution arithmetic in the context of deep learning: vdumoulin/conv_arithmetic},
url = {https://github.com/vdumoulin/conv_arithmetic},
year = {2019},
shorttitle = {A technical report on convolution arithmetic in the context of deep learning},
annote = {original-date: 2016-02-24T15:18:33Z},
}

@inproceedings{2014WangEnergy,
author = {Yu Wang and Boxun Li and Rong Luo and Yiran Chen and Ningyi Xu and Huazhong Yang},
abstract = {The world is experiencing a data revolution to discover knowledge in big data. Large scale neural networks are one of the mainstream tools of big data analytics. Processing big data with large scale neural networks includes two phases: the training phase and the operation phase. Huge computing power is required to support the training phase. And the energy efficiency (power efficiency) is one of the major considerations of the operation phase. We first explore the computing power of GPUs for big data analytics and demonstrate an efficient GPU implementation of the training phase of large scale recurrent neural networks (RNNs). We then introduce a promising ultrahigh energy efficient implementation of neural networks' operation phase by taking advantage of the emerging memristor technique. Experiment results show that the proposed GPU implementation of RNNs is able to achieve 2 $\sim$ 11× speed-up compared with the basic CPU implementation. And the scaled-up recurrent neural network trained with GPUs realizes an accuracy of 47% on the Microsoft Research Sentence Completion Challenge, the best result achieved by a single RNN on the same dataset. In addition, the proposed memristor-based implementation of neural networks demonstrates power efficiency of > 400 GFLOPS/W and achieves energy savings of 22× on the HMAX model compared with its pure digital implementation counterpart.},
title = {Energy efficient neural networks for big data analytics},
pages = {1--2},
year = {2014},
booktitle = {2014 Design, Automation Test in Europe Conference Exhibition (DATE)},
doi = {10.7873/date.2014.358},
}

@inproceedings{2014KapralovaBig,
author = {Olga Kapralova and John Alex and Eugene Weinstein and Pedro Moreno and Olivier Siohan},
year = {2014},
abstract = {Deep neural networks (DNNs) have recently become the state of the art technology in speech recognition systems. In this paper we propose a new approach to constructing large high quality unsupervised sets to train DNN models for large vocabulary speech recognition. The core of our technique consists of two steps. We first redecode speech logged by our production recognizer with a very accurate (and hence too slow for real-time usage) set of speech models to improve the quality of ground truth transcripts used for training alignments. Using confidence scores, transcript length and transcript flattening heuristics designed to cull salient utterances from three decades of speech per language, we then carefully select training data sets consisting of up to 15K hours of speech to be used to train acoustic models without any reliance on manual transcription. We show that this approach yields models with approximately 18K context dependent states that achieve 10% relative improvement in large vocabulary dictation and voice-search systems for Brazilian Portuguese, French, Italian and Russian languages.},
title = {A big data approach to acoustic model training corpus selection},
issn = {19909772},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
pages = {2083--2087},
keywords = {acoustic modeling,data selection,deep neural networks,large unsupervised training sets},
mendeley-tags = {acoustic modeling,data selection,deep neural networks,large unsupervised training sets},
}

@inproceedings{2018LiptonBbq,
author = {Zachary Lipton and Xiujun Li and Jianfeng Gao and Lihong Li and Faisal Ahmed and Li Deng},
shorttitle = {Bbq-networks},
year = {2017},
issn = {23318422},
abstract = {We present a new algorithm that significantly improves the efficiency of exploration for deep Q-learning agents in dialogue systems. Our agents explore via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop neural network. Our algorithm learns much faster than common exploration strategies such as $\epsilon$-greedy, Boltzmann, bootstrapping, and intrinsic-reward-based ones. Additionally, we show that spiking the replay buffer with experiences from just a few successful episodes can make Q-learning feasible when it might otherwise fail.},
title = {BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems},
booktitle = {arXiv},
}

@inproceedings{2018KimKorean,
author = {Juntae Kim and Heejin Choi and Jinuk Park and Minsoo Hahn and Sangjin Kim and Jong Jin Kim},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
pages = {1551--1555},
issn = {19909772},
volume = {2018-September},
doi = {10.21437/Interspeech.2018-1575},
publisher = {International Speech Communication Association},
title = {Korean singing voice synthesis system based on an LSTM recurrent neural network},
year = {2018},
abstract = {Singing voice synthesis (SVS) systems generate the singing voice from a musical score. Similar to the text-to-speech synthesis (TTS) field, SVS systems have also been greatly improved since the deep neural network (DNN) framework was introduced. Although they share many parts of the framework, the main difference between TTS and SVS systems is that the feature composing method, between linguistic and musical features, is important for SVS systems. In this paper, we propose a Korean SVS system based on a long-short term memory recurrent neural network (LSTM-RNN). At the feature composing stage, we propose a novel composing method, based on Korean syllable structure. At the synthesis stage, we adopt LSTM-RNN for the SVS. According to our experiments, our composed feature improved the naturalness of the voice, specifically in any part that has to be pronounced for a long time. Furthermore, LSTM-RNN outperformed the DNN based SVS system in both quantitative and qualitative evaluations.},
keywords = {singing voice synthesis,speech synthesis},
mendeley-tags = {singing voice synthesis,speech synthesis},
}

@inproceedings{2016NishimuraSinging,
author = {Kazuhiro Nakamura and Kei Hashimoto1 and Keiichiro Oura and Yoshihiko Nankaku and Keiichi Tokuda},
pages = {2478--2482},
arxivid = {1904.06868},
issn = {23318422},
eprint = {1904.06868},
abstract = {The present paper describes a singing voice synthesis based on convolutional neural networks (CNNs). Singing voice synthesis systems based on deep neural networks (DNNs) are currently being proposed and are improving the naturalness of synthesized singing voices. In these systems, the relationship between musical score feature sequences and acoustic feature sequences extracted from singing voices is modeled by DNNs. Then, an acoustic feature sequence of an arbitrary musical score is output in units of frames by the trained DNNs, and a natural trajectory of a singing voice is obtained by using a parameter generation algorithm. As singing voices contain rich expression, a powerful technique to model them accurately is required. In the proposed technique, long-term dependencies of singing voices are modeled by CNNs. An acoustic feature sequence is generated in units of segments that consist of long-term frames, and a natural trajectory is obtained without the parameter generation algorithm. Experimental results in a subjective listening test show that the proposed architecture can synthesize natural sounding singing voices.},
archiveprefix = {arXiv},
booktitle = {arXiv},
title = {Singing voice synthesis based on convolutional neural networks},
year = {2019},
keywords = {acoustic modeling,convolutional neural network,singing voice synthesis,statistical model},
mendeley-tags = {acoustic modeling,convolutional neural network,singing voice synthesis,statistical model},
}

@inproceedings{2014ZenDeep,
author = {Heiga Zen and Andrew Senior},
abstract = {Statistical parametric speech synthesis (SPSS) using deep neural networks (DNNs) has shown its potential to produce naturally-sounding synthesized speech. However, there are limitations in the current implementation of DNN-based acoustic modeling for speech synthesis, such as the unimodal nature of its objective function and its lack of ability to predict variances. To address these limitations, this paper investigates the use of a mixture density output layer. It can estimate full probability density functions over real-valued output features conditioned on the corresponding input features. Experimental results in objective and subjective evaluations show that the use of the mixture density output layer improves the prediction accuracy of acoustic features and the naturalness of the synthesized speech. \textcopyright 2014 IEEE.},
issn = {15206149},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
pages = {3844--3848},
title = {Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis},
url = {http://ieeexplore.ieee.org/document/6854321/},
publisher = {IEEE},
year = {2014},
doi = {10.1109/ICASSP.2014.6854321},
isbn = {9781479928927},
keywords = {deep neural networks,hidden markov models,mixture density networks,statistical parametric speech synthesis},
mendeley-tags = {deep neural networks,hidden markov models,mixture density networks,statistical parametric speech synthesis},
}

@article{2017BlaauwNeurala,
author = {Merlijn Blaauw and Jordi Bonada},
abstract = {We recently presented a new model for singing synthesis based on a modified version of theWaveNet architecture. Instead of modeling raw waveform, we model features produced by a parametric vocoder that separates the influence of pitch and timbre. This allows conveniently modifying pitch to match any target melody, facilitates training on more modest dataset sizes, and significantly reduces training and generation times. Nonetheless, compared to modeling waveform directly, ways of effectively handling higher-dimensional outputs, multiple feature streams and regularization become more important with our approach. In this work, we extend our proposed system to include additional components for predicting F0 and phonetic timings from a musical score with lyrics. These expression-related features are learned together with timbrical features from a single set of natural songs. We compare our method to existing statistical parametric, concatenative, and neural network-based approaches using quantitative metrics as well as listening tests.},
volume = {7},
number = {12},
title = {A neural parametric singing synthesizer modeling timbre and expression from natural songs},
doi = {10.3390/app7121313},
year = {2017},
pages = {1313},
journal = {Applied Sciences (Switzerland)},
issn = {20763417},
keywords = {autoregressive models,conditional generative models,deep learning,machine learning,singing synthesis},
mendeley-tags = {autoregressive models,conditional generative models,deep learning,machine learning,singing synthesis},
}

@article{fosler-lussier_markov_nodate,
author = {Eric Fosler-lussier},
title = {Markov Models and Hidden Markov Models: A Brief Tutorial},
abstract = {This tutorial gives a gentle introduction to Markov models and Hidden Markov models as mathematical abstractions, and relates them to their use in automatic speech recognition. This material was deveoped for the fall 1995 semester of CS188 Introduction to Artificial Intelligence at the University of California, Berkeley. It is tergeted for introductory AI courses; basic knowledge of probability is assumed . This version is slightly updated from the original, including a few minor error corrections, a short "Further reading" section, and exercises that were given as a homework in the Fall 1995 class.},
pages = {9},
year = {1998},
volume = {1198},
number = {510},
}

@article{2019GafniVid2game,
author = {Oran Gafni and Lior Wolf and Yaniv Taigman},
url = {http://arxiv.org/abs/1904.08379},
shorttitle = {Vid2Game},
title = {Vid2Game: Controllable characters extracted from real-world videos},
year = {2019},
archiveprefix = {arXiv},
abstract = {We are given a video of a person performing a certain activity, from which we extract a controllable model. The model generates novel image sequences of that person, according to arbitrary user-defined control signals, typically marking the displacement of the moving body. The generated video can have an arbitrary background, and effectively capture both the dynamics and appearance of the person. The method is based on two networks. The first network maps a current pose, and a single-instance control signal to the next pose. The second network maps the current pose, the new pose, and a given background, to an output frame. Both networks include multiple novelties that enable high-quality performance. This is demonstrated on multiple characters extracted from various videos of dancers and athletes.},
eprint = {1904.08379},
arxivid = {1904.08379},
issn = {23318422},
journal = {arXiv},
}

@book{2018SubramanianDeep,
author = {Vishnu Subramanian},
shorttitle = {Deep learning with PyTorch},
publisher = {Packt Publishing},
abstract = {A practical approach to building neural network models using PyTorch},
title = {Deep Learning with PyTorch: A practical approach to building neural network models using PyTorch},
isbn = {9781788624336},
annote = {OCLC: 1078352321},
booktitle = {O'Reilly Media},
pages = {255},
url = {http://proxy2.hec.ca/login?url=http://proquestcombo.safaribooksonline.com/?uiCode=hecmontreal///////%5C%5C&xmlId=9781788624336},
year = {2018},
}

@book{2003LakatosFundamentos,
author = {Eva Maria Lakatos and Marina de Andrade Marconi},
pages = {310},
pmid = {25246403},
title = {Fundamentos de metodologia cient\'ifica},
annote = {OCLC: 53849497},
isbn = {8522433976},
year = {2003},
booktitle = {Editora Atlas S. A.},
eprint = {arXiv:1011.1669v3},
publisher = {Atlas S\~ao Paulo},
archiveprefix = {arXiv},
arxivid = {arXiv:1011.1669v3},
abstract = {A Metodologia Cient\'ifica, mais do que uma disciplina, significa introduzir o dis- cente no mundo dos procedimentos sistem\'aticos e racionais, base da fonna\cc\~ao tanto do estudioso quanto do profissional, pois ambos atuam, al\'em da pr\'atica, no mundo das id\'eias. Podemos afirmar at\'e: a pr\'atica nasce da concep\cc\~ao sobre o que deve ser realiza- do e qualquer tomada de decis\~ao fundamenta-se naquilo que se afigura como o mais l$\sim$ gico, racional, eficiente e eficaz. Desse modo, a condensa\cc\~ao da trilogia - Metodologia cient(fica, T\'ecnicas de pes- quisa e Metodologia do trabalho cient(fico - nesta obra, procura suprir uma necessida- de existente em nossa bibliografia, ou seja, um trabalho que sintetize, ao mesmo tempo, procedimentos did\'aticos, fundamentos para trabalhos escolares, de fmal de curso e cient\'ificos, relat\'orios e memorandos, assim como sirva de base para a atividade profis- sional que, por defmi\cc\~ao, precisa ser ordenada, met\'odica e l\'ogica. As},
issn = {9788522457588},
}

@electronic{2018Caffe,
author = {Yangqing Jia and Evan Shelhamer},
howpublished = {online},
title = {Caffe Deep Learning Framework Homepage},
year = {2016},
url = {http://caffe.berkeleyvision.org/},
}

@article{1986RumelhartLearning,
author = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
volume = {323},
doi = {10.1038/323533a0},
number = {6088},
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure 1. \textcopyright 1986 Nature Publishing Group.},
journal = {Nature},
issn = {00280836},
pages = {533--536},
publisher = {Nature Publishing Group SN -},
title = {Learning representations by back-propagating errors},
year = {1986},
}

@electronic{2018Torch,
author = { Torch},
howpublished = {online},
title = {Torch, a scientific computing frmework for LuaJIT},
year = {2016},
url = {http://torch.ch/},
}

@electronic{2018Repositorio,
howpublished = {online},
url = {https://github.com/tesserato/tesserato.github.io},
title = {Reposit\'orio Disserta\cc\~ao},
}

@electronic{2018Theano,
url = {http://deeplearning.net/software/theano/},
title = {Theano 1.0.0 documentation},
howpublished = {online},
}

@article{2013LedfordStart,
author = {B Y Heidi Ledford},
title = {START-UP},
}

@article{TheDead,
author = {I S The},
number = {March 2002},
title = {DEAD ?},
}

@article{2018Theanoa,
url = {http://deeplearning.net/software/theano/%7B////////%5C%5C%25%7D3E},
title = {Theano},
volume = {1},
}

@book{PapertPerceptrons,
author = {Seymour A Papert},
title = {Perceptrons},
isbn = {0262631113},
}

@unpublished{Torch,
url = {http://torch.ch/%7B////////%5C%5C%25%7D3E},
title = {Torch},
}

@article{1997DavidcacchioneAmerican,
author = {Brian Hayes},
isbn = {2136240900},
issn = {00030996},
volume = {99},
number = {2},
pages = {106--110},
title = {The memristor},
journal = {American Scientist},
doi = {10.1511/2011.89.106},
year = {2011},
}

@book{2018Caffea,
publisher = {<},
url = {http://caffe.berkeleyvision.org/%7B////////%5C%5C%25%7D3E},
title = {Caffe},
}

@book{1969MinskiIntroduction,
author = {Partha P. Goswami},
booktitle = {Research Promotion Workshop},
publisher = {MIT Press, Cambridge},
title = {Introduction to Computational Geometry},
url = {https://www.tcs.tifr.res.in/$\sim$workshop/nitrkl_igga/arbintrocgtrichy.pdf},
year = {2010},
}

@article{CorporationL,
author = {Westinghouse Electric Corporation and East Pittsburgh and Ann Arbor},
title = {notitle},
number = {4},
pages = {978--986},
}

@article{1985Diego862,
author = {S A N Diego},
number = {V},
title = {862 18 120,},
}

@book{2011UlrichDesign,
author = {Karl T. Ulrich},
abstract = {The central theme of this monograph is that a unifying framework informs the human activity of design across all domains. With few exceptions, each idea in this work applies to graphics, environments, products, software, services, machines, and buildings. I dream that the design process could be integral to the primary, secondary, and post-secondary education of all individuals in modern society. This work is an attempt to lay out some of the ideas that would form that education.},
year = {2012},
doi = {10.2139/ssrn.1951106},
url = {https://www.amazon.com/Design-Creation-Artifacts-Karl-Ulrich-ebook/dp/B005S4EO1Y?SubscriptionId=AKIAIOBINVZYXZQZ2U3A///////%5C%5C&tag=chimbori05-20///////%5C%5C&linkCode=xm2///////%5C%5C&camp=2025///////%5C%5C&creative=165953///////%5C%5C&creativeASIN=B005S4EO1Y},
publisher = {University of Pennsylvania},
isbn = {9780983648703},
title = {Design: Creation of Artifacts in Society},
issn = {1556-5068},
booktitle = {SSRN Electronic Journal},
}

@article{schaffner2017towards,
author = {Michael Schaffner and Florian Scheidegger and Lukas Cavigelli and Hubert Kaeslin and Luca Benini and Aljosa Smolic},
year = {2017},
journal = {IEEE Transactions on Image Processing},
pages = {265--280},
number = {1},
publisher = {IEEE},
title = {Towards Edge-Aware Spatio-Temporal Filtering in Real-Time},
volume = {27},
}

@article{2017IshizakaAre,
author = {Alessio Ishizaka and Sajid Siraj},
doi = {10.1016/j.ejor.2017.05.041},
publisher = {Elsevier},
issn = {03772217},
abstract = {Many decision makers still question the usefulness of multi-criteria decision-making methods and prefer to rely on intuitive decisions. In this study we evaluated a number of multi-criteria decision-making tools for their usefulness using incentive-based experiments, which is a novel approach in operations research but common in psychology and experimental economics. In this experiment the participants were asked to compare five coffee shops to win a voucher for their best-rated shop. We found that, although the usefulness of different multi-criteria decision-making tools varied to some extent, all the tools were found to be useful in the sense that, when they decided to change their ranking, they followed the recommendation of the multi-criteria decision-making tool. Moreover, the level of inconsistency in the judgements provided had no significant effect on the usefulness of these tools.},
number = {2},
pages = {462--471},
year = {2018},
volume = {264},
title = {Are multi-criteria decision-making tools useful? An experimental comparative study of three methods},
journal = {European Journal of Operational Research},
keywords = {ahp,decision analysis,experimental evaluation,macbeth,smart},
mendeley-tags = {ahp,decision analysis,experimental evaluation,macbeth,smart},
}

@book{maeda2006laws,
author = {John Maeda},
url = {http://books.google.com/books?hl=en&lr=&id=lh9gRQ4i_zwC&oi=fnd&pg=PP10&dq=The+Laws+of+Simplicity&ots=Wzuj7AZ2GE&sig=vQoJ0EpjQzER41kn1N9erOU4nyk%5Cnhttp://mitpress.mit.edu/catalog/item/default.asp?tid=10933&ttype=2},
pages = {120},
abstract = {Technology has made our lives more full, yet at the same time we've become uncomfortably "full."},
title = {The Laws of Simplicity},
isbn = {9780262134729},
publisher = {MIT press},
year = {2006},
}

@inproceedings{2018DonahueSynthesizing,
author = {Chris Donahue and Julian McAuley and Miller Puckette},
howpublished = {Workshop},
url = {https://openreview.net/forum?id=r1RwYIJPM},
booktitle = {6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings},
year = {2018},
annote = {Published: Workshop},
abstract = {While Generative Adversarial Networks (GANs) have seen wide success at the problem of synthesizing realistic images, they have seen little application to audio generation. In this paper, we introduce WaveGAN, a first attempt at applying GANs to raw audio synthesis in an unsupervised setting. Our experiments on speech demonstrate that WaveGAN can produce intelligible words from a small vocabulary of human speech, as well as synthesize audio from other domains such as bird vocalizations, drums, and piano. Qualitatively, we find that human judges prefer the generated examples from WaveGAN over those from a method which na\"ively applies GANs on image-like audio feature representations.},
title = {Synthesizing audio with GANS},
}

@article{2017CaoSpatial,
author = {Jianan Cao and David J. Farnham and Upmanu Lall},
journal = {arXiv},
archiveprefix = {arXiv},
eprint = {1712.05293},
title = {Spatial-temporal wind field prediction by Artificial Neural Networks},
arxivid = {1712.05293},
abstract = {The prediction of near surface wind speed is becoming increasingly vital for the operation of electrical energy grids as the capacity of installed wind power grows. The majority of predictive wind speed modeling has focused on point-based time-series forecasting. Effectively balancing demand and supply in the presence of distributed wind turbine electricity generation, however, requires the prediction of wind fields in space and time. Additionally, predictions of full wind fields are particularly useful for future power planning such as the optimization of electricity power supply systems. In this paper, we propose a composite artificial neural network (ANN) model to predict the 6-hour and 24-hour ahead average wind speed over a large area (-3.15×106km2). The ANN model consists of a convolutional input layer, a Long Short-Term Memory (LSTM) hidden layer, and a transposed convolutional layer as the output layer. We compare the ANN model with two non-parametric models, a null persistence model and a mean value model, and find that the ANN model has substantially smaller error than each of these models. Additionally, the ANN model also generally performs better than integrated autoregressive moving average models, which are trained for optimal performance in specific locations.},
volume = {abs/1712.05293},
year = {2017},
issn = {23318422},
url = {http://arxiv.org/abs/1712.05293},
keywords = {artificial neural network,convolution,long short-term memory (lstm,space-time prediction,wind speed prediction},
mendeley-tags = {artificial neural network,convolution,long short-term memory (lstm,space-time prediction,wind speed prediction},
}

@book{2006BishopPattern,
author = {N. Abramson and D. Braverman and G. Sebestyen},
doi = {10.1109/TIT.1963.1057854},
pages = {257--261},
booktitle = {IEEE Transactions on Information Theory},
annote = {OCLC: 845772798},
publisher = {Springer-Verlag New York Inc.},
series = {Information science and statistics},
title = {Pattern recognition and machine learning},
isbn = {0-387-31073-8},
issn = {15579654},
volume = {9},
number = {4},
year = {1963},
url = {https://www.ebook.de/de/product/5324937/christopher///////%5C%5C_m///////%5C%5C_bishop///////%5C%5C_pattern///////%5C%5C_recognition///////%5C%5C_and///////%5C%5C_machine///////%5C%5C_learning.html},
edition = {Corrected at 8th printing 2009},
}

@book{2010LaiIntroduction,
author = {David Rubin and Erhard Krempl},
booktitle = {Introduction to Continuum Mechanics},
year = {2010},
annote = {OCLC: 832831309},
title = {Introduction to Continuum Mechanics},
abstract = {Continuum Mechanics is a branch of physical mechanics that describes the macroscopic mechanical behavior of solid or fluid materials considered to be continuously distributed. It is fundamental to the fields of civil, mechanical, chemical and bioengineering. This time-tested text has been used for over 35 years to introduce junior and senior-level undergraduate engineering students, as well as graduate students, to the basic principles of continuum mechanics and their applications to real engineering problems. The text begins with a detailed presentation of the coordinate invariant quantity, the tensor, introduced as a linear transformation. This is then followed by the formulation of the kinematics of deformation, large as well as very small, the description of stresses and the basic laws of continuum mechanics. As applications of these laws, the behaviors of certain material idealizations (models) including the elastic, viscous and viscoelastic materials, are presented.This new edition offers expanded coverage of the subject matter both in terms of details and contents, providing greater flexibility for either a one or two-semester course in either continuum mechanics or elasticity. Although this current edition has expanded the coverage of the subject matter, it nevertheless uses the same approach as that in the earlier editions - that one can cover advanced topics in an elementary way that go from simple to complex, using a wealth of illustrative examples and problems. It is, and will remain, one of the most accessible textbooks on this challenging engineering subject. Significantly expanded coverage of elasticity in Chapter 5, including solutions of some 3-D problems based on the fundamental potential functions approach.New section at the end of Chapter 4 devoted to the integral formulation of the field equationsSeven new appendices appear at the end of the relevant chapters to help make each chapter more self-containedExpanded and improved problem sets providing both intellectual challenges and engineering applications. \textcopyright 2010 Elsevier Inc. All rights reserved.},
doi = {10.1016/B978-0-7506-8560-3.X0001-1},
edition = {3. ed., reprint},
isbn = {9780750685603},
publisher = {Elsevier [u.a.]},
}

@inproceedings{2016PhurattanaprapinExtended,
author = {Khanittha Phurattanaprapin and Punyaphol Horata},
title = {Extended hierarchical extreme learning machine with multilayer perceptron},
abstract = {For learning in big datasets, the classification performance of ELM might be low due to input samples are not extracted features properly. To address this problem, the hierarchical extreme learning machine (H-ELM) framework was proposed based on the hierarchical learning architecture of multilayer perceptron. H-ELM composes of two parts; the first is the unsupervised multilayer encoding part and the second part is the supervised feature classification part. H-ELM can give higher accuracy rate than of the traditional ELM. However, it still has to enhance its classification performance. Therefore, this paper proposes a new method namely as the extending hierarchical extreme learning machine (EH-ELM). For the extended supervisor part of EH-ELM, we have got an idea from the two-layers extreme learning machine. To evaluate the performance of EH-ELM, three different image datasets; Semeion, MNIST, and NORB, were studied. The experimental results show that EH-ELM achieves better performance than of H-ELM and the other multi-layer framework.},
number = {2},
doi = {10.1109/JCSSE.2016.7748874},
year = {2016},
pages = {1--5},
url = {http://ieeexplore.ieee.org/document/7748874/},
volume = {10},
publisher = {IEEE},
booktitle = {2016 13th International Joint Conference on Computer Science and Software Engineering, JCSSE 2016},
isbn = {9781509020331},
keywords = {elm},
mendeley-tags = {elm},
}

@book{2017PattersonDeep,
author = {Josh Patterson and Adam Gibson},
isbn = {978-1-4919-1425-0},
url = {https://www.ebook.de/de/product/23640784/adam///////%5C%5C_gibson///////%5C%5C_josh///////%5C%5C_patterson///////%5C%5C_deep///////%5C%5C_learning///////%5C%5C_the///////%5C%5C_definitive///////%5C%5C_guide.html},
title = {Deep Learning: A Practitioner's Approach},
volume = {2017},
publisher = {O'Reilly Media, Inc.},
edition = {1},
}

@phdthesis{1974WerbosRegression,
author = {Science Thesis and Ph D Appl and Math Harvard},
type = {phdthesis},
number = {January 1974},
school = {Harvard University},
month = {aug},
title = {Beyond Regression : New Tools for Prediction and Analysis in the Behavioral},
url = {https://www.researchgate.net/publication/35055330///////%5C%5C_Beyond///////%5C%5C_regression///////%5C%5C_new///////%5C%5C_tools///////%5C%5C_for///////%5C%5C_prediction///////%5C%5C_and///////%5C%5C_analysis///////%5C%5C_in///////%5C%5C_the///////%5C%5C_behavior///////%5C%5C_sciences///////%5C%5C_microform},
year = {2018},
}

@misc{2006MakinBackpropagation,
author = {J G Makin},
title = {Backpropagation},
url = {http://www.cs.cornell.edu/courses/cs5740/2016sp/resources/backprop.pdf},
pages = {1--8},
}

@article{2016PersioArtiﬁcial,
author = {Luca Di Persio and Oleks Honchar and  r},
journal = {International Journal of Circuits, Systems and Signal Processing},
title = {Artificial neural networks architectures for stock price prediction: Comparisons and applications},
volume = {10},
year = {2016},
abstract = {We present an Artificial Neural Network (ANN) approach to predict stock market indices, particularly with respect to the forecast of their trend movements up or down. Exploiting different Neural Networks architectures, we provide numerical analysis of concrete financial time series. In particular, after a brief r´esum´e of the existing literature on the subject, we consider the Multi-layer Perceptron (MLP), the Convolutional Neural Networks (CNN), and the Long Short-Term Memory (LSTM) recurrent neural networks techniques. We focus on the importance of choosing the correct input features, along with their preprocessing, for the specific learning algorithm one wants to use. Eventually, we consider the S&P500 historical time series, predicting trend on the basis of data from the past days, and proposing a novel approach based on combination of wavelets and CNN, which outperforms the basic neural networks ones. We show, that neural networks are able to predict financial time series movements even trained only on plain time series data and propose more ways to improve results.},
pages = {403--413},
issn = {19984464},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{2001MuellerIntroduction,
author = {Klaus Robert M\"uller and Sebastian Mika and Gunnar R\"atsch and Koji Tsuda and Bernhard Sch\"olkopf},
title = {An introduction to kernel-based learning algorithms},
pages = {181--201},
volume = {12},
issn = {10459227},
pmid = {18244377},
abstract = {This paper provides an introduction to support vector machines (SVMs), kernel Fisher discriminant analysis, and kernel principal component analysis (PCA), as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis (VC) theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by finally discussing applications such as optical character recognition (OCR) and DNA analysis.},
doi = {10.1109/72.914517},
isbn = {1045-9227},
year = {2001},
number = {2},
journal = {IEEE Transactions on Neural Networks},
keywords = {seminal},
mendeley-tags = {seminal},
}

@inproceedings{1999JensenEnvelope,
author = {G. Agostini and M. Longari and E. Pollastri},
doi = {10.1109/mmsp.2001.962718},
abstract = {In this work, a set of features is evaluated for musical instrument recognition out of monophonic musical signals. Aiming to achieve a compact representation, the adopted features regard only spectral characteristics of sound and are limited in number. On top of these descriptors, various classification methods are implemented and tested. Over a dataset of 1007 tones from 27 musical instruments and without employing any hierarchical structure, Quadratic Discriminant Analysis shows the lowest error rate (7.19% for the individual instrument and 3.13% for instrument families), outperforming all the other classification methods (Canonical Discriminant Analysis, Support Vector Machines, Nearest Neighbours). The most relevant features are demonstrated to be the inharmonicity, the spectral centroid and the energy contained in the first partial.},
isbn = {0780370252},
booktitle = {2001 IEEE Fourth Workshop on Multimedia Signal Processing},
pages = {97--102},
year = {2001},
title = {Musical instrument timbres classification with spectral features},
issn = {1687-6172},
number = {1},
}

@article{2016OordConditional,
author = {A\"aron Van Den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
volume = {abs/1606.05328},
journal = {Advances in Neural Information Processing Systems},
archiveprefix = {arXiv},
issn = {10495258},
pages = {4797--4805},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
url = {http://arxiv.org/abs/1606.05328},
arxivid = {1606.05328},
eprint = {1606.05328},
year = {2016},
title = {Conditional image generation with PixelCNN decoders},
}

@misc{2017RamachandranSearching,
author = { Ramach and Prajit ran and Barret Zoph and Quoc V. Le},
eprint = {1710.05941},
year = {2017},
archiveprefix = {arXiv},
title = {Searching for activation functions},
booktitle = {arXiv},
arxivid = {1710.05941},
abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, f(x) = x sigmoid($\beta$x), which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9% for Mobile NASNet-A and 0.6% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
url = {https://arxiv.org/abs/1710.05941},
pages = {1--13},
issn = {23318422},
}

@book{2015RaschkaPython,
author = {Sebastian Raschka},
year = {2015},
shorttitle = {Python machine learning},
abstract = {Includes index. Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk - and answer - tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning - whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource. What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Pylearn 2 and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data - its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success. Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Pylearn2, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization. Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.},
annote = {OCLC: 927507196},
pages = {254},
booktitle = {Python machine learning :},
isbn = {9781783555130},
publisher = {Packt Publishing open source},
series = {Community experience distilled},
url = {www.packtpub.com},
title = {Python Machine Learning: Unlock deeper insights into machine learning with this vital guide to cutting-edge predictive analytics},
keywords = {machine learni,python (computer program language},
mendeley-tags = {machine learni,python (computer program language},
}

@article{2019StollCarbon,
author = {Christian Stoll and Lena Klaa\ssen and Ulrich Gallersd\"orfer},
year = {2019},
pages = {1647--1661},
abstract = {Blockchain technology has its roots in the cryptocurrency Bitcoin, which was the first successful attempt to validate transactions via a decentralized data protocol. This validation process requires vast amounts of electricity, which translates into a significant level of carbon emissions. Our approximation of Bitcoin's carbon footprint underlines the need to tackle the environmental externalities that result from cryptocurrencies. Blockchain solutions are increasingly discussed for a broad variety of use cases beyond cryptocurrencies. Although not all blockchain protocols are as energy intensive as Bitcoin's protocol, environmental aspects, the risk of collusion, and concerns about control must not be ignored in the debate on anticipated benefits. Our findings for the first stage of blockchain diffusion and the externalities we discuss may help policy-makers in setting the right rules as the adoption journey of blockchain technology has just started.},
number = {7},
journal = {Joule},
publisher = {Elsevier BV},
doi = {10.1016/j.joule.2019.05.012},
issn = {25424351},
month = {jun},
title = {The Carbon Footprint of Bitcoin},
volume = {3},
}

@article{2016ZweigAdvances,
author = {Geoffrey Zweig and Chengzhu Yu and Jasha Droppo and Andreas Stolcke},
arxivid = {1609.05935},
year = {2017},
archiveprefix = {arXiv},
title = {Advances in all-neural speech recognition},
volume = {abs/1609.05935},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
pages = {4805--4809},
url = {http://arxiv.org/abs/1609.05935},
doi = {10.1109/ICASSP.2017.7953069},
edition = {Acoustics,},
eprint = {1609.05935},
issn = {15206149},
abstract = {This paper advances the design of CTC-based all-neural (or end-to-end) speech recognizers. We propose a novel symbol inventory, and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner version. We present a number of stabilization and initialization methods we have found useful in training these networks. We evaluate our system on the commonly used NIST 2000 conversational telephony test set, and significantly exceed the previously published performance of similar systems, both with and without the use of an external language model and decoding technology.},
publisher = {AnaisIEEE},
isbn = {9781509041176},
keywords = {ctc,end-to-end training,recurrent neural network,speech recognition},
mendeley-tags = {ctc,end-to-end training,recurrent neural network,speech recognition},
}

@inproceedings{1992BoashashEstimating,
author = {Boualem Boashash},
abstract = {This paper, which addresses the important issue of estimating the instantaneous frequency (IF) of a signal, is a sequel to the paper which appears in this issue, and dealt with the concepts relating to the IF. In this paper the concept of IF is extended to be able to cope with discrete time signals. The specific problem explored is that of estimating the IF of frequency modulated (FM) discrete-time signals imbedded in Gaussian noise. There are many well established methods for estimating the IF—these methods include differentiation of the phase and smoothing thereof, adaptive frequency estimation techniques such as the phase locked loop (PLL), and extraction of the peak from time-varying spectral representations. More recently methods based on a modeling of the signal phase as a polynomial have been introduced. All of these methods are reviewed, and their performances are compared on both simulated and real data. Guidelines are given as to which estimation method should be used for a given signal class and signal-to-noise ratio (SNR). \textcopyright 1992 IEEE},
volume = {80},
number = {4},
doi = {10.1109/5.135378},
booktitle = {Proceedings of the IEEE},
pages = {540--568},
title = {Estimating and Interpreting the Instantaneous Frequency of a Signal—Part 2: Algorithms and Applications},
issn = {15582256},
year = {1992},
}

@article{2018VanDenOordWavenet,
author = {Aaron van den Oord and S Dieleman and  er and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
title = {WaveNet: A Generative Model for Raw Audio},
archiveprefix = {arXiv},
year = {2016},
url = {http://arxiv.org/abs/1609.03499},
eprint = {1609.03499},
volume = {abs/1609.03499},
howpublished = {online},
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
arxivid = {1609.03499},
publisher = {<},
}

@inproceedings{2017BlaauwNeural,
author = {Merlijn Blaauw and Jordi Bonada},
abstract = {We present a new model for singing synthesis based on a modified version of the WaveNet architecture. Instead of modeling raw waveform, we model features produced by a parametric vocoder that separates the influence of pitch and timbre. This allows conveniently modifying pitch to match any target melody, facilitates training on more modest dataset sizes, and significantly reduces training and generation times. Our model makes frame-wise predictions using mixture density outputs rather than categorical outputs in order to reduce the required parameter count. As we found overfitting to be an issue with the relatively small datasets used in our experiments, we propose a method to regularize the model and make the autoregressive generation process more robust to prediction errors. Using a simple multi-stream architecture, harmonic, aperiodic and voiced/unvoiced components can all be predicted in a coherent manner. We compare our method to existing parametric statistical and state-of-the-art concatenative methods using quantitative metrics and a listening test. While naive implementations of the autoregressive generation algorithm tend to be inefficient, using a smart algorithm we can greatly speed up the process and obtain a system that's competitive in both speed and quality.},
issn = {23318422},
booktitle = {arXiv},
title = {A neural parametric singing synthesizer},
url = {http://arxiv.org/abs/1704.03809},
year = {2017},
}

@electronic{2017Neural,
author = {Robert J. Merlo},
abstract = {Artificial intelligence computing offers lower cost and greater efficiency.},
number = {2},
title = {The neural network},
issn = {01499386},
pages = {33},
year = {1999},
howpublished = {online},
booktitle = {Energy (Norwalk, Connecticut)},
volume = {24},
url = {http://www.asimovinstitute.org/neural-network-zoo/},
publisher = {<},
}

@report{parker_learning-logic:_1985,
author = {David B. Parker},
title = {Learning-logic: Casting the cortex of the human brain in silicon.},
year = {1985},
booktitle = {Center for Computational Research in Economics and Management Science, MIT},
institution = {Massachusetts Institute of Technology, Center for Computational Research in Economics and Management Science},
url = {https://books.google.com.br/books?id=2kS9GwAACAAJ},
abstract = {In 1985, David Parker explored the ways the neurons in our brains work, i.e. how they individually operate and in conjunction. He explored the practical ways how to create artificial neurons, that can be connected into trainable networks. He proposed a Learning-Logic which according to his report consist of 1) a model of the neurons in the human cortex; 2) a practical way to create electronic circuits that can learn (Parker, 1985).},
}

@article{2017KlambauerSelf,
author = {G\"unter Klambauer and Thomas Unterthiner and Andreas Mayr and Sepp Hochreiter},
eprint = {1706.02515},
volume = {2017-December},
issn = {10495258},
abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance - even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization schemes, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs, and other machine learning methods such as random forests and support vector machines. For FNNs we considered (i) ReLU networks without normalization, (ii) batch normalization, (iii) layer normalization, (iv) weight normalization, (v) highway networks, and (vi) residual networks. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep.},
journal = {Advances in Neural Information Processing Systems},
archiveprefix = {arXiv},
url = {http://papers.nips.cc/paper/6698-self-normalizing-neural-networks.pdf},
arxivid = {1706.02515},
title = {Self-normalizing neural networks},
editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
year = {2017},
pages = {972--981},
publisher = {Curran Associates, Inc.},
}

@electronic{2015Open,
author = {C L I Pse and E Serv Ed},
pages = {2--5},
url = {https://github.com/crabacus/the-open-source-drumkit},
year = {2010},
booktitle = {Source},
howpublished = {online},
title = {the Open Source},
}

@book{noauthor_spline_2015,
author = {Amir Z. Averbuch and Pekka Neittaanm\"aki and Valery A. Zheludev},
publisher = {Springer Berlin Heidelberg},
pages = {1--287},
annote = {OCLC: 906187660},
booktitle = {Spline and Spline Wavelet Methods with Applications to Signal and Image Processing: Selected Topics},
doi = {10.1007/978-3-319-92123-5},
abstract = {This book provides a practical guide, complete with accompanying Matlab software, to many different types of polynomial and discrete splines and spline-based wavelets, multiwavelets and wavelet frames in signal and image processing applications. In self-contained form, it briefly outlines a broad range of polynomial and discrete splines with equidistant nodes and their signal-processing-relevant properties. In particular, interpolating, smoothing, and shift-orthogonal splines are presented.},
volume = {3},
isbn = {9783319921235},
title = {Spline and Spline wavelet methods with applications to signal and image processing: Selected topics},
year = {2018},
}

@book{Ruiz2015,
author = {Arr\'oliga Araica; Bl Ru\'iz and  \'on and John W. Creswell and Six Byzantine Portraits and Louis Cohen and Lawrence Manion and Keith Morrison and Μ. ΜΗΤΡΟ$\Sigma$$\Upsilon$$\Lambda$Η Μ. $\Theta$ΕΟ$\Delta$$\Omega$ΡΟ$\Upsilon$ and Bert Creemers},
title = {No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title},
pages = {54--67},
booktitle = {Book},
year = {2015},
url = {http://repositorio.unan.edu.ni/2986/1/5624.pdf},
volume = {3},
isbn = {0203985982},
number = {2},
abstract = {The six chapters of this theme issue consider three trends in educational effectiveness research: (1) integration of effectiveness phenomena at different levels, (2) a more model-driven approach than in the past, and (3) increased complexity of analysis tools and techniques to suit the new emphasis on process. (SLD)},
keywords = {emerging power,indonesian,military economic perspective},
mendeley-tags = {emerging power,indonesian,military economic perspective},
}

@book{2009BilbaoNumericala,
author = {Stefan Bilbao},
pages = {1--441},
booktitle = {Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics},
doi = {10.1002/9780470749012},
year = {2009},
month = {oct},
isbn = {9780470510469},
title = {Numerical Sound Synthesis: Finite Difference Schemes and Simulation in Musical Acoustics},
abstract = {Digital sound synthesis has long been approached using standard digital filtering techniques. Newer synthesis strategies, however, make use of physical descriptions of musical instruments, and allow for much more realistic and complex sound production and thereby synthesis becomes a problem of simulation. This book has a special focus on time domain finite difference methods presented within an audio framework. It covers time series and difference operators, and basic tools for the construction and analysis of finite difference schemes, including frequency-domain and energy-based methods, with special attention paid to problems inherent to sound synthesis. Various basic lumped systems and excitation mechanisms are covered, followed by a look at the 1D wave equation, linear bar and string vibration, acoustic tube modelling, and linear membrane and plate vibration. Various advanced topics, such as the nonlinear vibration of strings and plates, are given an elaborate treatment. Key features: Includes a historical overview of digital sound synthesis techniques, highlighting the links between the various physical modelling methodologies. A pedagogical presentation containing over 150 problems and programming exercises, and numerous figures and diagrams, and code fragments in the MATLAB\textregistered programming language helps the reader with limited experience of numerical methods reach an understanding of this subject. Offers a complete treatment of all of the major families of musical instruments, including certain audio effects. Numerical Sound Synthesis is suitable for audio and software engineers, and researchers in digital audio, sound synthesis and more general musical acoustics. Graduate students in electrical engineering, mechanical engineering or computer science, working on the more technical side of digital audio and sound synthesis, will also find this book of interest. \textcopyright 2009 John Wiley & Sons, Ltd.},
url = {https://www.ebook.de/de/product/9338750/stefan///////%5C%5C_bilbao///////%5C%5C_numerical///////%5C%5C_sound///////%5C%5C_synthesis.html},
publisher = {John Wiley \& Sons, Ltd},
}

@article{2012TielemanRmsprop,
author = {Tijmen Tieleman and G Hinton},
volume = {6},
number = {2},
url = {https://www.coursera.org/lecture/neural-networks/rmsprop-divide-the-gradient-by-a-running-average-of-its-recent-magnitude-YQHki},
year = {2012},
howpublished = {online},
title = {Divide the gradient by a running average of its recent magnitude. COURSERA Neural Netw},
journal = {Mach. Learn},
}

@book{2018Magenta,
publisher = {<},
title = {Magenta},
url = {https://magenta.tensorflow.org/ https://magenta.tensorflow.org/%7B////////%5C%5C%25%7D3E},
howpublished = {online},
}

@article{2015Ivy,
author = {Ivy Audio},
url = {http://www.ivyaudio.com/%7B////////%5C%5C%25%7D3E http://www.ivyaudio.com/},
howpublished = {online},
volume = {2018},
title = {Ivy Audio},
}

@article{Wu2016a,
author = {Zhizheng Wu and Simon King},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
issn = {15206149},
year = {2016},
eprint = {1601.02539},
title = {Investigating gated recurrent networks for speech synthesis},
doi = {10.1109/ICASSP.2016.7472657},
isbn = {9781479999880},
pages = {5140--5144},
volume = {2016-May},
archiveprefix = {arXiv},
arxivid = {1601.02539},
abstract = {Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feedforward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
}

@book{2018Keras,
author = {Chollet Fran\ccois},
abstract = {Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.},
address = {Keras Documentation, [s.d.]. Dispon�vel em},
issn = {00046256},
pmid = {1366099},
pages = {ascl:1806.022},
publisher = {<},
howpublished = {online},
booktitle = {Keras.Io},
isbn = {0022-538X (Print) 0022-538X (Linking)},
title = {Keras: The Python Deep Learning library},
year = {2015},
url = {https://ui.adsabs.harvard.edu/abs/2018ascl.soft06022C/abstract},
keywords = {software},
mendeley-tags = {software},
}

@article{torin_percussion_2015,
author = {Alberto Torin},
year = {2015},
title = {Percussion instrument modelling in 3D: sound synthesis through time domain numerical simulation},
type = {phdthesis},
}

@article{Sigtia2016b,
author = {Siddharth Sigtia and Emmanouil Benetos and Simon DIxon},
abstract = {We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network-based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yield the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.},
archiveprefix = {arXiv},
doi = {10.1109/TASLP.2016.2533858},
arxivid = {1508.01774},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
issn = {23299290},
eprint = {1508.01774},
publisher = {IEEE Press},
title = {An end-to-end neural network for polyphonic piano music transcription},
url = {https://arxiv.org/abs/1508.01774},
volume = {24},
year = {2016},
number = {5},
pages = {927--939},
keywords = {music transcription,state of the art},
mendeley-tags = {music transcription,state of the art},
}

@book{2018Neona,
title = {Neon},
howpublished = {online},
url = {https://ai.intel.com/neon/ https://ai.intel.com/neon/%7B////////%5C%5C%25%7D3E},
publisher = {<},
}

@book{2018Tensorflowa,
howpublished = {online},
publisher = {<},
title = {TensorFlow},
url = {https://www.tensorflow.org/%7B////////%5C%5C%25%7D3E https://www.tensorflow.org/},
}

@book{2018Nsynthsuper,
howpublished = {online},
url = {https://nsynthsuper.withgoogle.com/%7B////////%5C%5C%25%7D3E https://nsynthsuper.withgoogle.com/},
title = {NSynthSuper},
publisher = {<},
}

@article{2016HighlanderVery,
author = { Highl and Tyler er and Andres Rodriguez},
arxivid = {1601.06815},
pages = {160.1--160.9},
eprint = {1601.06815},
archiveprefix = {arXiv},
abstract = {Convolutional neural networks (CNNs) are currently state-of-the-art for various classification tasks, but are computationally expensive. Propagating through the convolutional layers is very slow, as each kernel in each layer must sequentially calculate many dot products for a single forward and backward propagation which equates to $\mathcalO(N^2n^2)$ per kernel per layer where the inputs are $N \times N$ arrays and the kernels are $n \times n$ arrays. Convolution can be efficiently performed as a Hadamard product in the frequency domain. The bottleneck is the transformation which has a cost of $\mathcalO(N^2\log_2 N)$ using the fast Fourier transform (FFT). However, the increase in efficiency is less significant when $N\gg n$ as is the case in CNNs. We mitigate this by using the "overlap-and-add" technique reducing the computational complexity to $\mathcalO(N^2\log_2 n)$ per kernel. This method increases the algorithm's efficiency in both the forward and backward propagation, reducing the training and testing time for CNNs. Our empirical results show our method reduces computational time by a factor of up to 16.3 times the traditional convolution implementation for a 8 $\times$ 8 kernel and a 224 $\times$ 224 image.},
title = {Very Efficient Training of Convolutional Neural Networks using Fast Fourier Transform and Overlap-and-Add},
year = {2015},
doi = {10.5244/c.29.160},
url = {http://arxiv.org/abs/1601.06815},
}

@article{2008DonosoFisica,
author = {Jos\'e Pedro Donoso and Alberto Tann\'us and Francisco Guimar\~aes and Thiago Corr\^ea de Freitas},
pages = {23051--230521},
title = {A f\'isica do violino},
journal = {Revista Brasileira de Ensino de Fisica},
number = {2},
volume = {30},
url = {http://www.scielo.br/scielo.php?pid=S0102-47442008000200006///////%5C%5C&script=sci///////%5C%5C_arttext},
year = {2008},
issn = {01024744},
doi = {10.1590/s1806-11172008000200006},
abstract = {In this work we present a general description of the physics of the violin. We examine the concepts which provide the physical support and reveal the richness and the pedagogical potential of the subject. We remark the contributions of physicists such as Helmholtz, Savart, Raman and Suanders to the instrument. of the way in which a bowed string vibrates, and the comprehension of the acoustical properties of the instrument. The role of each component of the violin is described in details. We also discuss the importance of the bridge, the plates and the body normal modes of vibration for the acoustical response of the instrument. The air-resonance of the enclosed air in the violin body (Helmholtz resonance) is disscussed using the equivalent fomalism between mechanical, electrical and acoustic oscillating systems. The production of the characteristic sound of the violin, which results from the vibrational waveform of a bowed string, is also described. Copyright by the Sociedade Brasileira de F\'isica.},
keywords = {acoustics,helmholtz,musical instruments,resonance,violin},
mendeley-tags = {acoustics,helmholtz,musical instruments,resonance,violin},
}

@unpublished{Donahue2014,
author = {Chris Donahue and Julian McAuley and Miller Puckette},
eprint = {1802.04208},
year = {2018},
abstract = {Audio signals are sampled at high temporal resolutions, and learning to synthesize audio requires capturing structure across a range of timescales. Generative adversarial networks (GANs) have seen wide success at generating images that are both locally and globally coherent, but they have seen little application to audio generation. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. WaveGAN is capable of synthesizing one second slices of audio waveforms with global coherence, suitable for sound effect generation. Our experiments demonstrate that-without labels-WaveGAN learns to produce intelligible words when trained on a smallvocabulary speech dataset, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. We compare WaveGAN to a method which applies GANs designed for image generation on image-like audio feature representations, finding both approaches to be promising.},
annote = {From Duplicate 2 (Adversarial audio synthesis - Donahue, Chris; McAuley, Julian; Puckette, Miller)preprint},
archiveprefix = {arXiv},
arxivid = {1802.04208},
booktitle = {arXiv},
title = {Adversarial audio synthesis},
issn = {23318422},
}

@article{GrinsteinNo,
author = {Eric Grinstein and Ngoc Q.K. Duong and Alexey Ozerov and Patrick Perez},
abstract = {'Style transfer' among images has recently emerged as a very active research topic, fuelled by the power of convolution neural networks (CNNs), and has become fast a very popular technology in social media. This paper investigates the analogous problem in the audio domain: How to transfer the style of a reference audio signal to a target audio content? We propose a flexible framework for the task, which uses a sound texture model to extract statistics characterizing the reference audio style, followed by an optimization-based audio texture synthesis to modify the target content. In contrast to mainstream optimization-based visual transfer method, the proposed process is initialized by the target content instead of random noise and the optimized loss is only about texture, not structure. These differences proved key for audio style transfer in our experiments. In order to extract features of interest, we investigate different architectures, whether pre-trained on other tasks, as done in image style transfer, or engineered based on the human auditory system. Experimental results on different types of audio signal confirm the potential of the proposed approach.},
isbn = {9781538646588},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
archiveprefix = {arXiv},
eprint = {1710.11385},
doi = {10.1109/ICASSP.2018.8461711},
arxivid = {1710.11385},
annote = {From Duplicate 2 (Audio Style Transfer - Grinstein, Eric; Duong, Ngoc Q.K.; Ozerov, Alexey; Perez, Patrick)preprint},
volume = {2018-April},
pages = {586--590},
title = {Audio Style Transfer},
year = {2018},
keywords = {audio style transfer,auditory system,deep neural network,sound texture model,texture synthesis},
mendeley-tags = {audio style transfer,auditory system,deep neural network,sound texture model,texture synthesis},
}

@book{2018BlennowMathematical,
author = {Mattias Blennow},
isbn = {978-0-521-67971-8},
doi = {10.1201/b22209},
booktitle = {Mathematical Methods for Physics and Engineering},
publisher = {Cambridge University Press},
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
edition = {3 edition},
title = {Mathematical Methods for Physics and Engineering},
shorttitle = {Mathematical Methods for Physics and Engineering},
year = {2018},
}

@book{2008DahlquistNumerical,
author = {Germund Dahlquist and \AAke Bj\"orck},
shorttitle = {Numerical Methods in Scientific Computing},
booktitle = {Numerical Methods in Scientific Computing, Volume I},
annote = {From Duplicate 1 (Numerical Methods in Scientific Computing, Volume I - Dahlquist, Germund; Bj\"orck, \AAke)Google-Books-ID: 2i7TjgEACAAJ},
doi = {10.1137/1.9780898717785},
publisher = {Society for Industrial and Applied Mathematics},
url = {http://fmipa.umri.ac.id/wp-content/uploads/2016/03/Dahlquist///////%5C%5C_G.///////%5C%5C_Bjoerck///////%5C%5C_A.///////%5C%5C_Vol.1.///////%5C%5C_Numerical///////%5C%5C_methodBookZZ.org///////%5C%5C_.pdf},
title = {Numerical Methods in Scientific Computing, Volume I},
isbn = {978-0-89871-644-3},
volume = {2},
abstract = {This new book from the authors of the classic book Numerical Methods addresses the increasingly important role of numerical methods in science and engineering. More cohesive and comprehensive than any other modern textbook in the field, it combines traditional and well-developed topics with other material that is rarely found in numerical analysis texts, such as interval arithmetic, elementary functions, operator series, convergence acceleration, and continued fractions. Although this volume is self-contained, more comprehensive treatments of matrix computations will be given in a forthcoming volume. A supplementary Website contains three appendices: an introduction to matrix computations; a description of Mulprec, a MATLAB multiple precision package; and a guide to literature, algorithms, and software in numerical analysis. Review questions, problems, and computer exercises are also included. For use in an introductory graduate course in numerical analysis and for researchers who use numerical methods in science and engineering.},
year = {2008},
}

@book{2016BonninBuilding,
author = {Luc Vinet and Alexei Zhedanov},
editor = {Zopounidis, Constantin},
number = {8},
series = {Applied optimization},
arxivid = {1011.1669},
pages = {25--44},
url = {http://dx.doi.org/10.1016/j.jsames.2011.03.003%0Ahttps://doi.org/10.1016/j.gr.2017.08.001%0Ahttp://dx.doi.org/10.1016/j.precamres.2014.12.018%0Ahttp://dx.doi.org/10.1016/j.precamres.2011.08.005%0Ahttp://dx.doi.org/10.1080/00206814.2014.902757%0Ahttp://dx. http://link.springer.com/10.1007/978-3-540-92828-7},
pmid = {25246403},
isbn = {978-3-540-92827-0},
eprint = {1011.1669},
year = {2011},
abstract = {We study a family of 'classical' orthogonal polynomials which satisfy (apart from a three-term recurrence relation) an eigenvalue problem with a differential operator of Dunkl type. These polynomials can be obtained from the little q-Jacobi polynomials in the limit q = -1. We also show that these polynomials provide a nontrivial realization of the Askey-Wilson algebra for q = -1. \textcopyright 2011 IOP Publishing Ltd.},
publisher = {Springer},
annote = {From Duplicate 2 (A 'missing' family of classical orthogonal polynomials - Vinet, Luc; Zhedanov, Alexei)OCLC: 845476314},
archiveprefix = {arXiv},
doi = {10.1088/1751-8113/44/8/085201},
title = {A 'missing' family of classical orthogonal polynomials},
booktitle = {Journal of Physics A: Mathematical and Theoretical},
issn = {17518113},
volume = {44},
}

@book{2011LoyMusimathicsa,
author = {Gareth Loy and John M Chowning},
edition = {Reprint edition},
issn = {0009-4978},
number = {03},
doi = {10.5860/choice.45-1511},
publisher = {MIT Press},
pages = {45--1511--45--1511},
shorttitle = {Musimathics},
title = {Musimathics: the mathematical foundations of music},
abstract = {"Mathematics can be as effortless as humming a tune, if you know the tune," writes Gareth Loy. In Musimathics, Loy teaches us the tune, providing a friendly and spirited tour of the mathematics of musica commonsense, self-contained introduction for the nonspecialist reader. It is designed for musicians who find their art increasingly mediated by technology, and for anyone who is interested in the intersection of art and science. In this volume, Loy presents the materials of music (notes, intervals, and scales); the physical properties of music (frequency, amplitude, duration, and timbre); the perception of music and sound (how we hear); and music composition. Musimathics is carefully structured so that new topics depend strictly on topics already presented, carrying the reader progressively from basic subjects to more advanced ones. Cross-references point to related topics and an extensive glossary defines commonly used terms. The book explains the mathematics and physics of music for the reader whose mathematics may not have gone beyond the early undergraduate level. Calling himself "a composer seduced into mathematics," Loy provides answers to foundational questions about the mathematics of music accessibly yet rigorously. The topics are all subjects that contemporary composers, musicians, and musical engineers have found to be important. The examples given are all practical problems in music and audio. The level of scholarship and the pedagogical approach also make Musimathics ideal for classroom use. Additional material can be found at a companion web site.},
volume = {45},
booktitle = {Choice Reviews Online},
isbn = {978-0-262-51655-6},
year = {2007},
annote = {From Duplicate 2 (Musimathics: the mathematical foundations of music - Loy, Gareth; Chowning, John M)OCLC: 935185987},
}

@article{2000MontiNo,
author = {American Journal of Sociology and Fitria Savira and Yudi Suharsono and American Journal of Sociology and  中島 and Fitria Savira and Yudi Suharsono},
number = {01},
pmid = {25246403},
title = {済無No Title No Title},
isbn = {9788578110796},
volume = {01},
url = {https://github.com/tesserato/tesserato.github.io%7B////////%5C%5C%25%7D3E},
arxivid = {arXiv:1011.1669v3},
year = {2013},
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 \AA for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
journal = {Journal of Chemical Information and Modeling},
eprint = {arXiv:1011.1669v3},
archiveprefix = {arXiv},
pages = {1689--1699},
issn = {1098-6596},
keywords = {icle},
mendeley-tags = {icle},
}

@article{Santurkar2017,
author = {Shibani Santurkar and David Budden and Nir Shavit},
journal = {2018 Picture Coding Symposium, PCS 2018 - Proceedings},
arxivid = {1703.01467},
year = {2018},
archiveprefix = {arXiv},
isbn = {9781538641606},
pages = {258--262},
abstract = {Traditional image and video compression algorithms rely on hand-crafted encoder/decoder pairs (codecs) that lack adaptability and are agnostic to the data being compressed. We describe the concept of generative compression, the compression of data using generative models, and suggest that it is a direction worth pursuing to produce more accurate and visually pleasing reconstructions at deeper compression levels for both image and video data. We also show that generative compression is orders- of-magnitude more robust to bit errors (e.g., from noisy channels) than traditional variable-length coding schemes.},
doi = {10.1109/PCS.2018.8456298},
eprint = {1703.01467},
title = {Generative Compression},
url = {http://arxiv.org/abs/1703.01467},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{He2016,
author = {Lei He and Volker Dellwo},
abstract = {A speech signal can be viewed as a high frequency carrier signal containing the temporal fine structure (TFS) that is modulated by a low frequency envelope (ENV). A widely used method to decompose a speech signal into the TFS and ENV is the Hilbert transform. Although this method has been available for about one century and is widely applied in various kinds of speech processing tasks (e.g. speech chimeras), there are only very few speech processing packages that contain readily available functions for the Hilbert transform, and there is very little textbook type literature tailored for speech scientists to explain the processes behind the transform. With this paper we provide the code for carrying out the Hilbert operation to obtain the TFS and ENV in the widely used speech processing software Praat, and explain the basics of the procedure. To verify our code, we compare the Hilbert transform in Praat with a widely applied function for the same purpose in MATLAB ("hilbert(.)"). We can confirm that both methods arrive at identical outputs.},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
doi = {10.21437/Interspeech.2016-1447},
pages = {530--534},
issn = {19909772},
title = {A Praat-based algorithm to extract the amplitude envelope and temporal fine structure using the Hilbert transform},
year = {2016},
number = {September},
volume = {08-12-September-2016},
keywords = {amplitude envelope,hilbert transform,praat,temporal fine structure},
mendeley-tags = {amplitude envelope,hilbert transform,praat,temporal fine structure},
}

@article{Wang2016,
author = {Zhenyang Wang and Zhidong Deng and Shiyao Wang},
doi = {10.1109/IJCNN.2016.7727308},
isbn = {9781509006199},
abstract = {Convolutional neural networks play an increasingly important role in computer vision tasks, especially in the field of visual object recognition. Many prominent models, such as Inception, Maxout, ResNet, and NIN, have been proposed to significantly improve recognition performance. Inspired from those models, we propose a novel module called self-adaptive module (SAM). SAM consists of four passes and one selector. Specifically, the four passes include two direct passes with different receptive fields and depths, one residual pass, and one Maxout pass. Actually, the residual pass is used to speed up convergence, while we take advantage of the Maxout pass to enhance approximate capabilities of SAM. The selector is further designed to help choose reasonable output. Basically, SAM is intended to simplify design of any new deep learning architecture, since it no longer requires consideration of how to select receptive fields and depths. Our SAM is tested on the visual object recognition datasets including CIFAR-10, CIFAR-100, MNIST, and SVHN. The experimental results demonstrate that the SAM-Net has superior recognition performances on the four benchmarks, which achieve test errors of 5.76%, 28.56%, 0.31%, and 1.98%, respectively.},
title = {SAM: A rethinking of prominent convolutional neural network architectures for visual object recognition},
pages = {1008--1014},
volume = {2016-October},
number = {July},
year = {2016},
journal = {Proceedings of the International Joint Conference on Neural Networks},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Cecotti2008,
author = {Hubert Cecotti and Axel Graeser},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
pages = {1--4},
abstract = {In BCI (Brain - Computer Interface) systems, brain signals must be processed to identify distinct activities that convey different mental states. We propose a new technique for the classification of electroencephalo-graphic (EEG) Steady-State Visual Evoked Potential (SSVEP) activity for non-invasive BCI. The proposed method is based on a Convolutional Neural Network that includes a Fourier transform between hidden layers in order to switch from the time domain to the frequency domain analysis in the network. The first step allows the creation of different channels. The second step is dedicated to the transformation of the signal in the frequency domain. The last step is the classification. It uses a hybrid rejection strategy that uses a junk class for the mental transition states and thresholds for the confidence values. The presented results with offline processing are obtained with 6 electrodes on 2 subjects with a time segment of 1s. The system is reliable for both subjects over 95%, with rejection criterion. \textcopyright 2008 IEEE.},
isbn = {9781424421756},
doi = {10.1109/icpr.2008.4761638},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761638%5Cnpapers3://publication/doi/10.1109/ICPR.2008.4761638},
year = {2008},
title = {Convolutional Neural Network with embedded Fourier transform for EEG classification},
}

@article{wang2015image,
author = {Bo Wang and Yubin Gao},
volume = {13},
journal = {Telkomnika (Telecommunication Computing Electronics and Control)},
number = {1},
doi = {10.12928/TELKOMNIKA.v13i1.1270},
abstract = {Image compression technology is to compress the redundancy between the pixels to reduce the transmission broadband and storage space by using the correlation of the image pixels. Fuzzy neural network effectively integrates neural network technology and fuzzy technology; combines learning, self-adaptivity, imagination and identity and uses rule-based reasoning and fuzzy information processing in the nodes; thus greatly improving the transparency of fuzzy neural network. This paper mainly investigates the applications of fuzzy neural network in image compression and realizes the image compression and reconstruction of fuzzy neural network. It is demonstrated in the simulation experiment that the image compression algorithm based on fuzzy neural network has significant advantages in training speed, compression quality and robustness.},
pages = {137--145},
issn = {23029293},
year = {2015},
title = {An image compression scheme based on fuzzy neural network},
keywords = {fuzzy theory,image compression,neural network},
mendeley-tags = {fuzzy theory,image compression,neural network},
}

@book{bbv13,
author = { Boulanger-Lew and Nicolas owski and Yoshua Bengio and Pascal Vincent},
isbn = {9781479903566},
eprint = {1212.1936},
abstract = {We investigate the problem of transforming an input sequence into a high-dimensional output sequence in order to transcribe polyphonic audio music into symbolic notation. We introduce a probabilistic model based on a recurrent neural network that is able to learn realistic output distributions given the input and we devise an efficient algorithm to search for the global mode of that distribution. The resulting method produces musically plausible transcriptions even under high levels of noise and drastically outperforms previous stateof- the-art approaches on five datasets of synthesized sounds and real recordings, approximately halving the test error rate. \textcopyright 2013 IEEE.},
pages = {3178--3182},
archiveprefix = {arXiv},
publisher = {Anais�IEEE},
doi = {10.1109/ICASSP.2013.6638244},
year = {2013},
arxivid = {1212.1936},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
issn = {15206149},
title = {High-dimensional sequence transduction},
keywords = {polyphonic transcription,recurrent neural network,restricted boltzmann machine,sequence transduction},
mendeley-tags = {polyphonic transcription,recurrent neural network,restricted boltzmann machine,sequence transduction},
}

@article{Brown1991,
author = {Judith C. Brown and Bin Zhang},
title = {Musical frequency tracking using the methods of conventional and "narrowed" autocorrelation},
abstract = {In two recent papers, a description is given of a means of obtaining an arbitrarily narrow peak in the calculation of the autocorrelation function [J. C. Brown, and M. S. Puckette, "Calculation of a narrowed autocorrelation function," J. Acoust. Soc. Am. 85, 1595–1601 (1989)] or of a narrow valley in the calculation of an inverse autocorrelation [J. C. Brown, and M. S. Puckette, "Musical information from a narrowed autocorrelation function," Proceedings of the 1987 International Conference on Computer Music, Urbana, Illinois, 84–88 (1987)]. These calculations are applied to the determination of the fundamental frequency of musical signals produced by keyboard, wind, and string instruments. These results are compared to frequency tracking results obtained on these sounds with conventional autocorrelation. In so doing it is determined first whether the method of autocorrelation is well-adapted to the problem of tracking the frequency of musical signals, and, second, under what conditions "narrowed" autocorrelation is advantageous. \textcopyright 1991, Acoustical Society of America. All rights reserved.},
volume = {89},
year = {1991},
doi = {10.1121/1.400923},
number = {5},
issn = {NA},
pages = {2346--2354},
journal = {Journal of the Acoustical Society of America},
}

@article{Janai2017,
author = {Joel Janai and Fatma Guney and Aseem Behl and Andreas Geiger},
eprint = {1704.05519},
journal = {arXiv},
issn = {23318422},
arxivid = {1704.05519},
url = {http://arxiv.org/abs/1704.05519},
abstract = {Recent years have witnessed amazing progress in AI related fields such as computer vision, machine learning and autonomous vehicles. As with any rapidly growing field, however, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several topic specific survey papers have been written, to date no general survey on problems, datasets and methods in computer vision for autonomous vehicles exists. This paper attempts to narrow this gap by providing a state-of-the-art survey on this topic. Our survey includes both the historically most relevant literature as well as the current state-of-the-art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning. Towards this goal, we first provide a taxonomy to classify each approach and then analyze the performance of the state-of-the-art on several challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we will also provide an interactive platform which allows to navigate topics and methods, and provides additional information and project links for each paper.},
year = {2017},
title = {Computer vision for autonomous vehicles: Problems, datasets and state-of-the-art},
archiveprefix = {arXiv},
doi = {10.1561/0600000079},
keywords = {image classification,object detection,review},
mendeley-tags = {image classification,object detection,review},
}

@article{Nielsen2017,
author = {Ga\"etan Hadjeres and Fran\ccois Pachet and Frank Nielsen},
title = {DeepBach: A steerable model for bach chorales generation},
archiveprefix = {arXiv},
isbn = {9781510855144},
year = {2017},
abstract = {This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data. This is in contrast with many automatic music composition approaches which tend to compose music sequentially. Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score. We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use.},
volume = {3},
journal = {34th International Conference on Machine Learning, ICML 2017},
eprint = {1612.01010},
arxivid = {1612.01010},
pages = {2187--2196},
}

@article{choi2016automatic,
author = {Keunwoo Choi and Gy\"orgy Fazekas and  S and Mark ler},
title = {Automatic tagging using deep convolutional neural networks},
journal = {Proceedings of the 17th International Society for Music Information Retrieval Conference, ISMIR 2016},
year = {2016},
pages = {805--811},
archiveprefix = {arXiv},
eprint = {1606.00298},
abstract = {We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.},
doi = {10.5281/zenodo.1416253},
isbn = {9780692755068},
arxivid = {1606.00298},
}

@article{Embrechts2009,
author = {Paul Embrechts and Marco Frei},
doi = {10.1007/s00186-008-0249-2},
year = {2009},
title = {Panjer recursion versus FFT for compound distributions},
journal = {Mathematical Methods of Operations Research},
number = {3},
volume = {69},
pages = {497--508},
issn = {14322994},
abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used. We give a survey of these tools, point out the respective merits and provide some numerical examples. \textcopyright 2008 Springer-Verlag.},
keywords = {compound distributions,fast fourier transform,panjer recursion,risk management},
mendeley-tags = {compound distributions,fast fourier transform,panjer recursion,risk management},
}

@article{Agerfalk2008a,
author = {P\"ar J. \AAgerfalk and Brian Fitzgerald},
journal = {MIS Quarterly: Management Information Systems},
abstract = {This paper presents a psychological contract perspective on the use of the open source development model as a global sourcing strategy - opensourcing, as we term it here-where-by commercial companies and open source communities collaborate on development of software of commercial interest to the company. Building on previous research on information systems outsourcing, a theoretical framework for exploring the opensourcing phenomenon is derived. The first phase of the research concerned qualitative case studies involving three commercial organizations (IONA Technologies, Philips Medical Systems, and Telefonica) that had "liberated" what had hitherto been proprietary software and sought to grow a global open source community around their product. We followed this with a large-scale survey involving additional exemplars of the phenomenon. The study identifies a number of symmetrical and complementary customer and community obligations that are associated with opensourcing success. We also identify a number of tension points on which customer and community perceptions tend to vary. Overall the key watchwords for opensourcing are openness, trust, tact, professionalism, transparency, and complementariness: The customer and community need to establish a trusted partnership of shared responsibility in building an overall opensourcing ecosystem. The study reveals an ongoing shift from OSS as a community of individual developers to OSS as a community of commercial organizations, primarily small to medium-sized enterprises. It also reveals that opensourcing provides ample opportunity for companies to headhunt top developers, hence moving from outsourcing to a largely unknown OSS workforce toward recruitment of developers from a global open source community whose talents have become known as a result of the opensourcing experience.},
pages = {385--409},
doi = {10.2307/25148845},
shorttitle = {OUTSOURCING TO AN UNKNOWN WORKFORCE},
title = {Outsourcing to an unknown workforce: Exploring opensourcing as a global sourcing strategy},
year = {2008},
number = {2},
issn = {02767783},
volume = {32},
keywords = {crowdsourcing,global software development,multimethod research,offshoring,open source,opensourcing,outsourcing},
mendeley-tags = {crowdsourcing,global software development,multimethod research,offshoring,open source,opensourcing,outsourcing},
}

@article{Palmes2005,
author = {Paulito P. Palmes and Taichi Hayasaka and Shiro Usui},
abstract = {Evolving gradient-learning artificial neural networks (ANNs) using an evolutionary algorithm (EA) is a popular approach to address the local optima and design problems of ANN. The typical approach is to combine the strength of backpropagation (BP) in weight learning and EA's capability of searching the architecture space. However, the BP's "gradient descent" approach requires a highly computer-intensive operation that relatively restricts the search coverage of EA by compelling it to use a small population size. To address this problem, we utilized mutation-based genetic neural network (MGNN) to replace BP by using the mutation strategy of local adaptation of evolutionary pogramming (EP) to effect weight learning. The MGNN's mutation enables the network to dynamically evolve its structure and adapt its weights at the same time. Moreover, MGNN's EP-based encoding scheme allows for a flexible and less restricted formulation of the fitness function and makes fitness computation fast and efficient. This makes it feasible to use larger population sizes and allows MGNN to have a relatively wide search coverage of the architecture space. MGNN implements a stopping criterion where overfitness occurrences are monitored through "sliding-windows" to avoid premature learning and overlearning. Statistical analysis of its performance to some well-known classification problems demonstrate its good generalization capability. It also reveals that locally adapting or scheduling the strategy parameters embedded in each individual network may provide a proper balance between the local and global searching capabilities of MGNN. \textcopyright 2005 IEEE.},
pages = {587--600},
doi = {10.1109/TNN.2005.844858},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
year = {2005},
pmid = {15940989},
number = {3},
volume = {16},
isbn = {1045-9227},
title = {Mutation-based genetic neural network},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@unpublished{m17,
author = {Parag K. Mital},
eprint = {1711.11160},
archiveprefix = {arXiv},
title = {Time Domain Neural Audio Style Transfer},
year = {2017},
abstract = {A recently published method for audio style transfer has shown how to extend the process of image style transfer to audio. This method synthesizes audio "content" and "style" independently using the magnitudes of a short time Fourier transform, shallow convolutional networks with randomly initialized filters, and iterative phase reconstruction with Griffin-Lim. In this work, we explore whether it is possible to directly optimize a time domain audio signal, removing the process of phase reconstruction and opening up possibilities for real-time applications and higher quality syntheses. We explore a variety of style transfer processes on neural networks that operate directly on time domain audio signals and demonstrate one such network capable of audio stylization.},
annote = {preprint},
arxivid = {1711.11160},
booktitle = {arXiv},
issn = {23318422},
}

@article{mao2000probabilistic,
author = {K. Z. Mao and K. C. Tan and W. Ser},
publisher = {IEEE},
doi = {10.1109/72.857781},
number = {4},
volume = {11},
journal = {IEEE Transactions on Neural Networks},
abstract = {Network structure determination is an important issue in pattern classification based on a probabilistic neural network. In this study, a supervised network structure determination algorithm is proposed. The proposed algorithm consists of two parts and runs in an iterative way. The first part identifies an appropriate smoothing parameter using a genetic algorithm, while the second part determines suitable pattern layer neurons using a forward regression orthogonal algorithm. The proposed algorithm is capable of offering a fairly small network structure with satisfactory classification accuracy.},
year = {2000},
pages = {1009--1016},
title = {Probabilistic neural-network structure determination for pattern classification},
issn = {10459227},
}

@article{Shin2016,
author = {Hoo Chang Shin and Holger R. Roth and Mingchen Gao and Le Lu and Ziyue Xu and Isabella Nogues and Jianhua Yao and Daniel Mollura and Ronald M. Summers},
year = {2016},
issn = {1558254X},
doi = {10.1109/TMI.2016.2528162},
eprint = {1602.03409},
abstract = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
journal = {IEEE Transactions on Medical Imaging},
number = {5},
pages = {1285--1298},
archiveprefix = {arXiv},
arxivid = {1602.03409},
isbn = {0278-0062 VO - 35},
pmid = {26886976},
title = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},
volume = {35},
keywords = {image classification,optimization},
mendeley-tags = {image classification,optimization},
}

@unpublished{e17,
author = {Jesse Engel and Cinjon Resnick and Adam Roberts and S Dieleman and  er and Mohammad Norouzi and Douglas Eck and Karen Simonyan},
pages = {1771--1780},
volume = {3},
arxivid = {1704.01279},
year = {2017},
booktitle = {34th International Conference on Machine Learning, ICML 2017},
isbn = {9781510855144},
abstract = {Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autocncodcr model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.},
eprint = {1704.01279},
title = {Neural audio synthesis of musical notes with WaveNet autoencoders},
annote = {preprint},
archiveprefix = {arXiv},
}

@article{Hou2015,
author = {Weijun Tian and Feng Shao and Gangyi Jiang and Mei Yu},
issn = {10039775},
number = {6},
pages = {968--975},
volume = {28},
abstract = {Stereoscopic image quality assessment is an effective way to evaluate the performance of stereoscopic video systems, but how to utilize human visual characteristics effectively is still a research focus in stereoscopic image quality assessment. In this paper, a blind image quality assessment method for stereoscopic images is proposed via deep learning. The proposed method is composed of two stages: training and testing. In the training stage, Gabor filter is applied to the left and right distorted images respectively, and natural statistical features under different scales and directions are extracted to act as monocular features. Then, left and right images are fused to construct a cyclopean map, and histograms of oriented gradient features are extracted from the cyclopean map to act as binocular features. Finally, a regression model between features and subjective scores is established via deep belief network. In the testing stage, based on the established regression model, left and right image quality scores are predicted and fused to get the final stereoscopic image quality score. Experimental results show that the proposed method is effective for both symmetrical and asymmetrical stereoscopic image databases, and can achieve high consistent alignment with subjective assessment.},
journal = {Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics},
year = {2016},
publisher = {IEEE},
title = {Blind image quality assessment for stereoscopic images via deep learning},
keywords = {image classification,sentiment analysis},
mendeley-tags = {image classification,sentiment analysis},
}

@article{Li2015,
author = {Junnan Li and Edmund Y. Lam},
year = {2015},
isbn = {9781479986330},
journal = {IST 2015 - 2015 IEEE International Conference on Imaging Systems and Techniques, Proceedings},
pages = {1--6},
issn = {1558-2809},
abstract = {We develop a technique using deep neural network for human facial expression recognition. Images of human faces are preprocessed with photometric normalization and histogram manipulation to remove illumination variance. Facial features are then extracted by convolving each preprocessed image with 40 Gabor filters. Kernel PCA is applied to features before feeding them into the deep neural network that consists of 1 input layer, 2 hidden layers and a softmax classifier. The deep network is trained using greedy layer-wise strategy. We use the Extended Cohn-Kanade Dataset for training and testing. Recognition tests are performed on six basic expressions (i.e. surprise, fear, disgust, anger, happiness, sadness). To test the robustness of the classification system further, and for benchmark comparison, we add a seventh emotion, namely 'contempt', for additional recognition tests. We construct confusion matrix to evaluate the performance of the deep network. It is demonstrated that the network generalizes to new images fairly successfully with an average recognition rate of 96.8% for six emotions and 91.7% for seven emotions. In comparison with shallower neural networks and SVM methods, the proposed deep network method can provide better recognition performance.},
doi = {10.1109/IST.2015.7294547},
title = {Facial expression recognition using deep neural networks},
keywords = {facial expression},
mendeley-tags = {facial expression},
}

@article{Goldberg2015,
author = {Yoav Goldberg},
issn = {10769757},
volume = {57},
eprint = {1510.00726},
archiveprefix = {arXiv},
title = {A primer on neural network models for natural language processing},
year = {2016},
abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
doi = {10.1613/jair.4992},
pages = {345--420},
url = {http://arxiv.org/abs/1510.00726},
journal = {Journal of Artificial Intelligence Research},
arxivid = {1510.00726},
keywords = {review,speech recognition,speech synthesis},
mendeley-tags = {review,speech recognition,speech synthesis},
}

@article{Gregor2016,
author = {Karol Gregor and Frederic Besse and Danilo Jimenez Rezende and Ivo Danihelka and Daan Wierstra},
journal = {Advances in Neural Information Processing Systems},
title = {Towards conceptual compression},
issn = {10495258},
arxivid = {1604.08772},
eprint = {1604.08772},
number = {Nips},
url = {http://arxiv.org/abs/1604.08772},
year = {2016},
abstract = {We introduce convolutional DRAW, a homogeneous deep generative model achieving state-of-the-art performance in latent variable image modeling. The algorithm naturally stratifies information into higher and lower level details, creating abstract features and as such addressing one of the fundamentally desired properties of representation learning. Furthermore, the hierarchical ordering of its latents creates the opportunity to selectively store global information about an image, yielding a high quality 'conceptual compression' framework.},
pages = {3556--3564},
archiveprefix = {arXiv},
keywords = {image compression - conceptual,state of the art},
mendeley-tags = {image compression - conceptual,state of the art},
}

@unpublished{i16,
author = {Phillip Isola and Jun Yan Zhu and Tinghui Zhou and Alexei A. Efros},
doi = {10.1109/CVPR.2017.632},
isbn = {9781538604571},
eprint = {1611.07004},
year = {2017},
pages = {5967--5976},
title = {Image-to-image translation with conditional adversarial networks},
volume = {2017-January},
arxivid = {1611.07004},
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
annote = {preprint},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
archiveprefix = {arXiv},
}

@article{Erickson2017,
author = {Bradley J. Erickson and Panagiotis Korfiatis and Zeynettin Akkus and Timothy Kline and Kenneth Philbrick},
year = {2017},
publisher = {Journal of Digital Imaging},
abstract = {Deep learning is an important new area of machine learning which encompasses a wide range of neural network architectures designed to complete various tasks. In the medical imaging domain, example tasks include organ segmentation, lesion detection, and tumor classification. The most popular network architecture for deep learning for images is the convolutional neural network (CNN). Whereas traditional machine learning requires determination and calculation of features from which the algorithm learns, deep learning approaches learn the important features as well as the proper weighting of those features to make predictions for new data. In this paper, we will describe some of the libraries and tools that are available to aid in the construction and efficient execution of deep learning as applied to medical images.},
number = {4},
pmid = {28315069},
pages = {400--405},
issn = {1618727X},
doi = {10.1007/s10278-017-9965-6},
journal = {Journal of Digital Imaging},
title = {Toolkits and Libraries for Deep Learning},
volume = {30},
keywords = {artificial intelligence,convolutional neural network,deep learning,machine learning},
mendeley-tags = {artificial intelligence,convolutional neural network,deep learning,machine learning},
}

@book{Petre2010,
author = {Martin Cunningham},
issn = {09607919},
number = {5},
pages = {36--37},
url = {http://books.google.com/books?id=_DDwCqx6wpcC&printsec=frontcover&dq=unwritten+rules+of+phd+research&hl=&cd=1&source=gbs_api%255Cnpapers2://publication/uuid/48967E01-55F9-4397-B941-310D9C5405FA%255Cnhttp://medcontent.metapress.com/index/A65RM03P4874243N.p},
title = {The unwritten rules of business extravagance},
abstract = {"I feel grateful to have found this book only a year into my PhD. It has opened my eyes to the world of academia. There is more to a PhD than just research in the sense of working on a problem, getting some results and publishing your findings. This book has allowed me to open my eyes and see all the other things I should be doing to fully succeed at my endeavour of becoming a researcher myself." Dominic Hosler, University of Sheffield This bestselling book on the process of PhD research provides readers with engaging discussion and comprehensive guidance on aspects that other books don't usually mention. Covering all the key topics of the previous edition, including what a PhD is really about, how to do one well, how to decipher what your supervisor actually means by terms like 'good referencing' and 'clean research question', and how to design, report and defend your research,the authors continue to offer an accessible, down-to-earth, and insightful account of the whole PhD process. Their advice addresses how to avoid some of the pitfalls en route to a successful submission. Updated throughout, the new edition includes new material on: Critical thinking Research skills The route to research independence Different models of study The Unwritten Rules of PhD Research is essential reading for anyone considering a PhD or embarking on one. It will tell you the things many students wish someone had told them before they started.},
year = {2004},
doi = {10.1049/em:20040508},
isbn = {9780335237029},
volume = {14},
booktitle = {Engineering Management},
pmid = {1275585},
}

@article{Silvescu1999,
author = {Adrian Silvescu},
title = {Fourier neural networks},
url = {http://ieeexplore.ieee.org/document/831544/},
issn = {1098-7576},
doi = {10.1109/ijcnn.1999.831544},
volume = {1},
abstract = {A new kind of neuron model that has a Fourier-like IN/OUT function is introduced. The model is discussed in a general theoretical framework and some completeness theorems are presented. Current experimental results show that the new model outperforms by a large margin both in representational power and convergence speed the classical mathematical model of neuron based on weighted sum of inputs filtered by a nonlinear function. The new model is also appealing from a neurophysiological point of view because it produces a more realistic representation by considering the inputs as oscillations.},
year = {1999},
isbn = {0-7803-5529-6},
pages = {488--491},
journal = {Proceedings of the International Joint Conference on Neural Networks},
}

@article{Gully2017,
author = {Amelia J. Gully and Takenori Yoshimura and Damian T. Murphy and Kei Hashimoto and Yoshihiko Nankaku and Keiichi Tokuda},
abstract = {Following recent advances in direct modeling of the speech waveform using a deep neural network, we propose a novel method that directly estimates a physical model of the vocal tract from the speech waveform, rather than magnetic resonance imaging data. This provides a clear relationship between the model and the size and shape of the vocal tract, offering considerable flexibility in terms of speech characteristics such as age and gender. Initial tests indicate that despite a highly simplified physical model, intelligible synthesized speech is obtained. This illustrates the potential of the combined technique for the control of physical models in general, and hence the generation of more natural-sounding synthetic speech.},
doi = {10.21437/Interspeech.2017-900},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
pages = {234--238},
volume = {2017-August},
title = {Articulatory text-to-speech synthesis using the digital waveguide mesh driven by a deep neural network},
year = {2017},
issn = {19909772},
keywords = {deep neural network,digital waveguide mesh,speech synthesis},
mendeley-tags = {deep neural network,digital waveguide mesh,speech synthesis},
}

@article{Pang2017,
author = {Yanwei Pang and Manli Sun and Xiaoheng Jiang and Xuelong Li},
year = {2018},
title = {Convolution in convolution for network in network},
doi = {10.1109/TNNLS.2017.2676130},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
arxivid = {1603.06759},
abstract = {Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and $ 1\times 1 $ convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.},
archiveprefix = {arXiv},
eprint = {1603.06759},
number = {5},
pages = {1587--1597},
pmid = {28328517},
publisher = {IEEE},
volume = {29},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{stanley2002evolving,
author = {Kenneth O. Stanley and Risto Miikkulainen},
issn = {10636560},
abstract = {An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.},
publisher = {MIT Press},
doi = {10.1162/106365602320169811},
number = {2},
pmid = {12180173},
journal = {Evolutionary Computation},
year = {2002},
pages = {99--127},
volume = {10},
title = {Evolving neural networks through augmenting topologies},
keywords = {competing conventions,genetic algorithms,network topologies,neural networks,neuroevolution,speciation},
mendeley-tags = {competing conventions,genetic algorithms,network topologies,neural networks,neuroevolution,speciation},
}

@article{Johnston2017a,
author = {Nick Johnston and Damien Vincent and David Minnen and Michele Covell and Saurabh Singh and Troy Chinen and Sung Jin Hwang and Joel Shor and George Toderici},
url = {http://arxiv.org/abs/1703.10114},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
year = {2018},
archiveprefix = {arXiv},
pages = {4385--4393},
title = {Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks},
abstract = {We propose a method for lossy image compression based on recurrent, convolutional neural networks that outperforms BPG (4:2:0), WebP, JPEG2000, and JPEG as measured by MS-SSIM. We introduce three improvements over previous research that lead to this state-of-the-art result using a single model. First, we modify the recurrent architecture to improve spatial diffusion, which allows the network to more effectively capture and propagate image information through the network's hidden state. Second, in addition to lossless entropy coding, we use a spatially adaptive bit allocation algorithm to more efficiently use the limited number of bits to encode visually complex image regions. Finally, we show that training with a pixel-wise loss weighted by SSIM increases reconstruction quality according to multiple metrics. We evaluate our method on the Kodak and Tecnick image sets and compare against standard codecs as well as recently published methods based on deep neural networks.},
arxivid = {1703.10114},
doi = {10.1109/CVPR.2018.00461},
isbn = {9781538664209},
issn = {10636919},
eprint = {1703.10114},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{Lee2018,
author = {Chen Yu Lee and Patrick Gallagher and Zhuowen Tu},
number = {4},
issn = {01628828},
eprint = {1509.08985},
doi = {10.1109/TPAMI.2017.2703082},
pages = {863--875},
pmid = {28504932},
title = {Generalizing Pooling Functions in CNNs: Mixed, Gated, and Tree},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
abstract = {In this paper, we seek to improve deep neural networks by generalizing the pooling operations that play a central role in the current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in: (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets. These benefits come with only a light increase in computational overhead during training (ranging from additional 5 to 15 percent in time complexity) and a very modest increase in the number of model parameters (e.g., additional 1, 9, and 27 parameters for mixed, gated, and 2-level tree pooling operators, respectively). To gain more insights about our proposed pooling methods, we also visualize the learned pooling masks and the embeddings of the internal feature responses for different pooling operations. Our proposed pooling operations are easy to implement and can be applied within various deep neural network architectures.},
archiveprefix = {arXiv},
arxivid = {1509.08985},
volume = {40},
year = {2018},
url = {http://arxiv.org/abs/1509.08985},
keywords = {optimization},
mendeley-tags = {optimization},
}

@article{L.Elman1990,
author = {Jeffrey L. Elman},
journal = {Cognitive Science},
abstract = {[PDF]},
volume = {14},
isbn = {1551-6709},
title = {Finding Structure in Time},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed&cmd=Retrieve&dopt=AbstractPlus&list_uids=17969258453606390073related:OdlkvFuhX_kJ%5Cnpapers2://publication/uuid/3DEB06EE-B169-47A0-BD84-BFEE3386098E},
issn = {03640213},
doi = {10.1207/s15516709cog1402_1},
pages = {179--211},
publisher = {Wiley Online Library},
pmid = {19563812},
number = {2},
year = {1990},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Use1960,
author = {Operational Use},
title = {Unclassified Limitation Changes To : From :},
year = {1960},
journal = {Distribution},
number = {May},
}

@article{Arik2017,
author = {Sercan Arik and Mike Chrzanowski and Adam Coates and Gregory Diamos and Andrew Gibiansky and Yongguo Kang and Xian Li and John Miller and Andrew Ng and Jonathan Raiman and Shubho Sengupta and Mohammad Shoeybi},
title = {Deep voice: Real-time neural text-to-speech},
volume = {1},
year = {2017},
abstract = {We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-tophoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For the segmentation model, wc propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component, our system is simpler and more flexible than traditional text-tospeech systems, where each component requires laborious feature engineering and extensive domain expertise. Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.},
url = {http://arxiv.org/abs/1702.07825},
pages = {264--273},
arxivid = {1702.07825},
journal = {34th International Conference on Machine Learning, ICML 2017},
number = {Icml},
archiveprefix = {arXiv},
eprint = {1702.07825},
isbn = {9781510855144},
issn = {1938-7228},
}

@article{Bengio2007,
author = {Antonello Giovannetti and M. Pierdominici and F. Mazzetta and S. Salemi and M. Marziali and D. Kuonen and F. Iebba and E. A. Lusi and A. Cossarizza and F. Aiuti},
volume = {124},
doi = {10.1046/j.1365-2249.2001.01502.x},
year = {2001},
pmid = {11359439},
issn = {00099104},
journal = {Clinical and Experimental Immunology},
abstract = {The immunological correlates of highly active antiretroviral therapy (HAART)-induced suppression of human immunodeficiency virus type 1 (HIV-1) replication have been investigated. 20 HIV-1-infected patients with mean CD4+ T cell count of 298/$\mu$l, plasma viral load of 4.7 log10 copies/ml and naive for protease inhibitors (PI) were studied during 12 months of HAART. An increased number of both CD4+ and CD8+ naive T cells and a normalization of the frequency of CCR5- and CXCR4-expressing CD4+ T cells were readily observed after starting therapy. Single cell analysis of cytokine production after 12 months of HAART showed an increased number of interleukin (IL)-2-, but not IL-4- and (IFN)-$\gamma$-, producing T cells and a decreased percentage of CD8+ IFN-$\gamma$ + cells. A correlation between the frequency of IFN-$\gamma$-producing T cells and that of memory, CCR5+ and CD95+ T cells was demonstrated in both CD4+ and CD8+ subsets. The diversity of T cell receptor (TCR) variable beta (BV) chain repertoire significantly increased after 12 months of HAART within the CD4+ but not the CD8+ T cell subset. However, the level of perturbation of the third complementarity-determining region (CDR3), was not significantly modified by effective therapy. The number of anti-HIV Gag and Pol cytotoxic T lymphocytes precursors (CTLp) decreased during HAART and highly correlated with the CD8 IFN-$\gamma$ response. Ameliorated clinical conditions were observed in all patients in absence of any opportunistic infections during all the study period. These observations indicate that a better restoration of immunity may be obtained in patients starting HAART at less advanced stages of the disease.},
number = {1},
title = {T cell responses to highly active antiretroviral therapy defined by chemokine receptors expression, cytokine production, T cell receptor repertoire and anti-HIV T-lymphocyte activity},
isbn = {1002620262},
pages = {21--31},
keywords = {theory},
mendeley-tags = {theory},
}

@book{Zikmund2012,
author = {Holly Boulton and Natasha Constantinou and Alex Fowke and Clare Pearce and  Goodbr and Lynne },
volume = {58},
pages = {206--210},
number = {3},
issn = {00057967},
isbn = {9781444114638},
year = {2005},
abstract = {Every behaviour has a function. The consequence of a behaviour can increase, decease or leave unchanged the likelihood of the behaviour occurring. By changing the environment, you can alter the antecedent (the event, situation or trigger that leads to the occurrence of the behaviour) and consequence (the response to the behaviour), and therefore change the behaviour itself.},
title = {Behaviour modification},
doi = {10.4324/9780203018958-7},
pmid = {880153},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6071007},
booktitle = {Child and Adolescent Mental Health: Theory and Practice},
}

@article{Iizuka2016a,
author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
title = {Let there be color!: Joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification},
number = {4},
journal = {ACM Transactions on Graphics},
year = {2016},
abstract = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
doi = {10.1145/2897824.2925974},
issn = {15577368},
pages = {1--11},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925974},
isbn = {9781450342797},
volume = {35},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Khorrami2016c,
author = {Mathew Varidel and Michael Pracy and Scott Croom and Matt S. Owers and Elaine Sadler},
url = {http://arxiv.org/abs/1602.07377},
title = {Resolved gas kinematics in a sample of low-redshift high star-formation rate galaxies},
journal = {Publications of the Astronomical Society of Australia},
archiveprefix = {arXiv},
doi = {10.1017/pasa.2016.3},
pages = {1--5},
arxivid = {1602.07377},
volume = {33},
abstract = {We have used integral field spectroscopy of a sample of six nearby (z $\sim$ 0.01–0.04) high star-formation rate (SFR ∼ 10–40 M yr−1) galaxies to investigate the relationship between local velocity dispersion and star-formation rate on sub-galactic scales. The low-redshift mitigates, to some extent, the effect of beam smearing which artificially inflates the measured dispersion as it combines regions with different line-of-sight velocities into a single spatial pixel. We compare the parametric maps of the velocity dispersion with the H$\alpha$ flux (a proxy for local star-formation rate), and the velocity gradient (a proxy for the local effect of beam smearing). We find, even for these very nearby galaxies, the H$\alpha$ velocity dispersion correlates more strongly with velocity gradient than with H$\alpha$ flux—implying that beam smearing is still having a significant effect on the velocity dispersion measurements. We obtain a first-order non parametric correction for the unweighted and flux weighted mean velocity dispersion by fitting a 2D linear regression model to the spaxel-by-spaxel data where the velocity gradient and the H$\alpha$ flux are the independent variables and the velocity dispersion is the dependent variable; and then extrapolating to zero velocity gradient. The corrected velocity dispersions are a factor of $\sim$1.3–4.5 and $\sim$1.3–2.7 lower than the uncorrected flux-weighted and unweighted mean line-of-sight velocity dispersion values, respectively. These corrections are larger than has been previously cited using disc models of the velocity and velocity dispersion field to correct for beam smearing. The corrected flux-weighted velocity dispersion values are $\sigma$m ∼ 20–50 km s−1.},
eprint = {1602.07377},
year = {2016},
issn = {14486083},
keywords = {galaxies: ism,galaxies: kinematics and dynamics,galaxies: star formation,galaxies: starburst},
mendeley-tags = {galaxies: ism,galaxies: kinematics and dynamics,galaxies: star formation,galaxies: starburst},
}

@article{Graves2013,
author = {Alex Graves and Abdel Rahman Mohamed and Geoffrey Hinton},
pages = {6645--6649},
eprint = {1303.5778},
pmid = {27295638},
url = {http://arxiv.org/abs/1303.5778},
year = {2013},
issn = {15206149},
archiveprefix = {arXiv},
arxivid = {1303.5778},
number = {3},
abstract = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score. \textcopyright 2013 IEEE.},
doi = {10.1109/ICASSP.2013.6638947},
isbn = {9781479903566},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
title = {Speech recognition with deep recurrent neural networks},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
}

@article{sak2015fast,
author = {Haşim Sak and Andrew Senior and Kanishka Rao and Francoise Beaufays},
archiveprefix = {arXiv},
title = {Fast and accurate recurrent neural network acoustic models for speech recognition},
issn = {19909772},
pages = {1468--1472},
eprint = {1507.06947},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
arxivid = {1507.06947},
year = {2015},
volume = {2015-January},
abstract = {We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition. More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC). In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition. We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding. CD phone modeling leads to further improvements. We also present initial results for LSTM RNN models outputting words directly.},
keywords = {acoustic modeling,connectionist temporal classification,ctc,long short-term memory recurrent neural networks,lstm rnn,speech recognition},
mendeley-tags = {acoustic modeling,connectionist temporal classification,ctc,long short-term memory recurrent neural networks,lstm rnn,speech recognition},
}

@article{Esteva2017,
author = {Andre Esteva and Brett Kuprel and Roberto A. Novoa and Justin Ko and Susan M. Swetter and Helen M. Blau and Sebastian Thrun},
doi = {10.1038/nature21056},
pmid = {28117445},
isbn = {0028-0836},
issn = {14764687},
year = {2017},
url = {http://www.nature.com/doifinder/10.1038/nature21056},
volume = {542},
title = {Dermatologist-level classification of skin cancer with deep neural networks},
publisher = {Nature Publishing Group},
abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images - two orders of magnitude larger than previous datasets - consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
number = {7639},
journal = {Nature},
pages = {115--118},
keywords = {health,image classification,state of the art},
mendeley-tags = {health,image classification,state of the art},
}

@article{Kopparapu,
author = {Sunil Kopparapu and M Satish},
arxivid = {1406.3172},
year = {2014},
eprint = {1406.3172},
archiveprefix = {arXiv},
number = {2},
abstract = {In this paper we show that the knowledge of noise statistics contaminating a signal can be effectively used to choose an optimal Gaussian filter to eliminate noise. Very specifically, we show that the additive white Gaussian noise (AWGN) contaminating a signal can be filtered best by using a Gaussian filter of specific characteristics. The design of the Gaussian filter bears relationship with the noise statistics and also some basic information about the signal. We first derive a relationship between the properties of the Gaussian filter, noise statistics and the signal and later show through experiments that this relationship can be used effectively to identify the optimal Gaussian filter that can effectively filter noise.},
url = {http://arxiv.org/abs/1406.3172},
pages = {1--7},
title = {Optimal Gaussian Filter for Effective Noise Filtering},
}

@article{Hopfield1982a,
author = {J. J. Hopfield},
doi = {10.1073/pnas.79.8.2554},
archiveprefix = {arXiv},
number = {8},
pages = {2554--2558},
title = {Neural networks and physical systems with emergent collective computational abilities.},
year = {1982},
isbn = {0027-8424},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
volume = {79},
eprint = {arXiv:1411.3159v1},
issn = {00278424},
arxivid = {arXiv:1411.3159v1},
abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
pmid = {6953413},
}

@article{Balle2016c,
author = {Alphonce G. Kyessi},
isbn = {0197-3975},
archiveprefix = {arXiv},
number = {1},
pmid = {16508805},
abstract = {Diminishing state resources coupled with inadequate urban management capacity and insufficiency of conventional approaches have rendered it impossible to provide basic infrastructure in urban areas in developing countries such as in the city of Dar es Salaam. In that situation fringe neighbourhoods are mostly hit. However, a notable phenomenon has emerged in informal and formal settlements where the communities, through self-help and local governance in their own neighbourhood associations, have organised to fill the gaps in infrastructure services left by the centralised institutions. Among other things, community groups mobilise and organise fund-raising, mutual self-help and external technical assistance to provide water supply and sanitation, roads and drainage channels within the immediate area. This seems to be a trend in infrastructure improvement in poor neighbourhoods including fringe settlements. Actors observed to be participating in the process of providing the basic services and facilities in some of the fringe settlements include Dar es Salaam City Council (DCC), the civil societies including political party organisations and private individuals as well as youth and women groups, and the donor community. This paper discusses the potentials and constraints existing in the provision of basic infrastructure to fringe settlements taking water management as an example. Potable water was chosen to explain the case because these settlements are not connected to the Dar es Salaam Water and Sanitation Authority (DAWASA-a centralised institution) water supply system and are remotely located. The purpose is to inform policy makers, researchers and practitioners including water providers and managers and water users on potentials and constraints existing in the provision and management of water supply in remote poor communities. Potable water as an essential need plays a major role in health development and if water is not easily accessible much time is wasted to search for it. One of the questions to be answered is how the residents, most of them being poor, are coping up with the deficiency of water supply in their fringe areas. \textcopyright 2003 Elsevier Ltd. All rights reserved.},
issn = {01973975},
url = {http://arxiv.org/abs/1611.01704},
doi = {10.1016/S0197-3975(03)00059-6},
eprint = {1611.01704},
pages = {1--25},
title = {Community-based urban water management in fringe neighbourhoods: The case of Dar es Salaam, Tanzania},
arxivid = {1611.01704},
volume = {29},
year = {2005},
journal = {Habitat International},
keywords = {neighbourhood associations,self-help,tanzania,water supply},
mendeley-tags = {neighbourhood associations,self-help,tanzania,water supply},
}

@article{Bonada2016,
author = {Jordi Bonada and Mart\'i Umbert and Merlijn Blaauw},
year = {2016},
volume = {08-12-September-2016},
title = {Expressive singing synthesis based on unit selection for the singing synthesis challenge 2016},
issn = {19909772},
doi = {10.21437/Interspeech.2016-872},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
abstract = {Sample and statistically based singing synthesizers typically require a large amount of data for automatically generating expressive synthetic performances. In this paper we present a singing synthesizer that using two rather small databases is able to generate expressive synthesis from an input consisting of notes and lyrics. The system is based on unit selection and uses the Wide-Band Harmonic Sinusoidal Model for transforming samples. The first database focuses on expression and consists of less than 2 minutes of free expressive singing using solely vowels. The second one is the timbre database which for the English case consists of roughly 35 minutes of monotonic singing of a set of sentences, one syllable per beat. The synthesis is divided in two steps. First, an expressive vowel singing performance of the target song is generated using the expression database. Next, this performance is used as input control of the synthesis using the timbre database and the target lyrics. A selection of synthetic performances have been submitted to the Interspeech Singing Synthesis Challenge 2016, in which they are compared to other competing systems.},
pages = {1230--1234},
keywords = {expression control,singing voice synthesis,unitselection},
mendeley-tags = {expression control,singing voice synthesis,unitselection},
}

@article{cortes2016adanet,
author = {Corinna Cortes and Xavier Gonzalvo and Vitaly Kuznetsov and Mehryar Mohri and Scott Yang},
isbn = {9781510855144},
archiveprefix = {arXiv},
pages = {1452--1466},
abstract = {We present new algorithms for adaptively learning artificial neural networks. Our algorithms (AdaNet) adaptively learn both the structure of the network and its weights. They are based on a solid theoretical analysis, including data-dependent generalization guarantees that we prove and discuss in detail. We report the results of large-scale experiments with one of our algorithms on several binary classification tasks extracted from the CIFAR-10 dataset and on the Criteo dataset. The results demonstrate that our algorithm can automatically learn network structures with very competitive performance accuracies when compared with those achieved by neural networks found by standard approaches.},
title = {AdaNet: Adaptive structural learning of artificial neural networks},
journal = {34th International Conference on Machine Learning, ICML 2017},
year = {2017},
arxivid = {1607.01097},
volume = {2},
eprint = {1607.01097},
}

@article{Yosinski2014,
author = {Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
eprint = {1411.1792},
archiveprefix = {arXiv},
title = {How transferable are features in deep neural networks?},
volume = {4},
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Trans-ferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
pages = {3320--3328},
url = {http://arxiv.org/abs/1411.1792},
arxivid = {1411.1792},
year = {2014},
issn = {10495258},
number = {January},
journal = {Advances in Neural Information Processing Systems},
keywords = {theory},
mendeley-tags = {theory},
}

@inproceedings{gatys2016image,
author = {Leon A. Gatys and Alex Ecker and er S. and Matthias Bethge},
isbn = {9781467388504},
abstract = {Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous wellknown artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation.},
pages = {2414--2423},
title = {Image Style Transfer Using Convolutional Neural Networks},
issn = {10636919},
doi = {10.1109/CVPR.2016.265},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
year = {2016},
volume = {2016-December},
}

@article{Omar2017a,
author = {Petter Gottschalk},
year = {2010},
number = {4},
issn = {17587239},
abstract = {Purpose – The purpose of this paper is to present a systematic approach to classify financial crime into main categories as well as sub categories. Design/methodology/approach – Based on a literature review, the main four categories were labeled corruption, fraud, theft, and manipulation, respectively. Findings – There is a massive variety of crime types and crime names in the literature that can successfully be allocated to main categories of financial crime. Research limitations/implications – The paper is based on exploratory research to stimulate future research in refining and improving the categories suggested here. Practical implications – The great variety of criminal activities is classified in this paper so that practitioners can organize their thinking around crime themes rather than crime examples when mapping crime. Social implications The public and society at large will be able to understand the confusing variety of financial crime in terms of main categories. Originality/value – There has been some confusion among both researchers and practitioners when communicating about examples of financial crime. The organizing framework in this paper will help allocate crime examples to main categories of financial crime. \textcopyright 2010, Emerald Group Publishing Limited},
isbn = {1359079051062},
journal = {Journal of Financial Crime},
pages = {441--458},
title = {Categories of financial crime},
url = {http://dx.doi.org/10.1108/eb025814%5Cnhttp://},
volume = {17},
doi = {10.1108/13590791011082797},
keywords = {classification,corruption,fraud,theft},
mendeley-tags = {classification,corruption,fraud,theft},
}

@article{Graves2013b,
author = {Yelong Shen and Xiaodong He and Jianfeng Gao and Li Deng and Gr\'egoire Mesnil},
eprint = {1308.0850},
year = {2014},
doi = {10.1145/2661829.2661935},
issn = {18792782},
abstract = {In this paper, we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document, we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next, the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally, a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models.},
archiveprefix = {arXiv},
isbn = {9781450325981},
pages = {101--110},
arxivid = {1308.0850},
journal = {CIKM 2014 - Proceedings of the 2014 ACM International Conference on Information and Knowledge Management},
pmid = {23459267},
title = {A latent semantic model with convolutional-pooling structure for information retrieval},
url = {http://arxiv.org/abs/1308.0850},
keywords = {convolutional neural network,semantic representation,web search},
mendeley-tags = {convolutional neural network,semantic representation,web search},
}

@article{Deng2016,
author = {Shuiguang Deng and Longtao Huang and Gu Xu and  ong and Xindong Wu and Zhaohui Wu},
issn = {21622388},
doi = {10.1109/TNNLS.2016.2514368},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
abstract = {With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user's trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users' interests and their trusted friends' interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.},
pages = {1164--1177},
volume = {28},
title = {On Deep Learning for Trust-Aware Recommendations in Social Networks},
isbn = {2162-2388 (Electronic)\r2162-237X (Linking)},
number = {5},
pmid = {26915135},
year = {2017},
keywords = {social recommendations},
mendeley-tags = {social recommendations},
}

@article{Fritzke1994,
author = {Bernd Fritzke},
year = {1994},
volume = {7},
issn = {08936080},
title = {Growing cell structures-A self-organizing network for unsupervised and supervised learning},
url = {http://linkinghub.elsevier.com/retrieve/pii/0893608094900914},
publisher = {Elsevier},
isbn = {0893-6080},
doi = {10.1016/0893-6080(94)90091-4},
abstract = {We present a new self-organizing neural network model that has two variants. The first variant performs unsupervised learning and can be used for data visualization, clustering, and vector quantization. The main advantage over existing approaches (e.g., the Kohonen feature map) is the ability of the model to automatically find a suitable network structure and size. This is achieved through a controlled growth process that also includes occasional removal of units. The second variant of the model is a supervised learning method that results from the combination of the above-mentioned self-organizing network with the radial basis function (RBF) approach. In this model it is possible-in contrast to earlier approaches-to perform the positioning of the RBF units and the supervised training of the weights in parallel. Therefore, the current classification error can be used to determine where to insert new RBF units. This leads to small networks that generalize very well. Results on the two-spirals benchmark and a vowel classification problem are presented that are better than any results previously published. \textcopyright 1994.},
number = {9},
pages = {1441--1460},
journal = {Neural Networks},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
}

@misc{Alves1922,
author = {Alda Judith ALVES},
volume = {0},
issn = {1980-5314},
year = {1992},
number = {81},
abstract = {The article analyzes the role of literature review in research works and points out the main inadequacies observed in graduates' dissertacions and theses regardind this aspect. The first section emphasizes the importance of a critical analysis of the state of the art in researchers' field of interest, so that a subject may be turned into a research problem. The second deals with the theoretical framework and discusses the dificulties of theory construction in the field od education. Finally, by using the caricature as a mean of stressing some features, the last section presents the most frequent mistakes observed in literature reviews.},
pages = {53--60},
title = {A "revisao da bibliografia" em teses e dissertacoes: meus tipos inesqueciveis},
booktitle = {Cadernos de Pesquisa},
keywords = {academic dissertation,education,higher,methodology,research},
mendeley-tags = {academic dissertation,education,higher,methodology,research},
}

@inproceedings{mollahosseini2016going,
author = {Ali Mollahosseini and David Chan and Mohammad H. Mahoor},
pages = {1--10},
title = {Going deeper in facial expression recognition using deep neural networks},
archiveprefix = {arXiv},
abstract = {Automated Facial Expression Recognition (FER) has remained a challenging and interesting problem in computer vision. Despite efforts made in developing various methods for FER, existing approaches lack generalizability when applied to unseen images or those that are captured in wild setting (i.e. the results are not significant). Most of the existing approaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where the classifier's hyper-parameters are tuned to give best recognition accuracies across a single database, or a small collection of similar databases. This paper proposes a deep neural network architecture to address the FER problem across multiple well-known standard face datasets. Specifically, our network consists of two convolutional layers each followed by max pooling and then four Inception layers. The network is a single component architecture that takes registered facial images as the input and classifies them into either of the six basic or the neutral expressions. We conducted comprehensive experiments on seven publicly available facial expression databases, viz. MultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of our proposed architecture are comparable to or better than the state-of-the-art methods and better than traditional convolutional neural networks in both accuracy and training time.},
organization = {IEEE},
year = {2016},
eprint = {1511.04110},
booktitle = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
doi = {10.1109/WACV.2016.7477450},
arxivid = {1511.04110},
isbn = {9781509006410},
}

@article{Song2016,
author = {Qing Song and Xu Zhao and Haijin Fan and Danwei Wang},
abstract = {We propose a robust recurrent kernel online learning (RRKOL) algorithm based on the celebrated real-time recurrent learning approach that exploits the kernel trick in a recurrent online training manner. The novel RRKOL algorithm guarantees weight convergence with regularized risk management through the use of adaptive recurrent hyperparameters for superior generalization performance. Based on a new concept of the structure update error with a variable parameter length, we are the first one to propose the detailed structure update error, such that the weight convergence and robust stability proof can be integrated with a kernel sparsification scheme based on a solid theoretical ground. The RRKOL algorithm automatically weighs the regularized term in the recurrent loss function, such that we not only minimize the estimation error but also improve the generalization performance through sparsification with simulation support.},
doi = {10.1109/TNNLS.2016.2518223},
pmid = {26890925},
publisher = {IEEE},
volume = {28},
issn = {21622388},
number = {5},
pages = {1068--1081},
title = {Robust Recurrent Kernel Online Learning},
year = {2017},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {forecasting},
mendeley-tags = {forecasting},
}

@article{Toderici2015a,
author = {George Toderici and Sean M. O'Malley and Sung Jin Hwang and Damien Vincent and David Minnen and Shumeet Baluja and Michele Covell and Rahul Sukthankar},
arxivid = {1511.06085},
archiveprefix = {arXiv},
eprint = {1511.06085},
url = {http://arxiv.org/abs/1511.06085},
title = {Variable rate image compression with recurrent neural networks},
year = {2016},
pages = {1--12},
abstract = {A large fraction of Internet traffic is now driven by requests from mobile devices with relatively small screens and often stringent bandwidth requirements. Due to these factors, it has become the norm for modern graphics-heavy websites to transmit low-resolution, low-bytecount image previews (thumbnails) as part of the initial page load process to improve apparent page responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore a current research focus, as any byte savings will significantly enhance the experience of mobile device users. Toward this end, we propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional LSTM recurrent networks. Our models address the main issues that have prevented autoencoder neural networks from competing with existing image compression algorithms: (1) our networks only need to be trained once (not per-image), regardless of input image dimensions and the desired compression rate; (2) our networks are progressive, meaning that the more bits are sent, the more accurate the image reconstruction; and (3) the proposed architecture is at least as efficient as a standard purpose-trained autoencoder for a given number of bits. On a large-scale benchmark of 32×32 thumbnails, our LSTM-based approaches provide better visual quality than (headerless) JPEG, JPEG2000 and WebP, with a storage size that is reduced by 10% or more.},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
keywords = {image compression- lossy},
mendeley-tags = {image compression- lossy},
}

@article{hornik89,
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators. \textcopyright 1989.},
title = {Multilayer feedforward networks are universal approximators},
publisher = {Elsevier},
volume = {2},
pages = {359--366},
doi = {10.1016/0893-6080(89)90020-8},
issn = {08936080},
journal = {Neural Networks},
number = {5},
year = {1989},
keywords = {back-propagation networks,feedforward networks,mapping networks,network representation capability,sigma-pi networks,squashing functions,stone-weierstrass theorem,universal approximation},
mendeley-tags = {back-propagation networks,feedforward networks,mapping networks,network representation capability,sigma-pi networks,squashing functions,stone-weierstrass theorem,universal approximation},
}

@article{Tang2015,
author = {Jiexiong Tang and Chenwei Deng and Guang Bin Huang},
title = {Extreme Learning Machine for Multilayer Perceptron},
number = {4},
doi = {10.1109/TNNLS.2015.2424995},
isbn = {2162-2388 (Electronic) 2162-237X (Linking)},
pmid = {25966483},
volume = {27},
pages = {809--821},
year = {2016},
abstract = {Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via ℓ1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {elm},
mendeley-tags = {elm},
}

@article{Collobert2004,
author = {Ronan Collobert and Samy Bengio},
institution = {ACM},
abstract = {We propose to study links between three important classification algorithms: Perceptrons, Multi-Layer Perceptrons (MLPs) and Support Vector Machines (SVMs). We first study ways to control the capacity of Perceptrons (mainly regularization parameters and early stopping), using the margin idea introduced with SVMs. After showing that under simple conditions a Perceptron is equivalent to an SVM, we show it can be computationally expensive in time to train an SVM (and thus a Perceptron) with stochastic gradient descent, mainly because of the margin maximization term in the cost function. We then show that if we remove this margin maximization term, the learning rate or the use of early stopping can still control the margin. These ideas are extended afterward to the case of MLPs. Moreover, under some assumptions it also appears that MLPs are a kind of mixture of SVMs, maximizing the margin in the hidden layer space. Finally, we present a very simple MLP based on the previous findings, which yields better performances in generalization and speed than the other models.},
doi = {10.1145/1015330.1015415},
journal = {Proceedings, Twenty-First International Conference on Machine Learning, ICML 2004},
title = {Links between Perceptrons, MLPs and SVMs},
isbn = {1581138385},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015415},
year = {2004},
pages = {177--184},
issn = {1581138385},
keywords = {theory},
mendeley-tags = {theory},
}

@article{Sarroff,
author = {Andy M. Sarroff and Michael Casey},
year = {2014},
number = {1},
isbn = {9789604661374},
journal = {Proceedings - 40th International Computer Music Conference, ICMC 2014 and 11th Sound and Music Computing Conference, SMC 2014 - Music Technology Meets Philosophy: From Digital Echos to Virtual Ethos},
abstract = {With an optimal network topology and tuning of hyperpa-rameters, artificial neural networks (ANNs) may be trained to learn a mapping from low level audio features to one or more higher-level representations. Such artificial neural networks are commonly used in classification and regression settings to perform arbitrary tasks. In this work we suggest repurposing autoencoding neural networks as musical audio synthesizers. We offer an interactive musical audio synthesis system that uses feedforward artificial neural networks for musical audio synthesis, rather than discriminative or regression tasks. In our system an ANN is trained on frames of low-level features. A high level representation of the musical audio is learned though an autoencoding neural net. Our real-time synthesis system allows one to interact directly with the parameters of the model and generate musical audio in real time. This work therefore proposes the exploitation of neural networks for creative musical applications. Copyright:},
volume = {1},
title = {Musical audio synthesis using autoencoding neural nets},
pages = {1411--1417},
}

@article{Huang2015,
author = {Guang Bin Huang},
abstract = {The emergent machine learning technique—extreme learning machines (ELMs)—has become a hot area of research over the past years, which is attributed to the growing research activities and significant contributions made by numerous researchers around the world. Recently, it has come to our attention that a number of misplaced notions and misunderstandings are being dissipated on the relationships between ELM and some earlier works. This paper wishes to clarify that (1) ELM theories manage to address the open problem which has puzzled the neural networks, machine learning and neuroscience communities for 60 years: whether hidden nodes/neurons need to be tuned in learning, and proved that in contrast to the common knowledge and conventional neural network learning tenets, hidden nodes/neurons do not need to be iteratively tuned in wide types of neural networks and learning models (Fourier series, biological learning, etc.). Unlike ELM theories, none of those earlier works provides theoretical foundations on feedforward neural networks with random hidden nodes; (2) ELM is proposed for both generalized single-hidden-layer feedforward network and multi-hidden-layer feedforward networks (including biological neural networks); (3) homogeneous architecture-based ELM is proposed for feature learning, clustering, regression and (binary/multi-class) classification. (4) Compared to ELM, SVM and LS-SVM tend to provide suboptimal solutions, and SVM and LS-SVM do not consider feature representations in hidden layers of multi-hidden-layer feedforward networks either.},
doi = {10.1007/s12559-015-9333-0},
journal = {Cognitive Computation},
number = {3},
isbn = {1866-9956},
issn = {18669964},
title = {What are Extreme Learning Machines? Filling the Gap Between Frank Rosenblatt's Dream and John von Neumann's Puzzle},
publisher = {Springer US},
year = {2015},
pages = {263--278},
volume = {7},
keywords = {elm},
mendeley-tags = {elm},
}

@article{Hoover2012,
author = {Amy K. Hoover and Paul A. Szerlip and Marie E. Norton and Trevor A. Brindle and Zachary Merritt and Kenneth O. Stanley},
isbn = {9781905254668},
journal = {Proceedings of the 3rd International Conference on Computational Creativity, ICCC 2012},
pages = {111--118},
title = {Generating a complete multipart musical composition from a single monophonic melody with functional scaffolding},
abstract = {This paper advances the state of the art for a computer-assisted approach to music generation called functional scaffolding for musical composition (FSMC), whose representation facilitates creative combination, exploration, and transformation of musical concepts. Music in FSMC is represented as a functional relationship between an existing human composition, or scaffold, and a generated accompaniment. This relationship is encoded by a type of artificial neural network called a compositional pattern producing network (CPPN). A human user without any musical expertise can then explore how accompaniment should relate to the scaffold through an interactive evolutionary process akin to animal breeding. While the power of such a functional representation has previously been shown to constrain the search to plausible accompaniments, this study goes further by showing that the user can tailor complete multipart arrangements from only a single original monophonic track provided by the user, thus enabling creativity without the need for musical expertise.},
year = {2012},
keywords = {music generation},
mendeley-tags = {music generation},
}

@article{Deng2015,
author = {Chen Wei Deng and Guang Bin Huang and Jia Xu and Jie Xiong Tang},
journal = {Science China Information Sciences},
year = {2015},
url = {http://link.springer.com/10.1007/s11432-014-5269-3},
doi = {10.1007/s11432-014-5269-3},
abstract = {Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that "random hidden neurons" capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.},
volume = {58},
title = {Extreme learning machines: new trends and applications},
issn = {1674733X},
pages = {1--16},
number = {2},
keywords = {elm,review},
mendeley-tags = {elm,review},
}

@article{k,
author = {Tejas D. Kulkarni and William F. Whitney and Pushmeet Kohli and Joshua B. Tenenbaum},
archiveprefix = {arXiv},
title = {Deep convolutional inverse graphics network},
eprint = {1503.03167},
abstract = {This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a model that aims to learn an interpretable representation of images, disentangled with respect to three-dimensional scene structure and viewing transformations such as depth rotations and lighting variations. The DC-IGN model is composed of multiple layers of convolution and de-convolution operators and is trained using the Stochastic Gradient Variational Bayes (SGVB) algorithm [10]. We propose a training procedure to encourage neurons in the graphics code layer to represent a specific transformation (e.g. pose or light). Given a single input image, our model can generate new images of the same object with variations in pose and lighting. We present qualitative and quantitative tests of the model's efficacy at learning a 3D rendering engine for varied object classes including faces and chairs.},
journal = {Advances in Neural Information Processing Systems},
issn = {10495258},
arxivid = {1503.03167},
pages = {2539--2547},
volume = {2015-January},
year = {2015},
}

@article{leung2003tuning,
author = {Li Sun Shu and Shinn Ying Ho and Shinn Jang Ho},
pages = {789--792},
title = {Tuning the structure and parameters of a neural network using an orthogonal simulated annealing algorithm},
volume = {14},
isbn = {9781424452279},
number = {1},
year = {2009},
abstract = {In this paper, an orthogonal simulated annealing algorithm (OSA) is applied to get an optimal network structure and parameters of a feedforward neural network at the same time. An orthogonal experimental design which based on OSA could efficiently generate large good candidate solutions by using a few computing cost. High performance of OSA-based method can be shown to efficiently obtain more accurate solution in prediction of the sunspot numbers problem, compare with other exited methods. \textcopyright2009 IEEE.},
doi = {10.1109/JCPC.2009.5420077},
publisher = {IEEE},
journal = {2009 Joint Conferences on Pervasive Computing, JCPC 2009},
}

@inproceedings{he2016deep,
author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
issn = {10636919},
arxivid = {1512.03385},
isbn = {9781467388504},
volume = {2016-December},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
pages = {770--778},
title = {Deep residual learning for image recognition},
archiveprefix = {arXiv},
year = {2016},
}

@article{Ephrat2017,
author = {Ariel Ephrat and Inbar Mosseri and Oran Lang and Tali Dekel and Kevin Wilson and Avinatan Hassidim and William T. Freeman and Michael Rubinstein},
archiveprefix = {arXiv},
eprint = {1804.03619},
arxivid = {1804.03619},
doi = {10.1145/3197517.3201357},
title = {Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
year = {2018},
volume = {37},
journal = {ACM Transactions on Graphics},
issn = {15577368},
abstract = {We present a joint audio-visual model for isolating a single speech signal from a mixture of sounds such as other speakers and background noise. Solving this task using only audio as input is extremely challenging and does not provide an association of the separated speech signals with speakers in the video. In this paper, we present a deep network-based model that incorporates both visual and auditory signals to solve this task. The visual features are used to "focus" the audio on desired speakers in a scene and to improve the speech separation quality. To train our joint audio-visual model, we introduce AVSpeech, a new dataset comprised of thousands of hours of video segments from the Web. We demonstrate the applicability of our method to classic speech separation tasks, as well as real-world scenarios involving heated interviews, noisy bars, and screaming children, only requiring the user to specify the face of the person in the video whose speech they want to isolate. Our method shows clear advantage over stateof- the-art audio-only speech separation in cases of mixed speech. In addition, our model, which is speaker-independent (trained once, applicable to any speaker), produces better results than recent audio-visual speech separation methods that are speaker-dependent (require training a separate model for each speaker of interest).},
number = {4},
keywords = {audio-visual,blstm,cnn,deep learning,source separation,speech enhancement},
mendeley-tags = {audio-visual,blstm,cnn,deep learning,source separation,speech enhancement},
}

@article{Vincent,
author = {Pascal Vincent and Alex De Br\'ebisson and  re and Xavier Bouthillier},
journal = {Advances in Neural Information Processing Systems},
pages = {1108--1116},
abstract = {An important class of problems involves training deep neural networks with sparse prediction targets of very high dimension D. These occur naturally in e.g. neural language models or the learning of word-embeddings, often posed as predicting the probability of next words among a vocabulary of size D (e.g. 200 000). Computing the equally large, but typically non-sparse D-dimensional output vector from a last hidden layer of reasonable dimension d (e.g. 500) incurs a prohibitive O(Dd) computational cost for each example, as does updating the D × d output weight matrix and computing the gradient needed for backpropagation to previous layers. While efficient handling of large sparse network inputs is trivial, the case of large sparse targets is not, and has thus so far been sidestepped with approximate alternatives such as hierarchical softmax or sampling-based approximations during training. In this work we develop an original algorithmic approach which, for a family of loss functions that includes squared error and spherical softmax, can compute the exact loss, gradient update for the output weights, and gradient for backpropagation, all in O(d2) per example instead of O(Dd), remarkably without ever computing the D-dimensional output. The proposed algorithm yields a speedup of D/4d, i.e. two orders of magnitude for typical sizes, for that critical part of the computations that often dominates the training time in this kind of network architecture.},
arxivid = {1412.7091},
issn = {10495258},
volume = {2015-January},
year = {2015},
eprint = {1412.7091},
title = {Efficient exact gradient update for training deep networks with very large sparse targets},
archiveprefix = {arXiv},
}

@misc{Martucci1994,
author = {Stephen A. Martucci},
issn = {19410476},
pages = {1038--1051},
title = {Symmetric Convolution and the Discrete Sine and Cosine Transforms},
abstract = {This paper discusses the use of symmetric convolution and the discrete sine and cosine transforms (DST's & DCT's) for general digital signal processing. The operation of symmetric convolution is a formalized approach to convolving symmetrically extended sequences. The result is the same as that obtained by taking an inverse discrete trigonometric transform (DTT) of the product of the forward DTT's of those two sequences. There are 16 members in the family of DTT's. Each provides a representation for a corresponding distinct type of symmetric-periodic sequence. In this paper, we define symmetric convolution, relate the DST's and DCT's to symmetric-periodic sequences, and then use these principles to develop simple but powerful convolution-multiplication properties for the entire family of DST's and DCT's. Symmetric convolution can be used for discrete linear filtering when the filter is symmetric or antisymmetric. The filtering will be efficient because fast algorithms exist for all versions of the DTT's. Conventional linear convolution is possible if we first zero-pad the input data. Symmetric convolution and its fast implementation using DTT's are now an alternative to circular convolution and the DFT. \textcopyright 1994 IEEE},
booktitle = {IEEE Transactions on Signal Processing},
number = {5},
doi = {10.1109/78.295213},
volume = {42},
year = {1994},
}

@article{Rosenblatt1958,
author = {F. Rosenblatt},
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2006 APA, all rights reserved). \textcopyright 1958 American Psychological Association.},
volume = {65},
isbn = {0033-295X},
doi = {10.1037/h0042519},
journal = {Psychological Review},
year = {1958},
title = {The perceptron: A probabilistic model for information storage and organization in the brain},
number = {6},
issn = {0033295X},
pages = {386--408},
pmid = {13602029},
url = {http://content.apa.org/journals/rev/65/6/386},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Salama2015,
author = {Khalid M. Salama and Ashraf M. Abdelbar},
number = {4},
volume = {9},
journal = {Swarm Intelligence},
pages = {229--265},
year = {2015},
abstract = {Ant colony optimization (ACO) has been successfully applied to classification, where the aim is to build a model that captures the relationships between the input attributes and the target class in a given domain's dataset. The constructed classification model can then be used to predict the unknown class of a new pattern. While artificial neural networks are one of the most widely used models for pattern classification, their application is commonly restricted to fully connected three-layer topologies. In this paper, we present a new algorithm, ANN-Miner, which uses ACO to learn the structure of feed-forward neural networks. We report computational results on 40 benchmark datasets for several variations of the algorithm. Performance is compared to the standard three-layer structure trained with two different weight-learning algorithms (back propagation, and the ACOR algorithm), and also to a greedy algorithm for learning NN structures. A nonparametric Friedman test is used to determine statistical significance. In addition, we compare our proposed algorithm with NEAT, a prominent evolutionary algorithm for evolving neural networks, as well as three different well-known state-of-the-art classifiers, namely the C4.5 decision tree induction algorithm, the Ripper classification rule induction algorithm, and support vector machines.},
doi = {10.1007/s11721-015-0112-z},
issn = {19353820},
publisher = {Springer US},
title = {Learning neural network structures with ant colony algorithms},
keywords = {evolutive},
mendeley-tags = {evolutive},
}

@inproceedings{kasabov2012neucube,
author = {Nikola Kasabov},
isbn = {9783642332111},
organization = {Springer},
issn = {03029743},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {225--243},
title = {NeuCube EvoSpike architecture for spatio-temporal modelling and pattern recognition of brain signals},
abstract = {The brain functions as a spatio-temporal information processing machine and deals extremely well with spatio-temporal data. Spatio- and spectro-temporal data (SSTD) are the most common data collected to measure brain signals and brain activities, along with the recently obtained gene and protein data. Yet, there are no computational models to integrate all these different types of data into a single model to help understand brain processes and for a better brain signal pattern recognition. The EU FP7 Marie Curie IIF EvoSpike project develops methods and tools for spatio and spectro temporal pattern recognition. This paper proposes a new evolving spiking model called NeuCube as part of the EvoSpike project, especially for modeling brain data. The NeuCube is 3D evolving Neurogenetic Brain Cube of spiking neurons that is an approximate map of structural and functional areas of interest of an animal or human brain. Optionally, gene information is included in the NeuCube in the form of gene regulatory networks that relate to spiking neuronal parameters of interest. Different types of brain SSTD can be used to train a NeuCube, including: EEG, fMRI, video-, image- and sound data, complex multimodal data. Potential applications are: EEG -, fMRI-, and multimodal brain data modeling and pattern recognition; Brain-Computer Interfaces; cognitive and emotional robots; neuro-prosthetics and neuro-rehabilitation; modeling brain diseases. Analysis of the internal structure of the model can trigger new hypotheses about spatio-temporal pathways in the brain. \textcopyright 2012 Springer-Verlag.},
doi = {10.1007/978-3-642-33212-8_21},
volume = {7477 LNAI},
year = {2012},
keywords = {computational neuro-genetic modelling,eeg,evolving neurogenetic brain cube,fmri,gene regulatory networks,pattern recognition,personalized modeling,probabilistic modeling,spatio/spectro-temporal brain data,spiking neural networks},
mendeley-tags = {computational neuro-genetic modelling,eeg,evolving neurogenetic brain cube,fmri,gene regulatory networks,pattern recognition,personalized modeling,probabilistic modeling,spatio/spectro-temporal brain data,spiking neural networks},
}

@inproceedings{nyc15,
author = {Anh Nguyen and Jason Yosinski and Jeff Clune},
eprint = {1412.1897},
arxivid = {1412.1897},
title = {Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
archiveprefix = {arXiv},
abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call 'fooling images' (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
isbn = {9781467369640},
issn = {10636919},
pages = {427--436},
volume = {07-12-June-2015},
doi = {10.1109/CVPR.2015.7298640},
year = {2015},
}

@article{Karpathy2014,
author = {Andrej Karpathy and George Toderici and Sanketh Shetty and Thomas Leung and Rahul Sukthankar and Fei Fei Li},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909619%0Apapers3://publication/doi/10.1109/CVPR.2014.223},
year = {2014},
arxivid = {1412.0767},
title = {Large-scale video classification with convolutional neural networks},
abstract = {Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a new dataset of 1 million YouTube videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggest a multiresolution, foveated architecture as a promising way of speeding up the training. Our best spatio-temporal networks display significant performance improvements compared to strong feature-based baselines (55.3% to 63.9%), but only a surprisingly modest improvement compared to single-frame models (59.3% to 60.9%). We further study the generalization performance of our best model by retraining the top layers on the UCF-101 Action Recognition dataset and observe significant performance improvements compared to the UCF-101 baseline model (63.3% up from 43.9%).},
issn = {10636919},
isbn = {9781479951178},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
eprint = {1412.0767},
archiveprefix = {arXiv},
doi = {10.1109/CVPR.2014.223},
pages = {1725--1732},
keywords = {video classification},
mendeley-tags = {video classification},
}

@article{s07,
author = {Kenneth O. Stanley},
issn = {13892576},
journal = {Genetic Programming and Evolvable Machines},
doi = {10.1007/s10710-007-9028-8},
pages = {131--162},
volume = {8},
year = {2007},
title = {Compositional pattern producing networks: A novel abstraction of development},
abstract = {Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two-dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed. \textcopyright Springer Science+Business Media, LLC 2007.},
number = {2},
keywords = {artificial embryogeny,complexity,developmental encoding,evolutionary computation,generative systems,indirect encoding,representation},
mendeley-tags = {artificial embryogeny,complexity,developmental encoding,evolutionary computation,generative systems,indirect encoding,representation},
}

@article{sangkloy2016scribbler,
author = {Patsorn Sangkloy and Jingwan Lu and Chen Fang and Fisher Yu and James Hays},
title = {Scribbler: Controlling deep image synthesis with sketch and color},
abstract = {Several recent works have used deep convolutional networks to generate realistic imagery. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach generates more realistic, diverse, and controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.},
doi = {10.1109/CVPR.2017.723},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
archiveprefix = {arXiv},
arxivid = {1612.00835},
pages = {6836--6845},
eprint = {1612.00835},
volume = {2017-January},
isbn = {9781538604571},
year = {2017},
}

@article{Arthur1875,
author = {W. Brian Arthur},
abstract = {At the peak of the Internet frenzy two years ago, when the Nasdaq was over 5,000 and dotcom millionaires were buying spreads in the hills above Palo Alto, it seemed that the information revolution would go on forever. Little tech companies were popping up everywhere, and small investors were reaping returns that made them feel like geniuses. Then the bubble burst. It burst, management guru Peter Drucker tells us, because "the information industry as a business wasn't going anywhere." The information revolution had been hyped, exaggerated. Neither computers nor the Internet, Drucker says, had added much to the economy. Is the information economy going nowhere? Is its revolution over? In Silicon Valley, certainly, the prospects look bleak. But history suggests that such pessimism is misplaced --that the information revolution's best days might actually lie ahead.},
journal = {Business 2.0},
title = {Is the Information Revolution Dead?},
year = {2002},
}

@inproceedings{tuohy2006evolved,
author = {Daniel R. Tuohy and W. D. Potter},
title = {An evolved neural network/HC hybrid for tablature creation in GA-based guitar arranging},
year = {2006},
booktitle = {International Computer Music Conference, ICMC 2006},
pages = {576--579},
abstract = {In this paper we describe a technique for creating guitar tablature using a neural network. Training data was parsed from an online repository of human-created tablatures. The contents of both the input layer and the set of training data have been optimized through genetic search in order to maximize the accuracy of the network. The output of the network is improved upon with a local heuristic hill-climber (HC). We implement this model in an existing system for generating guitar arrangements via genetic algorithm (GA). When compared to the original system for generating tablature, we note modest improvement in tablature quality and drastic improvements in execution time.},
}

@article{Uncini,
author = {Aurelio Uncini},
abstract = {In this paper we investigate on the use of adaptive spline neural networks, to define a new general class of physical-like sound synthesis models, based on a learning from examples strategy (in particular in this paper we study single-reed woodwind instruments). It is well known that one of the main problems in physical modeling concerns the difficulty of parameter identification and the definition of the exciter nonlinear function shape (which plays a key rule in the instrument timbre). In the proposed neural model we make use of FIR-IIR synapses followed by a Catmul-Rom spline based flexible nonlinear function whose shape can be modified by adapting its control points. This general structure can imitate an entire class of instruments by learning all the parameters (synaptic weights and spline control points) from recorded sounds. In order to obtain an efficient hardware/software implementation, the synaptic weights are constrained to be power-of-two terms while the nonlinear function can be implemented as a simple spline interpolation scheme or through a small lookup table. In order to demonstrate the effectiveness of the proposed model, experiments on a single-reed woodwind instruments have been carried out. \textcopyright 2002 Springer-Verlag Berlin Heidelberg.},
doi = {10.1007/3-540-45808-5_19},
issn = {16113349},
year = {2002},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
title = {Sound synthesis by flexible activation function recurrent neural networks},
isbn = {9783540442653},
volume = {2486 LNCS},
pages = {168--177},
keywords = {flexible activation function,physical model,power-of-two neural networks,sound synthesis,spline neural networks},
mendeley-tags = {flexible activation function,physical model,power-of-two neural networks,sound synthesis,spline neural networks},
}

@article{Yao1999,
author = {Xin Yao},
number = {9},
archiveprefix = {arXiv},
year = {1999},
isbn = {9780470287194},
issn = {00189219},
doi = {10.1109/5.784219},
pmid = {9821520},
journal = {Proceedings of the IEEE},
volume = {87},
arxivid = {1108.1530},
pages = {1423--1447},
title = {Evolving artificial neural networks},
abstract = {Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANN's) in recent years. This paper: 1) reviews different combinations between ANN's and evolutionary algorithms (EA's), including using EA's to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EA's; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANN's and EA's can lead to significantly better intelligent systems than relying on ANN's or EA's alone.},
eprint = {1108.1530},
keywords = {evolutive,seminal},
mendeley-tags = {evolutive,seminal},
}

@article{Clune2013,
author = {Jeff Clune and Jean Baptiste Mouret and Hod Lipson},
url = {http://rspb.royalsocietypublishing.org/cgi/doi/10.1098/rspb.2012.2863},
isbn = {1471-2954 (Electronic)\n0962-8452 (Linking)},
volume = {280},
eprint = {1207.2743},
year = {2013},
pages = {20122863--20122863},
arxivid = {1207.2743},
abstract = {A central biological question is how natural organisms are so evolvable (capable of quickly adapting to new environments). A key driver of evolvability is the widespread modularity of biological networks-their organization as functional, sparsely connected subunits-but there is no consensus regarding why modularity itself evolved. Although most hypotheses assume indirect selection for evolvability, here we demonstrate that the ubiquitous, direct selection pressure to reduce the cost of connections between network nodes causes the emergence of modular networks. Computational evolution experiments with selection pressures to maximize network performance and minimize connection costs yield networks that are significantly more modular and more evolvable than control experiments that only select for performance. These results will catalyse research in numerous disciplines, such as neuroscience and genetics, and enhance our ability to harness evolution for engineering purposes. \textcopyright 2013 The Authors.},
doi = {10.1098/rspb.2012.2863},
issn = {14712954},
number = {1755},
title = {The evolutionary origins of modularity},
pmid = {23363632},
journal = {Proceedings of the Royal Society B: Biological Sciences},
archiveprefix = {arXiv},
keywords = {evolution,evolvability,modularity,networks,systems biology},
mendeley-tags = {evolution,evolvability,modularity,networks,systems biology},
}

@article{balle2015density,
author = {Johannes Ball\'e and Valero Laparra and Eero P. Simoncelli},
year = {2016},
abstract = {We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. The data are linearly transformed, and each component is then normalized by a pooled activity measure, computed by ex-ponentiating a weighted sum of rectified and exponentiated components and a constant. We optimize the parameters of the full transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. The optimized transformation substantially Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than alternative methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We demonstrate the use of the model as a prior probability density that can be used to remove additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized using the same Gaussianization objective, thus offering an unsupervised method of optimizing a deep network architecture.},
eprint = {1511.06281},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
archiveprefix = {arXiv},
title = {Density modeling of images using a generalized normalization transformation},
arxivid = {1511.06281},
}

@article{Tsai2006a,
author = {Jinn Tsong Tsai and Jyh Horng Chou and Tung Kuan Liu},
number = {1},
pmid = {16526477},
title = {Tuning the structure and parameters of a neural network by using hybrid Taguchi-genetic algorithm},
doi = {10.1109/TNN.2005.860885},
abstract = {In this paper, a hybrid Taguchi-genetic algorithm (HTGA) is applied to solve the problem of tuning both network structure and parameters of a feedforward neural network. The HTGA approach is a method of combining the traditional genetic algorithm (TGA), which has a powerful global exploration capability, with the Taguchi method, which can exploit the optimum offspring. The Taguchi method is inserted between crossover and mutation operations of a TGA. Then, the systematic reasoning ability of the Taguchi method is incorporated in the crossover operations to select the better genes to achieve crossover, and consequently enhance the genetic algorithms. Therefore, the HTGA approach can be more robust, statistically sound, and quickly convergent. First, the authors evaluate the performance of the presented HTGA approach by studying some global numerical optimization problems. Then, the presented HTGA approach is effectively applied to solve three examples on forecasting the sunspot numbers, tuning the associative memory, and solving the XOR problem. The numbers of hidden nodes and the links of the feedforward neural network are chosen by increasing them from small numbers until the learning performance is good enough. As a result, a partially connected feedforward neural network can be obtained after tuning. This implies that the cost of implementation of the neural network can be reduced. In these studied problems of tuning both network structure and parameters of a feedforward neural network, there are many parameters and numerous local optima so that these studied problems are challenging enough for evaluating the performances of any proposed GA-based approaches. The computational experiments show that the presented HTGA approach can obtain better results than the existing method reported recently in the literature. \textcopyright 2006 IEEE.},
issn = {10459227},
year = {2006},
isbn = {1045-9227 (Print)\r1045-9227 (Linking)},
pages = {69--80},
volume = {17},
journal = {IEEE Transactions on Neural Networks},
keywords = {genetic algorithm (ga,neural networks (nn,taguchi method},
mendeley-tags = {genetic algorithm (ga,neural networks (nn,taguchi method},
}

@article{Graves2014,
author = {Pierre Yves Oudeyer and Frederic Kaplan},
year = {2009},
doi = {10.3389/neuro.12.006.2007},
title = {What is intrinsic motivation? A typology of computational approaches},
abstract = {Intrinsic motivation, centrally involved in spontaneous exploration and curiosity, is a crucial concept in developmental psychology. It has been argued to be a crucial mechanism for open-ended cognitive development in humans, and as such has gathered a growing interest from developmental roboticists in the recent years. The goal of this paper is threefold. First, it provides a synthesis of the different approaches of intrinsic motivation in psychology. Second, by interpreting these approaches in a computational reinforcement learning framework, we argue that they are not operational and even sometimes inconsistent. Third, we set the ground for a systematic operational study of intrinsic motivation by presenting a formal typology of possible computational approaches. This typology is partly based on existing computational models, but also presents new ways of conceptualizing intrinsic motivation. We argue that this kind of computational typology might be useful for opening new avenues for research both in psychology and developmental robotics. \textcopyright 2007 Oudeyer and Kaplan.},
arxivid = {1410.5401},
url = {http://arxiv.org/abs/1410.5401},
pages = {1--26},
isbn = {0028-0836},
number = {NOV},
journal = {Frontiers in Neurorobotics},
issn = {16625218},
archiveprefix = {arXiv},
volume = {3},
eprint = {1410.5401},
pmid = {18958277},
keywords = {other},
mendeley-tags = {other},
}

@article{Boser1992,
author = {Bernhard E. Boser and Isabelle M. Guyon and Vladimir N. Vapnik},
title = {Training algorithm for optimal margin classifiers},
url = {http://portal.acm.org/citation.cfm?doid=130385.130401},
year = {1992},
isbn = {089791497X},
journal = {Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory},
abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
pages = {144--152},
archiveprefix = {arXiv},
arxivid = {arXiv:1011.1669v3},
eprint = {arXiv:1011.1669v3},
institution = {ACM},
issn = {0-89791-497-X},
pmid = {25246403},
doi = {10.1145/130385.130401},
keywords = {seminal},
mendeley-tags = {seminal},
}

@unpublished{r16,
author = {Sebastian Ruder},
annote = {preprint},
title = {An overview of gradient descent optimization algorithms},
arxivid = {1609.04747},
url = {http://arxiv.org/abs/1609.04747},
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
archiveprefix = {arXiv},
year = {2016},
eprint = {1609.04747},
}

@article{Zen2015,
author = {Heiga Zen and Hasim Sak},
pages = {4470--4474},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
volume = {2015-August},
isbn = {9781467369978},
issn = {15206149},
doi = {10.1109/ICASSP.2015.7178816},
year = {2015},
abstract = {Long short-term memory recurrent neural networks (LSTM-RNNs) have been applied to various speech applications including acoustic modeling for statistical parametric speech synthesis. One of the concerns for applying them to text-to-speech applications is its effect on latency. To address this concern, this paper proposes a low-latency, streaming speech synthesis architecture using unidirectional LSTM-RNNs with a recurrent output layer. The use of unidirectional RNN architecture allows frame-synchronous streaming inference of output acoustic features given input linguistic features. The recurrent output layer further encourages smooth transition between acoustic features at consecutive frames. Experimental results in subjective listening tests show that the proposed architecture can synthesize natural sounding speech without requiring utterance-level batch processing.},
title = {Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis},
institution = {IEEE},
keywords = {speech synthesis},
mendeley-tags = {speech synthesis},
}

@article{Ojha2017,
author = {Varun Kumar Ojha and Ajith Abraham and V\'aclav Sn\'a\vsel},
year = {2017},
title = {Metaheuristic design of feedforward neural networks: A review of two decades of research},
arxivid = {1705.05584},
abstract = {Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN's generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN's application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era.},
doi = {10.1016/j.engappai.2017.01.013},
issn = {09521976},
archiveprefix = {arXiv},
eprint = {1705.05584},
number = {2017},
journal = {Engineering Applications of Artificial Intelligence},
pages = {97--116},
volume = {60},
keywords = {evolutive,review},
mendeley-tags = {evolutive,review},
}

@article{oord2016pixel,
author = {A\"aron Van Den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
archiveprefix = {arXiv},
arxivid = {1601.06759},
isbn = {9781510829008},
year = {2016},
title = {Pixel recurrent neural networks},
journal = {33rd International Conference on Machine Learning, ICML 2016},
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two- dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNel dataset. Samples generated from the model appear crisp, varied and globally coherent.},
eprint = {1601.06759},
pages = {2611--2620},
volume = {4},
}

@misc{Edmunds2000,
author = {Angela Edmunds and Anne Morris},
doi = {10.1016/S0268-4012(99)00051-1},
pmid = {10272},
url = {http://www.sciencedirect.com/science/article/pii/S0268401299000511},
volume = {20},
isbn = {0268-4012},
number = {1},
title = {Problem of information overload in business organizations: A review of the literature},
issn = {02684012},
pages = {17--28},
year = {2000},
booktitle = {International Journal of Information Management},
abstract = {This paper reviews the literature on the problem of information overload, with particular reference to business organizations. The literature reveals that although the problem of information overload has existed for many years, in recent years the problem has become more widely recognized and experienced. Both perceptions and the actual effects of information overload have been exacerbated by the rapid advances made in information and communication technology, although it is not clear cut as to whether the Internet has worsened or improved the situation. A theme stressed in the literature is the paradoxical situation that, although there is an abundance of information available, it is often difficult to obtain useful, relevant information when it is needed. Some solutions put forward to reduce information overload are: a reduction in the duplication of information found in the professional literature: the adoption of personal information management strategies, together with the integration of software solutions such as push technology and intelligent agents; and the provision of value-added information (filtered by software or information specialists). An emphasis is placed on technology as a tool and not the driver, while increased information literacy may provide the key to reducing information overload.},
keywords = {infoglut,information fatigue syndrome,information overload},
mendeley-tags = {infoglut,information fatigue syndrome,information overload},
}

@unpublished{z17,
author = {Ying Zhang and Mohammad Pezeshki and Phil\'emon Brakel and Saizheng Zhang and C\'esar Laurent and Yoshua Bengio and Aaron Courville},
archiveprefix = {arXiv},
arxivid = {1701.02720},
abstract = {Convolutional Neural Networks (CNNs) are effective models for reducing spectral variations and modeling spectral correlations in acoustic features for automatic speech recognition (ASR). Hybrid speech recognition systems incorporating CNNs with Hidden Markov Models/Gaussian Mixture Models (HMMs/GMMs) have achieved the state-of-the-art in various benchmarks. Meanwhile, Connectionist Temporal Classification (CTC) with Recurrent Neural Networks (RNNs), which is proposed for labeling unsegmented sequences, makes it feasible to train an 'end-to-end' speech recognition system instead of hybrid settings. However, RNNs are computationally expensive and sometimes difficult to train. In this paper, inspired by the advantages of both CNNs and the CTC approach, we propose an end-to-end speech framework for sequence labeling, by combining hierarchical CNNs with CTC directly without recurrent connections. By evaluating the approach on the TIMIT phoneme recognition task, we show that the proposed model is not only computationally efficient, but also competitive with the existing baseline systems. Moreover, we argue that CNNs have the capability to model temporal correlations with appropriate context information.},
volume = {08-12-September-2016},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
annote = {preprint},
title = {Towards end-to-end speech recognition with deep convolutional neural networks},
issn = {19909772},
year = {2016},
eprint = {1701.02720},
pages = {410--414},
doi = {10.21437/Interspeech.2016-1446},
keywords = {connectionist temporal classification,convolutional neural networks,speech recognition},
mendeley-tags = {connectionist temporal classification,convolutional neural networks,speech recognition},
}

@article{wang2017tacotron,
author = {Yuxuan Wang and R. J. Skerry-Ryan and Daisy Stanton and Yonghui Wu and Ron J. Weiss and Navdeep Jaitly and Zongheng Yang and Ying Xiao and Zhifeng Chen and Samy Bengio and Quoc Le},
doi = {10.21437/Interspeech.2017-1452},
archiveprefix = {arXiv},
volume = {2017-August},
year = {2017},
abstract = {A text-To-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-Toend generative text-To-speech model that synthesizes speech directly from characters. Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequenceto-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than samplelevel autoregressive methods.},
arxivid = {1703.10135},
issn = {19909772},
pages = {4006--4010},
title = {Tacotron: Towards end-To-end speech synthesis},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
url = {http://arxiv.org/abs/1703.10135},
eprint = {1703.10135},
keywords = {speech synthesis,state of the art},
mendeley-tags = {speech synthesis,state of the art},
}

@inproceedings{shi2016improving,
author = {Weiwei Shi and Yihong Gong and Xiaoyu Tao and Jinjun Wang and Nanning Zheng},
number = {7},
abstract = {We propose a novel method for improving performance accuracies of convolutional neural network (CNN) without the need to increase the network complexity. We accomplish the goal by applying the proposed Min-Max objective to a layer below the output layer of a CNN model in the course of training. The Min-Max objective explicitly ensures that the feature maps learned by a CNN model have the minimum within-manifold distance for each object manifold and the maximum between-manifold distances among different object manifolds. The Min-Max objective is general and able to be applied to different CNNs with insignificant increases in computation cost. Moreover, an incremental minibatch training procedure is also proposed in conjunction with the Min-Max objective to enable the handling of large-scale training data. Comprehensive experimental evaluations on several benchmark data sets with both the image classification and face verification tasks reveal that employing the proposed Min-Max objective in the training process can remarkably improve performance accuracies of a CNN model in comparison with the same model trained without using this objective.},
title = {Improving CNN performance accuracies with min-max objective},
year = {2018},
issn = {21622388},
pmid = {28613185},
booktitle = {IEEE Transactions on Neural Networks and Learning Systems},
pages = {2872--2885},
doi = {10.1109/TNNLS.2017.2705682},
volume = {29},
keywords = {convolutional neural network (cnn,face verification,image classification,incremental minibatch training procedure,min-max objective},
mendeley-tags = {convolutional neural network (cnn,face verification,image classification,incremental minibatch training procedure,min-max objective},
}

@article{Toderici2016b,
author = {George Toderici and Damien Vincent and Nick Johnston and Sung Jin Hwang and David Minnen and Joel Shor and Michele Covell},
isbn = {9781538604571},
pmid = {21655600},
doi = {10.1109/CVPR.2017.577},
title = {Full resolution image compression with recurrent neural networks},
issn = {08936080},
archiveprefix = {arXiv},
pages = {5435--5443},
url = {http://arxiv.org/abs/1608.05148},
volume = {2017-January},
abstract = {This paper presents a set of full-resolution lossy image compression methods based on neural networks. Each of the architectures we describe can provide variable compression rates during deployment without requiring retraining of the network: each network need only be trained once. All of our architectures consist of a recurrent neural network (RNN)-based encoder and decoder, a binarizer, and a neural network for entropy coding. We compare RNN types (LSTM, associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study "one-shot" versus additive reconstruction architectures and introduce a new scaled-additive framework. We compare to previous work, showing improvements of 4.3%-8.8% AUC (area under the rate-distortion curve), depending on the perceptual metric used. As far as we know, this is the first neural network architecture that is able to outperform JPEG at image compression across most bitrates on the rate-distortion curve on the Kodak dataset images, with and without the aid of entropy coding.},
arxivid = {1608.05148},
eprint = {1608.05148},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
year = {2017},
}

@article{Zagoruyko2016,
author = {Sergey Zagoruyko and Nikos Komodakis},
volume = {2016-September},
pages = {87.1--87.12},
doi = {10.5244/C.30.87},
year = {2016},
arxivid = {1605.07146},
title = {Wide Residual Networks},
url = {http://arxiv.org/abs/1605.07146},
abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR-10, CIFAR-100 and SVHN. Our code is available at https://github.com/szagoruyko/wide-residual-networks.},
archiveprefix = {arXiv},
journal = {British Machine Vision Conference 2016, BMVC 2016},
eprint = {1605.07146},
keywords = {image classification,object detection,state of the art},
mendeley-tags = {image classification,object detection,state of the art},
}

@article{Floreano2008a,
author = {Dario Floreano and Peter D\"urr and Claudio Mattiussi},
doi = {10.1007/s12065-007-0002-4},
issn = {18645909},
title = {Neuroevolution: From architectures to learning},
year = {2008},
abstract = {Artificial neural networks (ANNs) are applied to many real-world problems, ranging from pattern classification to robot control. In order to design a neural network for a particular task, the choice of an architecture (including the choice of a neuron model), and the choice of a learning algorithm have to be addressed. Evolutionary search methods can provide an automatic solution to these problems. New insights in both neuroscience and evolutionary biology have led to the development of increasingly powerful neuroevolution techniques over the last decade. This paper gives an overview of the most prominent methods for evolving ANNs with a special focus on recent advances in the synthesis of learning architectures. \textcopyright Springer-Verlag 2008.},
pages = {47--62},
journal = {Evolutionary Intelligence},
isbn = {1206500700},
number = {1},
volume = {1},
keywords = {evolutive,review},
mendeley-tags = {evolutive,review},
}

@article{Srivastava2014,
author = {Alekh Agarwal and Sah Negahban and   and Martin J. Wainwright},
isbn = {1532-4435},
title = {Noisy matrix decomposition via convex relaxation: Optimal rates in high dimensions},
abstract = {We analyze a class of estimators based on convex relaxation for solving high-dimensional matrix decomposition problems. The observations are noisy realizations of a linear transformation X of the sum of an (approximately) low rank matrix with a second matrix endowed with a complementary form of low-dimensional structure; this set-up includes many statistical models of interest, including factor analysis, multi-task regression and robust covariance estimation. We derive a general theorem that bounds the Frobenius norm error for an estimate of the pair obtained by solving a convex optimization problem that combines the nuclear norm with a general decomposable regularizer. Our results use a "spikiness" condition that is related to, but milder than, singular vector incoherence. We specialize our general result to two cases that have been studied in past work: low rank plus an entrywise sparse matrix, and low rank plus a columnwise sparse matrix. For both models, our theory yields nonasymptotic Frobenius error bounds for both deterministic and stochastic noise matrices, and applies to matrices that can be exactly or approximately low rank, and matrices that can be exactly or approximately sparse. Moreover, for the case of stochastic noise matrices and the identity observation operator, we establish matching lower bounds on the minimax error. The sharpness of our nonasymptotic predictions is confirmed by numerical simulations. \textcopyright Institute of Mathematical Statistics, 2012.},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
pages = {1171--1197},
issn = {00905364},
archiveprefix = {arXiv},
journal = {Annals of Statistics},
number = {2},
volume = {40},
year = {2012},
arxivid = {1102.4807},
keywords = {seminal},
mendeley-tags = {seminal},
}

@article{Theis2015,
author = {Lucas Theis and Matthias Bethge},
title = {Generative image modeling using spatial LSTMs},
volume = {2015-January},
arxivid = {1506.03478},
abstract = {Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multidimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.},
year = {2015},
url = {http://arxiv.org/abs/1506.03478},
eprint = {1506.03478},
journal = {Advances in Neural Information Processing Systems},
pages = {1927--1935},
issn = {10495258},
archiveprefix = {arXiv},
keywords = {image synthesis},
mendeley-tags = {image synthesis},
}

@article{Lin2013,
author = {Takuya Yoshioka and Nobutaka Ito and Marc Delcroix and Atsunori Ogawa and Keisuke Kinoshita and Masakiyo Fujimoto and Chengzhu Yu and Wojciech J. Fabian and Miquel Espi and Takuya Higuchi and Shoko Araki and Tomohiro Nakatani},
archiveprefix = {arXiv},
journal = {2015 IEEE Workshop on Automatic Speech Recognition and Understanding, ASRU 2015 - Proceedings},
pmid = {24356345},
title = {The NTT CHiME-3 system: Advances in speech enhancement and recognition for mobile multi-microphone devices},
url = {http://arxiv.org/abs/1312.4400},
year = {2016},
abstract = {CHiME-3 is a research community challenge organised in 2015 to evaluate speech recognition systems for mobile multi-microphone devices used in noisy daily environments. This paper describes NTT's CHiME-3 system, which integrates advanced speech enhancement and recognition techniques. Newly developed techniques include the use of spectral masks for acoustic beam-steering vector estimation and acoustic modelling with deep convolutional neural networks based on the «network in network» concept. In addition to these improvements, our system has several key differences from the official baseline system. The differences include multi-microphone training, dereverberation, and cross adaptation of neural networks with different architectures. The impacts that these techniques have on recognition performance are investigated. By combining these advanced techniques, our system achieves a 3.45% development error rate and a 5.83% evaluation error rate. Three simpler systems are also developed to perform evaluations with constrained set-ups.},
isbn = {9781479972913},
doi = {10.1109/ASRU.2015.7404828},
issn = {03029743},
arxivid = {1312.4400},
pages = {436--443},
eprint = {1312.4400},
keywords = {image classification},
mendeley-tags = {image classification},
}

@article{Bagozzi2006,
author = {Richard P. Bagozzi and Utpal M. Dholakia},
number = {7},
pmid = {21517591},
abstract = {We conceptualize participation in Linux user groups (LUGs) in terms of group-referent intentional actions and investigate cognitive (attitudes, perceived behavioral control, identification with the open source movement), affective (positive and negative anticipated emotions), and social (social identity) determinants of participation and its consequences on Linux-related behaviors of users. This survey-based study, conducted with 402 active LUG members representing 191 different LUGs from 23 countries and employing structural equation modeling methodology, supports the proposed model. Furthermore, we find that the Linux user's experience level moderates the extent of the LUG's social influence and its impact on the user's participation. We conclude with a consideration of the managerial and research implications of the study's findings. \textcopyright 2006 INFORMS.},
doi = {10.1287/mnsc.1060.0545},
pages = {1099--1115},
journal = {Management Science},
isbn = {0025-1909},
year = {2006},
issn = {00251909},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0545},
volume = {52},
title = {Open source software user communities: A study of participation in Linux user groups},
keywords = {anticipated emotions,linux,model of goal-directed behavior,novice versus experienced users,open source software,social identity,virtual communities,we-intentions},
mendeley-tags = {anticipated emotions,linux,model of goal-directed behavior,novice versus experienced users,open source software,social identity,virtual communities,we-intentions},
}

@article{egmont2002image,
author = {M. Egmont-Petersen and D. De Ridder and  H and H. els},
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments. \textcopyright 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
title = {Image processing with neural networks- A review},
doi = {10.1016/S0031-3203(01)00178-9},
number = {10},
volume = {35},
year = {2002},
issn = {00313203},
publisher = {Elsevier},
journal = {Pattern Recognition},
pages = {2279--2301},
keywords = {digital image processing,feature extraction,image compression,image understanding,invariant pattern recognition,neural networks,object recognition,optimization,preprocessing,segmentation},
mendeley-tags = {digital image processing,feature extraction,image compression,image understanding,invariant pattern recognition,neural networks,object recognition,optimization,preprocessing,segmentation},
}

@article{Silver2016,
author = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George Van Den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and S Dieleman and  er and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
title = {Mastering the game of Go with deep neural networks and tree search},
pmid = {26819042},
arxivid = {1610.00633},
eprint = {1610.00633},
year = {2016},
pages = {484--489},
archiveprefix = {arXiv},
url = {http://www.nature.com/doifinder/10.1038/nature16961},
volume = {529},
isbn = {1476-4687 (Electronic)\r0028-0836 (Linking)},
doi = {10.1038/nature16961},
journal = {Nature},
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
number = {7587},
issn = {14764687},
publisher = {Nature Publishing Group},
keywords = {games},
mendeley-tags = {games},
}

@article{Liao2016,
author = {Zhibin Liao and Gustavo Carneiro},
abstract = {Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets (e.g., CIFAR-10, CIFAR-100, MNIST, and SVHN). The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.},
archiveprefix = {arXiv},
journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
eprint = {1508.00330},
pages = {1--8},
title = {On the importance of normalisation layers in deep learning with piecewise linear activation units},
year = {2016},
doi = {10.1109/WACV.2016.7477624},
arxivid = {1508.00330},
institution = {IEEE},
isbn = {9781509006410},
keywords = {image classification,optimization,theory},
mendeley-tags = {image classification,optimization,theory},
}

@article{Choi2016b,
author = {Keunwoo Choi and Gyorgy Fazekas and  S and Mark ler and Kyunghyun Cho},
pages = {2392--2396},
archiveprefix = {arXiv},
url = {http://arxiv.org/abs/1609.04243},
year = {2017},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
title = {Convolutional recurrent neural networks for music classification},
abstract = {We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features. We compare CRNN with three CNN structures that have been used for music tagging while controlling the number of parameters with respect to their performance and training time per sample. Overall, we found that CRNNs show a strong performance with respect to the number of parameter and training time, indicating the effectiveness of its hybrid structure in music feature extraction and feature summarisation.},
doi = {10.1109/ICASSP.2017.7952585},
issn = {15206149},
arxivid = {1609.04243},
isbn = {9781509041176},
eprint = {1609.04243},
keywords = {convolutional neural networks,music classification,recurrent neural networks},
mendeley-tags = {convolutional neural networks,music classification,recurrent neural networks},
}

@inproceedings{kimoto1990stock,
author = {Takashi Kimoto and Kazuo Asakawa and Morio Yoda and Masakazu Takeoka},
pages = {1--6},
title = {Stock market prediction system with modular neural networks},
__markedentry = {[tesse:1]},
booktitle = {1990 IJCNN international joint conference on neural networks},
organization = {IEEE},
year = {1990},
}

@article{saad1998comparative,
author = {Emad W Saad and Danil V Prokhorov and Donald C Wunsch},
pages = {1456--1470},
title = {Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks},
__markedentry = {[tesse:1]},
journal = {IEEE Transactions on neural networks},
number = {6},
publisher = {IEEE},
year = {1998},
volume = {9},
}

@article{chen2003application,
author = {An-Sing Chen and Mark T Leung and Hazem Daouk},
pages = {901--923},
journal = {Computers \& Operations Research},
__markedentry = {[tesse:1]},
title = {Application of neural networks to an emerging financial market: forecasting and trading the Taiwan Stock Index},
publisher = {Elsevier},
volume = {30},
year = {2003},
number = {6},
}

@article{kim2003financial,
author = {Kyoung-jae Kim},
publisher = {Elsevier},
title = {Financial time series forecasting using support vector machines},
volume = {55},
number = {1-2},
year = {2003},
pages = {307--319},
journal = {Neurocomputing},
__markedentry = {[tesse:1]},
}

@article{2005HuangForecasting,
author = {Wei Huang and Yoshiteru Nakamori and Shou-Yang Wang},
title = {Forecasting stock market movement direction with support vector machine},
journal = {Computers \& Operations Research},
volume = {32},
pages = {2513--2522},
month = {oct},
year = {2005},
doi = {10.1016/j.cor.2004.03.016},
publisher = {Elsevier BV},
__markedentry = {[tesse:1]},
number = {10},
}

@article{enke2005use,
author = {David Enke and Suraphan Thawornwong},
year = {2005},
journal = {Expert Systems with applications},
number = {4},
volume = {29},
pages = {927--940},
title = {The use of data mining and neural networks for forecasting stock market returns},
publisher = {Elsevier},
__markedentry = {[tesse:1]},
}

@article{zhang2009stock,
author = {Yudong Zhang and Lenan Wu},
year = {2009},
__markedentry = {[tesse:1]},
journal = {Expert systems with applications},
publisher = {Elsevier},
volume = {36},
title = {Stock market prediction of S\&P 500 via combination of improved BCO approach and BP neural network},
pages = {8849--8854},
number = {5},
}

@article{atsalakis2009surveying,
author = {George S Atsalakis and Kimon P Valavanis},
journal = {Expert Systems with Applications},
title = {Surveying stock market forecasting techniques--Part II: Soft computing methods},
volume = {36},
publisher = {Elsevier},
year = {2009},
number = {3},
pages = {5932--5941},
__markedentry = {[tesse:1]},
}

@article{atsalakis2010surveying,
author = {George S Atsalakis and Kimon P Valavanis},
number = {1},
pages = {45--92},
__markedentry = {[tesse:1]},
title = {Surveying stock market forecasting techniques-Part I: Conventional methods},
journal = {Journal of Computational Optimization in Economics and Finance},
volume = {2},
year = {2010},
}

@article{kara2011predicting,
author = {Yakup Kara and Melek Acar Boyacioglu and \"Omer Kaan Baykan},
publisher = {Elsevier},
pages = {5311--5319},
year = {2011},
title = {Predicting direction of stock price index movement using artificial neural networks and support vector machines: The sample of the Istanbul Stock Exchange},
journal = {Expert systems with Applications},
number = {5},
__markedentry = {[tesse:1]},
volume = {38},
}

@article{guresen2011using,
author = {Erkam Guresen and Gulgun Kayakutlu and Tugrul U Daim},
__markedentry = {[tesse:1]},
year = {2011},
publisher = {Elsevier},
journal = {Expert Systems with Applications},
volume = {38},
number = {8},
pages = {10389--10397},
title = {Using artificial neural network models in stock market index prediction},
}

@article{mingers2015review,
author = {John Mingers and Loet Leydesdorff},
title = {A review of theory and practice in scientometrics},
year = {2015},
publisher = {Elsevier},
number = {1},
volume = {246},
pages = {1--19},
journal = {European journal of operational research},
}

@inproceedings{tan1995probabilistic,
author = {Hong Tan and D Prokhorov and D Wunsch},
year = {1995},
booktitle = {Proc. World Congr. Neural Networks},
title = {Probabilistic and time-delay neural-network techniques for conservative short-term stock trend prediction},
}

@article{kreesuradej1994time,
author = {W Kreesuradej and Donald C Wunsch and M Lane},
publisher = {Lawrence Erlbaum Associates},
year = {1994},
title = {Time delay neural network for small time series data sets},
}

@inproceedings{saad1996advanced,
author = {Emad W Saad and Danil V Prokhorov and Donald C Wunsch},
title = {Advanced neural network training methods for low false alarm stock trend prediction},
booktitle = {Proceedings of International Conference on Neural Networks (ICNN'96)},
volume = {4},
organization = {IEEE},
pages = {2021--2026},
year = {1996},
}

@inproceedings{zen_deep_2014,
author = {Heiga Zen and Andrew Senior},
date = {2014-05},
note = {event-place: Florence, Italy},
pages = {3844--3848},
isbn = {978-1-4799-2893-4},
url = {http://ieeexplore.ieee.org/document/6854321/},
title = {Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis},
eventtitle = {ICASSP 2014 - 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
publisher = {IEEE},
abstract = {Statistical parametric speech synthesis (SPSS) using deep neural networks (DNNs) has shown its potential to produce naturally-sounding synthesized speech. However, there are limitations in the current implementation of DNN-based acoustic modeling for speech synthesis, such as the unimodal nature of its objective function and its lack of ability to predict variances. To address these limitations, this paper investigates the use of a mixture density output layer. It can estimate full probability density functions over real-valued output features conditioned on the corresponding input features. Experimental results in objective and subjective evaluations show that the use of the mixture density output layer improves the prediction accuracy of acoustic features and the naturalness of the synthesized speech.},
doi = {10.1109/ICASSP.2014.6854321},
urldate = {2021-01-15},
file = {2014 Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis - Zen and Senior.pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2014 Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis - Zen and Senior.pdf\:application/pdf},
}

@article{lyubimov_mathematical_2016,
author = {N. A. Lyubimov and E. V. Zakharov},
title = {Mathematical model of acoustic speech production with mobile walls of the vocal tract},
doi = {10.1134/S1063771016020093},
shortjournal = {Acoust. Phys.},
urldate = {2021-01-15},
abstract = {A mathematical speech production model is considered that describes acoustic oscillation prop agation in a vocal tract with mobile walls. The wave field function satisfies the Helmholtz equation with boundary conditions of the third kind (impedance type). The impedance mode corresponds to a three parameter pendulum oscillation model. The experimental research demonstrates the nonlinear character of how the mobility of the vocal tract walls influence the spectral envelope of a speech signal.},
journaltitle = {Acoustical Physics},
volume = {62},
number = {2},
date = {2016-03},
url = {http://link.springer.com/10.1134/S1063771016020093},
pages = {225--234},
issn = {1063-7710, 1562-6865},
file = {2016 Mathematical model of acoustic speech production with mobile walls of the vocal tract - Lyubimov and Zakharov.pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2016 Mathematical model of acoustic speech production with mobile walls of the vocal tract - Lyubimov and Zakharov.pdf\:application/pdf},
}

@inproceedings{li_acoustic_2017,
author = {Bo Li and Tara N. Sainath and Arun Narayanan and Joe Caroselli and Michiel Bacchiani and Ananya Misra and Izhak Shafran and Haşim Sak and Golan Pundak and Kean Chin and Khe Chai Sim and Ron J. Weiss and Kevin W. Wilson and Ehsan Variani and Chanwoo Kim and Olivier Siohan and Mitchel Weintraub and Erik McDermott and Richard Rose and Matt Shannon},
url = {http://www.isca-speech.org/archive/Interspeech_2017/abstracts/0234.html},
doi = {10.21437/Interspeech.2017-234},
eventtitle = {Interspeech 2017},
abstract = {This paper describes the technical and system building advances made to the Google Home multichannel speech recognition system, which was launched in November 2016. Technical advances include an adaptive dereverberation frontend, the use of neural network models that do multichannel processing jointly with acoustic modeling, and Grid-LSTMs to model frequency variations. On the system level, improvements include adapting the model using Google Home speciﬁc data. We present results on a variety of multichannel sets. The combination of technical and system advances result in a reduction of WER of 8-28\% relative compared to the current production system.},
booktitle = {Interspeech 2017},
publisher = {ISCA},
title = {Acoustic Modeling for Google Home},
urldate = {2021-01-15},
pages = {399--403},
date = {2017-08-20},
file = {2017 Acoustic Modeling for Google Home - Li et al..pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2017 Acoustic Modeling for Google Home - Li et al..pdf\:application/pdf},
}

@article{maestre_creating_2019,
author = {Esteban Maestre and Gary Scavone},
title = {Creating Virtual Acoustic Replicas of Real Violins},
abstract = {We provide an overview of a current research project on measuring, modeling, and virtually recreating the sound radiation characteristics of real acoustic violins. Our general approach is based on measuring the directivity of an acoustic violin, and designing a digital ﬁlter structure that mimics the observed directivity while allowing interactive operation. The digital ﬁlter structure is fed by the electrical signal coming from a silent electric violin as played by a musician. In a hemi-anechoic chamber, we use a microphone array to characterize the frequency-dependent directivity transfer function of a real violin by exciting the bridge with an impact hammer and measuring the acoustic pressure at 4320 points on a sphere surrounding the instrument. From the input force and output pressure signals obtained from the real violin measurements, we use deconvolution to estimate 4320 impulse responses each corresponding to a radiation direction. With such impulse responses, we use State Wave Synthesis to model the observed directivity in time-varying conditions and efﬁciently render directional wavefronts in a virtual environment. We characterize the silent violin transfer function by exciting the bridge with an impact hammer and measuring the electrical signal at its output, leading to an impulse response that we use to design an inverse ﬁlter to recover the force excitation at the bridge.},
date = {2019},
pages = {7},
file = {2019 Creating Virtual Acoustic Replicas of Real Violins - Maestre and Scavone.pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2019 Creating Virtual Acoustic Replicas of Real Violins - Maestre and Scavone.pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@article{kapralova_big_nodate,
author = {Olga Kapralova and John Alex and Eugene Weinstein and Pedro Moreno and Olivier Siohan},
pages = {5},
title = {A big data approach to acoustic model training corpus selection},
abstract = {Deep neural networks (DNNs) have recently become the state of the art technology in speech recognition systems. In this paper we propose a new approach to constructing large high quality unsupervised sets to train DNN models for large vocabulary speech recognition. The core of our technique consists of two steps. We ﬁrst redecode speech logged by our production recognizer with a very accurate (and hence too slow for real-time usage) set of speech models to improve the quality of ground truth transcripts used for training alignments. Using conﬁdence scores, transcript length and transcript ﬂattening heuristics designed to cull salient utterances from three decades of speech per language, we then carefully select training data sets consisting of up to 15K hours of speech to be used to train acoustic models without any reliance on manual transcription. We show that this approach yields models with approximately 18K context dependent states that achieve 10\% relative improvement in large vocabulary dictation and voice-search systems for Brazilian Portuguese, French, Italian and Russian languages.},
file = {A big data approach to acoustic model training corpus selection - Kapralova et al..pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//A big data approach to acoustic model training corpus selection - Kapralova et al..pdf\:application/pdf},
}

@inproceedings{regnier_singing_2009,
author = {L. Regnier and G. Peeters},
isbn = {978-1-4244-2353-8},
abstract = {In this paper we investigate the problem of locating singing voice in music tracks. As opposed to most existing methods for this task, we rely on the extraction of the characteristics speciﬁc to singing voice. In our approach we suppose that the singing voice is characterized by harmonicity, formants, vibrato and tremolo. In the present study we deal only with the vibrato and tremolo characteristics. For this, we ﬁrst extract sinusoidal partials from the musical audio signal . The frequency modulation (vibrato) and amplitude modulation (tremolo) of each partial are then studied to determine if the partial corresponds to singing voice and hence the corresponding segment is supposed to contain singing voice. For this we estimate for each partial the rate (frequency of the modulations) and the extent (amplitude of modulation) of both vibrato and tremolo. A partial selection is then operated based on these values. A second criteria based on harmonicity is also introduced. Based on this, each segment can be labelled as singing or non-singing. Post-processing of the segmentation is then applied in order to remove short-duration segments. The proposed method is then evaluated on a large manually annotated test-set. The results of this evaluation are compared to the one obtained with a usual machine learning approach (MFCC and SFM modeling with GMM). The proposed method achieves very close results to the machine learning approach : 76.8\% compared to 77.4\% F-measure (frame classiﬁcation). This result is very promising, since both approaches are orthogonal and can then be combined.},
url = {http://ieeexplore.ieee.org/document/4959926/},
eventtitle = {ICASSP 2009 - 2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
pages = {1685--1688},
booktitle = {2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
doi = {10.1109/ICASSP.2009.4959926},
publisher = {IEEE},
urldate = {2021-01-15},
note = {event-place: Taipei, Taiwan},
date = {2009-04},
title = {Singing voice detection in music tracks using direct voice vibrato detection},
file = {2009 Singing voice detection in music tracks using direct voice vibrato detection - Regnier and Peeters.pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2009 Singing voice detection in music tracks using direct voice vibrato detection - Regnier and Peeters.pdf\:application/pdf},
}

@inproceedings{huang_singing-voice_2012,
author = {Po-Sen Huang and Scott Deeann Chen and Paris Smaragdis and Mark Hasegawa-Johnson},
title = {Singing-voice separation from monaural recordings using robust principal component analysis},
publisher = {IEEE},
date = {2012-03},
note = {event-place: Kyoto, Japan},
abstract = {Separating singing voices from music accompaniment is an important task in many applications, such as music information retrieval, lyric recognition and alignment. Music accompaniment can be assumed to be in a low-rank subspace, because of its repetition structure; on the other hand, singing voices can be regarded as relatively sparse within songs. In this paper, based on this assumption, we propose using robust principal component analysis for singing-voice separation from music accompaniment. Moreover, we examine the separation result by using a binary time-frequency masking method. Evaluations on the MIR-1K dataset show that this method can achieve around 1∼1.4 dB higher GNSDR compared with two state-of-the-art approaches without using prior training or requiring particular features.},
url = {http://ieeexplore.ieee.org/document/6287816/},
pages = {57--60},
booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
eventtitle = {ICASSP 2012 - 2012 IEEE International Conference on Acoustics, Speech and Signal Processing},
doi = {10.1109/ICASSP.2012.6287816},
isbn = {978-1-4673-0046-9 978-1-4673-0045-2 978-1-4673-0044-5},
urldate = {2021-01-15},
file = {2012 Singing-voice separation from monaural recordings using robust principal component analysis - Huang et al..pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2012 Singing-voice separation from monaural recordings using robust principal component analysis - Huang et al..pdf\:application/pdf},
}

@article{jarvelainen_audibility_2001,
author = {Hanna Järveläinen and Vesa Välimäki and Matti Karjalainen},
shortjournal = {Acoustics Research Letters Online},
urldate = {2021-01-15},
url = {http://asa.scitation.org/doi/10.1121/1.1374756},
journaltitle = {Acoustics Research Letters Online},
date = {2001-07},
volume = {2},
issn = {1529-7853},
title = {Audibility of the timbral effects of inharmonicity in stringed instrument tones},
doi = {10.1121/1.1374756},
pages = {79--84},
number = {3},
file = {2001 Audibility of the timbral effects of inharmonicity in stringed instrument tones - Järveläinen et al..pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2001 Audibility of the timbral effects of inharmonicity in stringed instrument tones - Järveläinen et al..pdf\:application/pdf},
keywords = {acoustics},
mendeley-tags = {acoustics},
}

@thesis{davidsson_structure-acoustic_2004,
author = {Peter Davidsson},
date = {2004},
institution = {Univ.},
shorttitle = {Structure-acoustic analysis},
location = {Lund},
type = {phdthesis},
title = {Structure-acoustic analysis: finite element modelling and reduction methods},
file = {2004 Structure-acoustic analysis finite element modelling and reduction methods - Davidsson.pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//2004 Structure-acoustic analysis finite element modelling and reduction methods - Davidsson.pdf\:application/pdf},
keywords = {test},
mendeley-tags = {test},
}

@article{kartofelev_modeling_nodate,
author = {Dmitri Kartofelev and Anatoli Stulov and Heidi-Maria Lehtonen and Vesa Va},
title = {MODELING A VIBRATING STRING TERMINATED AGAINST A BRIDGE WITH ARBITRARY GEOMETRY},
pages = {7},
file = {MODELING A VIBRATING STRING TERMINATED AGAINST A BRIDGE WITH ARBITRARY GEOMETRY - Kartofelev et al..pdf\:C/\://Users//tesse//Desktop//Files//Dropbox//BIBrep//Articles//Acoustics//MODELING A VIBRATING STRING TERMINATED AGAINST A BRIDGE WITH ARBITRARY GEOMETRY - Kartofelev et al..pdf\:application/pdf},
}

